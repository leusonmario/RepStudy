import org.junit.FixMethodOrder;
import org.junit.Test;
import org.junit.runners.MethodSorters;

@FixMethodOrder(MethodSorters.NAME_ASCENDING)
public class RegressionTest0 {

    public static boolean debug = false;

    @Test
    public void test00001() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00001");
        int int0 = org.apache.kafka.clients.consumer.ConsumerRecord.NULL_CHECKSUM;
        org.junit.Assert.assertTrue("'" + int0 + "' != '" + (-1) + "'", int0 == (-1));
    }

    @Test
    public void test00002() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00002");
        int int0 = org.apache.kafka.clients.consumer.ConsumerRecord.NULL_SIZE;
        org.junit.Assert.assertTrue("'" + int0 + "' != '" + (-1) + "'", int0 == (-1));
    }

    @Test
    public void test00003() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00003");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, java.io.Serializable> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.io.Serializable> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.io.Serializable>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00004() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00004");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.io.Serializable> serializableConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.io.Serializable>("hi!", (int) (byte) -1, (long) (byte) -1, (long) (short) 10, timestampType4, (long) 1, 10, (int) (byte) 10, (java.io.Serializable) (short) 1, (java.io.Serializable) 0);
    }

    @Test
    public void test00005() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00005");
        long long0 = org.apache.kafka.clients.consumer.ConsumerRecord.NO_TIMESTAMP;
        org.junit.Assert.assertTrue("'" + long0 + "' != '" + (-1L) + "'", long0 == (-1L));
    }

    @Test
    public void test00006() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00006");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.Object> strConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.Object> strConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.Object>(strConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00007() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00007");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long14 = strConsumerRecord13.timestamp();
        long long15 = strConsumerRecord13.checksum();
        org.apache.kafka.common.header.Headers headers17 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.Object> strConsumerRecordConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.Object>("", 1, (long) (short) 1, 0L, timestampType4, (java.lang.Long) 0L, 0, (-1), strConsumerRecord13, (java.lang.Object) 1L, headers17);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
    }

    @Test
    public void test00008() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00008");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.Comparable<java.lang.String>> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.Comparable<java.lang.String>> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.Comparable<java.lang.String>>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00009() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00009");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str22 = strConsumerRecord21.topic();
        java.lang.Class<?> wildcardClass23 = strConsumerRecord21.getClass();
        java.lang.Object obj24 = new java.lang.Object();
        org.apache.kafka.common.header.Headers headers25 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.Object> genericDeclarationConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.Object>("", (int) 'a', (long) 100, (long) (short) 1, timestampType12, (java.lang.Long) 1L, (int) (byte) 100, (int) (short) 100, (java.lang.reflect.GenericDeclaration) wildcardClass23, obj24, headers25);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "hi!" + "'", str22, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass23);
    }

    @Test
    public void test00010() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00010");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.header.Headers headers18 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 10, 52L, (long) 'a', timestampType12, (java.lang.Long) 10L, 1, (int) (short) 0, "", (java.io.Serializable) 100.0f, headers18);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test00011() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00011");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str10 = strConsumerRecord9.topic();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str21 = strConsumerRecord20.topic();
        java.lang.Class<?> wildcardClass22 = strConsumerRecord20.getClass();
        org.apache.kafka.common.header.Headers headers24 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int31 = strConsumerRecord30.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional32 = strConsumerRecord30.leaderEpoch();
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.Object> genericDeclarationConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.Object>("hi!", (int) (byte) -1, 0L, (long) 0, timestampType11, (java.lang.Long) 10L, 100, (-1), (java.lang.reflect.GenericDeclaration) wildcardClass22, (java.lang.Object) 'a', headers24, intOptional32);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "hi!" + "'", str10, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "hi!" + "'", str21, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass22);
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + (-1) + "'", int31 == (-1));
        org.junit.Assert.assertNotNull(intOptional32);
    }

    @Test
    public void test00012() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00012");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str10 = strConsumerRecord9.topic();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int23 = strConsumerRecord22.serializedValueSize();
        int int24 = strConsumerRecord22.partition();
        org.apache.kafka.common.header.Headers headers25 = strConsumerRecord22.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int32 = strConsumerRecord31.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional33 = strConsumerRecord31.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType11, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers25, intOptional33);
        java.lang.Class<?> wildcardClass35 = headers25.getClass();
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "hi!" + "'", str10, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + 100 + "'", int24 == 100);
        org.junit.Assert.assertNotNull(headers25);
        org.junit.Assert.assertTrue("'" + int32 + "' != '" + (-1) + "'", int32 == (-1));
        org.junit.Assert.assertNotNull(intOptional33);
        org.junit.Assert.assertNotNull(wildcardClass35);
    }

    @Test
    public void test00013() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00013");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.GenericDeclaration> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.GenericDeclaration> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.GenericDeclaration>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00014() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00014");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.lang.Object> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.Object> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.Object>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00015() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00015");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        java.lang.Class<?> wildcardClass11 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass11);
    }

    @Test
    public void test00016() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00016");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, java.io.Serializable> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.io.Serializable> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.io.Serializable>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00017() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00017");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00018() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00018");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str14 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int27 = strConsumerRecord26.serializedValueSize();
        int int28 = strConsumerRecord26.partition();
        org.apache.kafka.common.header.Headers headers29 = strConsumerRecord26.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType15, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers29, intOptional37);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int48 = strConsumerRecord47.serializedValueSize();
        int int49 = strConsumerRecord47.partition();
        org.apache.kafka.common.header.Headers headers50 = strConsumerRecord47.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str61 = strConsumerRecord60.topic();
        org.apache.kafka.common.record.TimestampType timestampType62 = strConsumerRecord60.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int74 = strConsumerRecord73.serializedValueSize();
        int int75 = strConsumerRecord73.partition();
        org.apache.kafka.common.header.Headers headers76 = strConsumerRecord73.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int83 = strConsumerRecord82.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional84 = strConsumerRecord82.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType62, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers76, intOptional84);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Optional<java.lang.Integer>> headerIterableConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Optional<java.lang.Integer>>("", (int) ' ', 10L, (long) 10, timestampType15, (long) (short) -1, 1, (int) '4', (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers50, intOptional84);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 100 + "'", int28 == 100);
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertTrue("'" + int48 + "' != '" + (-1) + "'", int48 == (-1));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 100 + "'", int49 == 100);
        org.junit.Assert.assertNotNull(headers50);
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "hi!" + "'", str61, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType62 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType62.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int74 + "' != '" + (-1) + "'", int74 == (-1));
        org.junit.Assert.assertTrue("'" + int75 + "' != '" + 100 + "'", int75 == 100);
        org.junit.Assert.assertNotNull(headers76);
        org.junit.Assert.assertTrue("'" + int83 + "' != '" + (-1) + "'", int83 == (-1));
        org.junit.Assert.assertNotNull(intOptional84);
    }

    @Test
    public void test00019() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00019");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, java.io.Serializable> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.io.Serializable> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.io.Serializable>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00020() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00020");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType7 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.key();
        long long10 = strConsumerRecord5.timestamp();
        long long11 = strConsumerRecord5.offset();
        java.lang.String str12 = strConsumerRecord5.toString();
        long long13 = strConsumerRecord5.checksum();
        java.lang.Class<?> wildcardClass14 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "" + "'", str9, "");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str12, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass14);
    }

    @Test
    public void test00021() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00021");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str10 = strConsumerRecord9.topic();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.header.Headers headers17 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) 'a', (long) (short) 1, (long) 'a', timestampType11, (java.lang.Long) 1L, (int) 'a', (int) '#', "", (java.io.Serializable) (short) 100, headers17);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "hi!" + "'", str10, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test00022() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00022");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Object> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Object> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Object>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00023() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00023");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        int int7 = strConsumerRecord5.partition();
        java.lang.String str8 = strConsumerRecord5.topic();
        long long9 = strConsumerRecord5.offset();
        java.io.Serializable serializable10 = strConsumerRecord5.value();
        java.lang.Class<?> wildcardClass11 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertEquals("'" + serializable10 + "' != '" + (short) 10 + "'", serializable10, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass11);
    }

    @Test
    public void test00024() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00024");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int10 = strConsumerRecord9.serializedValueSize();
        int int11 = strConsumerRecord9.partition();
        long long12 = strConsumerRecord9.offset();
        long long13 = strConsumerRecord9.offset();
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str37 = strConsumerRecord36.topic();
        org.apache.kafka.common.record.TimestampType timestampType38 = strConsumerRecord36.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int50 = strConsumerRecord49.serializedValueSize();
        int int51 = strConsumerRecord49.partition();
        org.apache.kafka.common.header.Headers headers52 = strConsumerRecord49.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int59 = strConsumerRecord58.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional60 = strConsumerRecord58.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType38, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers52, intOptional60);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int73 = strConsumerRecord72.serializedValueSize();
        int int74 = strConsumerRecord72.partition();
        org.apache.kafka.common.header.Headers headers75 = strConsumerRecord72.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType38, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers75);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) (byte) 10, (long) (short) 1, timestampType38, (long) '#', (int) (short) 10, 10, "hi!", (java.io.Serializable) ' ');
        org.apache.kafka.common.header.Headers headers83 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord89 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int90 = strConsumerRecord89.serializedValueSize();
        int int91 = strConsumerRecord89.partition();
        org.apache.kafka.common.header.Headers headers92 = strConsumerRecord89.headers();
        java.util.Optional<java.lang.Integer> intOptional93 = strConsumerRecord89.leaderEpoch();
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord94 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) -1, (long) (byte) -1, (long) 100, timestampType14, (java.lang.Long) 52L, (int) (byte) 10, 0, "", (java.io.Serializable) '#', headers83, intOptional93);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str37 + "' != '" + "hi!" + "'", str37, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType38 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType38.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + (-1) + "'", int50 == (-1));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 100 + "'", int51 == 100);
        org.junit.Assert.assertNotNull(headers52);
        org.junit.Assert.assertTrue("'" + int59 + "' != '" + (-1) + "'", int59 == (-1));
        org.junit.Assert.assertNotNull(intOptional60);
        org.junit.Assert.assertTrue("'" + int73 + "' != '" + (-1) + "'", int73 == (-1));
        org.junit.Assert.assertTrue("'" + int74 + "' != '" + 100 + "'", int74 == 100);
        org.junit.Assert.assertNotNull(headers75);
        org.junit.Assert.assertTrue("'" + int90 + "' != '" + (-1) + "'", int90 == (-1));
        org.junit.Assert.assertTrue("'" + int91 + "' != '" + 100 + "'", int91 == 100);
        org.junit.Assert.assertNotNull(headers92);
        org.junit.Assert.assertNotNull(intOptional93);
    }

    @Test
    public void test00025() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00025");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.reflect.Type> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.reflect.Type> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.reflect.Type>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00026() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00026");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType7 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.key();
        long long10 = strConsumerRecord5.timestamp();
        long long11 = strConsumerRecord5.offset();
        java.lang.String str12 = strConsumerRecord5.toString();
        long long13 = strConsumerRecord5.checksum();
        java.io.Serializable serializable14 = strConsumerRecord5.value();
        java.lang.String str15 = strConsumerRecord5.topic();
        java.lang.Class<?> wildcardClass16 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "" + "'", str9, "");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str12, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + (short) 10 + "'", serializable14, (short) 10);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass16);
    }

    @Test
    public void test00027() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00027");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.lang.String> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.String> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.String>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00028() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00028");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.String> strConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.String> strConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.String>(strConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00029() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00029");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00030() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00030");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.toString();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord5.leaderEpoch();
        long long11 = strConsumerRecord5.offset();
        java.lang.String str12 = strConsumerRecord5.topic();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
    }

    @Test
    public void test00031() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00031");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.io.Serializable> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.io.Serializable> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.io.Serializable>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00032() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00032");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, org.apache.kafka.common.header.Headers> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, org.apache.kafka.common.header.Headers> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, org.apache.kafka.common.header.Headers>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00033() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00033");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.lang.CharSequence> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.CharSequence> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.CharSequence>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00034() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00034");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Comparable<java.lang.String>> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Comparable<java.lang.String>> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Comparable<java.lang.String>>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00035() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00035");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, java.lang.reflect.Type> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.reflect.Type> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.reflect.Type>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00036() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00036");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str14 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int27 = strConsumerRecord26.serializedValueSize();
        int int28 = strConsumerRecord26.partition();
        org.apache.kafka.common.header.Headers headers29 = strConsumerRecord26.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType15, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers29, intOptional37);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int50 = strConsumerRecord49.serializedValueSize();
        int int51 = strConsumerRecord49.partition();
        org.apache.kafka.common.header.Headers headers52 = strConsumerRecord49.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType15, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers52);
        long long54 = strConsumerRecord53.offset();
        java.io.Serializable serializable55 = strConsumerRecord53.value();
        java.io.Serializable serializable56 = strConsumerRecord53.value();
        int int57 = strConsumerRecord53.partition();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 100 + "'", int28 == 100);
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + (-1) + "'", int50 == (-1));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 100 + "'", int51 == 100);
        org.junit.Assert.assertNotNull(headers52);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + 1L + "'", long54 == 1L);
        org.junit.Assert.assertEquals("'" + serializable55 + "' != '" + (-1.0d) + "'", serializable55, (-1.0d));
        org.junit.Assert.assertEquals("'" + serializable56 + "' != '" + (-1.0d) + "'", serializable56, (-1.0d));
        org.junit.Assert.assertTrue("'" + int57 + "' != '" + 10 + "'", int57 == 10);
    }

    @Test
    public void test00037() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00037");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        long long7 = strConsumerRecord5.checksum();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        long long9 = strConsumerRecord5.offset();
        long long10 = strConsumerRecord5.offset();
        int int11 = strConsumerRecord5.partition();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 52L + "'", long10 == 52L);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
    }

    @Test
    public void test00038() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00038");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.reflect.Type> strConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.reflect.Type> strConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.reflect.Type>(strConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00039() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00039");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.lang.reflect.AnnotatedElement> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.reflect.AnnotatedElement> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.reflect.AnnotatedElement>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00040() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00040");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.Comparable<java.lang.String>> strComparableConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.Comparable<java.lang.String>>("", (int) (short) 1, 100L, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
    }

    @Test
    public void test00041() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00041");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int9 = strConsumerRecord8.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord8.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str17 = strConsumerRecord16.topic();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord16.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord8, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType18);
        int int20 = strConsumerRecord8.serializedValueSize();
        java.lang.String str21 = strConsumerRecord8.key();
        java.lang.Class<?> wildcardClass22 = strConsumerRecord8.getClass();
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + (-1) + "'", int20 == (-1));
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "" + "'", str21, "");
        org.junit.Assert.assertNotNull(wildcardClass22);
    }

    @Test
    public void test00042() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00042");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.common.record.TimestampType> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.common.record.TimestampType> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.common.record.TimestampType>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00043() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00043");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, org.apache.kafka.common.record.TimestampType> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, org.apache.kafka.common.record.TimestampType> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, org.apache.kafka.common.record.TimestampType>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00044() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00044");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, org.apache.kafka.common.record.TimestampType> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, org.apache.kafka.common.record.TimestampType> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, org.apache.kafka.common.record.TimestampType>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00045() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00045");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, java.lang.reflect.AnnotatedElement> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.reflect.AnnotatedElement> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.reflect.AnnotatedElement>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00046() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00046");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.lang.Comparable<java.lang.String>> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.Comparable<java.lang.String>> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.Comparable<java.lang.String>>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00047() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00047");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType13 = strConsumerRecord12.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord12.timestampType();
        java.lang.String str15 = strConsumerRecord12.toString();
        int int16 = strConsumerRecord12.partition();
        org.apache.kafka.common.record.TimestampType timestampType17 = strConsumerRecord12.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType36 = strConsumerRecord35.timestampType();
        int int37 = strConsumerRecord35.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType38 = strConsumerRecord35.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType38, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long54 = strConsumerRecord53.timestamp();
        int int55 = strConsumerRecord53.partition();
        java.io.Serializable serializable56 = strConsumerRecord53.value();
        java.lang.Class<?> wildcardClass57 = serializable56.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long64 = strConsumerRecord63.timestamp();
        int int65 = strConsumerRecord63.partition();
        java.lang.String str66 = strConsumerRecord63.topic();
        long long67 = strConsumerRecord63.offset();
        java.lang.Class<?> wildcardClass68 = strConsumerRecord63.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration> typeConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration>("hi!", (int) (short) 0, (long) (byte) 1, 10L, timestampType38, (long) (byte) 10, (int) 'a', (int) (short) -1, (java.lang.reflect.Type) wildcardClass57, (java.lang.reflect.GenericDeclaration) wildcardClass68);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) '4', (long) (byte) 0, 1L, timestampType17, (long) (short) -1, 0, (int) (short) -1, "hi!", (java.io.Serializable) timestampType38);
        java.lang.Class<?> wildcardClass71 = timestampType38.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType78 = strConsumerRecord77.timestampType();
        int int79 = strConsumerRecord77.serializedKeySize();
        int int80 = strConsumerRecord77.partition();
        long long81 = strConsumerRecord77.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.lang.Object> annotatedElementConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.lang.Object>("", (int) (byte) 100, (long) (byte) 10, (java.lang.reflect.AnnotatedElement) wildcardClass71, (java.lang.Object) long81);
        org.junit.Assert.assertTrue("'" + timestampType13 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType13.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str15, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 100 + "'", int16 == 100);
        org.junit.Assert.assertTrue("'" + timestampType17 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType17.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType36 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType36.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + (-1) + "'", int37 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType38 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType38.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + (-1L) + "'", long54 == (-1L));
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + 100 + "'", int55 == 100);
        org.junit.Assert.assertEquals("'" + serializable56 + "' != '" + (short) 10 + "'", serializable56, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass57);
        org.junit.Assert.assertTrue("'" + long64 + "' != '" + (-1L) + "'", long64 == (-1L));
        org.junit.Assert.assertTrue("'" + int65 + "' != '" + 100 + "'", int65 == 100);
        org.junit.Assert.assertEquals("'" + str66 + "' != '" + "hi!" + "'", str66, "hi!");
        org.junit.Assert.assertTrue("'" + long67 + "' != '" + 52L + "'", long67 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass68);
        org.junit.Assert.assertNotNull(wildcardClass71);
        org.junit.Assert.assertTrue("'" + timestampType78 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType78.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int79 + "' != '" + (-1) + "'", int79 == (-1));
        org.junit.Assert.assertTrue("'" + int80 + "' != '" + 100 + "'", int80 == 100);
        org.junit.Assert.assertTrue("'" + long81 + "' != '" + (-1L) + "'", long81 == (-1L));
    }

    @Test
    public void test00048() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00048");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00049() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00049");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType26 = strConsumerRecord25.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str44 = strConsumerRecord43.topic();
        org.apache.kafka.common.record.TimestampType timestampType45 = strConsumerRecord43.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord35, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType45);
        java.lang.String str47 = strConsumerRecord35.topic();
        java.lang.Class<?> wildcardClass48 = strConsumerRecord35.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object> timestampTypeConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object>("hi!", (int) (short) 100, 1L, 100L, timestampType16, (long) (short) -1, (int) (byte) -1, (int) (byte) -1, timestampType26, (java.lang.Object) wildcardClass48);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement> charSequenceConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement>("", (int) (short) 10, (long) (byte) -1, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (java.lang.reflect.AnnotatedElement) wildcardClass48);
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType26 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType26.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertEquals("'" + str44 + "' != '" + "hi!" + "'", str44, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType45 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType45.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str47 + "' != '" + "hi!" + "'", str47, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass48);
    }

    @Test
    public void test00050() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00050");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, java.lang.String> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.String> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.String>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00051() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00051");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long19 = strConsumerRecord18.timestamp();
        int int20 = strConsumerRecord18.partition();
        org.apache.kafka.common.record.TimestampType timestampType21 = strConsumerRecord18.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord40 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str41 = strConsumerRecord40.topic();
        org.apache.kafka.common.record.TimestampType timestampType42 = strConsumerRecord40.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int54 = strConsumerRecord53.serializedValueSize();
        int int55 = strConsumerRecord53.partition();
        org.apache.kafka.common.header.Headers headers56 = strConsumerRecord53.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord62 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int63 = strConsumerRecord62.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional64 = strConsumerRecord62.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType42, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers56, intOptional64);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int77 = strConsumerRecord76.serializedValueSize();
        int int78 = strConsumerRecord76.partition();
        org.apache.kafka.common.header.Headers headers79 = strConsumerRecord76.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType42, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers79);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (short) 0, (long) '4', (long) 1, timestampType21, (java.lang.Long) 100L, (int) (byte) -1, (int) '#', "hi!", (java.io.Serializable) 10.0d, headers79);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) -1, (long) (byte) -1, (long) (-1), timestampType4, 52L, (int) (byte) -1, 0, "hi!", (java.io.Serializable) "hi!");
        java.lang.Class<?> wildcardClass83 = strConsumerRecord82.getClass();
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 100 + "'", int20 == 100);
        org.junit.Assert.assertTrue("'" + timestampType21 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType21.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str41 + "' != '" + "hi!" + "'", str41, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType42 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType42.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + (-1) + "'", int54 == (-1));
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + 100 + "'", int55 == 100);
        org.junit.Assert.assertNotNull(headers56);
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + (-1) + "'", int63 == (-1));
        org.junit.Assert.assertNotNull(intOptional64);
        org.junit.Assert.assertTrue("'" + int77 + "' != '" + (-1) + "'", int77 == (-1));
        org.junit.Assert.assertTrue("'" + int78 + "' != '" + 100 + "'", int78 == 100);
        org.junit.Assert.assertNotNull(headers79);
        org.junit.Assert.assertNotNull(wildcardClass83);
    }

    @Test
    public void test00052() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00052");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, org.apache.kafka.common.record.TimestampType> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, org.apache.kafka.common.record.TimestampType> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, org.apache.kafka.common.record.TimestampType>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00053() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00053");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, org.apache.kafka.common.header.Headers> strConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, org.apache.kafka.common.header.Headers> strConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, org.apache.kafka.common.header.Headers>(strConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00054() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00054");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, java.lang.CharSequence> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.CharSequence> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.CharSequence>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00055() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00055");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        long long10 = strConsumerRecord5.checksum();
        long long11 = strConsumerRecord5.checksum();
        int int12 = strConsumerRecord5.partition();
        java.lang.String str13 = strConsumerRecord5.topic();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
    }

    @Test
    public void test00056() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00056");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        int int9 = strConsumerRecord5.serializedValueSize();
        java.lang.String str10 = strConsumerRecord5.key();
        long long11 = strConsumerRecord5.timestamp();
        int int12 = strConsumerRecord5.serializedValueSize();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "" + "'", str10, "");
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
    }

    @Test
    public void test00057() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00057");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, java.lang.CharSequence> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.CharSequence> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.CharSequence>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00058() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00058");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 10, (long) 32, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
    }

    @Test
    public void test00059() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00059");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, org.apache.kafka.common.header.Headers> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, org.apache.kafka.common.header.Headers> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, org.apache.kafka.common.header.Headers>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00060() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00060");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.io.Serializable> strConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.io.Serializable> strConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.io.Serializable>(strConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00061() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00061");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.reflect.AnnotatedElement> strConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.reflect.AnnotatedElement> strConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.reflect.AnnotatedElement>(strConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00062() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00062");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, java.util.Optional<java.lang.Integer>> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.util.Optional<java.lang.Integer>> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.util.Optional<java.lang.Integer>>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00063() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00063");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, java.lang.String> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.String> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.String>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00064() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00064");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, java.lang.reflect.AnnotatedElement> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.reflect.AnnotatedElement> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.reflect.AnnotatedElement>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00065() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00065");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, java.util.Optional<java.lang.Integer>> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.util.Optional<java.lang.Integer>> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.util.Optional<java.lang.Integer>>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00066() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00066");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.CharSequence> strConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.CharSequence> strConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.CharSequence>(strConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00067() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00067");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int9 = strConsumerRecord8.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord8.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str17 = strConsumerRecord16.topic();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord16.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord8, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType18);
        int int20 = strConsumerRecord8.serializedValueSize();
        java.io.Serializable serializable21 = strConsumerRecord8.value();
        long long22 = strConsumerRecord8.checksum();
        java.lang.Class<?> wildcardClass23 = strConsumerRecord8.getClass();
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + (-1) + "'", int20 == (-1));
        org.junit.Assert.assertEquals("'" + serializable21 + "' != '" + (short) 10 + "'", serializable21, (short) 10);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass23);
    }

    @Test
    public void test00068() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00068");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, java.lang.Object> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.Object> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.Object>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00069() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00069");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        long long7 = strConsumerRecord5.checksum();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        int int9 = strConsumerRecord5.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord5.leaderEpoch();
        java.lang.Class<?> wildcardClass11 = intOptional10.getClass();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertNotNull(wildcardClass11);
    }

    @Test
    public void test00070() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00070");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.String> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.String> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.String>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00071() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00071");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int9 = strConsumerRecord8.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord8.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str17 = strConsumerRecord16.topic();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord16.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord8, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType18);
        java.lang.String str20 = strConsumerRecord8.topic();
        long long21 = strConsumerRecord8.offset();
        java.io.Serializable serializable22 = strConsumerRecord8.value();
        int int23 = strConsumerRecord8.partition();
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertEquals("'" + serializable22 + "' != '" + (short) 10 + "'", serializable22, (short) 10);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 100 + "'", int23 == 100);
    }

    @Test
    public void test00072() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00072");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.Iterable<org.apache.kafka.common.header.Header>> strConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.Iterable<org.apache.kafka.common.header.Header>> strConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.Iterable<org.apache.kafka.common.header.Header>>(strConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00073() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00073");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.reflect.AnnotatedElement> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.reflect.AnnotatedElement> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.reflect.AnnotatedElement>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00074() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00074");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType13 = strConsumerRecord12.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord12.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord12.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType25 = strConsumerRecord24.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int35 = strConsumerRecord34.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional36 = strConsumerRecord34.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str43 = strConsumerRecord42.topic();
        org.apache.kafka.common.record.TimestampType timestampType44 = strConsumerRecord42.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord34, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType44);
        java.lang.String str46 = strConsumerRecord34.topic();
        java.lang.Class<?> wildcardClass47 = strConsumerRecord34.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object> timestampTypeConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object>("hi!", (int) (short) 100, 1L, 100L, timestampType15, (long) (short) -1, (int) (byte) -1, (int) (byte) -1, timestampType25, (java.lang.Object) wildcardClass47);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord62 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType63 = strConsumerRecord62.timestampType();
        int int64 = strConsumerRecord62.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType65 = strConsumerRecord62.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType65, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long81 = strConsumerRecord80.timestamp();
        int int82 = strConsumerRecord80.partition();
        java.io.Serializable serializable83 = strConsumerRecord80.value();
        java.lang.Class<?> wildcardClass84 = serializable83.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord90 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long91 = strConsumerRecord90.timestamp();
        int int92 = strConsumerRecord90.partition();
        java.lang.String str93 = strConsumerRecord90.topic();
        long long94 = strConsumerRecord90.offset();
        java.lang.Class<?> wildcardClass95 = strConsumerRecord90.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration> typeConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration>("hi!", (int) (short) 0, (long) (byte) 1, 10L, timestampType65, (long) (byte) 10, (int) 'a', (int) (short) -1, (java.lang.reflect.Type) wildcardClass84, (java.lang.reflect.GenericDeclaration) wildcardClass95);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Object> timestampTypeEnumConsumerRecord97 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Object>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)", (int) '#', (long) ' ', (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType15, (java.lang.Object) (short) -1);
        org.junit.Assert.assertTrue("'" + timestampType13 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType13.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType25 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType25.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int35 + "' != '" + (-1) + "'", int35 == (-1));
        org.junit.Assert.assertNotNull(intOptional36);
        org.junit.Assert.assertEquals("'" + str43 + "' != '" + "hi!" + "'", str43, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType44 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType44.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str46 + "' != '" + "hi!" + "'", str46, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass47);
        org.junit.Assert.assertTrue("'" + timestampType63 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType63.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int64 + "' != '" + (-1) + "'", int64 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType65 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType65.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long81 + "' != '" + (-1L) + "'", long81 == (-1L));
        org.junit.Assert.assertTrue("'" + int82 + "' != '" + 100 + "'", int82 == 100);
        org.junit.Assert.assertEquals("'" + serializable83 + "' != '" + (short) 10 + "'", serializable83, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass84);
        org.junit.Assert.assertTrue("'" + long91 + "' != '" + (-1L) + "'", long91 == (-1L));
        org.junit.Assert.assertTrue("'" + int92 + "' != '" + 100 + "'", int92 == 100);
        org.junit.Assert.assertEquals("'" + str93 + "' != '" + "hi!" + "'", str93, "hi!");
        org.junit.Assert.assertTrue("'" + long94 + "' != '" + 52L + "'", long94 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass95);
    }

    @Test
    public void test00075() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00075");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00076() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00076");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType7 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.key();
        int int10 = strConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "" + "'", str9, "");
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
    }

    @Test
    public void test00077() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00077");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional7 = strConsumerRecord5.leaderEpoch();
        java.lang.String str8 = strConsumerRecord5.key();
        long long9 = strConsumerRecord5.checksum();
        int int10 = strConsumerRecord5.serializedKeySize();
        long long11 = strConsumerRecord5.timestamp();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "" + "'", str8, "");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
    }

    @Test
    public void test00078() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00078");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, java.lang.reflect.AnnotatedElement> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.reflect.AnnotatedElement> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.reflect.AnnotatedElement>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00079() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00079");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, java.lang.Object> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.Object> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.Object>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00080() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00080");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>> strConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>> strConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>>(strConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00081() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00081");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        java.lang.String str9 = strConsumerRecord5.toString();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        int int11 = strConsumerRecord5.partition();
        java.lang.String str12 = strConsumerRecord5.toString();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str12, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
    }

    @Test
    public void test00082() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00082");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.header.Headers> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.header.Headers> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.header.Headers>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00083() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00083");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, org.apache.kafka.common.record.TimestampType> strConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, org.apache.kafka.common.record.TimestampType> strConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, org.apache.kafka.common.record.TimestampType>(strConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00084() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00084");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, java.lang.reflect.AnnotatedElement> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.reflect.AnnotatedElement> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.reflect.AnnotatedElement>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00085() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00085");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        int int8 = strConsumerRecord5.partition();
        int int9 = strConsumerRecord5.partition();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord5.leaderEpoch();
        java.lang.Class<?> wildcardClass11 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 100 + "'", int8 == 100);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + 100 + "'", int9 == 100);
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertNotNull(wildcardClass11);
    }

    @Test
    public void test00086() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00086");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Object> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Object> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Object>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00087() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00087");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str18 = strConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int31 = strConsumerRecord30.serializedValueSize();
        int int32 = strConsumerRecord30.partition();
        org.apache.kafka.common.header.Headers headers33 = strConsumerRecord30.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int40 = strConsumerRecord39.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional41 = strConsumerRecord39.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType19, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers33, intOptional41);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int54 = strConsumerRecord53.serializedValueSize();
        int int55 = strConsumerRecord53.partition();
        org.apache.kafka.common.header.Headers headers56 = strConsumerRecord53.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType19, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (short) -1, (long) '4', 0L, timestampType19, (long) (byte) 10, (-1), 0, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 1.0f);
        int int64 = strConsumerRecord63.serializedValueSize();
        java.lang.String str65 = strConsumerRecord63.toString();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "hi!" + "'", str18, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + (-1) + "'", int31 == (-1));
        org.junit.Assert.assertTrue("'" + int32 + "' != '" + 100 + "'", int32 == 100);
        org.junit.Assert.assertNotNull(headers33);
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + (-1) + "'", int40 == (-1));
        org.junit.Assert.assertNotNull(intOptional41);
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + (-1) + "'", int54 == (-1));
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + 100 + "'", int55 == 100);
        org.junit.Assert.assertNotNull(headers56);
        org.junit.Assert.assertTrue("'" + int64 + "' != '" + 0 + "'", int64 == 0);
        org.junit.Assert.assertEquals("'" + str65 + "' != '" + "ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0)" + "'", str65, "ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0)");
    }

    @Test
    public void test00088() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00088");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, org.apache.kafka.common.header.Headers> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, org.apache.kafka.common.header.Headers> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, org.apache.kafka.common.header.Headers>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00089() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00089");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.util.Optional<java.lang.Integer>> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.util.Optional<java.lang.Integer>> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.util.Optional<java.lang.Integer>>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00090() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00090");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, java.lang.reflect.GenericDeclaration> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.reflect.GenericDeclaration> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.reflect.GenericDeclaration>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00091() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00091");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int13 = strConsumerRecord12.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional14 = strConsumerRecord12.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str21 = strConsumerRecord20.topic();
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord20.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord12, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType22);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) -1, 100L, (long) 10, timestampType22, 0L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 0.0f);
        long long30 = strConsumerRecord29.offset();
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertNotNull(intOptional14);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "hi!" + "'", str21, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + 100L + "'", long30 == 100L);
    }

    @Test
    public void test00092() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00092");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord17.timestampType();
        java.lang.String str21 = strConsumerRecord17.key();
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType33 = strConsumerRecord32.timestampType();
        java.lang.Class<?> wildcardClass34 = strConsumerRecord32.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType22, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass34);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int46 = strConsumerRecord45.serializedValueSize();
        int int47 = strConsumerRecord45.partition();
        long long48 = strConsumerRecord45.offset();
        java.lang.String str49 = strConsumerRecord45.key();
        org.apache.kafka.common.record.TimestampType timestampType50 = strConsumerRecord45.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str61 = strConsumerRecord60.topic();
        org.apache.kafka.common.record.TimestampType timestampType62 = strConsumerRecord60.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int74 = strConsumerRecord73.serializedValueSize();
        int int75 = strConsumerRecord73.partition();
        org.apache.kafka.common.header.Headers headers76 = strConsumerRecord73.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int83 = strConsumerRecord82.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional84 = strConsumerRecord82.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType62, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers76, intOptional84);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 97, (long) 1, (long) (short) 0, timestampType22, (java.lang.Long) 100L, (-1), 0, "hi!", (java.io.Serializable) timestampType50, headers76);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (short) 100, (long) 35, "", (java.io.Serializable) timestampType22);
        int int88 = strConsumerRecord87.partition();
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "" + "'", str21, "");
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType33 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType33.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass34);
        org.junit.Assert.assertTrue("'" + int46 + "' != '" + (-1) + "'", int46 == (-1));
        org.junit.Assert.assertTrue("'" + int47 + "' != '" + 100 + "'", int47 == 100);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + 52L + "'", long48 == 52L);
        org.junit.Assert.assertEquals("'" + str49 + "' != '" + "" + "'", str49, "");
        org.junit.Assert.assertTrue("'" + timestampType50 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType50.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "hi!" + "'", str61, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType62 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType62.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int74 + "' != '" + (-1) + "'", int74 == (-1));
        org.junit.Assert.assertTrue("'" + int75 + "' != '" + 100 + "'", int75 == 100);
        org.junit.Assert.assertNotNull(headers76);
        org.junit.Assert.assertTrue("'" + int83 + "' != '" + (-1) + "'", int83 == (-1));
        org.junit.Assert.assertNotNull(intOptional84);
        org.junit.Assert.assertTrue("'" + int88 + "' != '" + 100 + "'", int88 == 100);
    }

    @Test
    public void test00093() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00093");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00094() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00094");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int9 = strConsumerRecord8.serializedValueSize();
        int int10 = strConsumerRecord8.partition();
        long long11 = strConsumerRecord8.offset();
        long long12 = strConsumerRecord8.offset();
        org.apache.kafka.common.record.TimestampType timestampType13 = strConsumerRecord8.timestampType();
        java.io.Serializable serializable14 = strConsumerRecord8.value();
        java.lang.Class<?> wildcardClass15 = strConsumerRecord8.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType30 = strConsumerRecord29.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType31 = strConsumerRecord29.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType32 = strConsumerRecord29.timestampType();
        java.lang.String str33 = strConsumerRecord29.key();
        org.apache.kafka.common.record.TimestampType timestampType34 = strConsumerRecord29.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType45 = strConsumerRecord44.timestampType();
        java.lang.Class<?> wildcardClass46 = strConsumerRecord44.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType34, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass46);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int58 = strConsumerRecord57.serializedValueSize();
        int int59 = strConsumerRecord57.partition();
        long long60 = strConsumerRecord57.offset();
        java.lang.String str61 = strConsumerRecord57.key();
        org.apache.kafka.common.record.TimestampType timestampType62 = strConsumerRecord57.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str73 = strConsumerRecord72.topic();
        org.apache.kafka.common.record.TimestampType timestampType74 = strConsumerRecord72.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int86 = strConsumerRecord85.serializedValueSize();
        int int87 = strConsumerRecord85.partition();
        org.apache.kafka.common.header.Headers headers88 = strConsumerRecord85.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord94 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int95 = strConsumerRecord94.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional96 = strConsumerRecord94.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord97 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType74, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers88, intOptional96);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 97, (long) 1, (long) (short) 0, timestampType34, (java.lang.Long) 100L, (-1), 0, "hi!", (java.io.Serializable) timestampType62, headers88);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.io.Serializable> genericDeclarationConsumerRecord99 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.io.Serializable>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 100, NoTimestampType = 0, serialized key size = 35, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) (byte) 1, (long) (byte) 10, (java.lang.reflect.GenericDeclaration) wildcardClass15, (java.io.Serializable) 1);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 100 + "'", int10 == 100);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType13 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType13.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + (short) 10 + "'", serializable14, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass15);
        org.junit.Assert.assertTrue("'" + timestampType30 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType30.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType32 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType32.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "" + "'", str33, "");
        org.junit.Assert.assertTrue("'" + timestampType34 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType34.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType45 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType45.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass46);
        org.junit.Assert.assertTrue("'" + int58 + "' != '" + (-1) + "'", int58 == (-1));
        org.junit.Assert.assertTrue("'" + int59 + "' != '" + 100 + "'", int59 == 100);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + 52L + "'", long60 == 52L);
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "" + "'", str61, "");
        org.junit.Assert.assertTrue("'" + timestampType62 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType62.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str73 + "' != '" + "hi!" + "'", str73, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType74 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType74.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int86 + "' != '" + (-1) + "'", int86 == (-1));
        org.junit.Assert.assertTrue("'" + int87 + "' != '" + 100 + "'", int87 == 100);
        org.junit.Assert.assertNotNull(headers88);
        org.junit.Assert.assertTrue("'" + int95 + "' != '" + (-1) + "'", int95 == (-1));
        org.junit.Assert.assertNotNull(intOptional96);
    }

    @Test
    public void test00095() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00095");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> strConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> strConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(strConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00096() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00096");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, java.util.Optional<java.lang.Integer>> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.util.Optional<java.lang.Integer>> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.util.Optional<java.lang.Integer>>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00097() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00097");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord17.timestampType();
        java.lang.String str21 = strConsumerRecord17.key();
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType33 = strConsumerRecord32.timestampType();
        java.lang.Class<?> wildcardClass34 = strConsumerRecord32.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType22, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass34);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int46 = strConsumerRecord45.serializedValueSize();
        int int47 = strConsumerRecord45.partition();
        long long48 = strConsumerRecord45.offset();
        long long49 = strConsumerRecord45.offset();
        org.apache.kafka.common.record.TimestampType timestampType50 = strConsumerRecord45.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int57 = strConsumerRecord56.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional58 = strConsumerRecord56.leaderEpoch();
        java.lang.String str59 = strConsumerRecord56.key();
        org.apache.kafka.common.header.Headers headers60 = strConsumerRecord56.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> serializableConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("", (int) ' ', 0L, (long) '4', timestampType22, (java.lang.Long) 52L, (int) (short) -1, (int) (short) 10, (java.io.Serializable) 100, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType50, headers60);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType72 = strConsumerRecord71.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType73 = strConsumerRecord71.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType74 = strConsumerRecord71.timestampType();
        org.apache.kafka.common.header.Headers headers75 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int82 = strConsumerRecord81.serializedValueSize();
        int int83 = strConsumerRecord81.partition();
        long long84 = strConsumerRecord81.offset();
        long long85 = strConsumerRecord81.offset();
        org.apache.kafka.common.record.TimestampType timestampType86 = strConsumerRecord81.timestampType();
        java.lang.String str87 = strConsumerRecord81.toString();
        int int88 = strConsumerRecord81.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional89 = strConsumerRecord81.leaderEpoch();
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord90 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (short) 0, (long) (byte) 10, (long) 'a', timestampType22, (java.lang.Long) 35L, (int) (byte) 1, (int) (short) 1, "hi!", (java.io.Serializable) timestampType74, headers75, intOptional89);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "" + "'", str21, "");
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType33 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType33.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass34);
        org.junit.Assert.assertTrue("'" + int46 + "' != '" + (-1) + "'", int46 == (-1));
        org.junit.Assert.assertTrue("'" + int47 + "' != '" + 100 + "'", int47 == 100);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + 52L + "'", long48 == 52L);
        org.junit.Assert.assertTrue("'" + long49 + "' != '" + 52L + "'", long49 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType50 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType50.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int57 + "' != '" + (-1) + "'", int57 == (-1));
        org.junit.Assert.assertNotNull(intOptional58);
        org.junit.Assert.assertEquals("'" + str59 + "' != '" + "" + "'", str59, "");
        org.junit.Assert.assertNotNull(headers60);
        org.junit.Assert.assertTrue("'" + timestampType72 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType72.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType73 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType73.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType74 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType74.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int82 + "' != '" + (-1) + "'", int82 == (-1));
        org.junit.Assert.assertTrue("'" + int83 + "' != '" + 100 + "'", int83 == 100);
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + 52L + "'", long84 == 52L);
        org.junit.Assert.assertTrue("'" + long85 + "' != '" + 52L + "'", long85 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType86 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType86.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str87 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str87, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int88 + "' != '" + (-1) + "'", int88 == (-1));
        org.junit.Assert.assertNotNull(intOptional89);
    }

    @Test
    public void test00098() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00098");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType21 = strConsumerRecord20.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord20.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType23 = strConsumerRecord20.timestampType();
        java.lang.String str24 = strConsumerRecord20.key();
        org.apache.kafka.common.record.TimestampType timestampType25 = strConsumerRecord20.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType36 = strConsumerRecord35.timestampType();
        java.lang.Class<?> wildcardClass37 = strConsumerRecord35.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType25, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass37);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str49 = strConsumerRecord48.topic();
        java.lang.Class<?> wildcardClass50 = strConsumerRecord48.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) -1, 100L, (long) 0, timestampType25, (long) (short) 1, (int) '#', 0, "hi!", (java.io.Serializable) wildcardClass50);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType66 = strConsumerRecord65.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType67 = strConsumerRecord65.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType68 = strConsumerRecord65.timestampType();
        java.lang.String str69 = strConsumerRecord65.key();
        org.apache.kafka.common.record.TimestampType timestampType70 = strConsumerRecord65.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType81 = strConsumerRecord80.timestampType();
        java.lang.Class<?> wildcardClass82 = strConsumerRecord80.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType70, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass82);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement> charSequenceConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement>("", (int) (byte) 0, (long) (byte) 0, (long) (byte) 10, timestampType25, (long) (short) 100, 0, 0, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", (java.lang.reflect.AnnotatedElement) wildcardClass82);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.lang.Comparable<java.lang.String>> annotatedElementConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 10, (-1L), (java.lang.reflect.AnnotatedElement) wildcardClass82, (java.lang.Comparable<java.lang.String>) "");
        org.junit.Assert.assertTrue("'" + timestampType21 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType21.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str24 + "' != '" + "" + "'", str24, "");
        org.junit.Assert.assertTrue("'" + timestampType25 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType25.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType36 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType36.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass37);
        org.junit.Assert.assertEquals("'" + str49 + "' != '" + "hi!" + "'", str49, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass50);
        org.junit.Assert.assertTrue("'" + timestampType66 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType66.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType67 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType67.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType68 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType68.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str69 + "' != '" + "" + "'", str69, "");
        org.junit.Assert.assertTrue("'" + timestampType70 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType70.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType81 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType81.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass82);
    }

    @Test
    public void test00099() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00099");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional7 = strConsumerRecord5.leaderEpoch();
        java.lang.String str8 = strConsumerRecord5.key();
        long long9 = strConsumerRecord5.checksum();
        int int10 = strConsumerRecord5.partition();
        java.lang.String str11 = strConsumerRecord5.toString();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "" + "'", str8, "");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 100 + "'", int10 == 100);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str11, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
    }

    @Test
    public void test00100() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00100");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedKeySize();
        int int8 = strConsumerRecord5.partition();
        int int9 = strConsumerRecord5.serializedKeySize();
        java.lang.String str10 = strConsumerRecord5.key();
        int int11 = strConsumerRecord5.partition();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 100 + "'", int8 == 100);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "" + "'", str10, "");
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
    }

    @Test
    public void test00101() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00101");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00102() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00102");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.lang.String> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.String> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.String>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00103() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00103");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        java.lang.String str11 = strConsumerRecord5.toString();
        int int12 = strConsumerRecord5.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional13 = strConsumerRecord5.leaderEpoch();
        java.lang.String str14 = strConsumerRecord5.toString();
        long long15 = strConsumerRecord5.checksum();
        java.lang.Class<?> wildcardClass16 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str11, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str14, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass16);
    }

    @Test
    public void test00104() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00104");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str14 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int27 = strConsumerRecord26.serializedValueSize();
        int int28 = strConsumerRecord26.partition();
        org.apache.kafka.common.header.Headers headers29 = strConsumerRecord26.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType15, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers29, intOptional37);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int50 = strConsumerRecord49.serializedValueSize();
        int int51 = strConsumerRecord49.partition();
        org.apache.kafka.common.header.Headers headers52 = strConsumerRecord49.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType15, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers52);
        long long54 = strConsumerRecord53.offset();
        java.io.Serializable serializable55 = strConsumerRecord53.value();
        java.io.Serializable serializable56 = strConsumerRecord53.value();
        java.util.Optional<java.lang.Integer> intOptional57 = strConsumerRecord53.leaderEpoch();
        long long58 = strConsumerRecord53.offset();
        java.lang.Class<?> wildcardClass59 = strConsumerRecord53.getClass();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 100 + "'", int28 == 100);
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + (-1) + "'", int50 == (-1));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 100 + "'", int51 == 100);
        org.junit.Assert.assertNotNull(headers52);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + 1L + "'", long54 == 1L);
        org.junit.Assert.assertEquals("'" + serializable55 + "' != '" + (-1.0d) + "'", serializable55, (-1.0d));
        org.junit.Assert.assertEquals("'" + serializable56 + "' != '" + (-1.0d) + "'", serializable56, (-1.0d));
        org.junit.Assert.assertNotNull(intOptional57);
        org.junit.Assert.assertTrue("'" + long58 + "' != '" + 1L + "'", long58 == 1L);
        org.junit.Assert.assertNotNull(wildcardClass59);
    }

    @Test
    public void test00105() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00105");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        org.apache.kafka.common.header.Headers headers7 = strConsumerRecord5.headers();
        int int8 = strConsumerRecord5.serializedKeySize();
        org.apache.kafka.common.header.Headers headers9 = strConsumerRecord5.headers();
        org.apache.kafka.common.header.Headers headers10 = strConsumerRecord5.headers();
        java.lang.String str11 = strConsumerRecord5.key();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertNotNull(headers7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNotNull(headers9);
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "hi!" + "'", str11, "hi!");
    }

    @Test
    public void test00106() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00106");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        int int7 = strConsumerRecord5.partition();
        java.lang.String str8 = strConsumerRecord5.topic();
        int int9 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        int int11 = strConsumerRecord5.partition();
        long long12 = strConsumerRecord5.timestamp();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
    }

    @Test
    public void test00107() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00107");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long10 = strConsumerRecord9.timestamp();
        int int11 = strConsumerRecord9.partition();
        java.lang.String str12 = strConsumerRecord9.topic();
        long long13 = strConsumerRecord9.offset();
        java.io.Serializable serializable14 = strConsumerRecord9.value();
        java.lang.String str15 = strConsumerRecord9.topic();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType27 = strConsumerRecord26.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 0, (long) '4', (long) (byte) -1, timestampType16, (long) 10, (int) (short) 0, 0, "hi!", (java.io.Serializable) timestampType27);
        long long29 = strConsumerRecord28.timestamp();
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + (short) 10 + "'", serializable14, (short) 10);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType27 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType27.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long29 + "' != '" + (-1L) + "'", long29 == (-1L));
    }

    @Test
    public void test00108() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00108");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        java.lang.String str17 = strConsumerRecord13.key();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType29 = strConsumerRecord28.timestampType();
        java.lang.Class<?> wildcardClass30 = strConsumerRecord28.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType18, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass30);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str42 = strConsumerRecord41.topic();
        java.lang.Class<?> wildcardClass43 = strConsumerRecord41.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) -1, 100L, (long) 0, timestampType18, (long) (short) 1, (int) '#', 0, "hi!", (java.io.Serializable) wildcardClass43);
        long long45 = strConsumerRecord44.offset();
        java.lang.String str46 = strConsumerRecord44.topic();
        java.lang.Class<?> wildcardClass47 = strConsumerRecord44.getClass();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType29 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType29.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass30);
        org.junit.Assert.assertEquals("'" + str42 + "' != '" + "hi!" + "'", str42, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass43);
        org.junit.Assert.assertTrue("'" + long45 + "' != '" + 100L + "'", long45 == 100L);
        org.junit.Assert.assertEquals("'" + str46 + "' != '" + "" + "'", str46, "");
        org.junit.Assert.assertNotNull(wildcardClass47);
    }

    @Test
    public void test00109() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00109");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.lang.reflect.GenericDeclaration> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.reflect.GenericDeclaration> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.reflect.GenericDeclaration>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00110() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00110");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        long long10 = strConsumerRecord5.checksum();
        long long11 = strConsumerRecord5.timestamp();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
    }

    @Test
    public void test00111() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00111");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers10 = strConsumerRecord9.headers();
        java.io.Serializable serializable11 = strConsumerRecord9.value();
        java.lang.String str12 = strConsumerRecord9.key();
        java.lang.String str13 = strConsumerRecord9.key();
        java.lang.String str14 = strConsumerRecord9.key();
        java.util.Optional<java.lang.Integer> intOptional15 = strConsumerRecord9.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.util.Optional<java.lang.Integer>> charSequenceConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.util.Optional<java.lang.Integer>>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 100, NoTimestampType = 0, serialized key size = 35, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) (byte) -1, 52L, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0)", intOptional15);
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertEquals("'" + serializable11 + "' != '" + (short) 0 + "'", serializable11, (short) 0);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertNotNull(intOptional15);
    }

    @Test
    public void test00112() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00112");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.reflect.Type> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.reflect.Type> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.reflect.Type>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00113() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00113");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        java.io.Serializable serializable7 = strConsumerRecord5.value();
        java.lang.String str8 = strConsumerRecord5.key();
        int int9 = strConsumerRecord5.serializedValueSize();
        java.lang.String str10 = strConsumerRecord5.key();
        org.apache.kafka.common.header.Headers headers11 = strConsumerRecord5.headers();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertEquals("'" + serializable7 + "' != '" + (short) 0 + "'", serializable7, (short) 0);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "hi!" + "'", str10, "hi!");
        org.junit.Assert.assertNotNull(headers11);
    }

    @Test
    public void test00114() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00114");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, java.lang.Comparable<java.lang.String>> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.Comparable<java.lang.String>> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.Comparable<java.lang.String>>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00115() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00115");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        java.lang.String str17 = strConsumerRecord13.key();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int40 = strConsumerRecord39.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional41 = strConsumerRecord39.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str48 = strConsumerRecord47.topic();
        org.apache.kafka.common.record.TimestampType timestampType49 = strConsumerRecord47.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord39, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType49);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) -1, 100L, (long) 10, timestampType49, 0L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 0.0f);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType66 = strConsumerRecord65.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType67 = strConsumerRecord65.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType68 = strConsumerRecord65.timestampType();
        java.lang.Object obj69 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object> timestampTypeConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object>("", 0, (long) (byte) 100, (long) (byte) -1, timestampType49, (long) (byte) 100, (int) (short) 10, (int) (short) -1, timestampType68, obj69);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long77 = strConsumerRecord76.timestamp();
        long long78 = strConsumerRecord76.checksum();
        long long79 = strConsumerRecord76.timestamp();
        org.apache.kafka.common.header.Headers headers80 = strConsumerRecord76.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int87 = strConsumerRecord86.serializedValueSize();
        int int88 = strConsumerRecord86.partition();
        int int89 = strConsumerRecord86.partition();
        int int90 = strConsumerRecord86.partition();
        java.util.Optional<java.lang.Integer> intOptional91 = strConsumerRecord86.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord92 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) (byte) 0, 10L, 52L, timestampType18, (java.lang.Long) 100L, (int) (short) 100, 100, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (java.io.Serializable) "", headers80, intOptional91);
        java.util.Optional<java.lang.Integer> intOptional96 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.String> intOptionalConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", (int) (short) 1, (long) 52, 10L, timestampType18, (long) 52, 0, 32, intOptional96, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = null)");
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + (-1) + "'", int40 == (-1));
        org.junit.Assert.assertNotNull(intOptional41);
        org.junit.Assert.assertEquals("'" + str48 + "' != '" + "hi!" + "'", str48, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType49 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType49.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType66 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType66.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType67 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType67.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType68 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType68.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long77 + "' != '" + (-1L) + "'", long77 == (-1L));
        org.junit.Assert.assertTrue("'" + long78 + "' != '" + (-1L) + "'", long78 == (-1L));
        org.junit.Assert.assertTrue("'" + long79 + "' != '" + (-1L) + "'", long79 == (-1L));
        org.junit.Assert.assertNotNull(headers80);
        org.junit.Assert.assertTrue("'" + int87 + "' != '" + (-1) + "'", int87 == (-1));
        org.junit.Assert.assertTrue("'" + int88 + "' != '" + 100 + "'", int88 == 100);
        org.junit.Assert.assertTrue("'" + int89 + "' != '" + 100 + "'", int89 == 100);
        org.junit.Assert.assertTrue("'" + int90 + "' != '" + 100 + "'", int90 == 100);
        org.junit.Assert.assertNotNull(intOptional91);
    }

    @Test
    public void test00116() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00116");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, java.lang.reflect.GenericDeclaration> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.reflect.GenericDeclaration> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.reflect.GenericDeclaration>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00117() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00117");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        long long7 = strConsumerRecord5.offset();
        long long8 = strConsumerRecord5.offset();
        java.lang.String str9 = strConsumerRecord5.key();
        int int10 = strConsumerRecord5.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord5.timestampType();
        int int12 = strConsumerRecord5.serializedValueSize();
        long long13 = strConsumerRecord5.offset();
        java.lang.Class<?> wildcardClass14 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + 52L + "'", long7 == 52L);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "" + "'", str9, "");
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass14);
    }

    @Test
    public void test00118() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00118");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        int int7 = strConsumerRecord5.partition();
        java.io.Serializable serializable8 = strConsumerRecord5.value();
        int int9 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        int int11 = strConsumerRecord5.partition();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + serializable8 + "' != '" + (short) 10 + "'", serializable8, (short) 10);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
    }

    @Test
    public void test00119() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00119");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.serializedValueSize();
        long long8 = strConsumerRecord5.offset();
        java.lang.String str9 = strConsumerRecord5.topic();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "hi!" + "'", str9, "hi!");
    }

    @Test
    public void test00120() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00120");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00121() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00121");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long10 = strConsumerRecord9.timestamp();
        int int11 = strConsumerRecord9.partition();
        java.lang.String str12 = strConsumerRecord9.topic();
        long long13 = strConsumerRecord9.offset();
        java.io.Serializable serializable14 = strConsumerRecord9.value();
        org.apache.kafka.common.header.Headers headers15 = strConsumerRecord9.headers();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int26 = strConsumerRecord25.serializedValueSize();
        int int27 = strConsumerRecord25.serializedValueSize();
        long long28 = strConsumerRecord25.offset();
        java.lang.String str29 = strConsumerRecord25.key();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        int int37 = strConsumerRecord35.partition();
        java.lang.String str38 = strConsumerRecord35.topic();
        org.apache.kafka.common.record.TimestampType timestampType39 = strConsumerRecord35.timestampType();
        org.apache.kafka.common.header.Headers headers40 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> strConsumerRecordConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", 10, (long) 1, (long) 'a', timestampType16, (java.lang.Long) 52L, 0, (int) (short) 1, strConsumerRecord25, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType39, headers40);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + (short) 10 + "'", serializable14, (short) 10);
        org.junit.Assert.assertNotNull(headers15);
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int26 + "' != '" + (-1) + "'", int26 == (-1));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + long28 + "' != '" + 52L + "'", long28 == 52L);
        org.junit.Assert.assertEquals("'" + str29 + "' != '" + "" + "'", str29, "");
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + 100 + "'", int37 == 100);
        org.junit.Assert.assertEquals("'" + str38 + "' != '" + "hi!" + "'", str38, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType39 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType39.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test00122() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00122");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, java.util.Optional<java.lang.Integer>> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.util.Optional<java.lang.Integer>> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.util.Optional<java.lang.Integer>>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00123() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00123");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long10 = strConsumerRecord9.timestamp();
        int int11 = strConsumerRecord9.partition();
        java.lang.String str12 = strConsumerRecord9.topic();
        int int13 = strConsumerRecord9.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int26 = strConsumerRecord25.serializedValueSize();
        long long27 = strConsumerRecord25.timestamp();
        org.apache.kafka.common.header.Headers headers28 = strConsumerRecord25.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType35 = strConsumerRecord34.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType36 = strConsumerRecord34.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType37 = strConsumerRecord34.timestampType();
        java.lang.String str38 = strConsumerRecord34.key();
        long long39 = strConsumerRecord34.timestamp();
        long long40 = strConsumerRecord34.offset();
        java.lang.String str41 = strConsumerRecord34.toString();
        long long42 = strConsumerRecord34.checksum();
        java.io.Serializable serializable43 = strConsumerRecord34.value();
        int int44 = strConsumerRecord34.partition();
        java.util.Optional<java.lang.Integer> intOptional45 = strConsumerRecord34.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (int) (byte) 0, (long) '#', (long) ' ', timestampType14, (java.lang.Long) (-1L), (int) ' ', (int) (short) 1, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", (java.io.Serializable) 10, headers28, intOptional45);
        java.lang.Class<?> wildcardClass47 = headers28.getClass();
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int26 + "' != '" + (-1) + "'", int26 == (-1));
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + (-1L) + "'", long27 == (-1L));
        org.junit.Assert.assertNotNull(headers28);
        org.junit.Assert.assertTrue("'" + timestampType35 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType35.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType36 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType36.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType37 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType37.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str38 + "' != '" + "" + "'", str38, "");
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + (-1L) + "'", long39 == (-1L));
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + 52L + "'", long40 == 52L);
        org.junit.Assert.assertEquals("'" + str41 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str41, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long42 + "' != '" + (-1L) + "'", long42 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable43 + "' != '" + (short) 10 + "'", serializable43, (short) 10);
        org.junit.Assert.assertTrue("'" + int44 + "' != '" + 100 + "'", int44 == 100);
        org.junit.Assert.assertNotNull(intOptional45);
        org.junit.Assert.assertNotNull(wildcardClass47);
    }

    @Test
    public void test00124() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00124");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, java.lang.Object> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.Object> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.Object>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00125() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00125");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord17.timestampType();
        java.lang.String str21 = strConsumerRecord17.key();
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType33 = strConsumerRecord32.timestampType();
        java.lang.Class<?> wildcardClass34 = strConsumerRecord32.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType22, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass34);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int46 = strConsumerRecord45.serializedValueSize();
        int int47 = strConsumerRecord45.partition();
        long long48 = strConsumerRecord45.offset();
        java.lang.String str49 = strConsumerRecord45.key();
        org.apache.kafka.common.record.TimestampType timestampType50 = strConsumerRecord45.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str61 = strConsumerRecord60.topic();
        org.apache.kafka.common.record.TimestampType timestampType62 = strConsumerRecord60.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int74 = strConsumerRecord73.serializedValueSize();
        int int75 = strConsumerRecord73.partition();
        org.apache.kafka.common.header.Headers headers76 = strConsumerRecord73.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int83 = strConsumerRecord82.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional84 = strConsumerRecord82.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType62, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers76, intOptional84);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 97, (long) 1, (long) (short) 0, timestampType22, (java.lang.Long) 100L, (-1), 0, "hi!", (java.io.Serializable) timestampType50, headers76);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (short) 100, (long) 35, "", (java.io.Serializable) timestampType22);
        java.lang.Class<?> wildcardClass88 = strConsumerRecord87.getClass();
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "" + "'", str21, "");
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType33 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType33.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass34);
        org.junit.Assert.assertTrue("'" + int46 + "' != '" + (-1) + "'", int46 == (-1));
        org.junit.Assert.assertTrue("'" + int47 + "' != '" + 100 + "'", int47 == 100);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + 52L + "'", long48 == 52L);
        org.junit.Assert.assertEquals("'" + str49 + "' != '" + "" + "'", str49, "");
        org.junit.Assert.assertTrue("'" + timestampType50 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType50.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "hi!" + "'", str61, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType62 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType62.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int74 + "' != '" + (-1) + "'", int74 == (-1));
        org.junit.Assert.assertTrue("'" + int75 + "' != '" + 100 + "'", int75 == 100);
        org.junit.Assert.assertNotNull(headers76);
        org.junit.Assert.assertTrue("'" + int83 + "' != '" + (-1) + "'", int83 == (-1));
        org.junit.Assert.assertNotNull(intOptional84);
        org.junit.Assert.assertNotNull(wildcardClass88);
    }

    @Test
    public void test00126() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00126");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.timestamp();
        int int10 = strConsumerRecord5.serializedKeySize();
        java.lang.String str11 = strConsumerRecord5.key();
        org.apache.kafka.common.header.Headers headers12 = strConsumerRecord5.headers();
        java.lang.String str13 = strConsumerRecord5.toString();
        long long14 = strConsumerRecord5.offset();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str13, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
    }

    @Test
    public void test00127() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00127");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType30 = strConsumerRecord29.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int40 = strConsumerRecord39.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional41 = strConsumerRecord39.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str48 = strConsumerRecord47.topic();
        org.apache.kafka.common.record.TimestampType timestampType49 = strConsumerRecord47.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord39, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType49);
        java.lang.String str51 = strConsumerRecord39.topic();
        java.lang.Class<?> wildcardClass52 = strConsumerRecord39.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object> timestampTypeConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object>("hi!", (int) (short) 100, 1L, 100L, timestampType20, (long) (short) -1, (int) (byte) -1, (int) (byte) -1, timestampType30, (java.lang.Object) wildcardClass52);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) -1, (long) '#', "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass52);
        java.io.Serializable serializable55 = strConsumerRecord54.value();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)", (int) (short) -1, (long) '#', "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", serializable55);
        int int57 = strConsumerRecord56.serializedKeySize();
        org.apache.kafka.common.header.Headers headers58 = strConsumerRecord56.headers();
        long long59 = strConsumerRecord56.timestamp();
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType30 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType30.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + (-1) + "'", int40 == (-1));
        org.junit.Assert.assertNotNull(intOptional41);
        org.junit.Assert.assertEquals("'" + str48 + "' != '" + "hi!" + "'", str48, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType49 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType49.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str51 + "' != '" + "hi!" + "'", str51, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass52);
        org.junit.Assert.assertNotNull(serializable55);
        org.junit.Assert.assertTrue("'" + int57 + "' != '" + (-1) + "'", int57 == (-1));
        org.junit.Assert.assertNotNull(headers58);
        org.junit.Assert.assertTrue("'" + long59 + "' != '" + (-1L) + "'", long59 == (-1L));
    }

    @Test
    public void test00128() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00128");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        java.lang.String str9 = strConsumerRecord5.toString();
        java.io.Serializable serializable10 = strConsumerRecord5.value();
        org.apache.kafka.common.header.Headers headers11 = strConsumerRecord5.headers();
        java.lang.Class<?> wildcardClass12 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + serializable10 + "' != '" + (short) 10 + "'", serializable10, (short) 10);
        org.junit.Assert.assertNotNull(headers11);
        org.junit.Assert.assertNotNull(wildcardClass12);
    }

    @Test
    public void test00129() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00129");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType17 = strConsumerRecord16.timestampType();
        int int18 = strConsumerRecord16.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord16.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType19, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) (short) 10, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", (java.io.Serializable) "");
        java.lang.String str27 = strConsumerRecord26.key();
        java.util.Optional<java.lang.Integer> intOptional28 = strConsumerRecord26.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType39 = strConsumerRecord38.timestampType();
        int int40 = strConsumerRecord38.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType41 = strConsumerRecord38.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", 1, 52L, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (java.io.Serializable) timestampType41);
        org.apache.kafka.common.record.TimestampType timestampType43 = strConsumerRecord42.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType> intOptionalConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType>("hi!", (-1), (long) (byte) 100, intOptional28, timestampType43);
        java.lang.Class<?> wildcardClass45 = timestampType43.getClass();
        org.junit.Assert.assertTrue("'" + timestampType17 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType17.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + (-1) + "'", int18 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str27 + "' != '" + "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)" + "'", str27, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)");
        org.junit.Assert.assertNotNull(intOptional28);
        org.junit.Assert.assertTrue("'" + timestampType39 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType39.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + (-1) + "'", int40 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType41 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType41.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType43 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType43.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass45);
    }

    @Test
    public void test00130() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00130");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        long long7 = strConsumerRecord5.checksum();
        long long8 = strConsumerRecord5.timestamp();
        java.lang.String str9 = strConsumerRecord5.topic();
        long long10 = strConsumerRecord5.timestamp();
        java.io.Serializable serializable11 = strConsumerRecord5.value();
        java.lang.String str12 = strConsumerRecord5.key();
        java.lang.String str13 = strConsumerRecord5.topic();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + (-1L) + "'", long8 == (-1L));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "hi!" + "'", str9, "hi!");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable11 + "' != '" + (short) 10 + "'", serializable11, (short) 10);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "" + "'", str12, "");
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
    }

    @Test
    public void test00131() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00131");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str22 = strConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = strConsumerRecord21.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int35 = strConsumerRecord34.serializedValueSize();
        int int36 = strConsumerRecord34.partition();
        org.apache.kafka.common.header.Headers headers37 = strConsumerRecord34.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int44 = strConsumerRecord43.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional45 = strConsumerRecord43.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType23, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers37, intOptional45);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int58 = strConsumerRecord57.serializedValueSize();
        int int59 = strConsumerRecord57.partition();
        org.apache.kafka.common.header.Headers headers60 = strConsumerRecord57.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType23, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers60);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (short) -1, (long) '4', 0L, timestampType23, (long) (byte) 10, (-1), 0, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 1.0f);
        int int68 = strConsumerRecord67.serializedValueSize();
        java.lang.Class<?> wildcardClass69 = strConsumerRecord67.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.io.Serializable> charSequenceConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 0, (long) 35, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (java.io.Serializable) wildcardClass69);
        java.lang.Class<?> wildcardClass71 = charSequenceConsumerRecord70.getClass();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "hi!" + "'", str22, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int35 + "' != '" + (-1) + "'", int35 == (-1));
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + 100 + "'", int36 == 100);
        org.junit.Assert.assertNotNull(headers37);
        org.junit.Assert.assertTrue("'" + int44 + "' != '" + (-1) + "'", int44 == (-1));
        org.junit.Assert.assertNotNull(intOptional45);
        org.junit.Assert.assertTrue("'" + int58 + "' != '" + (-1) + "'", int58 == (-1));
        org.junit.Assert.assertTrue("'" + int59 + "' != '" + 100 + "'", int59 == 100);
        org.junit.Assert.assertNotNull(headers60);
        org.junit.Assert.assertTrue("'" + int68 + "' != '" + 0 + "'", int68 == 0);
        org.junit.Assert.assertNotNull(wildcardClass69);
        org.junit.Assert.assertNotNull(wildcardClass71);
    }

    @Test
    public void test00132() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00132");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00133() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00133");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.reflect.AnnotatedElement> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.reflect.AnnotatedElement> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.reflect.AnnotatedElement>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00134() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00134");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.Type> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.Type> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.Type>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00135() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00135");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.lang.reflect.GenericDeclaration> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.reflect.GenericDeclaration> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.reflect.GenericDeclaration>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00136() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00136");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long14 = strConsumerRecord13.timestamp();
        int int15 = strConsumerRecord13.partition();
        java.lang.String str16 = strConsumerRecord13.topic();
        long long17 = strConsumerRecord13.offset();
        java.io.Serializable serializable18 = strConsumerRecord13.value();
        java.lang.String str19 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType31 = strConsumerRecord30.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 0, (long) '4', (long) (byte) -1, timestampType20, (long) 10, (int) (short) 0, 0, "hi!", (java.io.Serializable) timestampType31);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType47 = strConsumerRecord46.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType48 = strConsumerRecord46.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType49 = strConsumerRecord46.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType59 = strConsumerRecord58.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int69 = strConsumerRecord68.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional70 = strConsumerRecord68.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str77 = strConsumerRecord76.topic();
        org.apache.kafka.common.record.TimestampType timestampType78 = strConsumerRecord76.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord68, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType78);
        java.lang.String str80 = strConsumerRecord68.topic();
        java.lang.Class<?> wildcardClass81 = strConsumerRecord68.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object> timestampTypeConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object>("hi!", (int) (short) 100, 1L, 100L, timestampType49, (long) (short) -1, (int) (byte) -1, (int) (byte) -1, timestampType59, (java.lang.Object) wildcardClass81);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 1, (long) (-1), 100L, timestampType20, (long) 1, (int) (byte) 1, 0, "", (java.io.Serializable) timestampType49);
        long long84 = strConsumerRecord83.checksum();
        org.apache.kafka.common.header.Headers headers85 = strConsumerRecord83.headers();
        java.io.Serializable serializable86 = strConsumerRecord83.value();
        java.lang.String str87 = strConsumerRecord83.key();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "hi!" + "'", str16, "hi!");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertEquals("'" + serializable18 + "' != '" + (short) 10 + "'", serializable18, (short) 10);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType47 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType47.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType48 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType48.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType49 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType49.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType59 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType59.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int69 + "' != '" + (-1) + "'", int69 == (-1));
        org.junit.Assert.assertNotNull(intOptional70);
        org.junit.Assert.assertEquals("'" + str77 + "' != '" + "hi!" + "'", str77, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType78 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType78.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "hi!" + "'", str80, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass81);
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + 1L + "'", long84 == 1L);
        org.junit.Assert.assertNotNull(headers85);
        org.junit.Assert.assertTrue("'" + serializable86 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", serializable86.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str87 + "' != '" + "" + "'", str87, "");
    }

    @Test
    public void test00137() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00137");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, java.lang.reflect.Type> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.reflect.Type> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.reflect.Type>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00138() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00138");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, java.lang.CharSequence> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.CharSequence> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.CharSequence>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00139() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00139");
        java.io.Serializable serializable4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", (int) (byte) -1, 35L, "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)", serializable4);
        java.lang.String str6 = strConsumerRecord5.key();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)" + "'", str6, "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)");
    }

    @Test
    public void test00140() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00140");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        org.apache.kafka.common.header.Headers headers10 = strConsumerRecord5.headers();
        long long11 = strConsumerRecord5.checksum();
        int int12 = strConsumerRecord5.serializedKeySize();
        int int13 = strConsumerRecord5.serializedKeySize();
        java.lang.String str14 = strConsumerRecord5.key();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
    }

    @Test
    public void test00141() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00141");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.io.Serializable> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.io.Serializable> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.io.Serializable>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00142() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00142");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord9.timestampType();
        java.lang.String str13 = strConsumerRecord9.key();
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers26 = strConsumerRecord25.headers();
        org.apache.kafka.common.header.Headers headers27 = strConsumerRecord25.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int37 = strConsumerRecord36.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional38 = strConsumerRecord36.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str45 = strConsumerRecord44.topic();
        org.apache.kafka.common.record.TimestampType timestampType46 = strConsumerRecord44.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord36, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType46);
        int int48 = strConsumerRecord36.serializedValueSize();
        java.lang.String str49 = strConsumerRecord36.key();
        java.lang.String str50 = strConsumerRecord36.key();
        java.util.Optional<java.lang.Integer> intOptional51 = strConsumerRecord36.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) ' ', (long) (byte) 100, timestampType14, (java.lang.Long) 0L, 0, (int) (short) -1, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", (java.io.Serializable) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", headers27, intOptional51);
        org.apache.kafka.common.record.TimestampType timestampType53 = strConsumerRecord52.timestampType();
        java.lang.Class<?> wildcardClass54 = strConsumerRecord52.getClass();
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers26);
        org.junit.Assert.assertNotNull(headers27);
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + (-1) + "'", int37 == (-1));
        org.junit.Assert.assertNotNull(intOptional38);
        org.junit.Assert.assertEquals("'" + str45 + "' != '" + "hi!" + "'", str45, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType46 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType46.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int48 + "' != '" + (-1) + "'", int48 == (-1));
        org.junit.Assert.assertEquals("'" + str49 + "' != '" + "" + "'", str49, "");
        org.junit.Assert.assertEquals("'" + str50 + "' != '" + "" + "'", str50, "");
        org.junit.Assert.assertNotNull(intOptional51);
        org.junit.Assert.assertTrue("'" + timestampType53 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType53.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass54);
    }

    @Test
    public void test00143() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00143");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        long long7 = strConsumerRecord5.checksum();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType9 = strConsumerRecord5.timestampType();
        long long10 = strConsumerRecord5.offset();
        int int11 = strConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertTrue("'" + timestampType9 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType9.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 52L + "'", long10 == 52L);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
    }

    @Test
    public void test00144() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00144");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, org.apache.kafka.common.header.Headers> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, org.apache.kafka.common.header.Headers> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, org.apache.kafka.common.header.Headers>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00145() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00145");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.checksum();
        org.apache.kafka.common.header.Headers headers10 = strConsumerRecord5.headers();
        int int11 = strConsumerRecord5.serializedKeySize();
        int int12 = strConsumerRecord5.serializedValueSize();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
    }

    @Test
    public void test00146() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00146");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        int int11 = strConsumerRecord9.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.header.Headers headers18 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str29 = strConsumerRecord28.topic();
        org.apache.kafka.common.record.TimestampType timestampType30 = strConsumerRecord28.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord40 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType41 = strConsumerRecord40.timestampType();
        int int42 = strConsumerRecord40.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType43 = strConsumerRecord40.timestampType();
        java.lang.String str44 = strConsumerRecord40.toString();
        java.util.Optional<java.lang.Integer> intOptional45 = strConsumerRecord40.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType46 = strConsumerRecord40.timestampType();
        java.lang.Class<?> wildcardClass47 = timestampType46.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int57 = strConsumerRecord56.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional58 = strConsumerRecord56.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str65 = strConsumerRecord64.topic();
        org.apache.kafka.common.record.TimestampType timestampType66 = strConsumerRecord64.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord56, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType66);
        org.apache.kafka.common.header.Headers headers68 = strConsumerRecord56.headers();
        org.apache.kafka.common.header.Headers headers69 = strConsumerRecord56.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int79 = strConsumerRecord78.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional80 = strConsumerRecord78.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str87 = strConsumerRecord86.topic();
        org.apache.kafka.common.record.TimestampType timestampType88 = strConsumerRecord86.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord89 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord78, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType88);
        java.lang.String str90 = strConsumerRecord78.topic();
        long long91 = strConsumerRecord78.offset();
        long long92 = strConsumerRecord78.offset();
        java.lang.String str93 = strConsumerRecord78.toString();
        java.lang.String str94 = strConsumerRecord78.key();
        long long95 = strConsumerRecord78.checksum();
        org.apache.kafka.common.header.Headers headers96 = strConsumerRecord78.headers();
        java.util.Optional<java.lang.Integer> intOptional97 = strConsumerRecord78.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0)", 10, 1L, 100L, timestampType30, (java.lang.Long) 0L, 0, (int) (byte) 10, "ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0)", (java.io.Serializable) wildcardClass47, headers69, intOptional97);
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord99 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (short) -1, 10L, 100L, timestampType12, (java.lang.Long) 52L, 0, (int) ' ', (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0), partition = 10, leaderEpoch = null, offset = 100, NoTimestampType = 32, serialized key size = -1, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = hi!)", (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)", headers18, intOptional97);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str29 + "' != '" + "hi!" + "'", str29, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType30 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType30.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType41 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType41.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int42 + "' != '" + (-1) + "'", int42 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType43 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType43.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str44 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str44, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional45);
        org.junit.Assert.assertTrue("'" + timestampType46 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType46.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass47);
        org.junit.Assert.assertTrue("'" + int57 + "' != '" + (-1) + "'", int57 == (-1));
        org.junit.Assert.assertNotNull(intOptional58);
        org.junit.Assert.assertEquals("'" + str65 + "' != '" + "hi!" + "'", str65, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType66 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType66.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers68);
        org.junit.Assert.assertNotNull(headers69);
        org.junit.Assert.assertTrue("'" + int79 + "' != '" + (-1) + "'", int79 == (-1));
        org.junit.Assert.assertNotNull(intOptional80);
        org.junit.Assert.assertEquals("'" + str87 + "' != '" + "hi!" + "'", str87, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType88 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType88.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str90 + "' != '" + "hi!" + "'", str90, "hi!");
        org.junit.Assert.assertTrue("'" + long91 + "' != '" + 52L + "'", long91 == 52L);
        org.junit.Assert.assertTrue("'" + long92 + "' != '" + 52L + "'", long92 == 52L);
        org.junit.Assert.assertEquals("'" + str93 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str93, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + str94 + "' != '" + "" + "'", str94, "");
        org.junit.Assert.assertTrue("'" + long95 + "' != '" + (-1L) + "'", long95 == (-1L));
        org.junit.Assert.assertNotNull(headers96);
        org.junit.Assert.assertNotNull(intOptional97);
    }

    @Test
    public void test00147() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00147");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str18 = strConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int31 = strConsumerRecord30.serializedValueSize();
        int int32 = strConsumerRecord30.partition();
        org.apache.kafka.common.header.Headers headers33 = strConsumerRecord30.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int40 = strConsumerRecord39.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional41 = strConsumerRecord39.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType19, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers33, intOptional41);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int53 = strConsumerRecord52.serializedValueSize();
        int int54 = strConsumerRecord52.partition();
        long long55 = strConsumerRecord52.offset();
        java.lang.String str56 = strConsumerRecord52.key();
        org.apache.kafka.common.record.TimestampType timestampType57 = strConsumerRecord52.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (short) 1, (long) (byte) 10, (long) 'a', timestampType19, 1L, (int) (byte) -1, (int) (byte) 10, "hi!", (java.io.Serializable) timestampType57);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType68 = strConsumerRecord67.timestampType();
        int int69 = strConsumerRecord67.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType70 = strConsumerRecord67.timestampType();
        java.lang.String str71 = strConsumerRecord67.toString();
        java.util.Optional<java.lang.Integer> intOptional72 = strConsumerRecord67.leaderEpoch();
        long long73 = strConsumerRecord67.offset();
        java.util.Optional<java.lang.Integer> intOptional74 = strConsumerRecord67.leaderEpoch();
        org.apache.kafka.common.header.Headers headers75 = strConsumerRecord67.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int82 = strConsumerRecord81.serializedValueSize();
        int int83 = strConsumerRecord81.partition();
        long long84 = strConsumerRecord81.offset();
        long long85 = strConsumerRecord81.checksum();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>> headersConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (-1), (long) 10, 1L, timestampType57, (long) (byte) 100, (int) (short) 1, 10, headers75, strConsumerRecord81);
        java.lang.Class<?> wildcardClass87 = headers75.getClass();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "hi!" + "'", str18, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + (-1) + "'", int31 == (-1));
        org.junit.Assert.assertTrue("'" + int32 + "' != '" + 100 + "'", int32 == 100);
        org.junit.Assert.assertNotNull(headers33);
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + (-1) + "'", int40 == (-1));
        org.junit.Assert.assertNotNull(intOptional41);
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + (-1) + "'", int53 == (-1));
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + 100 + "'", int54 == 100);
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + 52L + "'", long55 == 52L);
        org.junit.Assert.assertEquals("'" + str56 + "' != '" + "" + "'", str56, "");
        org.junit.Assert.assertTrue("'" + timestampType57 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType57.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType68 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType68.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int69 + "' != '" + (-1) + "'", int69 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType70 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType70.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str71 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str71, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional72);
        org.junit.Assert.assertTrue("'" + long73 + "' != '" + 52L + "'", long73 == 52L);
        org.junit.Assert.assertNotNull(intOptional74);
        org.junit.Assert.assertNotNull(headers75);
        org.junit.Assert.assertTrue("'" + int82 + "' != '" + (-1) + "'", int82 == (-1));
        org.junit.Assert.assertTrue("'" + int83 + "' != '" + 100 + "'", int83 == 100);
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + 52L + "'", long84 == 52L);
        org.junit.Assert.assertTrue("'" + long85 + "' != '" + (-1L) + "'", long85 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass87);
    }

    @Test
    public void test00148() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00148");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int9 = strConsumerRecord8.serializedValueSize();
        int int10 = strConsumerRecord8.partition();
        long long11 = strConsumerRecord8.offset();
        long long12 = strConsumerRecord8.offset();
        org.apache.kafka.common.header.Headers headers13 = strConsumerRecord8.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType32 = strConsumerRecord31.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType33 = strConsumerRecord31.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType34 = strConsumerRecord31.timestampType();
        java.lang.String str35 = strConsumerRecord31.key();
        org.apache.kafka.common.record.TimestampType timestampType36 = strConsumerRecord31.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType47 = strConsumerRecord46.timestampType();
        java.lang.Class<?> wildcardClass48 = strConsumerRecord46.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType36, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass48);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str60 = strConsumerRecord59.topic();
        java.lang.Class<?> wildcardClass61 = strConsumerRecord59.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord62 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) -1, 100L, (long) 0, timestampType36, (long) (short) 1, (int) '#', 0, "hi!", (java.io.Serializable) wildcardClass61);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType77 = strConsumerRecord76.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType78 = strConsumerRecord76.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType79 = strConsumerRecord76.timestampType();
        java.lang.String str80 = strConsumerRecord76.key();
        org.apache.kafka.common.record.TimestampType timestampType81 = strConsumerRecord76.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord91 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType92 = strConsumerRecord91.timestampType();
        java.lang.Class<?> wildcardClass93 = strConsumerRecord91.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord94 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType81, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass93);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement> charSequenceConsumerRecord95 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement>("", (int) (byte) 0, (long) (byte) 0, (long) (byte) 10, timestampType36, (long) (short) 100, 0, 0, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", (java.lang.reflect.AnnotatedElement) wildcardClass93);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.lang.reflect.GenericDeclaration> headersConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)", 0, (long) 0, headers13, (java.lang.reflect.GenericDeclaration) wildcardClass93);
        java.lang.Class<?> wildcardClass97 = headersConsumerRecord96.getClass();
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 100 + "'", int10 == 100);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + timestampType32 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType32.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType33 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType33.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType34 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType34.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str35 + "' != '" + "" + "'", str35, "");
        org.junit.Assert.assertTrue("'" + timestampType36 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType36.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType47 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType47.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass48);
        org.junit.Assert.assertEquals("'" + str60 + "' != '" + "hi!" + "'", str60, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass61);
        org.junit.Assert.assertTrue("'" + timestampType77 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType77.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType78 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType78.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType79 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType79.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "" + "'", str80, "");
        org.junit.Assert.assertTrue("'" + timestampType81 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType81.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType92 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType92.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass93);
        org.junit.Assert.assertNotNull(wildcardClass97);
    }

    @Test
    public void test00149() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00149");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00150() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00150");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.AnnotatedElement> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.AnnotatedElement> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.AnnotatedElement>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00151() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00151");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str21 = strConsumerRecord20.topic();
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord20.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int34 = strConsumerRecord33.serializedValueSize();
        int int35 = strConsumerRecord33.partition();
        org.apache.kafka.common.header.Headers headers36 = strConsumerRecord33.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int43 = strConsumerRecord42.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional44 = strConsumerRecord42.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType22, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers36, intOptional44);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int57 = strConsumerRecord56.serializedValueSize();
        int int58 = strConsumerRecord56.partition();
        org.apache.kafka.common.header.Headers headers59 = strConsumerRecord56.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType22, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers59);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int72 = strConsumerRecord71.serializedValueSize();
        int int73 = strConsumerRecord71.partition();
        long long74 = strConsumerRecord71.offset();
        long long75 = strConsumerRecord71.offset();
        org.apache.kafka.common.header.Headers headers76 = strConsumerRecord71.headers();
        long long77 = strConsumerRecord71.checksum();
        long long78 = strConsumerRecord71.checksum();
        org.apache.kafka.common.header.Headers headers79 = strConsumerRecord71.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0)", (int) (short) 10, 100L, (long) 32, timestampType22, (java.lang.Long) (-1L), (int) (byte) -1, 32, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) "hi!", headers79);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.String> objConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.String>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 100, NoTimestampType = 0, serialized key size = 35, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 0, (long) 100, (java.lang.Object) strConsumerRecord80, "");
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "hi!" + "'", str21, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + (-1) + "'", int34 == (-1));
        org.junit.Assert.assertTrue("'" + int35 + "' != '" + 100 + "'", int35 == 100);
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + (-1) + "'", int43 == (-1));
        org.junit.Assert.assertNotNull(intOptional44);
        org.junit.Assert.assertTrue("'" + int57 + "' != '" + (-1) + "'", int57 == (-1));
        org.junit.Assert.assertTrue("'" + int58 + "' != '" + 100 + "'", int58 == 100);
        org.junit.Assert.assertNotNull(headers59);
        org.junit.Assert.assertTrue("'" + int72 + "' != '" + (-1) + "'", int72 == (-1));
        org.junit.Assert.assertTrue("'" + int73 + "' != '" + 100 + "'", int73 == 100);
        org.junit.Assert.assertTrue("'" + long74 + "' != '" + 52L + "'", long74 == 52L);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + 52L + "'", long75 == 52L);
        org.junit.Assert.assertNotNull(headers76);
        org.junit.Assert.assertTrue("'" + long77 + "' != '" + (-1L) + "'", long77 == (-1L));
        org.junit.Assert.assertTrue("'" + long78 + "' != '" + (-1L) + "'", long78 == (-1L));
        org.junit.Assert.assertNotNull(headers79);
    }

    @Test
    public void test00152() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00152");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str10 = strConsumerRecord9.topic();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int23 = strConsumerRecord22.serializedValueSize();
        int int24 = strConsumerRecord22.partition();
        org.apache.kafka.common.header.Headers headers25 = strConsumerRecord22.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int32 = strConsumerRecord31.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional33 = strConsumerRecord31.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType11, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers25, intOptional33);
        java.lang.Class<?> wildcardClass35 = strConsumerRecord34.getClass();
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "hi!" + "'", str10, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + 100 + "'", int24 == 100);
        org.junit.Assert.assertNotNull(headers25);
        org.junit.Assert.assertTrue("'" + int32 + "' != '" + (-1) + "'", int32 == (-1));
        org.junit.Assert.assertNotNull(intOptional33);
        org.junit.Assert.assertNotNull(wildcardClass35);
    }

    @Test
    public void test00153() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00153");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        java.io.Serializable serializable7 = strConsumerRecord5.value();
        java.lang.String str8 = strConsumerRecord5.key();
        int int9 = strConsumerRecord5.serializedValueSize();
        long long10 = strConsumerRecord5.offset();
        java.lang.String str11 = strConsumerRecord5.topic();
        long long12 = strConsumerRecord5.timestamp();
        java.lang.String str13 = strConsumerRecord5.topic();
        int int14 = strConsumerRecord5.serializedValueSize();
        long long15 = strConsumerRecord5.offset();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertEquals("'" + serializable7 + "' != '" + (short) 0 + "'", serializable7, (short) 0);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 1L + "'", long10 == 1L);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 1L + "'", long15 == 1L);
    }

    @Test
    public void test00154() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00154");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, java.lang.reflect.GenericDeclaration> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.reflect.GenericDeclaration> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.reflect.GenericDeclaration>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00155() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00155");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, org.apache.kafka.common.record.TimestampType> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, org.apache.kafka.common.record.TimestampType> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, org.apache.kafka.common.record.TimestampType>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00156() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00156");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers26 = strConsumerRecord25.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str37 = strConsumerRecord36.topic();
        org.apache.kafka.common.record.TimestampType timestampType38 = strConsumerRecord36.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int50 = strConsumerRecord49.serializedValueSize();
        int int51 = strConsumerRecord49.partition();
        org.apache.kafka.common.header.Headers headers52 = strConsumerRecord49.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int59 = strConsumerRecord58.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional60 = strConsumerRecord58.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType38, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers52, intOptional60);
        java.util.Optional<java.lang.Integer> intOptional62 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.Iterable<org.apache.kafka.common.header.Header>> serializableConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.Iterable<org.apache.kafka.common.header.Header>>("", (int) (short) -1, (long) (-1), 0L, timestampType15, (java.lang.Long) (-1L), (int) '#', (int) (byte) 0, (java.io.Serializable) (byte) -1, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers26, headers52, intOptional62);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int75 = strConsumerRecord74.serializedValueSize();
        int int76 = strConsumerRecord74.partition();
        long long77 = strConsumerRecord74.offset();
        long long78 = strConsumerRecord74.offset();
        org.apache.kafka.common.header.Headers headers79 = strConsumerRecord74.headers();
        long long80 = strConsumerRecord74.checksum();
        long long81 = strConsumerRecord74.checksum();
        org.apache.kafka.common.header.Headers headers82 = strConsumerRecord74.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 0, (long) (short) 1, 100L, timestampType15, (java.lang.Long) 0L, 0, (int) (byte) 1, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (java.io.Serializable) 1L, headers82);
        long long84 = strConsumerRecord83.checksum();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers26);
        org.junit.Assert.assertEquals("'" + str37 + "' != '" + "hi!" + "'", str37, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType38 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType38.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + (-1) + "'", int50 == (-1));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 100 + "'", int51 == 100);
        org.junit.Assert.assertNotNull(headers52);
        org.junit.Assert.assertTrue("'" + int59 + "' != '" + (-1) + "'", int59 == (-1));
        org.junit.Assert.assertNotNull(intOptional60);
        org.junit.Assert.assertTrue("'" + int75 + "' != '" + (-1) + "'", int75 == (-1));
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + 100 + "'", int76 == 100);
        org.junit.Assert.assertTrue("'" + long77 + "' != '" + 52L + "'", long77 == 52L);
        org.junit.Assert.assertTrue("'" + long78 + "' != '" + 52L + "'", long78 == 52L);
        org.junit.Assert.assertNotNull(headers79);
        org.junit.Assert.assertTrue("'" + long80 + "' != '" + (-1L) + "'", long80 == (-1L));
        org.junit.Assert.assertTrue("'" + long81 + "' != '" + (-1L) + "'", long81 == (-1L));
        org.junit.Assert.assertNotNull(headers82);
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + 0L + "'", long84 == 0L);
    }

    @Test
    public void test00157() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00157");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        int int7 = strConsumerRecord5.partition();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.toString();
        long long10 = strConsumerRecord5.checksum();
        java.util.Optional<java.lang.Integer> intOptional11 = strConsumerRecord5.leaderEpoch();
        java.lang.Class<?> wildcardClass12 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertNotNull(intOptional11);
        org.junit.Assert.assertNotNull(wildcardClass12);
    }

    @Test
    public void test00158() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00158");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        int int7 = strConsumerRecord5.partition();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.toString();
        long long10 = strConsumerRecord5.offset();
        org.apache.kafka.common.header.Headers headers11 = strConsumerRecord5.headers();
        org.apache.kafka.common.header.Headers headers12 = strConsumerRecord5.headers();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 52L + "'", long10 == 52L);
        org.junit.Assert.assertNotNull(headers11);
        org.junit.Assert.assertNotNull(headers12);
    }

    @Test
    public void test00159() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00159");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        long long7 = strConsumerRecord5.offset();
        org.apache.kafka.common.header.Headers headers8 = strConsumerRecord5.headers();
        long long9 = strConsumerRecord5.checksum();
        java.lang.Class<?> wildcardClass10 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + 52L + "'", long7 == 52L);
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass10);
    }

    @Test
    public void test00160() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00160");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        int int7 = strConsumerRecord5.partition();
        java.lang.String str8 = strConsumerRecord5.topic();
        long long9 = strConsumerRecord5.offset();
        java.io.Serializable serializable10 = strConsumerRecord5.value();
        long long11 = strConsumerRecord5.checksum();
        int int12 = strConsumerRecord5.serializedValueSize();
        long long13 = strConsumerRecord5.timestamp();
        long long14 = strConsumerRecord5.checksum();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertEquals("'" + serializable10 + "' != '" + (short) 10 + "'", serializable10, (short) 10);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
    }

    @Test
    public void test00161() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00161");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional7 = strConsumerRecord5.leaderEpoch();
        java.lang.String str8 = strConsumerRecord5.topic();
        java.lang.String str9 = strConsumerRecord5.toString();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        int int11 = strConsumerRecord5.serializedKeySize();
        int int12 = strConsumerRecord5.partition();
        int int13 = strConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
    }

    @Test
    public void test00162() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00162");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, java.util.Optional<java.lang.Integer>> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.util.Optional<java.lang.Integer>> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.util.Optional<java.lang.Integer>>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00163() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00163");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long18 = strConsumerRecord17.timestamp();
        int int19 = strConsumerRecord17.partition();
        java.lang.String str20 = strConsumerRecord17.topic();
        long long21 = strConsumerRecord17.offset();
        java.io.Serializable serializable22 = strConsumerRecord17.value();
        java.lang.String str23 = strConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType24 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType35 = strConsumerRecord34.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 0, (long) '4', (long) (byte) -1, timestampType24, (long) 10, (int) (short) 0, 0, "hi!", (java.io.Serializable) timestampType35);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType51 = strConsumerRecord50.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType52 = strConsumerRecord50.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord66 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType67 = strConsumerRecord66.timestampType();
        int int68 = strConsumerRecord66.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType69 = strConsumerRecord66.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType69, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", 100, (long) 0, 1L, timestampType52, (long) (short) 1, (int) (byte) 1, (int) (short) 1, "hi!", (java.io.Serializable) '#');
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) '4', (long) (byte) 1, (long) '#', timestampType35, (long) (short) 100, 0, (int) ' ', "hi!", (java.io.Serializable) 1L);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType89 = strConsumerRecord88.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType90 = strConsumerRecord88.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType91 = strConsumerRecord88.timestampType();
        java.lang.String str92 = strConsumerRecord88.key();
        long long93 = strConsumerRecord88.timestamp();
        long long94 = strConsumerRecord88.offset();
        java.lang.String str95 = strConsumerRecord88.toString();
        long long96 = strConsumerRecord88.checksum();
        org.apache.kafka.common.header.Headers headers97 = strConsumerRecord88.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", 10, (long) (byte) 1, (long) (short) 10, timestampType35, (java.lang.Long) 1L, (int) (byte) 10, 0, "hi!", (java.io.Serializable) 52L, headers97);
        java.lang.String str99 = strConsumerRecord98.toString();
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 100 + "'", int19 == 100);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertEquals("'" + serializable22 + "' != '" + (short) 10 + "'", serializable22, (short) 10);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "hi!" + "'", str23, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType24 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType24.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType35 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType35.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType51 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType51.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType52 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType52.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType67 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType67.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int68 + "' != '" + (-1) + "'", int68 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType69 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType69.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType89 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType89.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType90 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType90.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType91 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType91.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str92 + "' != '" + "" + "'", str92, "");
        org.junit.Assert.assertTrue("'" + long93 + "' != '" + (-1L) + "'", long93 == (-1L));
        org.junit.Assert.assertTrue("'" + long94 + "' != '" + 52L + "'", long94 == 52L);
        org.junit.Assert.assertEquals("'" + str95 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str95, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long96 + "' != '" + (-1L) + "'", long96 == (-1L));
        org.junit.Assert.assertNotNull(headers97);
        org.junit.Assert.assertEquals("'" + str99 + "' != '" + "ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 10, serialized key size = 10, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 52)" + "'", str99, "ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 10, serialized key size = 10, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 52)");
    }

    @Test
    public void test00164() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00164");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str9 = strConsumerRecord8.topic();
        java.io.Serializable serializable10 = strConsumerRecord8.value();
        java.lang.String str11 = strConsumerRecord8.topic();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord8.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long23 = strConsumerRecord22.timestamp();
        int int24 = strConsumerRecord22.partition();
        org.apache.kafka.common.record.TimestampType timestampType25 = strConsumerRecord22.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str45 = strConsumerRecord44.topic();
        org.apache.kafka.common.record.TimestampType timestampType46 = strConsumerRecord44.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int58 = strConsumerRecord57.serializedValueSize();
        int int59 = strConsumerRecord57.partition();
        org.apache.kafka.common.header.Headers headers60 = strConsumerRecord57.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord66 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int67 = strConsumerRecord66.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional68 = strConsumerRecord66.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType46, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers60, intOptional68);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int81 = strConsumerRecord80.serializedValueSize();
        int int82 = strConsumerRecord80.partition();
        org.apache.kafka.common.header.Headers headers83 = strConsumerRecord80.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType46, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers83);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (short) 0, (long) '4', (long) 1, timestampType25, (java.lang.Long) 100L, (int) (byte) -1, (int) '#', "hi!", (java.io.Serializable) 10.0d, headers83);
        java.util.Optional<java.lang.Integer> intOptional86 = strConsumerRecord85.leaderEpoch();
        java.lang.Class<?> wildcardClass87 = strConsumerRecord85.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.reflect.AnnotatedElement> timestampTypeEnumConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.reflect.AnnotatedElement>("", 1, (long) 10, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType12, (java.lang.reflect.AnnotatedElement) wildcardClass87);
        java.lang.Class<?> wildcardClass89 = timestampType12.getClass();
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "hi!" + "'", str9, "hi!");
        org.junit.Assert.assertEquals("'" + serializable10 + "' != '" + (short) 10 + "'", serializable10, (short) 10);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "hi!" + "'", str11, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long23 + "' != '" + (-1L) + "'", long23 == (-1L));
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + 100 + "'", int24 == 100);
        org.junit.Assert.assertTrue("'" + timestampType25 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType25.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str45 + "' != '" + "hi!" + "'", str45, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType46 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType46.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int58 + "' != '" + (-1) + "'", int58 == (-1));
        org.junit.Assert.assertTrue("'" + int59 + "' != '" + 100 + "'", int59 == 100);
        org.junit.Assert.assertNotNull(headers60);
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + (-1) + "'", int67 == (-1));
        org.junit.Assert.assertNotNull(intOptional68);
        org.junit.Assert.assertTrue("'" + int81 + "' != '" + (-1) + "'", int81 == (-1));
        org.junit.Assert.assertTrue("'" + int82 + "' != '" + 100 + "'", int82 == 100);
        org.junit.Assert.assertNotNull(headers83);
        org.junit.Assert.assertNotNull(intOptional86);
        org.junit.Assert.assertNotNull(wildcardClass87);
        org.junit.Assert.assertNotNull(wildcardClass89);
    }

    @Test
    public void test00165() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00165");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType7 = strConsumerRecord5.timestampType();
        java.lang.String str8 = strConsumerRecord5.toString();
        int int9 = strConsumerRecord5.partition();
        java.lang.String str10 = strConsumerRecord5.key();
        int int11 = strConsumerRecord5.serializedValueSize();
        long long12 = strConsumerRecord5.timestamp();
        java.lang.String str13 = strConsumerRecord5.topic();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str8, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + 100 + "'", int9 == 100);
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "" + "'", str10, "");
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
    }

    @Test
    public void test00166() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00166");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int30 = strConsumerRecord29.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional31 = strConsumerRecord29.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str38 = strConsumerRecord37.topic();
        org.apache.kafka.common.record.TimestampType timestampType39 = strConsumerRecord37.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord40 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord29, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType39);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) -1, 100L, (long) 10, timestampType39, 0L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 0.0f);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType56 = strConsumerRecord55.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType57 = strConsumerRecord55.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType58 = strConsumerRecord55.timestampType();
        java.lang.Object obj59 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object> timestampTypeConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object>("", 0, (long) (byte) 100, (long) (byte) -1, timestampType39, (long) (byte) 100, (int) (short) 10, (int) (short) -1, timestampType58, obj59);
        java.io.Serializable serializable65 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType72 = strConsumerRecord71.timestampType();
        int int73 = strConsumerRecord71.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType74 = strConsumerRecord71.timestampType();
        java.lang.String str75 = strConsumerRecord71.toString();
        java.util.Optional<java.lang.Integer> intOptional76 = strConsumerRecord71.leaderEpoch();
        long long77 = strConsumerRecord71.offset();
        java.util.Optional<java.lang.Integer> intOptional78 = strConsumerRecord71.leaderEpoch();
        org.apache.kafka.common.header.Headers headers79 = strConsumerRecord71.headers();
        org.apache.kafka.common.header.Headers headers80 = strConsumerRecord71.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int87 = strConsumerRecord86.serializedValueSize();
        int int88 = strConsumerRecord86.partition();
        long long89 = strConsumerRecord86.offset();
        long long90 = strConsumerRecord86.offset();
        org.apache.kafka.common.record.TimestampType timestampType91 = strConsumerRecord86.timestampType();
        java.lang.String str92 = strConsumerRecord86.toString();
        int int93 = strConsumerRecord86.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional94 = strConsumerRecord86.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord95 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 32, 0L, timestampType39, (java.lang.Long) (-1L), 52, 52, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", serializable65, headers80, intOptional94);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Iterable<org.apache.kafka.common.header.Header>> charSequenceConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Iterable<org.apache.kafka.common.header.Header>>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", 10, 100L, (long) (byte) 100, timestampType4, 10L, (int) (short) 1, (int) (short) 0, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0), partition = 32, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)", (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers80);
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertNotNull(intOptional31);
        org.junit.Assert.assertEquals("'" + str38 + "' != '" + "hi!" + "'", str38, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType39 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType39.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType56 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType56.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType57 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType57.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType58 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType58.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType72 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType72.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int73 + "' != '" + (-1) + "'", int73 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType74 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType74.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str75 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str75, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional76);
        org.junit.Assert.assertTrue("'" + long77 + "' != '" + 52L + "'", long77 == 52L);
        org.junit.Assert.assertNotNull(intOptional78);
        org.junit.Assert.assertNotNull(headers79);
        org.junit.Assert.assertNotNull(headers80);
        org.junit.Assert.assertTrue("'" + int87 + "' != '" + (-1) + "'", int87 == (-1));
        org.junit.Assert.assertTrue("'" + int88 + "' != '" + 100 + "'", int88 == 100);
        org.junit.Assert.assertTrue("'" + long89 + "' != '" + 52L + "'", long89 == 52L);
        org.junit.Assert.assertTrue("'" + long90 + "' != '" + 52L + "'", long90 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType91 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType91.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str92 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str92, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int93 + "' != '" + (-1) + "'", int93 == (-1));
        org.junit.Assert.assertNotNull(intOptional94);
    }

    @Test
    public void test00167() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00167");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, java.util.Optional<java.lang.Integer>> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.util.Optional<java.lang.Integer>> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.util.Optional<java.lang.Integer>>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00168() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00168");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.toString();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord5.leaderEpoch();
        long long11 = strConsumerRecord5.offset();
        java.util.Optional<java.lang.Integer> intOptional12 = strConsumerRecord5.leaderEpoch();
        org.apache.kafka.common.header.Headers headers13 = strConsumerRecord5.headers();
        long long14 = strConsumerRecord5.offset();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
    }

    @Test
    public void test00169() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00169");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long10 = strConsumerRecord9.timestamp();
        int int11 = strConsumerRecord9.partition();
        java.lang.String str12 = strConsumerRecord9.topic();
        long long13 = strConsumerRecord9.offset();
        java.io.Serializable serializable14 = strConsumerRecord9.value();
        java.lang.String str15 = strConsumerRecord9.topic();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType27 = strConsumerRecord26.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 0, (long) '4', (long) (byte) -1, timestampType16, (long) 10, (int) (short) 0, 0, "hi!", (java.io.Serializable) timestampType27);
        org.apache.kafka.common.record.TimestampType timestampType29 = strConsumerRecord28.timestampType();
        java.util.Optional<java.lang.Integer> intOptional30 = strConsumerRecord28.leaderEpoch();
        int int31 = strConsumerRecord28.serializedKeySize();
        int int32 = strConsumerRecord28.partition();
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + (short) 10 + "'", serializable14, (short) 10);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType27 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType27.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType29 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType29.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(intOptional30);
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 0 + "'", int31 == 0);
        org.junit.Assert.assertTrue("'" + int32 + "' != '" + 0 + "'", int32 == 0);
    }

    @Test
    public void test00170() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00170");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        java.lang.String str9 = strConsumerRecord5.toString();
        long long10 = strConsumerRecord5.checksum();
        int int11 = strConsumerRecord5.partition();
        long long12 = strConsumerRecord5.offset();
        java.lang.String str13 = strConsumerRecord5.toString();
        int int14 = strConsumerRecord5.partition();
        long long15 = strConsumerRecord5.checksum();
        long long16 = strConsumerRecord5.offset();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str13, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 100 + "'", int14 == 100);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 52L + "'", long16 == 52L);
    }

    @Test
    public void test00171() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00171");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str22 = strConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = strConsumerRecord21.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int35 = strConsumerRecord34.serializedValueSize();
        int int36 = strConsumerRecord34.partition();
        org.apache.kafka.common.header.Headers headers37 = strConsumerRecord34.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int44 = strConsumerRecord43.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional45 = strConsumerRecord43.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType23, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers37, intOptional45);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int58 = strConsumerRecord57.serializedValueSize();
        int int59 = strConsumerRecord57.partition();
        org.apache.kafka.common.header.Headers headers60 = strConsumerRecord57.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType23, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers60);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (short) -1, (long) '4', 0L, timestampType23, (long) (byte) 10, (-1), 0, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 1.0f);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers79 = strConsumerRecord78.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long86 = strConsumerRecord85.timestamp();
        long long87 = strConsumerRecord85.checksum();
        java.util.Optional<java.lang.Integer> intOptional88 = strConsumerRecord85.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord89 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 0, 0L, (long) '#', timestampType23, (java.lang.Long) 100L, 0, (int) (short) 100, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", headers79, intOptional88);
        java.lang.Class<?> wildcardClass90 = strConsumerRecord89.getClass();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "hi!" + "'", str22, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int35 + "' != '" + (-1) + "'", int35 == (-1));
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + 100 + "'", int36 == 100);
        org.junit.Assert.assertNotNull(headers37);
        org.junit.Assert.assertTrue("'" + int44 + "' != '" + (-1) + "'", int44 == (-1));
        org.junit.Assert.assertNotNull(intOptional45);
        org.junit.Assert.assertTrue("'" + int58 + "' != '" + (-1) + "'", int58 == (-1));
        org.junit.Assert.assertTrue("'" + int59 + "' != '" + 100 + "'", int59 == 100);
        org.junit.Assert.assertNotNull(headers60);
        org.junit.Assert.assertNotNull(headers79);
        org.junit.Assert.assertTrue("'" + long86 + "' != '" + (-1L) + "'", long86 == (-1L));
        org.junit.Assert.assertTrue("'" + long87 + "' != '" + (-1L) + "'", long87 == (-1L));
        org.junit.Assert.assertNotNull(intOptional88);
        org.junit.Assert.assertNotNull(wildcardClass90);
    }

    @Test
    public void test00172() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00172");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        java.io.Serializable serializable7 = strConsumerRecord5.value();
        java.lang.String str8 = strConsumerRecord5.key();
        org.apache.kafka.common.header.Headers headers9 = strConsumerRecord5.headers();
        org.apache.kafka.common.header.Headers headers10 = strConsumerRecord5.headers();
        java.lang.Class<?> wildcardClass11 = headers10.getClass();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertEquals("'" + serializable7 + "' != '" + (short) 0 + "'", serializable7, (short) 0);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertNotNull(headers9);
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertNotNull(wildcardClass11);
    }

    @Test
    public void test00173() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00173");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        int int15 = strConsumerRecord13.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", 1, 52L, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (java.io.Serializable) timestampType16);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 1, (-1L), "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (java.io.Serializable) "");
        java.io.Serializable serializable19 = strConsumerRecord18.value();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + serializable19 + "' != '" + "" + "'", serializable19, "");
    }

    @Test
    public void test00174() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00174");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord11 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) 10, 0L, "hi!", (java.io.Serializable) timestampType10);
        int int12 = strConsumerRecord11.serializedKeySize();
        java.lang.String str13 = strConsumerRecord11.topic();
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str13, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
    }

    @Test
    public void test00175() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00175");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long18 = strConsumerRecord17.timestamp();
        int int19 = strConsumerRecord17.partition();
        java.lang.String str20 = strConsumerRecord17.topic();
        long long21 = strConsumerRecord17.offset();
        java.io.Serializable serializable22 = strConsumerRecord17.value();
        java.lang.String str23 = strConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType24 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType35 = strConsumerRecord34.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 0, (long) '4', (long) (byte) -1, timestampType24, (long) 10, (int) (short) 0, 0, "hi!", (java.io.Serializable) timestampType35);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType51 = strConsumerRecord50.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType52 = strConsumerRecord50.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord66 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType67 = strConsumerRecord66.timestampType();
        int int68 = strConsumerRecord66.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType69 = strConsumerRecord66.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType69, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", 100, (long) 0, 1L, timestampType52, (long) (short) 1, (int) (byte) 1, (int) (short) 1, "hi!", (java.io.Serializable) '#');
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) '4', (long) (byte) 1, (long) '#', timestampType35, (long) (short) 100, 0, (int) ' ', "hi!", (java.io.Serializable) 1L);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType89 = strConsumerRecord88.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType90 = strConsumerRecord88.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType91 = strConsumerRecord88.timestampType();
        java.lang.String str92 = strConsumerRecord88.key();
        long long93 = strConsumerRecord88.timestamp();
        long long94 = strConsumerRecord88.offset();
        java.lang.String str95 = strConsumerRecord88.toString();
        long long96 = strConsumerRecord88.checksum();
        org.apache.kafka.common.header.Headers headers97 = strConsumerRecord88.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", 10, (long) (byte) 1, (long) (short) 10, timestampType35, (java.lang.Long) 1L, (int) (byte) 10, 0, "hi!", (java.io.Serializable) 52L, headers97);
        int int99 = strConsumerRecord98.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 100 + "'", int19 == 100);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertEquals("'" + serializable22 + "' != '" + (short) 10 + "'", serializable22, (short) 10);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "hi!" + "'", str23, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType24 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType24.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType35 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType35.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType51 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType51.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType52 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType52.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType67 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType67.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int68 + "' != '" + (-1) + "'", int68 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType69 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType69.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType89 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType89.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType90 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType90.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType91 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType91.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str92 + "' != '" + "" + "'", str92, "");
        org.junit.Assert.assertTrue("'" + long93 + "' != '" + (-1L) + "'", long93 == (-1L));
        org.junit.Assert.assertTrue("'" + long94 + "' != '" + 52L + "'", long94 == 52L);
        org.junit.Assert.assertEquals("'" + str95 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str95, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long96 + "' != '" + (-1L) + "'", long96 == (-1L));
        org.junit.Assert.assertNotNull(headers97);
        org.junit.Assert.assertTrue("'" + int99 + "' != '" + 10 + "'", int99 == 10);
    }

    @Test
    public void test00176() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00176");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord17.timestampType();
        java.lang.String str21 = strConsumerRecord17.key();
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType33 = strConsumerRecord32.timestampType();
        java.lang.Class<?> wildcardClass34 = strConsumerRecord32.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType22, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass34);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int46 = strConsumerRecord45.serializedValueSize();
        int int47 = strConsumerRecord45.partition();
        long long48 = strConsumerRecord45.offset();
        long long49 = strConsumerRecord45.offset();
        org.apache.kafka.common.record.TimestampType timestampType50 = strConsumerRecord45.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int57 = strConsumerRecord56.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional58 = strConsumerRecord56.leaderEpoch();
        java.lang.String str59 = strConsumerRecord56.key();
        org.apache.kafka.common.header.Headers headers60 = strConsumerRecord56.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> serializableConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("", (int) ' ', 0L, (long) '4', timestampType22, (java.lang.Long) 52L, (int) (short) -1, (int) (short) 10, (java.io.Serializable) 100, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType50, headers60);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long76 = strConsumerRecord75.timestamp();
        int int77 = strConsumerRecord75.partition();
        java.io.Serializable serializable78 = strConsumerRecord75.value();
        java.lang.Class<?> wildcardClass79 = strConsumerRecord75.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, 52L, "", (java.io.Serializable) wildcardClass79);
        org.apache.kafka.common.header.Headers headers81 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers88 = strConsumerRecord87.headers();
        java.io.Serializable serializable89 = strConsumerRecord87.value();
        java.lang.String str90 = strConsumerRecord87.key();
        java.lang.String str91 = strConsumerRecord87.key();
        int int92 = strConsumerRecord87.partition();
        java.util.Optional<java.lang.Integer> intOptional93 = strConsumerRecord87.leaderEpoch();
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord94 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", (-1), 0L, (long) (byte) 10, timestampType22, (java.lang.Long) 0L, (int) (short) 100, (int) (short) 100, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (java.io.Serializable) wildcardClass79, headers81, intOptional93);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "" + "'", str21, "");
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType33 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType33.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass34);
        org.junit.Assert.assertTrue("'" + int46 + "' != '" + (-1) + "'", int46 == (-1));
        org.junit.Assert.assertTrue("'" + int47 + "' != '" + 100 + "'", int47 == 100);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + 52L + "'", long48 == 52L);
        org.junit.Assert.assertTrue("'" + long49 + "' != '" + 52L + "'", long49 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType50 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType50.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int57 + "' != '" + (-1) + "'", int57 == (-1));
        org.junit.Assert.assertNotNull(intOptional58);
        org.junit.Assert.assertEquals("'" + str59 + "' != '" + "" + "'", str59, "");
        org.junit.Assert.assertNotNull(headers60);
        org.junit.Assert.assertTrue("'" + long76 + "' != '" + (-1L) + "'", long76 == (-1L));
        org.junit.Assert.assertTrue("'" + int77 + "' != '" + 100 + "'", int77 == 100);
        org.junit.Assert.assertEquals("'" + serializable78 + "' != '" + (short) 10 + "'", serializable78, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass79);
        org.junit.Assert.assertNotNull(headers88);
        org.junit.Assert.assertEquals("'" + serializable89 + "' != '" + (short) 0 + "'", serializable89, (short) 0);
        org.junit.Assert.assertEquals("'" + str90 + "' != '" + "hi!" + "'", str90, "hi!");
        org.junit.Assert.assertEquals("'" + str91 + "' != '" + "hi!" + "'", str91, "hi!");
        org.junit.Assert.assertTrue("'" + int92 + "' != '" + 1 + "'", int92 == 1);
        org.junit.Assert.assertNotNull(intOptional93);
    }

    @Test
    public void test00177() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00177");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.io.Serializable> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.io.Serializable> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.io.Serializable>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00178() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00178");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        java.lang.String str17 = strConsumerRecord13.key();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType29 = strConsumerRecord28.timestampType();
        java.lang.Class<?> wildcardClass30 = strConsumerRecord28.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType18, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass30);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str42 = strConsumerRecord41.topic();
        java.lang.Class<?> wildcardClass43 = strConsumerRecord41.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) -1, 100L, (long) 0, timestampType18, (long) (short) 1, (int) '#', 0, "hi!", (java.io.Serializable) wildcardClass43);
        org.apache.kafka.common.header.Headers headers45 = strConsumerRecord44.headers();
        java.lang.Class<?> wildcardClass46 = headers45.getClass();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType29 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType29.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass30);
        org.junit.Assert.assertEquals("'" + str42 + "' != '" + "hi!" + "'", str42, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass43);
        org.junit.Assert.assertNotNull(headers45);
        org.junit.Assert.assertNotNull(wildcardClass46);
    }

    @Test
    public void test00179() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00179");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType26 = strConsumerRecord25.timestampType();
        int int27 = strConsumerRecord25.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType28 = strConsumerRecord25.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType28, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long44 = strConsumerRecord43.timestamp();
        int int45 = strConsumerRecord43.partition();
        java.io.Serializable serializable46 = strConsumerRecord43.value();
        java.lang.Class<?> wildcardClass47 = serializable46.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long54 = strConsumerRecord53.timestamp();
        int int55 = strConsumerRecord53.partition();
        java.lang.String str56 = strConsumerRecord53.topic();
        long long57 = strConsumerRecord53.offset();
        java.lang.Class<?> wildcardClass58 = strConsumerRecord53.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration> typeConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration>("hi!", (int) (short) 0, (long) (byte) 1, 10L, timestampType28, (long) (byte) 10, (int) 'a', (int) (short) -1, (java.lang.reflect.Type) wildcardClass47, (java.lang.reflect.GenericDeclaration) wildcardClass58);
        java.io.Serializable serializable64 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 100, 0L, 0L, timestampType28, (long) 10, (int) '#', 10, "hi!", serializable64);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType76 = strConsumerRecord75.timestampType();
        int int77 = strConsumerRecord75.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType78 = strConsumerRecord75.timestampType();
        java.lang.Class<?> wildcardClass79 = timestampType78.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (int) 'a', (long) ' ', (long) 0, timestampType28, (long) (short) 100, (-1), (int) (byte) 10, "hi!", (java.io.Serializable) wildcardClass79);
        long long81 = strConsumerRecord80.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType82 = strConsumerRecord80.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType86 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord92 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers93 = strConsumerRecord92.headers();
        java.io.Serializable serializable94 = strConsumerRecord92.value();
        java.lang.String str95 = strConsumerRecord92.key();
        java.lang.String str96 = strConsumerRecord92.toString();
        org.apache.kafka.common.record.TimestampType timestampType97 = strConsumerRecord92.timestampType();
        java.lang.Class<?> wildcardClass98 = timestampType97.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.reflect.Type> timestampTypeConsumerRecord99 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.reflect.Type>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 100, NoTimestampType = 0, serialized key size = 35, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (-1), (long) 52, (long) (byte) 0, timestampType82, 1L, 1, 0, timestampType86, (java.lang.reflect.Type) wildcardClass98);
        org.junit.Assert.assertTrue("'" + timestampType26 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType26.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType28 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType28.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + (-1L) + "'", long44 == (-1L));
        org.junit.Assert.assertTrue("'" + int45 + "' != '" + 100 + "'", int45 == 100);
        org.junit.Assert.assertEquals("'" + serializable46 + "' != '" + (short) 10 + "'", serializable46, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass47);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + (-1L) + "'", long54 == (-1L));
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + 100 + "'", int55 == 100);
        org.junit.Assert.assertEquals("'" + str56 + "' != '" + "hi!" + "'", str56, "hi!");
        org.junit.Assert.assertTrue("'" + long57 + "' != '" + 52L + "'", long57 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass58);
        org.junit.Assert.assertTrue("'" + timestampType76 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType76.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int77 + "' != '" + (-1) + "'", int77 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType78 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType78.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass79);
        org.junit.Assert.assertTrue("'" + long81 + "' != '" + 0L + "'", long81 == 0L);
        org.junit.Assert.assertTrue("'" + timestampType82 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType82.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers93);
        org.junit.Assert.assertEquals("'" + serializable94 + "' != '" + (short) 0 + "'", serializable94, (short) 0);
        org.junit.Assert.assertEquals("'" + str95 + "' != '" + "hi!" + "'", str95, "hi!");
        org.junit.Assert.assertEquals("'" + str96 + "' != '" + "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)" + "'", str96, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)");
        org.junit.Assert.assertTrue("'" + timestampType97 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType97.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass98);
    }

    @Test
    public void test00180() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00180");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str18 = strConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int31 = strConsumerRecord30.serializedValueSize();
        int int32 = strConsumerRecord30.partition();
        org.apache.kafka.common.header.Headers headers33 = strConsumerRecord30.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int40 = strConsumerRecord39.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional41 = strConsumerRecord39.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType19, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers33, intOptional41);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int54 = strConsumerRecord53.serializedValueSize();
        int int55 = strConsumerRecord53.partition();
        org.apache.kafka.common.header.Headers headers56 = strConsumerRecord53.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType19, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int69 = strConsumerRecord68.serializedValueSize();
        int int70 = strConsumerRecord68.partition();
        long long71 = strConsumerRecord68.offset();
        long long72 = strConsumerRecord68.offset();
        org.apache.kafka.common.header.Headers headers73 = strConsumerRecord68.headers();
        long long74 = strConsumerRecord68.checksum();
        long long75 = strConsumerRecord68.checksum();
        org.apache.kafka.common.header.Headers headers76 = strConsumerRecord68.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0)", (int) (short) 10, 100L, (long) 32, timestampType19, (java.lang.Long) (-1L), (int) (byte) -1, 32, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) "hi!", headers76);
        java.lang.String str78 = strConsumerRecord77.toString();
        java.lang.Class<?> wildcardClass79 = strConsumerRecord77.getClass();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "hi!" + "'", str18, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + (-1) + "'", int31 == (-1));
        org.junit.Assert.assertTrue("'" + int32 + "' != '" + 100 + "'", int32 == 100);
        org.junit.Assert.assertNotNull(headers33);
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + (-1) + "'", int40 == (-1));
        org.junit.Assert.assertNotNull(intOptional41);
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + (-1) + "'", int54 == (-1));
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + 100 + "'", int55 == 100);
        org.junit.Assert.assertNotNull(headers56);
        org.junit.Assert.assertTrue("'" + int69 + "' != '" + (-1) + "'", int69 == (-1));
        org.junit.Assert.assertTrue("'" + int70 + "' != '" + 100 + "'", int70 == 100);
        org.junit.Assert.assertTrue("'" + long71 + "' != '" + 52L + "'", long71 == 52L);
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + 52L + "'", long72 == 52L);
        org.junit.Assert.assertNotNull(headers73);
        org.junit.Assert.assertTrue("'" + long74 + "' != '" + (-1L) + "'", long74 == (-1L));
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + (-1L) + "'", long75 == (-1L));
        org.junit.Assert.assertNotNull(headers76);
        org.junit.Assert.assertEquals("'" + str78 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0), partition = 10, leaderEpoch = null, offset = 100, NoTimestampType = 32, serialized key size = -1, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = hi!)" + "'", str78, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0), partition = 10, leaderEpoch = null, offset = 100, NoTimestampType = 32, serialized key size = -1, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = hi!)");
        org.junit.Assert.assertNotNull(wildcardClass79);
    }

    @Test
    public void test00181() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00181");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        int int11 = strConsumerRecord5.serializedValueSize();
        java.io.Serializable serializable12 = strConsumerRecord5.value();
        java.lang.String str13 = strConsumerRecord5.topic();
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord5.timestampType();
        java.lang.Class<?> wildcardClass15 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + serializable12 + "' != '" + (short) 10 + "'", serializable12, (short) 10);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass15);
    }

    @Test
    public void test00182() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00182");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.Comparable<java.lang.String>> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0), partition = 10, leaderEpoch = null, offset = 100, NoTimestampType = 32, serialized key size = -1, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = hi!)", 0, (long) (byte) -1, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)");
    }

    @Test
    public void test00183() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00183");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str14 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int27 = strConsumerRecord26.serializedValueSize();
        int int28 = strConsumerRecord26.partition();
        org.apache.kafka.common.header.Headers headers29 = strConsumerRecord26.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType15, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers29, intOptional37);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", (int) (byte) 100, 52L, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", (java.io.Serializable) 0L);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 100 + "'", int28 == 100);
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(intOptional37);
    }

    @Test
    public void test00184() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00184");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long14 = strConsumerRecord13.timestamp();
        int int15 = strConsumerRecord13.partition();
        java.lang.String str16 = strConsumerRecord13.topic();
        long long17 = strConsumerRecord13.offset();
        java.io.Serializable serializable18 = strConsumerRecord13.value();
        java.lang.String str19 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType31 = strConsumerRecord30.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 0, (long) '4', (long) (byte) -1, timestampType20, (long) 10, (int) (short) 0, 0, "hi!", (java.io.Serializable) timestampType31);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType47 = strConsumerRecord46.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType48 = strConsumerRecord46.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType49 = strConsumerRecord46.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType59 = strConsumerRecord58.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int69 = strConsumerRecord68.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional70 = strConsumerRecord68.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str77 = strConsumerRecord76.topic();
        org.apache.kafka.common.record.TimestampType timestampType78 = strConsumerRecord76.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord68, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType78);
        java.lang.String str80 = strConsumerRecord68.topic();
        java.lang.Class<?> wildcardClass81 = strConsumerRecord68.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object> timestampTypeConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object>("hi!", (int) (short) 100, 1L, 100L, timestampType49, (long) (short) -1, (int) (byte) -1, (int) (byte) -1, timestampType59, (java.lang.Object) wildcardClass81);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 1, (long) (-1), 100L, timestampType20, (long) 1, (int) (byte) 1, 0, "", (java.io.Serializable) timestampType49);
        long long84 = strConsumerRecord83.timestamp();
        java.util.Optional<java.lang.Integer> intOptional85 = strConsumerRecord83.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "hi!" + "'", str16, "hi!");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertEquals("'" + serializable18 + "' != '" + (short) 10 + "'", serializable18, (short) 10);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType47 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType47.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType48 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType48.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType49 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType49.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType59 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType59.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int69 + "' != '" + (-1) + "'", int69 == (-1));
        org.junit.Assert.assertNotNull(intOptional70);
        org.junit.Assert.assertEquals("'" + str77 + "' != '" + "hi!" + "'", str77, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType78 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType78.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "hi!" + "'", str80, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass81);
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + 100L + "'", long84 == 100L);
        org.junit.Assert.assertNotNull(intOptional85);
    }

    @Test
    public void test00185() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00185");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        java.lang.String str11 = strConsumerRecord5.key();
        java.lang.String str12 = strConsumerRecord5.toString();
        java.io.Serializable serializable13 = strConsumerRecord5.value();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str12, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + serializable13 + "' != '" + (short) 10 + "'", serializable13, (short) 10);
    }

    @Test
    public void test00186() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00186");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, org.apache.kafka.common.header.Headers> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, org.apache.kafka.common.header.Headers> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, org.apache.kafka.common.header.Headers>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00187() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00187");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        java.io.Serializable serializable7 = strConsumerRecord5.value();
        java.lang.String str8 = strConsumerRecord5.key();
        int int9 = strConsumerRecord5.serializedValueSize();
        long long10 = strConsumerRecord5.offset();
        java.lang.String str11 = strConsumerRecord5.topic();
        long long12 = strConsumerRecord5.timestamp();
        int int13 = strConsumerRecord5.partition();
        int int14 = strConsumerRecord5.partition();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertEquals("'" + serializable7 + "' != '" + (short) 0 + "'", serializable7, (short) 0);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 1L + "'", long10 == 1L);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 1 + "'", int13 == 1);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 1 + "'", int14 == 1);
    }

    @Test
    public void test00188() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00188");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, java.lang.Iterable<org.apache.kafka.common.header.Header>> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.Iterable<org.apache.kafka.common.header.Header>> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.Iterable<org.apache.kafka.common.header.Header>>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00189() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00189");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        java.lang.Class<?> wildcardClass7 = headers6.getClass();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertNotNull(wildcardClass7);
    }

    @Test
    public void test00190() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00190");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        int int11 = strConsumerRecord5.serializedValueSize();
        java.io.Serializable serializable12 = strConsumerRecord5.value();
        java.lang.String str13 = strConsumerRecord5.topic();
        int int14 = strConsumerRecord5.partition();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + serializable12 + "' != '" + (short) 10 + "'", serializable12, (short) 10);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 100 + "'", int14 == 100);
    }

    @Test
    public void test00191() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00191");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord14.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord14.timestampType();
        java.lang.String str17 = strConsumerRecord14.toString();
        int int18 = strConsumerRecord14.partition();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord14.timestampType();
        int int20 = strConsumerRecord14.serializedValueSize();
        java.lang.Class<?> wildcardClass21 = strConsumerRecord14.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement> charSequenceConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 35, (long) 0, (long) 52, timestampType4, (long) 32, 52, (int) (short) 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", (java.lang.reflect.AnnotatedElement) wildcardClass21);
        java.lang.Class<?> wildcardClass23 = charSequenceConsumerRecord22.getClass();
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str17, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 100 + "'", int18 == 100);
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + (-1) + "'", int20 == (-1));
        org.junit.Assert.assertNotNull(wildcardClass21);
        org.junit.Assert.assertNotNull(wildcardClass23);
    }

    @Test
    public void test00192() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00192");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType7 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.key();
        long long10 = strConsumerRecord5.timestamp();
        long long11 = strConsumerRecord5.offset();
        java.lang.String str12 = strConsumerRecord5.topic();
        long long13 = strConsumerRecord5.timestamp();
        long long14 = strConsumerRecord5.checksum();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "" + "'", str9, "");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
    }

    @Test
    public void test00193() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00193");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType7 = strConsumerRecord5.timestampType();
        java.lang.String str8 = strConsumerRecord5.toString();
        int int9 = strConsumerRecord5.partition();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        int int11 = strConsumerRecord5.serializedValueSize();
        long long12 = strConsumerRecord5.checksum();
        org.apache.kafka.common.header.Headers headers13 = strConsumerRecord5.headers();
        long long14 = strConsumerRecord5.timestamp();
        java.lang.String str15 = strConsumerRecord5.key();
        java.lang.String str16 = strConsumerRecord5.toString();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str8, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + 100 + "'", int9 == 100);
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "" + "'", str15, "");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str16, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
    }

    @Test
    public void test00194() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00194");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, java.lang.Object> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.Object> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.Object>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00195() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00195");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str18 = strConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int31 = strConsumerRecord30.serializedValueSize();
        int int32 = strConsumerRecord30.partition();
        org.apache.kafka.common.header.Headers headers33 = strConsumerRecord30.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int40 = strConsumerRecord39.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional41 = strConsumerRecord39.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType19, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers33, intOptional41);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int54 = strConsumerRecord53.serializedValueSize();
        int int55 = strConsumerRecord53.partition();
        org.apache.kafka.common.header.Headers headers56 = strConsumerRecord53.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType19, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (short) -1, (long) '4', 0L, timestampType19, (long) (byte) 10, (-1), 0, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 1.0f);
        int int64 = strConsumerRecord63.serializedValueSize();
        int int65 = strConsumerRecord63.partition();
        int int66 = strConsumerRecord63.partition();
        java.lang.Class<?> wildcardClass67 = strConsumerRecord63.getClass();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "hi!" + "'", str18, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + (-1) + "'", int31 == (-1));
        org.junit.Assert.assertTrue("'" + int32 + "' != '" + 100 + "'", int32 == 100);
        org.junit.Assert.assertNotNull(headers33);
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + (-1) + "'", int40 == (-1));
        org.junit.Assert.assertNotNull(intOptional41);
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + (-1) + "'", int54 == (-1));
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + 100 + "'", int55 == 100);
        org.junit.Assert.assertNotNull(headers56);
        org.junit.Assert.assertTrue("'" + int64 + "' != '" + 0 + "'", int64 == 0);
        org.junit.Assert.assertTrue("'" + int65 + "' != '" + (-1) + "'", int65 == (-1));
        org.junit.Assert.assertTrue("'" + int66 + "' != '" + (-1) + "'", int66 == (-1));
        org.junit.Assert.assertNotNull(wildcardClass67);
    }

    @Test
    public void test00196() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00196");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long10 = strConsumerRecord9.timestamp();
        int int11 = strConsumerRecord9.partition();
        java.io.Serializable serializable12 = strConsumerRecord9.value();
        java.lang.Class<?> wildcardClass13 = strConsumerRecord9.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, 52L, "", (java.io.Serializable) wildcardClass13);
        java.io.Serializable serializable15 = strConsumerRecord14.value();
        java.lang.String str16 = strConsumerRecord14.key();
        int int17 = strConsumerRecord14.serializedKeySize();
        java.io.Serializable serializable18 = strConsumerRecord14.value();
        long long19 = strConsumerRecord14.offset();
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertEquals("'" + serializable12 + "' != '" + (short) 10 + "'", serializable12, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass13);
        org.junit.Assert.assertNotNull(serializable15);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + (-1) + "'", int17 == (-1));
        org.junit.Assert.assertNotNull(serializable18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
    }

    @Test
    public void test00197() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00197");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, java.lang.reflect.AnnotatedElement> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.reflect.AnnotatedElement> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.reflect.AnnotatedElement>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00198() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00198");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord9.timestampType();
        java.lang.String str12 = strConsumerRecord9.toString();
        int int13 = strConsumerRecord9.partition();
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord15 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (short) 10, (long) (byte) 0, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) timestampType14);
        int int16 = strConsumerRecord15.partition();
        int int17 = strConsumerRecord15.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord15.timestampType();
        int int19 = strConsumerRecord15.partition();
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str12, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 100 + "'", int13 == 100);
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
    }

    @Test
    public void test00199() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00199");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str18 = strConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int31 = strConsumerRecord30.serializedValueSize();
        int int32 = strConsumerRecord30.partition();
        org.apache.kafka.common.header.Headers headers33 = strConsumerRecord30.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int40 = strConsumerRecord39.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional41 = strConsumerRecord39.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType19, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers33, intOptional41);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int54 = strConsumerRecord53.serializedValueSize();
        int int55 = strConsumerRecord53.partition();
        org.apache.kafka.common.header.Headers headers56 = strConsumerRecord53.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType19, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int69 = strConsumerRecord68.serializedValueSize();
        int int70 = strConsumerRecord68.partition();
        long long71 = strConsumerRecord68.offset();
        long long72 = strConsumerRecord68.offset();
        org.apache.kafka.common.header.Headers headers73 = strConsumerRecord68.headers();
        long long74 = strConsumerRecord68.checksum();
        long long75 = strConsumerRecord68.checksum();
        org.apache.kafka.common.header.Headers headers76 = strConsumerRecord68.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0)", (int) (short) 10, 100L, (long) 32, timestampType19, (java.lang.Long) (-1L), (int) (byte) -1, 32, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) "hi!", headers76);
        java.lang.Class<?> wildcardClass78 = strConsumerRecord77.getClass();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "hi!" + "'", str18, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + (-1) + "'", int31 == (-1));
        org.junit.Assert.assertTrue("'" + int32 + "' != '" + 100 + "'", int32 == 100);
        org.junit.Assert.assertNotNull(headers33);
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + (-1) + "'", int40 == (-1));
        org.junit.Assert.assertNotNull(intOptional41);
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + (-1) + "'", int54 == (-1));
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + 100 + "'", int55 == 100);
        org.junit.Assert.assertNotNull(headers56);
        org.junit.Assert.assertTrue("'" + int69 + "' != '" + (-1) + "'", int69 == (-1));
        org.junit.Assert.assertTrue("'" + int70 + "' != '" + 100 + "'", int70 == 100);
        org.junit.Assert.assertTrue("'" + long71 + "' != '" + 52L + "'", long71 == 52L);
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + 52L + "'", long72 == 52L);
        org.junit.Assert.assertNotNull(headers73);
        org.junit.Assert.assertTrue("'" + long74 + "' != '" + (-1L) + "'", long74 == (-1L));
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + (-1L) + "'", long75 == (-1L));
        org.junit.Assert.assertNotNull(headers76);
        org.junit.Assert.assertNotNull(wildcardClass78);
    }

    @Test
    public void test00200() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00200");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int13 = strConsumerRecord12.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional14 = strConsumerRecord12.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str21 = strConsumerRecord20.topic();
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord20.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord12, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType22);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) -1, 100L, (long) 10, timestampType22, 0L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 0.0f);
        int int30 = strConsumerRecord29.partition();
        java.lang.Class<?> wildcardClass31 = strConsumerRecord29.getClass();
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertNotNull(intOptional14);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "hi!" + "'", str21, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertNotNull(wildcardClass31);
    }

    @Test
    public void test00201() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00201");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str14 = strConsumerRecord13.topic();
        java.lang.Class<?> wildcardClass15 = strConsumerRecord13.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", 10, (long) (byte) -1, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (java.io.Serializable) wildcardClass15);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", 35, (long) (short) 1, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0), partition = 10, leaderEpoch = null, offset = 100, NoTimestampType = 32, serialized key size = -1, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = hi!)", (java.io.Serializable) 10);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass15);
    }

    @Test
    public void test00202() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00202");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        java.lang.String str17 = strConsumerRecord13.key();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType29 = strConsumerRecord28.timestampType();
        java.lang.Class<?> wildcardClass30 = strConsumerRecord28.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType18, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass30);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int42 = strConsumerRecord41.serializedValueSize();
        int int43 = strConsumerRecord41.partition();
        long long44 = strConsumerRecord41.offset();
        java.lang.String str45 = strConsumerRecord41.key();
        org.apache.kafka.common.record.TimestampType timestampType46 = strConsumerRecord41.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str57 = strConsumerRecord56.topic();
        org.apache.kafka.common.record.TimestampType timestampType58 = strConsumerRecord56.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int70 = strConsumerRecord69.serializedValueSize();
        int int71 = strConsumerRecord69.partition();
        org.apache.kafka.common.header.Headers headers72 = strConsumerRecord69.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int79 = strConsumerRecord78.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional80 = strConsumerRecord78.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType58, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers72, intOptional80);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 97, (long) 1, (long) (short) 0, timestampType18, (java.lang.Long) 100L, (-1), 0, "hi!", (java.io.Serializable) timestampType46, headers72);
        int int83 = strConsumerRecord82.serializedKeySize();
        java.lang.String str84 = strConsumerRecord82.topic();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType29 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType29.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass30);
        org.junit.Assert.assertTrue("'" + int42 + "' != '" + (-1) + "'", int42 == (-1));
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + 100 + "'", int43 == 100);
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + 52L + "'", long44 == 52L);
        org.junit.Assert.assertEquals("'" + str45 + "' != '" + "" + "'", str45, "");
        org.junit.Assert.assertTrue("'" + timestampType46 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType46.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str57 + "' != '" + "hi!" + "'", str57, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType58 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType58.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int70 + "' != '" + (-1) + "'", int70 == (-1));
        org.junit.Assert.assertTrue("'" + int71 + "' != '" + 100 + "'", int71 == 100);
        org.junit.Assert.assertNotNull(headers72);
        org.junit.Assert.assertTrue("'" + int79 + "' != '" + (-1) + "'", int79 == (-1));
        org.junit.Assert.assertNotNull(intOptional80);
        org.junit.Assert.assertTrue("'" + int83 + "' != '" + (-1) + "'", int83 == (-1));
        org.junit.Assert.assertEquals("'" + str84 + "' != '" + "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)" + "'", str84, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)");
    }

    @Test
    public void test00203() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00203");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        int int15 = strConsumerRecord13.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType16, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) (short) 10, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", (java.io.Serializable) "");
        java.lang.String str24 = strConsumerRecord23.key();
        java.util.Optional<java.lang.Integer> intOptional25 = strConsumerRecord23.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType26 = strConsumerRecord23.timestampType();
        int int27 = strConsumerRecord23.partition();
        java.lang.Class<?> wildcardClass28 = strConsumerRecord23.getClass();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str24 + "' != '" + "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)" + "'", str24, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)");
        org.junit.Assert.assertNotNull(intOptional25);
        org.junit.Assert.assertTrue("'" + timestampType26 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType26.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + 35 + "'", int27 == 35);
        org.junit.Assert.assertNotNull(wildcardClass28);
    }

    @Test
    public void test00204() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00204");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int13 = strConsumerRecord12.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional14 = strConsumerRecord12.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str21 = strConsumerRecord20.topic();
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord20.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord12, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType22);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) -1, 100L, (long) 10, timestampType22, 0L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 0.0f);
        int int30 = strConsumerRecord29.partition();
        int int31 = strConsumerRecord29.serializedKeySize();
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertNotNull(intOptional14);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "hi!" + "'", str21, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 100 + "'", int31 == 100);
    }

    @Test
    public void test00205() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00205");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        long long7 = strConsumerRecord5.checksum();
        long long8 = strConsumerRecord5.timestamp();
        java.util.Optional<java.lang.Integer> intOptional9 = strConsumerRecord5.leaderEpoch();
        java.lang.String str10 = strConsumerRecord5.key();
        int int11 = strConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + (-1L) + "'", long8 == (-1L));
        org.junit.Assert.assertNotNull(intOptional9);
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "" + "'", str10, "");
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
    }

    @Test
    public void test00206() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00206");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, java.lang.reflect.Type> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.reflect.Type> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.reflect.Type>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00207() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00207");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.timestamp();
        int int10 = strConsumerRecord5.serializedKeySize();
        java.io.Serializable serializable11 = strConsumerRecord5.value();
        org.apache.kafka.common.header.Headers headers12 = strConsumerRecord5.headers();
        java.lang.String str13 = strConsumerRecord5.topic();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
        org.junit.Assert.assertEquals("'" + serializable11 + "' != '" + (short) 10 + "'", serializable11, (short) 10);
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
    }

    @Test
    public void test00208() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00208");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord17.timestampType();
        java.lang.String str21 = strConsumerRecord17.key();
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType33 = strConsumerRecord32.timestampType();
        java.lang.Class<?> wildcardClass34 = strConsumerRecord32.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType22, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass34);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType53 = strConsumerRecord52.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) 10, 0L, "hi!", (java.io.Serializable) timestampType53);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType65 = strConsumerRecord64.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int72 = strConsumerRecord71.serializedValueSize();
        int int73 = strConsumerRecord71.partition();
        org.apache.kafka.common.header.Headers headers74 = strConsumerRecord71.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) ' ', 0L, (long) (byte) 10, timestampType53, (java.lang.Long) 0L, 10, (-1), "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (java.io.Serializable) timestampType65, headers74);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int82 = strConsumerRecord81.serializedValueSize();
        int int83 = strConsumerRecord81.partition();
        long long84 = strConsumerRecord81.offset();
        java.lang.String str85 = strConsumerRecord81.key();
        org.apache.kafka.common.record.TimestampType timestampType86 = strConsumerRecord81.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> timestampTypeEnumConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (-1), 100L, (long) (short) 1, timestampType22, (long) (byte) 1, (int) (byte) 10, (int) (short) 1, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType65, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType86);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) (byte) -1, (long) (short) 0, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (java.io.Serializable) "hi!");
        org.apache.kafka.common.record.TimestampType timestampType89 = strConsumerRecord88.timestampType();
        java.lang.String str90 = strConsumerRecord88.key();
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "" + "'", str21, "");
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType33 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType33.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass34);
        org.junit.Assert.assertTrue("'" + timestampType53 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType53.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType65 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType65.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int72 + "' != '" + (-1) + "'", int72 == (-1));
        org.junit.Assert.assertTrue("'" + int73 + "' != '" + 100 + "'", int73 == 100);
        org.junit.Assert.assertNotNull(headers74);
        org.junit.Assert.assertTrue("'" + int82 + "' != '" + (-1) + "'", int82 == (-1));
        org.junit.Assert.assertTrue("'" + int83 + "' != '" + 100 + "'", int83 == 100);
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + 52L + "'", long84 == 52L);
        org.junit.Assert.assertEquals("'" + str85 + "' != '" + "" + "'", str85, "");
        org.junit.Assert.assertTrue("'" + timestampType86 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType86.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType89 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType89.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str90 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)" + "'", str90, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)");
    }

    @Test
    public void test00209() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00209");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", 35, 32L, (long) (short) 10, timestampType11, (long) (short) 100, (int) '#', 0, "", (java.io.Serializable) true);
        java.lang.String str18 = strConsumerRecord17.key();
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
    }

    @Test
    public void test00210() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00210");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, java.io.Serializable> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.io.Serializable> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.io.Serializable>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00211() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00211");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        int int11 = strConsumerRecord9.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType23 = strConsumerRecord22.timestampType();
        int int24 = strConsumerRecord22.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional25 = strConsumerRecord22.leaderEpoch();
        java.lang.String str26 = strConsumerRecord22.toString();
        long long27 = strConsumerRecord22.checksum();
        int int28 = strConsumerRecord22.partition();
        java.lang.Class<?> wildcardClass29 = strConsumerRecord22.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers36 = strConsumerRecord35.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType43 = strConsumerRecord42.timestampType();
        int int44 = strConsumerRecord42.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional45 = strConsumerRecord42.leaderEpoch();
        java.lang.String str46 = strConsumerRecord42.toString();
        java.util.Optional<java.lang.Integer> intOptional47 = strConsumerRecord42.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0), partition = 10, leaderEpoch = null, offset = 100, NoTimestampType = 32, serialized key size = -1, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = hi!)", 52, (long) '#', (long) (short) 1, timestampType12, (java.lang.Long) 0L, (int) (short) -1, 10, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", (java.io.Serializable) wildcardClass29, headers36, intOptional47);
        java.lang.Class<?> wildcardClass49 = timestampType12.getClass();
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
        org.junit.Assert.assertNotNull(intOptional25);
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str26, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + (-1L) + "'", long27 == (-1L));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 100 + "'", int28 == 100);
        org.junit.Assert.assertNotNull(wildcardClass29);
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertTrue("'" + timestampType43 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType43.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int44 + "' != '" + (-1) + "'", int44 == (-1));
        org.junit.Assert.assertNotNull(intOptional45);
        org.junit.Assert.assertEquals("'" + str46 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str46, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional47);
        org.junit.Assert.assertNotNull(wildcardClass49);
    }

    @Test
    public void test00212() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00212");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.toString();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord5.leaderEpoch();
        long long11 = strConsumerRecord5.offset();
        int int12 = strConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional13 = strConsumerRecord5.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional14 = strConsumerRecord5.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional15 = strConsumerRecord5.leaderEpoch();
        long long16 = strConsumerRecord5.checksum();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNotNull(intOptional14);
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
    }

    @Test
    public void test00213() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00213");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        org.apache.kafka.common.header.Headers headers7 = strConsumerRecord5.headers();
        int int8 = strConsumerRecord5.serializedKeySize();
        org.apache.kafka.common.header.Headers headers9 = strConsumerRecord5.headers();
        org.apache.kafka.common.header.Headers headers10 = strConsumerRecord5.headers();
        long long11 = strConsumerRecord5.timestamp();
        java.lang.String str12 = strConsumerRecord5.key();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertNotNull(headers7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNotNull(headers9);
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
    }

    @Test
    public void test00214() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00214");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int24 = strConsumerRecord23.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional25 = strConsumerRecord23.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str32 = strConsumerRecord31.topic();
        org.apache.kafka.common.record.TimestampType timestampType33 = strConsumerRecord31.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord23, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType33);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord40 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) -1, 100L, (long) 10, timestampType33, 0L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 0.0f);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType50 = strConsumerRecord49.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType51 = strConsumerRecord49.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType52 = strConsumerRecord49.timestampType();
        java.lang.Object obj53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object> timestampTypeConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object>("", 0, (long) (byte) 100, (long) (byte) -1, timestampType33, (long) (byte) 100, (int) (short) 10, (int) (short) -1, timestampType52, obj53);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (short) 10, (-1L), 10L, timestampType52, 35L, 100, 0, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", (java.io.Serializable) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 1, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = #)");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord66 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int67 = strConsumerRecord66.serializedValueSize();
        int int68 = strConsumerRecord66.partition();
        long long69 = strConsumerRecord66.offset();
        long long70 = strConsumerRecord66.offset();
        long long71 = strConsumerRecord66.checksum();
        long long72 = strConsumerRecord66.checksum();
        org.apache.kafka.common.header.Headers headers73 = strConsumerRecord66.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.Iterable<org.apache.kafka.common.header.Header>> serializableConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.Iterable<org.apache.kafka.common.header.Header>>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0), partition = 32, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)", (int) (byte) 1, (long) (short) 100, (java.io.Serializable) "", (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers73);
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
        org.junit.Assert.assertNotNull(intOptional25);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "hi!" + "'", str32, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType33 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType33.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType50 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType50.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType51 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType51.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType52 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType52.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + (-1) + "'", int67 == (-1));
        org.junit.Assert.assertTrue("'" + int68 + "' != '" + 100 + "'", int68 == 100);
        org.junit.Assert.assertTrue("'" + long69 + "' != '" + 52L + "'", long69 == 52L);
        org.junit.Assert.assertTrue("'" + long70 + "' != '" + 52L + "'", long70 == 52L);
        org.junit.Assert.assertTrue("'" + long71 + "' != '" + (-1L) + "'", long71 == (-1L));
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + (-1L) + "'", long72 == (-1L));
        org.junit.Assert.assertNotNull(headers73);
    }

    @Test
    public void test00215() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00215");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str14 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int27 = strConsumerRecord26.serializedValueSize();
        int int28 = strConsumerRecord26.partition();
        org.apache.kafka.common.header.Headers headers29 = strConsumerRecord26.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType15, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers29, intOptional37);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int50 = strConsumerRecord49.serializedValueSize();
        int int51 = strConsumerRecord49.partition();
        org.apache.kafka.common.header.Headers headers52 = strConsumerRecord49.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType15, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers52);
        long long54 = strConsumerRecord53.offset();
        java.io.Serializable serializable55 = strConsumerRecord53.value();
        java.io.Serializable serializable56 = strConsumerRecord53.value();
        java.util.Optional<java.lang.Integer> intOptional57 = strConsumerRecord53.leaderEpoch();
        long long58 = strConsumerRecord53.offset();
        long long59 = strConsumerRecord53.timestamp();
        java.io.Serializable serializable60 = strConsumerRecord53.value();
        long long61 = strConsumerRecord53.offset();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 100 + "'", int28 == 100);
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + (-1) + "'", int50 == (-1));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 100 + "'", int51 == 100);
        org.junit.Assert.assertNotNull(headers52);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + 1L + "'", long54 == 1L);
        org.junit.Assert.assertEquals("'" + serializable55 + "' != '" + (-1.0d) + "'", serializable55, (-1.0d));
        org.junit.Assert.assertEquals("'" + serializable56 + "' != '" + (-1.0d) + "'", serializable56, (-1.0d));
        org.junit.Assert.assertNotNull(intOptional57);
        org.junit.Assert.assertTrue("'" + long58 + "' != '" + 1L + "'", long58 == 1L);
        org.junit.Assert.assertTrue("'" + long59 + "' != '" + 0L + "'", long59 == 0L);
        org.junit.Assert.assertEquals("'" + serializable60 + "' != '" + (-1.0d) + "'", serializable60, (-1.0d));
        org.junit.Assert.assertTrue("'" + long61 + "' != '" + 1L + "'", long61 == 1L);
    }

    @Test
    public void test00216() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00216");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str17 = strConsumerRecord16.topic();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord16.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int30 = strConsumerRecord29.serializedValueSize();
        int int31 = strConsumerRecord29.partition();
        org.apache.kafka.common.header.Headers headers32 = strConsumerRecord29.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int39 = strConsumerRecord38.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional40 = strConsumerRecord38.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType18, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers32, intOptional40);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int53 = strConsumerRecord52.serializedValueSize();
        int int54 = strConsumerRecord52.partition();
        org.apache.kafka.common.header.Headers headers55 = strConsumerRecord52.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType18, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers55);
        long long57 = strConsumerRecord56.checksum();
        java.lang.Class<?> wildcardClass58 = strConsumerRecord56.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int65 = strConsumerRecord64.serializedValueSize();
        int int66 = strConsumerRecord64.partition();
        java.lang.String str67 = strConsumerRecord64.topic();
        long long68 = strConsumerRecord64.checksum();
        int int69 = strConsumerRecord64.serializedValueSize();
        org.apache.kafka.common.header.Headers headers70 = strConsumerRecord64.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.Iterable<org.apache.kafka.common.header.Header>> genericDeclarationConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.Iterable<org.apache.kafka.common.header.Header>>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) ' ', (long) '4', (java.lang.reflect.GenericDeclaration) wildcardClass58, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers70);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 100 + "'", int31 == 100);
        org.junit.Assert.assertNotNull(headers32);
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + (-1) + "'", int39 == (-1));
        org.junit.Assert.assertNotNull(intOptional40);
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + (-1) + "'", int53 == (-1));
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + 100 + "'", int54 == 100);
        org.junit.Assert.assertNotNull(headers55);
        org.junit.Assert.assertTrue("'" + long57 + "' != '" + 52L + "'", long57 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass58);
        org.junit.Assert.assertTrue("'" + int65 + "' != '" + (-1) + "'", int65 == (-1));
        org.junit.Assert.assertTrue("'" + int66 + "' != '" + 100 + "'", int66 == 100);
        org.junit.Assert.assertEquals("'" + str67 + "' != '" + "hi!" + "'", str67, "hi!");
        org.junit.Assert.assertTrue("'" + long68 + "' != '" + (-1L) + "'", long68 == (-1L));
        org.junit.Assert.assertTrue("'" + int69 + "' != '" + (-1) + "'", int69 == (-1));
        org.junit.Assert.assertNotNull(headers70);
    }

    @Test
    public void test00217() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00217");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        long long7 = strConsumerRecord5.checksum();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType9 = strConsumerRecord5.timestampType();
        java.lang.String str10 = strConsumerRecord5.topic();
        java.util.Optional<java.lang.Integer> intOptional11 = strConsumerRecord5.leaderEpoch();
        int int12 = strConsumerRecord5.partition();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertTrue("'" + timestampType9 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType9.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "hi!" + "'", str10, "hi!");
        org.junit.Assert.assertNotNull(intOptional11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
    }

    @Test
    public void test00218() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00218");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.toString();
        long long10 = strConsumerRecord5.offset();
        java.lang.String str11 = strConsumerRecord5.toString();
        long long12 = strConsumerRecord5.offset();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 52L + "'", long10 == 52L);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str11, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
    }

    @Test
    public void test00219() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00219");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        java.lang.String str17 = strConsumerRecord13.key();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType29 = strConsumerRecord28.timestampType();
        java.lang.Class<?> wildcardClass30 = strConsumerRecord28.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType18, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass30);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str42 = strConsumerRecord41.topic();
        java.lang.Class<?> wildcardClass43 = strConsumerRecord41.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) -1, 100L, (long) 0, timestampType18, (long) (short) 1, (int) '#', 0, "hi!", (java.io.Serializable) wildcardClass43);
        java.io.Serializable serializable45 = strConsumerRecord44.value();
        long long46 = strConsumerRecord44.timestamp();
        int int47 = strConsumerRecord44.serializedKeySize();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType29 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType29.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass30);
        org.junit.Assert.assertEquals("'" + str42 + "' != '" + "hi!" + "'", str42, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass43);
        org.junit.Assert.assertNotNull(serializable45);
        org.junit.Assert.assertTrue("'" + long46 + "' != '" + 0L + "'", long46 == 0L);
        org.junit.Assert.assertTrue("'" + int47 + "' != '" + 35 + "'", int47 == 35);
    }

    @Test
    public void test00220() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00220");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.String> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.String> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.String>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00221() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00221");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType7 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.key();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        int int11 = strConsumerRecord5.partition();
        org.apache.kafka.common.header.Headers headers12 = strConsumerRecord5.headers();
        long long13 = strConsumerRecord5.timestamp();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "" + "'", str9, "");
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
    }

    @Test
    public void test00222() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00222");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00223() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00223");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, java.lang.CharSequence> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.CharSequence> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.CharSequence>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00224() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00224");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long19 = strConsumerRecord18.timestamp();
        long long20 = strConsumerRecord18.checksum();
        java.util.Optional<java.lang.Integer> intOptional21 = strConsumerRecord18.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord18.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int32 = strConsumerRecord31.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional33 = strConsumerRecord31.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int40 = strConsumerRecord39.serializedValueSize();
        int int41 = strConsumerRecord39.partition();
        java.lang.Class<?> wildcardClass42 = strConsumerRecord39.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType52 = strConsumerRecord51.timestampType();
        int int53 = strConsumerRecord51.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional54 = strConsumerRecord51.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long61 = strConsumerRecord60.timestamp();
        int int62 = strConsumerRecord60.partition();
        java.lang.String str63 = strConsumerRecord60.topic();
        long long64 = strConsumerRecord60.offset();
        java.io.Serializable serializable65 = strConsumerRecord60.value();
        java.lang.String str66 = strConsumerRecord60.topic();
        org.apache.kafka.common.header.Headers headers67 = strConsumerRecord60.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.Iterable<org.apache.kafka.common.header.Header>> intOptionalConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.Iterable<org.apache.kafka.common.header.Header>>("", (int) (short) 10, (long) (short) 1, intOptional54, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers67);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int78 = strConsumerRecord77.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional79 = strConsumerRecord77.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str86 = strConsumerRecord85.topic();
        org.apache.kafka.common.record.TimestampType timestampType87 = strConsumerRecord85.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord77, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType87);
        int int89 = strConsumerRecord77.serializedValueSize();
        java.lang.String str90 = strConsumerRecord77.key();
        java.lang.String str91 = strConsumerRecord77.key();
        java.util.Optional<java.lang.Integer> intOptional92 = strConsumerRecord77.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.reflect.GenericDeclaration> intOptionalConsumerRecord93 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (-1), (long) 100, (long) (-1), timestampType22, (java.lang.Long) 10L, 0, (int) (byte) 10, intOptional33, (java.lang.reflect.GenericDeclaration) wildcardClass42, headers67, intOptional92);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord94 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) (byte) 10, (long) '#', (-1L), timestampType4, (long) ' ', (int) (byte) 10, 1, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)", (java.io.Serializable) (-1));
        java.lang.Class<?> wildcardClass95 = strConsumerRecord94.getClass();
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
        org.junit.Assert.assertNotNull(intOptional21);
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int32 + "' != '" + (-1) + "'", int32 == (-1));
        org.junit.Assert.assertNotNull(intOptional33);
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + (-1) + "'", int40 == (-1));
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + 100 + "'", int41 == 100);
        org.junit.Assert.assertNotNull(wildcardClass42);
        org.junit.Assert.assertTrue("'" + timestampType52 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType52.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + (-1) + "'", int53 == (-1));
        org.junit.Assert.assertNotNull(intOptional54);
        org.junit.Assert.assertTrue("'" + long61 + "' != '" + (-1L) + "'", long61 == (-1L));
        org.junit.Assert.assertTrue("'" + int62 + "' != '" + 100 + "'", int62 == 100);
        org.junit.Assert.assertEquals("'" + str63 + "' != '" + "hi!" + "'", str63, "hi!");
        org.junit.Assert.assertTrue("'" + long64 + "' != '" + 52L + "'", long64 == 52L);
        org.junit.Assert.assertEquals("'" + serializable65 + "' != '" + (short) 10 + "'", serializable65, (short) 10);
        org.junit.Assert.assertEquals("'" + str66 + "' != '" + "hi!" + "'", str66, "hi!");
        org.junit.Assert.assertNotNull(headers67);
        org.junit.Assert.assertTrue("'" + int78 + "' != '" + (-1) + "'", int78 == (-1));
        org.junit.Assert.assertNotNull(intOptional79);
        org.junit.Assert.assertEquals("'" + str86 + "' != '" + "hi!" + "'", str86, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType87 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType87.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int89 + "' != '" + (-1) + "'", int89 == (-1));
        org.junit.Assert.assertEquals("'" + str90 + "' != '" + "" + "'", str90, "");
        org.junit.Assert.assertEquals("'" + str91 + "' != '" + "" + "'", str91, "");
        org.junit.Assert.assertNotNull(intOptional92);
        org.junit.Assert.assertNotNull(wildcardClass95);
    }

    @Test
    public void test00225() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00225");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str14 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int27 = strConsumerRecord26.serializedValueSize();
        int int28 = strConsumerRecord26.partition();
        org.apache.kafka.common.header.Headers headers29 = strConsumerRecord26.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType15, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers29, intOptional37);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int50 = strConsumerRecord49.serializedValueSize();
        int int51 = strConsumerRecord49.partition();
        org.apache.kafka.common.header.Headers headers52 = strConsumerRecord49.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType15, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers52);
        long long54 = strConsumerRecord53.offset();
        java.lang.String str55 = strConsumerRecord53.topic();
        long long56 = strConsumerRecord53.offset();
        int int57 = strConsumerRecord53.serializedValueSize();
        int int58 = strConsumerRecord53.serializedValueSize();
        int int59 = strConsumerRecord53.serializedKeySize();
        java.lang.String str60 = strConsumerRecord53.topic();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 100 + "'", int28 == 100);
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + (-1) + "'", int50 == (-1));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 100 + "'", int51 == 100);
        org.junit.Assert.assertNotNull(headers52);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + 1L + "'", long54 == 1L);
        org.junit.Assert.assertEquals("'" + str55 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str55, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + 1L + "'", long56 == 1L);
        org.junit.Assert.assertTrue("'" + int57 + "' != '" + 1 + "'", int57 == 1);
        org.junit.Assert.assertTrue("'" + int58 + "' != '" + 1 + "'", int58 == 1);
        org.junit.Assert.assertTrue("'" + int59 + "' != '" + 100 + "'", int59 == 100);
        org.junit.Assert.assertEquals("'" + str60 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str60, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
    }

    @Test
    public void test00226() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00226");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        long long7 = strConsumerRecord5.timestamp();
        java.io.Serializable serializable8 = strConsumerRecord5.value();
        org.apache.kafka.common.record.TimestampType timestampType9 = strConsumerRecord5.timestampType();
        int int10 = strConsumerRecord5.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable8 + "' != '" + (short) 10 + "'", serializable8, (short) 10);
        org.junit.Assert.assertTrue("'" + timestampType9 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType9.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
    }

    @Test
    public void test00227() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00227");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.lang.Iterable<org.apache.kafka.common.header.Header>> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.Iterable<org.apache.kafka.common.header.Header>> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.Iterable<org.apache.kafka.common.header.Header>>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00228() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00228");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.util.Optional<java.lang.Integer>> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.util.Optional<java.lang.Integer>> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.util.Optional<java.lang.Integer>>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00229() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00229");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord9.timestampType();
        java.io.Serializable serializable16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int23 = strConsumerRecord22.serializedValueSize();
        int int24 = strConsumerRecord22.partition();
        long long25 = strConsumerRecord22.offset();
        long long26 = strConsumerRecord22.offset();
        org.apache.kafka.common.record.TimestampType timestampType27 = strConsumerRecord22.timestampType();
        java.lang.String str28 = strConsumerRecord22.toString();
        org.apache.kafka.common.header.Headers headers29 = strConsumerRecord22.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        int int37 = strConsumerRecord35.partition();
        long long38 = strConsumerRecord35.offset();
        long long39 = strConsumerRecord35.offset();
        org.apache.kafka.common.header.Headers headers40 = strConsumerRecord35.headers();
        long long41 = strConsumerRecord35.checksum();
        int int42 = strConsumerRecord35.serializedKeySize();
        int int43 = strConsumerRecord35.serializedValueSize();
        long long44 = strConsumerRecord35.offset();
        java.util.Optional<java.lang.Integer> intOptional45 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", 0, 35L, 100L, timestampType11, (java.lang.Long) 52L, 10, (int) (byte) 10, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", serializable16, headers29, intOptional45);
        java.lang.Class<?> wildcardClass47 = headers29.getClass();
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + 100 + "'", int24 == 100);
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + 52L + "'", long25 == 52L);
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + 52L + "'", long26 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType27 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType27.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str28 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str28, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + 100 + "'", int37 == 100);
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + 52L + "'", long38 == 52L);
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + 52L + "'", long39 == 52L);
        org.junit.Assert.assertNotNull(headers40);
        org.junit.Assert.assertTrue("'" + long41 + "' != '" + (-1L) + "'", long41 == (-1L));
        org.junit.Assert.assertTrue("'" + int42 + "' != '" + (-1) + "'", int42 == (-1));
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + (-1) + "'", int43 == (-1));
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + 52L + "'", long44 == 52L);
        org.junit.Assert.assertNotNull(intOptional45);
        org.junit.Assert.assertNotNull(wildcardClass47);
    }

    @Test
    public void test00230() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00230");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.toString();
        long long10 = strConsumerRecord5.offset();
        java.lang.String str11 = strConsumerRecord5.toString();
        java.lang.Class<?> wildcardClass12 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 52L + "'", long10 == 52L);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str11, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(wildcardClass12);
    }

    @Test
    public void test00231() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00231");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        int int7 = strConsumerRecord5.partition();
        java.io.Serializable serializable8 = strConsumerRecord5.value();
        int int9 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        long long11 = strConsumerRecord5.checksum();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + serializable8 + "' != '" + (short) 10 + "'", serializable8, (short) 10);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
    }

    @Test
    public void test00232() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00232");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long14 = strConsumerRecord13.timestamp();
        int int15 = strConsumerRecord13.partition();
        java.lang.String str16 = strConsumerRecord13.topic();
        long long17 = strConsumerRecord13.offset();
        java.io.Serializable serializable18 = strConsumerRecord13.value();
        java.lang.String str19 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType31 = strConsumerRecord30.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 0, (long) '4', (long) (byte) -1, timestampType20, (long) 10, (int) (short) 0, 0, "hi!", (java.io.Serializable) timestampType31);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType47 = strConsumerRecord46.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType48 = strConsumerRecord46.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord62 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType63 = strConsumerRecord62.timestampType();
        int int64 = strConsumerRecord62.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType65 = strConsumerRecord62.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType65, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", 100, (long) 0, 1L, timestampType48, (long) (short) 1, (int) (byte) 1, (int) (short) 1, "hi!", (java.io.Serializable) '#');
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) '4', (long) (byte) 1, (long) '#', timestampType31, (long) (short) 100, 0, (int) ' ', "hi!", (java.io.Serializable) 1L);
        org.apache.kafka.common.record.TimestampType timestampType74 = strConsumerRecord73.timestampType();
        int int75 = strConsumerRecord73.serializedKeySize();
        java.lang.Class<?> wildcardClass76 = strConsumerRecord73.getClass();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "hi!" + "'", str16, "hi!");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertEquals("'" + serializable18 + "' != '" + (short) 10 + "'", serializable18, (short) 10);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType47 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType47.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType48 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType48.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType63 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType63.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int64 + "' != '" + (-1) + "'", int64 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType65 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType65.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType74 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType74.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int75 + "' != '" + 0 + "'", int75 == 0);
        org.junit.Assert.assertNotNull(wildcardClass76);
    }

    @Test
    public void test00233() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00233");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedKeySize();
        int int8 = strConsumerRecord5.partition();
        java.io.Serializable serializable9 = strConsumerRecord5.value();
        int int10 = strConsumerRecord5.serializedValueSize();
        int int11 = strConsumerRecord5.partition();
        int int12 = strConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 100 + "'", int8 == 100);
        org.junit.Assert.assertEquals("'" + serializable9 + "' != '" + (short) 10 + "'", serializable9, (short) 10);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
    }

    @Test
    public void test00234() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00234");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0), partition = 32, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)", (-1), (long) (short) 10, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 1, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = #)", (java.io.Serializable) true);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 10L + "'", long8 == 10L);
    }

    @Test
    public void test00235() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00235");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional7 = strConsumerRecord5.leaderEpoch();
        java.lang.String str8 = strConsumerRecord5.key();
        long long9 = strConsumerRecord5.offset();
        java.lang.String str10 = strConsumerRecord5.toString();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord5.timestampType();
        int int12 = strConsumerRecord5.partition();
        long long13 = strConsumerRecord5.offset();
        java.io.Serializable serializable14 = strConsumerRecord5.value();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "" + "'", str8, "");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str10, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + (short) 10 + "'", serializable14, (short) 10);
    }

    @Test
    public void test00236() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00236");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        int int15 = strConsumerRecord13.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType16, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", 0, 1L, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional24 = strConsumerRecord23.leaderEpoch();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(intOptional24);
    }

    @Test
    public void test00237() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00237");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord15 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) 10, 0L, "hi!", (java.io.Serializable) timestampType14);
        java.lang.String str16 = strConsumerRecord15.topic();
        org.apache.kafka.common.record.TimestampType timestampType17 = strConsumerRecord15.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType28 = strConsumerRecord27.timestampType();
        int int29 = strConsumerRecord27.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType30 = strConsumerRecord27.timestampType();
        java.lang.String str31 = strConsumerRecord27.toString();
        java.util.Optional<java.lang.Integer> intOptional32 = strConsumerRecord27.leaderEpoch();
        long long33 = strConsumerRecord27.offset();
        org.apache.kafka.common.record.TimestampType timestampType34 = strConsumerRecord27.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord40 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long41 = strConsumerRecord40.timestamp();
        int int42 = strConsumerRecord40.partition();
        java.lang.String str43 = strConsumerRecord40.topic();
        long long44 = strConsumerRecord40.offset();
        org.apache.kafka.common.header.Headers headers45 = strConsumerRecord40.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", 97, 0L, (long) (short) 100, timestampType17, (java.lang.Long) 52L, (int) (byte) 100, 32, "", (java.io.Serializable) timestampType34, headers45);
        long long47 = strConsumerRecord46.timestamp();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str16, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + timestampType17 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType17.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType28 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType28.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int29 + "' != '" + (-1) + "'", int29 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType30 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType30.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str31 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str31, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional32);
        org.junit.Assert.assertTrue("'" + long33 + "' != '" + 52L + "'", long33 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType34 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType34.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long41 + "' != '" + (-1L) + "'", long41 == (-1L));
        org.junit.Assert.assertTrue("'" + int42 + "' != '" + 100 + "'", int42 == 100);
        org.junit.Assert.assertEquals("'" + str43 + "' != '" + "hi!" + "'", str43, "hi!");
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + 52L + "'", long44 == 52L);
        org.junit.Assert.assertNotNull(headers45);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 100L + "'", long47 == 100L);
    }

    @Test
    public void test00238() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00238");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long18 = strConsumerRecord17.timestamp();
        int int19 = strConsumerRecord17.partition();
        java.lang.String str20 = strConsumerRecord17.topic();
        long long21 = strConsumerRecord17.offset();
        java.io.Serializable serializable22 = strConsumerRecord17.value();
        java.lang.String str23 = strConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType24 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType35 = strConsumerRecord34.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 0, (long) '4', (long) (byte) -1, timestampType24, (long) 10, (int) (short) 0, 0, "hi!", (java.io.Serializable) timestampType35);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType51 = strConsumerRecord50.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType52 = strConsumerRecord50.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord66 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType67 = strConsumerRecord66.timestampType();
        int int68 = strConsumerRecord66.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType69 = strConsumerRecord66.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType69, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", 100, (long) 0, 1L, timestampType52, (long) (short) 1, (int) (byte) 1, (int) (short) 1, "hi!", (java.io.Serializable) '#');
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) '4', (long) (byte) 1, (long) '#', timestampType35, (long) (short) 100, 0, (int) ' ', "hi!", (java.io.Serializable) 1L);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType89 = strConsumerRecord88.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType90 = strConsumerRecord88.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType91 = strConsumerRecord88.timestampType();
        java.lang.String str92 = strConsumerRecord88.key();
        long long93 = strConsumerRecord88.timestamp();
        long long94 = strConsumerRecord88.offset();
        java.lang.String str95 = strConsumerRecord88.toString();
        long long96 = strConsumerRecord88.checksum();
        org.apache.kafka.common.header.Headers headers97 = strConsumerRecord88.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", 10, (long) (byte) 1, (long) (short) 10, timestampType35, (java.lang.Long) 1L, (int) (byte) 10, 0, "hi!", (java.io.Serializable) 52L, headers97);
        long long99 = strConsumerRecord98.offset();
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 100 + "'", int19 == 100);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertEquals("'" + serializable22 + "' != '" + (short) 10 + "'", serializable22, (short) 10);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "hi!" + "'", str23, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType24 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType24.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType35 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType35.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType51 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType51.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType52 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType52.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType67 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType67.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int68 + "' != '" + (-1) + "'", int68 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType69 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType69.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType89 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType89.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType90 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType90.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType91 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType91.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str92 + "' != '" + "" + "'", str92, "");
        org.junit.Assert.assertTrue("'" + long93 + "' != '" + (-1L) + "'", long93 == (-1L));
        org.junit.Assert.assertTrue("'" + long94 + "' != '" + 52L + "'", long94 == 52L);
        org.junit.Assert.assertEquals("'" + str95 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str95, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long96 + "' != '" + (-1L) + "'", long96 == (-1L));
        org.junit.Assert.assertNotNull(headers97);
        org.junit.Assert.assertTrue("'" + long99 + "' != '" + 1L + "'", long99 == 1L);
    }

    @Test
    public void test00239() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00239");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.Comparable<java.lang.String>> strConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.Comparable<java.lang.String>> strConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.Comparable<java.lang.String>>(strConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00240() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00240");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        int int7 = strConsumerRecord5.partition();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        int int9 = strConsumerRecord5.serializedKeySize();
        long long10 = strConsumerRecord5.checksum();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord5.timestampType();
        java.lang.String str12 = strConsumerRecord5.toString();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str12, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
    }

    @Test
    public void test00241() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00241");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00242() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00242");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, java.lang.Iterable<org.apache.kafka.common.header.Header>> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.Iterable<org.apache.kafka.common.header.Header>> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.Iterable<org.apache.kafka.common.header.Header>>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00243() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00243");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord19.timestampType();
        int int21 = strConsumerRecord19.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord19.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType22, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long38 = strConsumerRecord37.timestamp();
        int int39 = strConsumerRecord37.partition();
        java.io.Serializable serializable40 = strConsumerRecord37.value();
        java.lang.Class<?> wildcardClass41 = serializable40.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long48 = strConsumerRecord47.timestamp();
        int int49 = strConsumerRecord47.partition();
        java.lang.String str50 = strConsumerRecord47.topic();
        long long51 = strConsumerRecord47.offset();
        java.lang.Class<?> wildcardClass52 = strConsumerRecord47.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration> typeConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration>("hi!", (int) (short) 0, (long) (byte) 1, 10L, timestampType22, (long) (byte) 10, (int) 'a', (int) (short) -1, (java.lang.reflect.Type) wildcardClass41, (java.lang.reflect.GenericDeclaration) wildcardClass52);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord66 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int67 = strConsumerRecord66.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional68 = strConsumerRecord66.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str75 = strConsumerRecord74.topic();
        org.apache.kafka.common.record.TimestampType timestampType76 = strConsumerRecord74.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord66, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType76);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) -1, 100L, (long) 10, timestampType76, 0L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 0.0f);
        java.lang.Class<?> wildcardClass84 = strConsumerRecord83.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.AnnotatedElement> typeConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = 100, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 100)", 100, 35L, (java.lang.reflect.Type) wildcardClass52, (java.lang.reflect.AnnotatedElement) wildcardClass84);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord91 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType92 = strConsumerRecord91.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType93 = strConsumerRecord91.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType94 = strConsumerRecord91.timestampType();
        java.lang.String str95 = strConsumerRecord91.key();
        org.apache.kafka.common.record.TimestampType timestampType96 = strConsumerRecord91.timestampType();
        int int97 = strConsumerRecord91.partition();
        org.apache.kafka.common.header.Headers headers98 = strConsumerRecord91.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers> annotatedElementConsumerRecord99 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers>("ConsumerRecord(topic = , partition = 35, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), value = )", (int) ' ', (long) (byte) 10, (java.lang.reflect.AnnotatedElement) wildcardClass84, headers98);
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + (-1L) + "'", long38 == (-1L));
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + 100 + "'", int39 == 100);
        org.junit.Assert.assertEquals("'" + serializable40 + "' != '" + (short) 10 + "'", serializable40, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass41);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 100 + "'", int49 == 100);
        org.junit.Assert.assertEquals("'" + str50 + "' != '" + "hi!" + "'", str50, "hi!");
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + 52L + "'", long51 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass52);
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + (-1) + "'", int67 == (-1));
        org.junit.Assert.assertNotNull(intOptional68);
        org.junit.Assert.assertEquals("'" + str75 + "' != '" + "hi!" + "'", str75, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType76 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType76.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass84);
        org.junit.Assert.assertTrue("'" + timestampType92 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType92.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType93 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType93.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType94 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType94.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str95 + "' != '" + "" + "'", str95, "");
        org.junit.Assert.assertTrue("'" + timestampType96 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType96.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int97 + "' != '" + 100 + "'", int97 == 100);
        org.junit.Assert.assertNotNull(headers98);
    }

    @Test
    public void test00244() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00244");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.lang.CharSequence> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.CharSequence> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.CharSequence>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00245() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00245");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str14 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int27 = strConsumerRecord26.serializedValueSize();
        int int28 = strConsumerRecord26.partition();
        org.apache.kafka.common.header.Headers headers29 = strConsumerRecord26.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType15, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers29, intOptional37);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int49 = strConsumerRecord48.serializedValueSize();
        int int50 = strConsumerRecord48.partition();
        long long51 = strConsumerRecord48.offset();
        java.lang.String str52 = strConsumerRecord48.key();
        org.apache.kafka.common.record.TimestampType timestampType53 = strConsumerRecord48.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (short) 1, (long) (byte) 10, (long) 'a', timestampType15, 1L, (int) (byte) -1, (int) (byte) 10, "hi!", (java.io.Serializable) timestampType53);
        java.lang.Class<?> wildcardClass55 = strConsumerRecord54.getClass();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 100 + "'", int28 == 100);
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + (-1) + "'", int49 == (-1));
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + 100 + "'", int50 == 100);
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + 52L + "'", long51 == 52L);
        org.junit.Assert.assertEquals("'" + str52 + "' != '" + "" + "'", str52, "");
        org.junit.Assert.assertTrue("'" + timestampType53 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType53.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass55);
    }

    @Test
    public void test00246() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00246");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        org.apache.kafka.common.header.Headers headers7 = strConsumerRecord5.headers();
        int int8 = strConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional9 = strConsumerRecord5.leaderEpoch();
        java.lang.Class<?> wildcardClass10 = strConsumerRecord5.getClass();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertNotNull(headers7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNotNull(intOptional9);
        org.junit.Assert.assertNotNull(wildcardClass10);
    }

    @Test
    public void test00247() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00247");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, org.apache.kafka.common.header.Headers> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, org.apache.kafka.common.header.Headers> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, org.apache.kafka.common.header.Headers>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00248() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00248");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.io.Serializable> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.io.Serializable> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.io.Serializable>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00249() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00249");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, org.apache.kafka.common.record.TimestampType> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, org.apache.kafka.common.record.TimestampType> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, org.apache.kafka.common.record.TimestampType>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00250() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00250");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord9.timestampType();
        java.lang.String str12 = strConsumerRecord9.toString();
        int int13 = strConsumerRecord9.partition();
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord15 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (short) 10, (long) (byte) 0, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) timestampType14);
        java.lang.Class<?> wildcardClass16 = strConsumerRecord15.getClass();
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str12, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 100 + "'", int13 == 100);
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass16);
    }

    @Test
    public void test00251() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00251");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        org.apache.kafka.common.header.Headers headers10 = strConsumerRecord5.headers();
        long long11 = strConsumerRecord5.checksum();
        int int12 = strConsumerRecord5.serializedKeySize();
        int int13 = strConsumerRecord5.serializedValueSize();
        int int14 = strConsumerRecord5.partition();
        java.lang.Class<?> wildcardClass15 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 100 + "'", int14 == 100);
        org.junit.Assert.assertNotNull(wildcardClass15);
    }

    @Test
    public void test00252() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00252");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord21.timestampType();
        int int23 = strConsumerRecord21.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType24 = strConsumerRecord21.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType24, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long40 = strConsumerRecord39.timestamp();
        int int41 = strConsumerRecord39.partition();
        java.io.Serializable serializable42 = strConsumerRecord39.value();
        java.lang.Class<?> wildcardClass43 = serializable42.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long50 = strConsumerRecord49.timestamp();
        int int51 = strConsumerRecord49.partition();
        java.lang.String str52 = strConsumerRecord49.topic();
        long long53 = strConsumerRecord49.offset();
        java.lang.Class<?> wildcardClass54 = strConsumerRecord49.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration> typeConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration>("hi!", (int) (short) 0, (long) (byte) 1, 10L, timestampType24, (long) (byte) 10, (int) 'a', (int) (short) -1, (java.lang.reflect.Type) wildcardClass43, (java.lang.reflect.GenericDeclaration) wildcardClass54);
        java.io.Serializable serializable60 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 100, 0L, 0L, timestampType24, (long) 10, (int) '#', 10, "hi!", serializable60);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord62 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", (int) (byte) 100, (long) (short) -1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", serializable60);
        int int63 = strConsumerRecord62.partition();
        java.lang.String str64 = strConsumerRecord62.toString();
        long long65 = strConsumerRecord62.checksum();
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType24 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType24.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + 100 + "'", int41 == 100);
        org.junit.Assert.assertEquals("'" + serializable42 + "' != '" + (short) 10 + "'", serializable42, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass43);
        org.junit.Assert.assertTrue("'" + long50 + "' != '" + (-1L) + "'", long50 == (-1L));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 100 + "'", int51 == 100);
        org.junit.Assert.assertEquals("'" + str52 + "' != '" + "hi!" + "'", str52, "hi!");
        org.junit.Assert.assertTrue("'" + long53 + "' != '" + 52L + "'", long53 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass54);
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 100 + "'", int63 == 100);
        org.junit.Assert.assertEquals("'" + str64 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = null)" + "'", str64, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = null)");
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + (-1L) + "'", long65 == (-1L));
    }

    @Test
    public void test00253() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00253");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long18 = strConsumerRecord17.timestamp();
        int int19 = strConsumerRecord17.partition();
        java.lang.String str20 = strConsumerRecord17.topic();
        long long21 = strConsumerRecord17.offset();
        java.io.Serializable serializable22 = strConsumerRecord17.value();
        java.lang.String str23 = strConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType24 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType35 = strConsumerRecord34.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 0, (long) '4', (long) (byte) -1, timestampType24, (long) 10, (int) (short) 0, 0, "hi!", (java.io.Serializable) timestampType35);
        org.apache.kafka.common.record.TimestampType timestampType37 = strConsumerRecord36.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long48 = strConsumerRecord47.timestamp();
        int int49 = strConsumerRecord47.partition();
        java.lang.String str50 = strConsumerRecord47.topic();
        long long51 = strConsumerRecord47.offset();
        java.io.Serializable serializable52 = strConsumerRecord47.value();
        java.lang.String str53 = strConsumerRecord47.topic();
        org.apache.kafka.common.record.TimestampType timestampType54 = strConsumerRecord47.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int61 = strConsumerRecord60.serializedValueSize();
        int int62 = strConsumerRecord60.partition();
        int int63 = strConsumerRecord60.partition();
        org.apache.kafka.common.header.Headers headers64 = strConsumerRecord60.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (int) (short) -1, (long) '4', (long) 10, timestampType37, (java.lang.Long) 100L, (int) (byte) 10, 0, "", (java.io.Serializable) timestampType54, headers64);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord66 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) (byte) 0, (long) (byte) 100, "", (java.io.Serializable) 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 100 + "'", int19 == 100);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertEquals("'" + serializable22 + "' != '" + (short) 10 + "'", serializable22, (short) 10);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "hi!" + "'", str23, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType24 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType24.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType35 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType35.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType37 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType37.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 100 + "'", int49 == 100);
        org.junit.Assert.assertEquals("'" + str50 + "' != '" + "hi!" + "'", str50, "hi!");
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + 52L + "'", long51 == 52L);
        org.junit.Assert.assertEquals("'" + serializable52 + "' != '" + (short) 10 + "'", serializable52, (short) 10);
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "hi!" + "'", str53, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType54 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType54.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + (-1) + "'", int61 == (-1));
        org.junit.Assert.assertTrue("'" + int62 + "' != '" + 100 + "'", int62 == 100);
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 100 + "'", int63 == 100);
        org.junit.Assert.assertNotNull(headers64);
    }

    @Test
    public void test00254() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00254");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        java.io.Serializable serializable7 = strConsumerRecord5.value();
        java.lang.String str8 = strConsumerRecord5.key();
        java.lang.String str9 = strConsumerRecord5.toString();
        java.lang.String str10 = strConsumerRecord5.toString();
        long long11 = strConsumerRecord5.checksum();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord5.timestampType();
        java.lang.Class<?> wildcardClass13 = timestampType12.getClass();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertEquals("'" + serializable7 + "' != '" + (short) 0 + "'", serializable7, (short) 0);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)" + "'", str9, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)");
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)" + "'", str10, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)");
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass13);
    }

    @Test
    public void test00255() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00255");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        org.apache.kafka.common.header.Headers headers10 = strConsumerRecord5.headers();
        long long11 = strConsumerRecord5.checksum();
        java.lang.String str12 = strConsumerRecord5.key();
        java.lang.String str13 = strConsumerRecord5.toString();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "" + "'", str12, "");
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str13, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
    }

    @Test
    public void test00256() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00256");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType17 = strConsumerRecord16.timestampType();
        int int18 = strConsumerRecord16.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional19 = strConsumerRecord16.leaderEpoch();
        java.lang.String str20 = strConsumerRecord16.toString();
        java.io.Serializable serializable21 = strConsumerRecord16.value();
        org.apache.kafka.common.header.Headers headers22 = strConsumerRecord16.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers30 = strConsumerRecord29.headers();
        org.apache.kafka.common.header.Headers headers31 = strConsumerRecord29.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long38 = strConsumerRecord37.timestamp();
        long long39 = strConsumerRecord37.timestamp();
        java.util.Optional<java.lang.Integer> intOptional40 = strConsumerRecord37.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.lang.Comparable<java.lang.String>> headersConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) '4', (long) (short) -1, 0L, timestampType7, (java.lang.Long) 0L, 0, 97, headers22, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", headers31, intOptional40);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.lang.CharSequence> headersConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.lang.CharSequence>("", 0, (long) 32, headers22, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = 52, serialized key size = 35, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)");
        org.junit.Assert.assertTrue("'" + timestampType17 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType17.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + (-1) + "'", int18 == (-1));
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str20, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + serializable21 + "' != '" + (short) 10 + "'", serializable21, (short) 10);
        org.junit.Assert.assertNotNull(headers22);
        org.junit.Assert.assertNotNull(headers30);
        org.junit.Assert.assertNotNull(headers31);
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + (-1L) + "'", long38 == (-1L));
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + (-1L) + "'", long39 == (-1L));
        org.junit.Assert.assertNotNull(intOptional40);
    }

    @Test
    public void test00257() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00257");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        java.lang.String str8 = strConsumerRecord5.topic();
        java.lang.String str9 = strConsumerRecord5.toString();
        long long10 = strConsumerRecord5.checksum();
        int int11 = strConsumerRecord5.serializedValueSize();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
    }

    @Test
    public void test00258() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00258");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int9 = strConsumerRecord8.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord8.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str17 = strConsumerRecord16.topic();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord16.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord8, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType18);
        int int20 = strConsumerRecord8.serializedValueSize();
        java.io.Serializable serializable21 = strConsumerRecord8.value();
        long long22 = strConsumerRecord8.checksum();
        java.io.Serializable serializable23 = strConsumerRecord8.value();
        long long24 = strConsumerRecord8.timestamp();
        int int25 = strConsumerRecord8.partition();
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + (-1) + "'", int20 == (-1));
        org.junit.Assert.assertEquals("'" + serializable21 + "' != '" + (short) 10 + "'", serializable21, (short) 10);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable23 + "' != '" + (short) 10 + "'", serializable23, (short) 10);
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + (-1L) + "'", long24 == (-1L));
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + 100 + "'", int25 == 100);
    }

    @Test
    public void test00259() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00259");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00260() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00260");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str6 = strConsumerRecord5.topic();
        int int7 = strConsumerRecord5.serializedValueSize();
        int int8 = strConsumerRecord5.partition();
        org.apache.kafka.common.record.TimestampType timestampType9 = strConsumerRecord5.timestampType();
        java.lang.String str10 = strConsumerRecord5.topic();
        int int11 = strConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "hi!" + "'", str6, "hi!");
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 100 + "'", int8 == 100);
        org.junit.Assert.assertTrue("'" + timestampType9 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType9.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "hi!" + "'", str10, "hi!");
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
    }

    @Test
    public void test00261() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00261");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional7 = strConsumerRecord5.leaderEpoch();
        java.lang.String str8 = strConsumerRecord5.topic();
        org.apache.kafka.common.record.TimestampType timestampType9 = strConsumerRecord5.timestampType();
        java.lang.Class<?> wildcardClass10 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType9 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType9.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass10);
    }

    @Test
    public void test00262() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00262");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00263() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00263");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType7 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.key();
        long long10 = strConsumerRecord5.timestamp();
        java.lang.String str11 = strConsumerRecord5.topic();
        java.lang.String str12 = strConsumerRecord5.topic();
        int int13 = strConsumerRecord5.partition();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "" + "'", str9, "");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "hi!" + "'", str11, "hi!");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 100 + "'", int13 == 100);
    }

    @Test
    public void test00264() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00264");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional7 = strConsumerRecord5.leaderEpoch();
        java.lang.String str8 = strConsumerRecord5.key();
        org.apache.kafka.common.header.Headers headers9 = strConsumerRecord5.headers();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        int int11 = strConsumerRecord5.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional12 = strConsumerRecord5.leaderEpoch();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "" + "'", str8, "");
        org.junit.Assert.assertNotNull(headers9);
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertNotNull(intOptional12);
    }

    @Test
    public void test00265() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00265");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, java.lang.Comparable<java.lang.String>> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.Comparable<java.lang.String>> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.Comparable<java.lang.String>>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00266() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00266");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        java.io.Serializable serializable7 = strConsumerRecord5.value();
        java.lang.String str8 = strConsumerRecord5.key();
        int int9 = strConsumerRecord5.serializedValueSize();
        java.lang.String str10 = strConsumerRecord5.key();
        long long11 = strConsumerRecord5.checksum();
        long long12 = strConsumerRecord5.timestamp();
        java.lang.String str13 = strConsumerRecord5.key();
        int int14 = strConsumerRecord5.serializedValueSize();
        java.lang.Class<?> wildcardClass15 = strConsumerRecord5.getClass();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertEquals("'" + serializable7 + "' != '" + (short) 0 + "'", serializable7, (short) 0);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "hi!" + "'", str10, "hi!");
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertNotNull(wildcardClass15);
    }

    @Test
    public void test00267() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00267");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Optional<java.lang.Integer>> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Optional<java.lang.Integer>> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Optional<java.lang.Integer>>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00268() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00268");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        int int10 = strConsumerRecord5.partition();
        java.lang.String str11 = strConsumerRecord5.toString();
        org.apache.kafka.common.header.Headers headers12 = strConsumerRecord5.headers();
        int int13 = strConsumerRecord5.partition();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 100 + "'", int10 == 100);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str11, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 100 + "'", int13 == 100);
    }

    @Test
    public void test00269() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00269");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int10 = strConsumerRecord9.serializedValueSize();
        int int11 = strConsumerRecord9.partition();
        long long12 = strConsumerRecord9.offset();
        long long13 = strConsumerRecord9.offset();
        java.util.Optional<java.lang.Integer> intOptional14 = strConsumerRecord9.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType30 = strConsumerRecord29.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType31 = strConsumerRecord29.timestampType();
        java.lang.String str32 = strConsumerRecord29.toString();
        int int33 = strConsumerRecord29.partition();
        org.apache.kafka.common.record.TimestampType timestampType34 = strConsumerRecord29.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType53 = strConsumerRecord52.timestampType();
        int int54 = strConsumerRecord52.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType55 = strConsumerRecord52.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType55, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long71 = strConsumerRecord70.timestamp();
        int int72 = strConsumerRecord70.partition();
        java.io.Serializable serializable73 = strConsumerRecord70.value();
        java.lang.Class<?> wildcardClass74 = serializable73.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long81 = strConsumerRecord80.timestamp();
        int int82 = strConsumerRecord80.partition();
        java.lang.String str83 = strConsumerRecord80.topic();
        long long84 = strConsumerRecord80.offset();
        java.lang.Class<?> wildcardClass85 = strConsumerRecord80.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration> typeConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration>("hi!", (int) (short) 0, (long) (byte) 1, 10L, timestampType55, (long) (byte) 10, (int) 'a', (int) (short) -1, (java.lang.reflect.Type) wildcardClass74, (java.lang.reflect.GenericDeclaration) wildcardClass85);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) '4', (long) (byte) 0, 1L, timestampType34, (long) (short) -1, 0, (int) (short) -1, "hi!", (java.io.Serializable) timestampType55);
        org.apache.kafka.common.header.Headers headers88 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord89 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)", 35, 0L, 52L, timestampType15, (java.lang.Long) 10L, (int) (short) 10, 10, "ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0), partition = 32, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)", (java.io.Serializable) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", headers88);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertNotNull(intOptional14);
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType30 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType30.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str32, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + 100 + "'", int33 == 100);
        org.junit.Assert.assertTrue("'" + timestampType34 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType34.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType53 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType53.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + (-1) + "'", int54 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType55 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType55.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long71 + "' != '" + (-1L) + "'", long71 == (-1L));
        org.junit.Assert.assertTrue("'" + int72 + "' != '" + 100 + "'", int72 == 100);
        org.junit.Assert.assertEquals("'" + serializable73 + "' != '" + (short) 10 + "'", serializable73, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass74);
        org.junit.Assert.assertTrue("'" + long81 + "' != '" + (-1L) + "'", long81 == (-1L));
        org.junit.Assert.assertTrue("'" + int82 + "' != '" + 100 + "'", int82 == 100);
        org.junit.Assert.assertEquals("'" + str83 + "' != '" + "hi!" + "'", str83, "hi!");
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + 52L + "'", long84 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass85);
    }

    @Test
    public void test00270() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00270");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        java.io.Serializable serializable7 = strConsumerRecord5.value();
        java.lang.String str8 = strConsumerRecord5.key();
        int int9 = strConsumerRecord5.serializedValueSize();
        long long10 = strConsumerRecord5.offset();
        java.lang.String str11 = strConsumerRecord5.topic();
        long long12 = strConsumerRecord5.timestamp();
        java.lang.String str13 = strConsumerRecord5.topic();
        java.io.Serializable serializable14 = strConsumerRecord5.value();
        long long15 = strConsumerRecord5.offset();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertEquals("'" + serializable7 + "' != '" + (short) 0 + "'", serializable7, (short) 0);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 1L + "'", long10 == 1L);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + (short) 0 + "'", serializable14, (short) 0);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 1L + "'", long15 == 1L);
    }

    @Test
    public void test00271() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00271");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        int int11 = strConsumerRecord9.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional12 = strConsumerRecord9.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType13 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType17 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int24 = strConsumerRecord23.serializedValueSize();
        long long25 = strConsumerRecord23.timestamp();
        org.apache.kafka.common.header.Headers headers26 = strConsumerRecord23.headers();
        int int27 = strConsumerRecord23.serializedValueSize();
        java.lang.String str28 = strConsumerRecord23.toString();
        java.lang.Class<?> wildcardClass29 = strConsumerRecord23.getClass();
        org.apache.kafka.common.header.Headers headers30 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType37 = strConsumerRecord36.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType38 = strConsumerRecord36.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType39 = strConsumerRecord36.timestampType();
        java.lang.String str40 = strConsumerRecord36.key();
        long long41 = strConsumerRecord36.timestamp();
        long long42 = strConsumerRecord36.offset();
        java.lang.String str43 = strConsumerRecord36.toString();
        long long44 = strConsumerRecord36.checksum();
        long long45 = strConsumerRecord36.timestamp();
        java.util.Optional<java.lang.Integer> intOptional46 = strConsumerRecord36.leaderEpoch();
        long long47 = strConsumerRecord36.checksum();
        java.util.Optional<java.lang.Integer> intOptional48 = strConsumerRecord36.leaderEpoch();
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.reflect.GenericDeclaration> timestampTypeConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = , partition = 35, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), value = )", 100, (long) (short) -1, (long) (byte) -1, timestampType13, (java.lang.Long) (-1L), (int) ' ', (int) (byte) 100, timestampType17, (java.lang.reflect.GenericDeclaration) wildcardClass29, headers30, intOptional48);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + timestampType13 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType13.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + (-1L) + "'", long25 == (-1L));
        org.junit.Assert.assertNotNull(headers26);
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertEquals("'" + str28 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str28, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(wildcardClass29);
        org.junit.Assert.assertTrue("'" + timestampType37 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType37.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType38 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType38.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType39 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType39.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str40 + "' != '" + "" + "'", str40, "");
        org.junit.Assert.assertTrue("'" + long41 + "' != '" + (-1L) + "'", long41 == (-1L));
        org.junit.Assert.assertTrue("'" + long42 + "' != '" + 52L + "'", long42 == 52L);
        org.junit.Assert.assertEquals("'" + str43 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str43, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + (-1L) + "'", long44 == (-1L));
        org.junit.Assert.assertTrue("'" + long45 + "' != '" + (-1L) + "'", long45 == (-1L));
        org.junit.Assert.assertNotNull(intOptional46);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + (-1L) + "'", long47 == (-1L));
        org.junit.Assert.assertNotNull(intOptional48);
    }

    @Test
    public void test00272() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00272");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        java.lang.String str9 = strConsumerRecord5.toString();
        long long10 = strConsumerRecord5.checksum();
        int int11 = strConsumerRecord5.partition();
        long long12 = strConsumerRecord5.offset();
        java.lang.String str13 = strConsumerRecord5.toString();
        java.lang.String str14 = strConsumerRecord5.toString();
        int int15 = strConsumerRecord5.partition();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str13, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str14, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
    }

    @Test
    public void test00273() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00273");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        long long7 = strConsumerRecord5.offset();
        long long8 = strConsumerRecord5.offset();
        java.io.Serializable serializable9 = strConsumerRecord5.value();
        int int10 = strConsumerRecord5.partition();
        org.apache.kafka.common.header.Headers headers11 = strConsumerRecord5.headers();
        java.lang.Class<?> wildcardClass12 = headers11.getClass();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + 52L + "'", long7 == 52L);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertEquals("'" + serializable9 + "' != '" + (short) 10 + "'", serializable9, (short) 10);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 100 + "'", int10 == 100);
        org.junit.Assert.assertNotNull(headers11);
        org.junit.Assert.assertNotNull(wildcardClass12);
    }

    @Test
    public void test00274() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00274");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        int int15 = strConsumerRecord13.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType16, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) (short) 10, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", (java.io.Serializable) "");
        int int24 = strConsumerRecord23.serializedKeySize();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
    }

    @Test
    public void test00275() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00275");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00276() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00276");
        java.io.Serializable serializable4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", (int) (byte) -1, 35L, "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)", serializable4);
        java.lang.Class<?> wildcardClass6 = strConsumerRecord5.getClass();
        org.junit.Assert.assertNotNull(wildcardClass6);
    }

    @Test
    public void test00277() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00277");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00278() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00278");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedKeySize();
        int int8 = strConsumerRecord5.partition();
        long long9 = strConsumerRecord5.timestamp();
        int int10 = strConsumerRecord5.partition();
        java.io.Serializable serializable11 = strConsumerRecord5.value();
        java.io.Serializable serializable12 = strConsumerRecord5.value();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 100 + "'", int8 == 100);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 100 + "'", int10 == 100);
        org.junit.Assert.assertEquals("'" + serializable11 + "' != '" + (short) 10 + "'", serializable11, (short) 10);
        org.junit.Assert.assertEquals("'" + serializable12 + "' != '" + (short) 10 + "'", serializable12, (short) 10);
    }

    @Test
    public void test00279() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00279");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        int int7 = strConsumerRecord5.partition();
        java.io.Serializable serializable8 = strConsumerRecord5.value();
        org.apache.kafka.common.record.TimestampType timestampType9 = strConsumerRecord5.timestampType();
        int int10 = strConsumerRecord5.serializedValueSize();
        java.lang.Class<?> wildcardClass11 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + serializable8 + "' != '" + (short) 10 + "'", serializable8, (short) 10);
        org.junit.Assert.assertTrue("'" + timestampType9 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType9.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
        org.junit.Assert.assertNotNull(wildcardClass11);
    }

    @Test
    public void test00280() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00280");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.lang.reflect.AnnotatedElement> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.reflect.AnnotatedElement> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.reflect.AnnotatedElement>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00281() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00281");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int17 = strConsumerRecord16.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional18 = strConsumerRecord16.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str25 = strConsumerRecord24.topic();
        org.apache.kafka.common.record.TimestampType timestampType26 = strConsumerRecord24.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord16, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType26);
        java.lang.String str28 = strConsumerRecord16.topic();
        long long29 = strConsumerRecord16.offset();
        long long30 = strConsumerRecord16.offset();
        java.lang.String str31 = strConsumerRecord16.toString();
        int int32 = strConsumerRecord16.serializedKeySize();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long39 = strConsumerRecord38.timestamp();
        int int40 = strConsumerRecord38.partition();
        java.io.Serializable serializable41 = strConsumerRecord38.value();
        java.lang.Class<?> wildcardClass42 = serializable41.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long49 = strConsumerRecord48.timestamp();
        long long50 = strConsumerRecord48.checksum();
        java.util.Optional<java.lang.Integer> intOptional51 = strConsumerRecord48.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType52 = strConsumerRecord48.timestampType();
        java.lang.String str53 = strConsumerRecord48.topic();
        long long54 = strConsumerRecord48.checksum();
        long long55 = strConsumerRecord48.timestamp();
        java.lang.String str56 = strConsumerRecord48.toString();
        org.apache.kafka.common.header.Headers headers57 = strConsumerRecord48.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers64 = strConsumerRecord63.headers();
        java.io.Serializable serializable65 = strConsumerRecord63.value();
        java.lang.String str66 = strConsumerRecord63.key();
        java.lang.String str67 = strConsumerRecord63.key();
        int int68 = strConsumerRecord63.partition();
        java.util.Optional<java.lang.Integer> intOptional69 = strConsumerRecord63.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.reflect.GenericDeclaration> strConsumerRecordConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", 10, (long) (short) -1, (long) (byte) 100, timestampType4, (java.lang.Long) (-1L), 100, (-1), strConsumerRecord16, (java.lang.reflect.GenericDeclaration) wildcardClass42, headers57, intOptional69);
        int int71 = strConsumerRecord16.serializedValueSize();
        long long72 = strConsumerRecord16.timestamp();
        int int73 = strConsumerRecord16.serializedValueSize();
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + (-1) + "'", int17 == (-1));
        org.junit.Assert.assertNotNull(intOptional18);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "hi!" + "'", str25, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType26 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType26.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str28 + "' != '" + "hi!" + "'", str28, "hi!");
        org.junit.Assert.assertTrue("'" + long29 + "' != '" + 52L + "'", long29 == 52L);
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + 52L + "'", long30 == 52L);
        org.junit.Assert.assertEquals("'" + str31 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str31, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int32 + "' != '" + (-1) + "'", int32 == (-1));
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + (-1L) + "'", long39 == (-1L));
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + 100 + "'", int40 == 100);
        org.junit.Assert.assertEquals("'" + serializable41 + "' != '" + (short) 10 + "'", serializable41, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass42);
        org.junit.Assert.assertTrue("'" + long49 + "' != '" + (-1L) + "'", long49 == (-1L));
        org.junit.Assert.assertTrue("'" + long50 + "' != '" + (-1L) + "'", long50 == (-1L));
        org.junit.Assert.assertNotNull(intOptional51);
        org.junit.Assert.assertTrue("'" + timestampType52 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType52.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "hi!" + "'", str53, "hi!");
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + (-1L) + "'", long54 == (-1L));
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + (-1L) + "'", long55 == (-1L));
        org.junit.Assert.assertEquals("'" + str56 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str56, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(headers57);
        org.junit.Assert.assertNotNull(headers64);
        org.junit.Assert.assertEquals("'" + serializable65 + "' != '" + (short) 0 + "'", serializable65, (short) 0);
        org.junit.Assert.assertEquals("'" + str66 + "' != '" + "hi!" + "'", str66, "hi!");
        org.junit.Assert.assertEquals("'" + str67 + "' != '" + "hi!" + "'", str67, "hi!");
        org.junit.Assert.assertTrue("'" + int68 + "' != '" + 1 + "'", int68 == 1);
        org.junit.Assert.assertNotNull(intOptional69);
        org.junit.Assert.assertTrue("'" + int71 + "' != '" + (-1) + "'", int71 == (-1));
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + (-1L) + "'", long72 == (-1L));
        org.junit.Assert.assertTrue("'" + int73 + "' != '" + (-1) + "'", int73 == (-1));
    }

    @Test
    public void test00282() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00282");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int21 = strConsumerRecord20.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional22 = strConsumerRecord20.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str29 = strConsumerRecord28.topic();
        org.apache.kafka.common.record.TimestampType timestampType30 = strConsumerRecord28.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord20, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType30);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) -1, 100L, (long) 10, timestampType30, 0L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 0.0f);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int48 = strConsumerRecord47.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional49 = strConsumerRecord47.leaderEpoch();
        java.lang.String str50 = strConsumerRecord47.topic();
        org.apache.kafka.common.record.TimestampType timestampType51 = strConsumerRecord47.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers58 = strConsumerRecord57.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int68 = strConsumerRecord67.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional69 = strConsumerRecord67.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str76 = strConsumerRecord75.topic();
        org.apache.kafka.common.record.TimestampType timestampType77 = strConsumerRecord75.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord67, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType77);
        int int79 = strConsumerRecord67.serializedValueSize();
        java.lang.String str80 = strConsumerRecord67.key();
        java.lang.String str81 = strConsumerRecord67.key();
        java.util.Optional<java.lang.Integer> intOptional82 = strConsumerRecord67.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", 10, (long) (byte) 1, (long) (short) 1, timestampType30, (java.lang.Long) 0L, (int) '#', 100, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", (java.io.Serializable) timestampType51, headers58, intOptional82);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord89 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) 1, (long) 'a', (long) (short) 1, timestampType30, (long) 10, (int) '#', (int) (byte) 100, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (java.io.Serializable) "");
        java.lang.Class<?> wildcardClass90 = timestampType30.getClass();
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertNotNull(intOptional22);
        org.junit.Assert.assertEquals("'" + str29 + "' != '" + "hi!" + "'", str29, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType30 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType30.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int48 + "' != '" + (-1) + "'", int48 == (-1));
        org.junit.Assert.assertNotNull(intOptional49);
        org.junit.Assert.assertEquals("'" + str50 + "' != '" + "hi!" + "'", str50, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType51 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType51.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers58);
        org.junit.Assert.assertTrue("'" + int68 + "' != '" + (-1) + "'", int68 == (-1));
        org.junit.Assert.assertNotNull(intOptional69);
        org.junit.Assert.assertEquals("'" + str76 + "' != '" + "hi!" + "'", str76, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType77 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType77.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int79 + "' != '" + (-1) + "'", int79 == (-1));
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "" + "'", str80, "");
        org.junit.Assert.assertEquals("'" + str81 + "' != '" + "" + "'", str81, "");
        org.junit.Assert.assertNotNull(intOptional82);
        org.junit.Assert.assertNotNull(wildcardClass90);
    }

    @Test
    public void test00283() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00283");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, java.lang.String> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.String> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.String>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00284() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00284");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers10 = strConsumerRecord9.headers();
        org.apache.kafka.common.header.Headers headers11 = strConsumerRecord9.headers();
        java.lang.Class<?> wildcardClass12 = headers11.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (short) 10, (long) 97, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (java.io.Serializable) wildcardClass12);
        java.lang.Class<?> wildcardClass14 = strConsumerRecord13.getClass();
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertNotNull(headers11);
        org.junit.Assert.assertNotNull(wildcardClass12);
        org.junit.Assert.assertNotNull(wildcardClass14);
    }

    @Test
    public void test00285() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00285");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long10 = strConsumerRecord9.timestamp();
        long long11 = strConsumerRecord9.offset();
        org.apache.kafka.common.header.Headers headers12 = strConsumerRecord9.headers();
        long long13 = strConsumerRecord9.checksum();
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int24 = strConsumerRecord23.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional25 = strConsumerRecord23.leaderEpoch();
        java.lang.String str26 = strConsumerRecord23.key();
        long long27 = strConsumerRecord23.offset();
        java.io.Serializable serializable28 = strConsumerRecord23.value();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long39 = strConsumerRecord38.timestamp();
        int int40 = strConsumerRecord38.partition();
        java.io.Serializable serializable41 = strConsumerRecord38.value();
        java.lang.Class<?> wildcardClass42 = strConsumerRecord38.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, 52L, "", (java.io.Serializable) wildcardClass42);
        java.io.Serializable serializable44 = strConsumerRecord43.value();
        java.lang.String str45 = strConsumerRecord43.toString();
        org.apache.kafka.common.header.Headers headers46 = strConsumerRecord43.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.kafka.common.header.Headers> objConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.kafka.common.header.Headers>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType), value = 0), partition = 35, leaderEpoch = null, offset = 97, NoTimestampType = 100, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = 10)", 0, 0L, (long) (byte) -1, timestampType14, 0L, 52, 100, (java.lang.Object) serializable28, headers46);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
        org.junit.Assert.assertNotNull(intOptional25);
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "" + "'", str26, "");
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + 52L + "'", long27 == 52L);
        org.junit.Assert.assertEquals("'" + serializable28 + "' != '" + (short) 10 + "'", serializable28, (short) 10);
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + (-1L) + "'", long39 == (-1L));
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + 100 + "'", int40 == 100);
        org.junit.Assert.assertEquals("'" + serializable41 + "' != '" + (short) 10 + "'", serializable41, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass42);
        org.junit.Assert.assertNotNull(serializable44);
        org.junit.Assert.assertEquals("'" + str45 + "' != '" + "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)" + "'", str45, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)");
        org.junit.Assert.assertNotNull(headers46);
    }

    @Test
    public void test00286() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00286");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        int int15 = strConsumerRecord13.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long26 = strConsumerRecord25.timestamp();
        int int27 = strConsumerRecord25.partition();
        java.lang.String str28 = strConsumerRecord25.topic();
        long long29 = strConsumerRecord25.offset();
        java.lang.Class<?> wildcardClass30 = strConsumerRecord25.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int37 = strConsumerRecord36.serializedValueSize();
        int int38 = strConsumerRecord36.partition();
        org.apache.kafka.common.header.Headers headers39 = strConsumerRecord36.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType46 = strConsumerRecord45.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType47 = strConsumerRecord45.timestampType();
        org.apache.kafka.common.header.Headers headers48 = strConsumerRecord45.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str59 = strConsumerRecord58.topic();
        org.apache.kafka.common.record.TimestampType timestampType60 = strConsumerRecord58.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int72 = strConsumerRecord71.serializedValueSize();
        int int73 = strConsumerRecord71.partition();
        org.apache.kafka.common.header.Headers headers74 = strConsumerRecord71.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int81 = strConsumerRecord80.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional82 = strConsumerRecord80.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType60, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers74, intOptional82);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers> annotatedElementConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers>("hi!", (int) (short) 1, 1L, 100L, timestampType16, (java.lang.Long) 1L, 100, (int) (byte) 10, (java.lang.reflect.AnnotatedElement) wildcardClass30, headers39, headers48, intOptional82);
        java.io.Serializable serializable89 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord90 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (int) (short) -1, (long) '#', (long) (-1), timestampType16, 1L, 32, 97, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", serializable89);
        int int91 = strConsumerRecord90.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional92 = strConsumerRecord90.leaderEpoch();
        java.io.Serializable serializable93 = strConsumerRecord90.value();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + (-1L) + "'", long26 == (-1L));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + 100 + "'", int27 == 100);
        org.junit.Assert.assertEquals("'" + str28 + "' != '" + "hi!" + "'", str28, "hi!");
        org.junit.Assert.assertTrue("'" + long29 + "' != '" + 52L + "'", long29 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass30);
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + (-1) + "'", int37 == (-1));
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + 100 + "'", int38 == 100);
        org.junit.Assert.assertNotNull(headers39);
        org.junit.Assert.assertTrue("'" + timestampType46 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType46.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType47 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType47.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers48);
        org.junit.Assert.assertEquals("'" + str59 + "' != '" + "hi!" + "'", str59, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType60 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType60.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int72 + "' != '" + (-1) + "'", int72 == (-1));
        org.junit.Assert.assertTrue("'" + int73 + "' != '" + 100 + "'", int73 == 100);
        org.junit.Assert.assertNotNull(headers74);
        org.junit.Assert.assertTrue("'" + int81 + "' != '" + (-1) + "'", int81 == (-1));
        org.junit.Assert.assertNotNull(intOptional82);
        org.junit.Assert.assertTrue("'" + int91 + "' != '" + 32 + "'", int91 == 32);
        org.junit.Assert.assertNotNull(intOptional92);
        org.junit.Assert.assertNull(serializable93);
    }

    @Test
    public void test00287() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00287");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, org.apache.kafka.common.header.Headers> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, org.apache.kafka.common.header.Headers> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, org.apache.kafka.common.header.Headers>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00288() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00288");
        java.lang.Object obj3 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        int int15 = strConsumerRecord13.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", 1, 52L, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (java.io.Serializable) timestampType16);
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord17.timestampType();
        java.io.Serializable serializable19 = strConsumerRecord17.value();
        java.lang.Class<?> wildcardClass20 = strConsumerRecord17.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 10, serialized key size = 10, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 52)", (int) '4', (long) 0, obj3, (java.io.Serializable) wildcardClass20);
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + serializable19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", serializable19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass20);
    }

    @Test
    public void test00289() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00289");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str14 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int27 = strConsumerRecord26.serializedValueSize();
        int int28 = strConsumerRecord26.partition();
        org.apache.kafka.common.header.Headers headers29 = strConsumerRecord26.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType15, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers29, intOptional37);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int50 = strConsumerRecord49.serializedValueSize();
        int int51 = strConsumerRecord49.partition();
        org.apache.kafka.common.header.Headers headers52 = strConsumerRecord49.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType15, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers52);
        long long54 = strConsumerRecord53.offset();
        java.lang.String str55 = strConsumerRecord53.topic();
        long long56 = strConsumerRecord53.offset();
        org.apache.kafka.common.header.Headers headers57 = strConsumerRecord53.headers();
        long long58 = strConsumerRecord53.timestamp();
        long long59 = strConsumerRecord53.timestamp();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 100 + "'", int28 == 100);
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + (-1) + "'", int50 == (-1));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 100 + "'", int51 == 100);
        org.junit.Assert.assertNotNull(headers52);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + 1L + "'", long54 == 1L);
        org.junit.Assert.assertEquals("'" + str55 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str55, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + 1L + "'", long56 == 1L);
        org.junit.Assert.assertNotNull(headers57);
        org.junit.Assert.assertTrue("'" + long58 + "' != '" + 0L + "'", long58 == 0L);
        org.junit.Assert.assertTrue("'" + long59 + "' != '" + 0L + "'", long59 == 0L);
    }

    @Test
    public void test00290() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00290");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        java.io.Serializable serializable7 = strConsumerRecord5.value();
        java.lang.String str8 = strConsumerRecord5.key();
        int int9 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        long long11 = strConsumerRecord5.offset();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertEquals("'" + serializable7 + "' != '" + (short) 0 + "'", serializable7, (short) 0);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 1L + "'", long11 == 1L);
    }

    @Test
    public void test00291() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00291");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00292() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00292");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, java.lang.Iterable<org.apache.kafka.common.header.Header>> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.Iterable<org.apache.kafka.common.header.Header>> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.Iterable<org.apache.kafka.common.header.Header>>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00293() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00293");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, org.apache.kafka.common.record.TimestampType> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, org.apache.kafka.common.record.TimestampType> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, org.apache.kafka.common.record.TimestampType>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00294() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00294");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType7 = strConsumerRecord5.timestampType();
        java.lang.String str8 = strConsumerRecord5.toString();
        int int9 = strConsumerRecord5.partition();
        int int10 = strConsumerRecord5.partition();
        long long11 = strConsumerRecord5.offset();
        int int12 = strConsumerRecord5.partition();
        org.apache.kafka.common.header.Headers headers13 = strConsumerRecord5.headers();
        java.lang.String str14 = strConsumerRecord5.toString();
        java.lang.Class<?> wildcardClass15 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str8, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + 100 + "'", int9 == 100);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 100 + "'", int10 == 100);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str14, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(wildcardClass15);
    }

    @Test
    public void test00295() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00295");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        java.io.Serializable serializable7 = strConsumerRecord5.value();
        java.lang.String str8 = strConsumerRecord5.key();
        int int9 = strConsumerRecord5.serializedValueSize();
        long long10 = strConsumerRecord5.offset();
        java.lang.String str11 = strConsumerRecord5.topic();
        long long12 = strConsumerRecord5.timestamp();
        long long13 = strConsumerRecord5.offset();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertEquals("'" + serializable7 + "' != '" + (short) 0 + "'", serializable7, (short) 0);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 1L + "'", long10 == 1L);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 1L + "'", long13 == 1L);
    }

    @Test
    public void test00296() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00296");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.Iterable<org.apache.kafka.common.header.Header>> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.Iterable<org.apache.kafka.common.header.Header>> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.Iterable<org.apache.kafka.common.header.Header>>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00297() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00297");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long27 = strConsumerRecord26.timestamp();
        int int28 = strConsumerRecord26.partition();
        org.apache.kafka.common.record.TimestampType timestampType29 = strConsumerRecord26.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType44 = strConsumerRecord43.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) 10, 0L, "hi!", (java.io.Serializable) timestampType44);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType56 = strConsumerRecord55.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord62 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int63 = strConsumerRecord62.serializedValueSize();
        int int64 = strConsumerRecord62.partition();
        org.apache.kafka.common.header.Headers headers65 = strConsumerRecord62.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord66 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) ' ', 0L, (long) (byte) 10, timestampType44, (java.lang.Long) 0L, 10, (-1), "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (java.io.Serializable) timestampType56, headers65);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 0, 52L, (long) '#', timestampType16, (java.lang.Long) 0L, (int) (short) 10, (int) (short) -1, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (java.io.Serializable) timestampType29, headers65);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType82 = strConsumerRecord81.timestampType();
        int int83 = strConsumerRecord81.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType84 = strConsumerRecord81.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", 1, 52L, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (java.io.Serializable) timestampType84);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", 1, (long) (byte) 1, (long) '#', timestampType29, (long) 100, 52, 10, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", (java.io.Serializable) 52L);
        org.apache.kafka.common.header.Headers headers87 = strConsumerRecord86.headers();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + (-1L) + "'", long27 == (-1L));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 100 + "'", int28 == 100);
        org.junit.Assert.assertTrue("'" + timestampType29 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType29.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType44 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType44.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType56 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType56.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + (-1) + "'", int63 == (-1));
        org.junit.Assert.assertTrue("'" + int64 + "' != '" + 100 + "'", int64 == 100);
        org.junit.Assert.assertNotNull(headers65);
        org.junit.Assert.assertTrue("'" + timestampType82 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType82.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int83 + "' != '" + (-1) + "'", int83 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType84 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType84.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers87);
    }

    @Test
    public void test00298() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00298");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str6 = strConsumerRecord5.topic();
        org.apache.kafka.common.record.TimestampType timestampType7 = strConsumerRecord5.timestampType();
        long long8 = strConsumerRecord5.checksum();
        long long9 = strConsumerRecord5.offset();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "hi!" + "'", str6, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + (-1L) + "'", long8 == (-1L));
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
    }

    @Test
    public void test00299() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00299");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        java.lang.String str9 = strConsumerRecord5.key();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        java.lang.String str11 = strConsumerRecord5.toString();
        java.lang.Class<?> wildcardClass12 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "" + "'", str9, "");
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str11, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(wildcardClass12);
    }

    @Test
    public void test00300() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00300");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        java.lang.String str9 = strConsumerRecord5.toString();
        long long10 = strConsumerRecord5.timestamp();
        java.lang.String str11 = strConsumerRecord5.topic();
        org.apache.kafka.common.header.Headers headers12 = strConsumerRecord5.headers();
        java.lang.String str13 = strConsumerRecord5.topic();
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord5.timestampType();
        java.lang.String str15 = strConsumerRecord5.key();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "hi!" + "'", str11, "hi!");
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "" + "'", str15, "");
    }

    @Test
    public void test00301() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00301");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType7 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.key();
        long long10 = strConsumerRecord5.timestamp();
        long long11 = strConsumerRecord5.offset();
        java.lang.String str12 = strConsumerRecord5.toString();
        long long13 = strConsumerRecord5.checksum();
        java.io.Serializable serializable14 = strConsumerRecord5.value();
        java.io.Serializable serializable15 = strConsumerRecord5.value();
        java.io.Serializable serializable16 = strConsumerRecord5.value();
        org.apache.kafka.common.record.TimestampType timestampType17 = strConsumerRecord5.timestampType();
        java.lang.Class<?> wildcardClass18 = timestampType17.getClass();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "" + "'", str9, "");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str12, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + (short) 10 + "'", serializable14, (short) 10);
        org.junit.Assert.assertEquals("'" + serializable15 + "' != '" + (short) 10 + "'", serializable15, (short) 10);
        org.junit.Assert.assertEquals("'" + serializable16 + "' != '" + (short) 10 + "'", serializable16, (short) 10);
        org.junit.Assert.assertTrue("'" + timestampType17 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType17.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass18);
    }

    @Test
    public void test00302() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00302");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.reflect.AnnotatedElement annotatedElement8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int18 = strConsumerRecord17.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional19 = strConsumerRecord17.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str26 = strConsumerRecord25.topic();
        org.apache.kafka.common.record.TimestampType timestampType27 = strConsumerRecord25.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord17, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType27);
        org.apache.kafka.common.header.Headers headers29 = strConsumerRecord17.headers();
        org.apache.kafka.common.header.Headers headers30 = strConsumerRecord17.headers();
        org.apache.kafka.common.header.Headers headers31 = strConsumerRecord17.headers();
        org.apache.kafka.common.header.Headers headers32 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers> annotatedElementConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 1, leaderEpoch = null, offset = 100, NoTimestampType = 100, serialized key size = 97, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 0, (long) 32, (long) 1, timestampType4, (java.lang.Long) 100L, (int) (byte) -1, (int) (byte) 10, annotatedElement8, headers31, headers32);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + (-1) + "'", int18 == (-1));
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "hi!" + "'", str26, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType27 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType27.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertNotNull(headers30);
        org.junit.Assert.assertNotNull(headers31);
    }

    @Test
    public void test00303() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00303");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedKeySize();
        int int8 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType9 = strConsumerRecord5.timestampType();
        java.lang.String str10 = strConsumerRecord5.topic();
        java.lang.String str11 = strConsumerRecord5.key();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType9 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType9.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "hi!" + "'", str10, "hi!");
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
    }

    @Test
    public void test00304() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00304");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers10 = strConsumerRecord9.headers();
        java.io.Serializable serializable11 = strConsumerRecord9.value();
        java.lang.String str12 = strConsumerRecord9.key();
        org.apache.kafka.common.record.TimestampType timestampType13 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int23 = strConsumerRecord22.serializedValueSize();
        int int24 = strConsumerRecord22.partition();
        long long25 = strConsumerRecord22.offset();
        long long26 = strConsumerRecord22.offset();
        org.apache.kafka.common.header.Headers headers27 = strConsumerRecord22.headers();
        java.io.Serializable serializable28 = strConsumerRecord22.value();
        java.lang.String str29 = strConsumerRecord22.toString();
        int int30 = strConsumerRecord22.serializedKeySize();
        java.lang.String str31 = strConsumerRecord22.toString();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType50 = strConsumerRecord49.timestampType();
        int int51 = strConsumerRecord49.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType52 = strConsumerRecord49.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType52, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", 0, 1L, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (java.io.Serializable) '#');
        org.apache.kafka.common.record.TimestampType timestampType60 = strConsumerRecord59.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int71 = strConsumerRecord70.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional72 = strConsumerRecord70.leaderEpoch();
        java.lang.String str73 = strConsumerRecord70.key();
        long long74 = strConsumerRecord70.offset();
        java.lang.String str75 = strConsumerRecord70.toString();
        org.apache.kafka.common.record.TimestampType timestampType76 = strConsumerRecord70.timestampType();
        java.lang.String str77 = strConsumerRecord70.toString();
        java.util.Optional<java.lang.Integer> intOptional78 = strConsumerRecord70.leaderEpoch();
        java.lang.Class<?> wildcardClass79 = strConsumerRecord70.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = null)", 0, (long) '4', (long) (short) -1, timestampType60, (long) 100, (int) (byte) 10, 52, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0), partition = 10, leaderEpoch = null, offset = 100, NoTimestampType = 32, serialized key size = -1, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = hi!)", (java.io.Serializable) wildcardClass79);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.reflect.Type> objConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.reflect.Type>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 10, serialized key size = 10, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 52)", 52, (long) 32, (long) 52, timestampType13, (long) (-1), (-1), (int) (short) 10, (java.lang.Object) str31, (java.lang.reflect.Type) wildcardClass79);
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertEquals("'" + serializable11 + "' != '" + (short) 0 + "'", serializable11, (short) 0);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType13 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType13.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + 100 + "'", int24 == 100);
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + 52L + "'", long25 == 52L);
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + 52L + "'", long26 == 52L);
        org.junit.Assert.assertNotNull(headers27);
        org.junit.Assert.assertEquals("'" + serializable28 + "' != '" + (short) 10 + "'", serializable28, (short) 10);
        org.junit.Assert.assertEquals("'" + str29 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str29, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertEquals("'" + str31 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str31, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + timestampType50 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType50.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + (-1) + "'", int51 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType52 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType52.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType60 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType60.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int71 + "' != '" + (-1) + "'", int71 == (-1));
        org.junit.Assert.assertNotNull(intOptional72);
        org.junit.Assert.assertEquals("'" + str73 + "' != '" + "" + "'", str73, "");
        org.junit.Assert.assertTrue("'" + long74 + "' != '" + 52L + "'", long74 == 52L);
        org.junit.Assert.assertEquals("'" + str75 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str75, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + timestampType76 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType76.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str77 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str77, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional78);
        org.junit.Assert.assertNotNull(wildcardClass79);
    }

    @Test
    public void test00305() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00305");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) 100, (long) 0, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 1, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = #)", (java.io.Serializable) 100.0d);
        int int6 = strConsumerRecord5.partition();
        org.apache.kafka.common.header.Headers headers7 = strConsumerRecord5.headers();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + 100 + "'", int6 == 100);
        org.junit.Assert.assertNotNull(headers7);
    }

    @Test
    public void test00306() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00306");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        java.lang.String str8 = strConsumerRecord5.topic();
        long long9 = strConsumerRecord5.checksum();
        long long10 = strConsumerRecord5.offset();
        long long11 = strConsumerRecord5.offset();
        java.lang.String str12 = strConsumerRecord5.key();
        long long13 = strConsumerRecord5.timestamp();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 52L + "'", long10 == 52L);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "" + "'", str12, "");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
    }

    @Test
    public void test00307() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00307");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        int int15 = strConsumerRecord13.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long26 = strConsumerRecord25.timestamp();
        int int27 = strConsumerRecord25.partition();
        java.lang.String str28 = strConsumerRecord25.topic();
        long long29 = strConsumerRecord25.offset();
        java.lang.Class<?> wildcardClass30 = strConsumerRecord25.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int37 = strConsumerRecord36.serializedValueSize();
        int int38 = strConsumerRecord36.partition();
        org.apache.kafka.common.header.Headers headers39 = strConsumerRecord36.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType46 = strConsumerRecord45.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType47 = strConsumerRecord45.timestampType();
        org.apache.kafka.common.header.Headers headers48 = strConsumerRecord45.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str59 = strConsumerRecord58.topic();
        org.apache.kafka.common.record.TimestampType timestampType60 = strConsumerRecord58.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int72 = strConsumerRecord71.serializedValueSize();
        int int73 = strConsumerRecord71.partition();
        org.apache.kafka.common.header.Headers headers74 = strConsumerRecord71.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int81 = strConsumerRecord80.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional82 = strConsumerRecord80.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType60, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers74, intOptional82);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers> annotatedElementConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers>("hi!", (int) (short) 1, 1L, 100L, timestampType16, (java.lang.Long) 1L, 100, (int) (byte) 10, (java.lang.reflect.AnnotatedElement) wildcardClass30, headers39, headers48, intOptional82);
        java.io.Serializable serializable89 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord90 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (int) (short) -1, (long) '#', (long) (-1), timestampType16, 1L, 32, 97, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", serializable89);
        java.lang.Class<?> wildcardClass91 = strConsumerRecord90.getClass();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + (-1L) + "'", long26 == (-1L));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + 100 + "'", int27 == 100);
        org.junit.Assert.assertEquals("'" + str28 + "' != '" + "hi!" + "'", str28, "hi!");
        org.junit.Assert.assertTrue("'" + long29 + "' != '" + 52L + "'", long29 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass30);
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + (-1) + "'", int37 == (-1));
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + 100 + "'", int38 == 100);
        org.junit.Assert.assertNotNull(headers39);
        org.junit.Assert.assertTrue("'" + timestampType46 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType46.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType47 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType47.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers48);
        org.junit.Assert.assertEquals("'" + str59 + "' != '" + "hi!" + "'", str59, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType60 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType60.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int72 + "' != '" + (-1) + "'", int72 == (-1));
        org.junit.Assert.assertTrue("'" + int73 + "' != '" + 100 + "'", int73 == 100);
        org.junit.Assert.assertNotNull(headers74);
        org.junit.Assert.assertTrue("'" + int81 + "' != '" + (-1) + "'", int81 == (-1));
        org.junit.Assert.assertNotNull(intOptional82);
        org.junit.Assert.assertNotNull(wildcardClass91);
    }

    @Test
    public void test00308() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00308");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str14 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int27 = strConsumerRecord26.serializedValueSize();
        int int28 = strConsumerRecord26.partition();
        org.apache.kafka.common.header.Headers headers29 = strConsumerRecord26.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType15, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers29, intOptional37);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int50 = strConsumerRecord49.serializedValueSize();
        int int51 = strConsumerRecord49.partition();
        org.apache.kafka.common.header.Headers headers52 = strConsumerRecord49.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType15, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers52);
        long long54 = strConsumerRecord53.checksum();
        java.io.Serializable serializable55 = strConsumerRecord53.value();
        long long56 = strConsumerRecord53.offset();
        org.apache.kafka.common.record.TimestampType timestampType57 = strConsumerRecord53.timestampType();
        java.util.Optional<java.lang.Integer> intOptional58 = strConsumerRecord53.leaderEpoch();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 100 + "'", int28 == 100);
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + (-1) + "'", int50 == (-1));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 100 + "'", int51 == 100);
        org.junit.Assert.assertNotNull(headers52);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + 52L + "'", long54 == 52L);
        org.junit.Assert.assertEquals("'" + serializable55 + "' != '" + (-1.0d) + "'", serializable55, (-1.0d));
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + 1L + "'", long56 == 1L);
        org.junit.Assert.assertTrue("'" + timestampType57 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType57.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(intOptional58);
    }

    @Test
    public void test00309() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00309");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.lang.Comparable<java.lang.String>> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.Comparable<java.lang.String>> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.Comparable<java.lang.String>>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00310() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00310");
        java.io.Serializable serializable3 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int21 = strConsumerRecord20.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional22 = strConsumerRecord20.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str29 = strConsumerRecord28.topic();
        org.apache.kafka.common.record.TimestampType timestampType30 = strConsumerRecord28.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord20, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType30);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) -1, 100L, (long) 10, timestampType30, 0L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 0.0f);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int48 = strConsumerRecord47.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional49 = strConsumerRecord47.leaderEpoch();
        java.lang.String str50 = strConsumerRecord47.topic();
        org.apache.kafka.common.record.TimestampType timestampType51 = strConsumerRecord47.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers58 = strConsumerRecord57.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int68 = strConsumerRecord67.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional69 = strConsumerRecord67.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str76 = strConsumerRecord75.topic();
        org.apache.kafka.common.record.TimestampType timestampType77 = strConsumerRecord75.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord67, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType77);
        int int79 = strConsumerRecord67.serializedValueSize();
        java.lang.String str80 = strConsumerRecord67.key();
        java.lang.String str81 = strConsumerRecord67.key();
        java.util.Optional<java.lang.Integer> intOptional82 = strConsumerRecord67.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", 10, (long) (byte) 1, (long) (short) 1, timestampType30, (java.lang.Long) 0L, (int) '#', 100, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", (java.io.Serializable) timestampType51, headers58, intOptional82);
        int int84 = strConsumerRecord83.partition();
        org.apache.kafka.common.record.TimestampType timestampType85 = strConsumerRecord83.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> serializableConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", 32, 0L, serializable3, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType85);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertNotNull(intOptional22);
        org.junit.Assert.assertEquals("'" + str29 + "' != '" + "hi!" + "'", str29, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType30 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType30.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int48 + "' != '" + (-1) + "'", int48 == (-1));
        org.junit.Assert.assertNotNull(intOptional49);
        org.junit.Assert.assertEquals("'" + str50 + "' != '" + "hi!" + "'", str50, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType51 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType51.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers58);
        org.junit.Assert.assertTrue("'" + int68 + "' != '" + (-1) + "'", int68 == (-1));
        org.junit.Assert.assertNotNull(intOptional69);
        org.junit.Assert.assertEquals("'" + str76 + "' != '" + "hi!" + "'", str76, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType77 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType77.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int79 + "' != '" + (-1) + "'", int79 == (-1));
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "" + "'", str80, "");
        org.junit.Assert.assertEquals("'" + str81 + "' != '" + "" + "'", str81, "");
        org.junit.Assert.assertNotNull(intOptional82);
        org.junit.Assert.assertTrue("'" + int84 + "' != '" + 10 + "'", int84 == 10);
        org.junit.Assert.assertTrue("'" + timestampType85 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType85.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test00311() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00311");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.toString();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord5.leaderEpoch();
        long long11 = strConsumerRecord5.offset();
        java.util.Optional<java.lang.Integer> intOptional12 = strConsumerRecord5.leaderEpoch();
        int int13 = strConsumerRecord5.partition();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 100 + "'", int13 == 100);
    }

    @Test
    public void test00312() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00312");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional7 = strConsumerRecord5.leaderEpoch();
        java.lang.String str8 = strConsumerRecord5.key();
        long long9 = strConsumerRecord5.checksum();
        int int10 = strConsumerRecord5.partition();
        int int11 = strConsumerRecord5.serializedKeySize();
        java.lang.String str12 = strConsumerRecord5.toString();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "" + "'", str8, "");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 100 + "'", int10 == 100);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str12, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
    }

    @Test
    public void test00313() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00313");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        java.io.Serializable serializable7 = strConsumerRecord5.value();
        java.lang.String str8 = strConsumerRecord5.key();
        java.lang.String str9 = strConsumerRecord5.toString();
        int int10 = strConsumerRecord5.serializedValueSize();
        long long11 = strConsumerRecord5.offset();
        int int12 = strConsumerRecord5.partition();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertEquals("'" + serializable7 + "' != '" + (short) 0 + "'", serializable7, (short) 0);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)" + "'", str9, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)");
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 1L + "'", long11 == 1L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 1 + "'", int12 == 1);
    }

    @Test
    public void test00314() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00314");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long9 = strConsumerRecord8.timestamp();
        long long10 = strConsumerRecord8.timestamp();
        java.io.Serializable serializable11 = strConsumerRecord8.value();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord8.timestampType();
        java.lang.String str13 = strConsumerRecord8.toString();
        java.lang.Class<?> wildcardClass14 = strConsumerRecord8.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long25 = strConsumerRecord24.timestamp();
        int int26 = strConsumerRecord24.partition();
        java.lang.String str27 = strConsumerRecord24.topic();
        int int28 = strConsumerRecord24.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType29 = strConsumerRecord24.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord40 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int41 = strConsumerRecord40.serializedValueSize();
        long long42 = strConsumerRecord40.timestamp();
        org.apache.kafka.common.header.Headers headers43 = strConsumerRecord40.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType50 = strConsumerRecord49.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType51 = strConsumerRecord49.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType52 = strConsumerRecord49.timestampType();
        java.lang.String str53 = strConsumerRecord49.key();
        long long54 = strConsumerRecord49.timestamp();
        long long55 = strConsumerRecord49.offset();
        java.lang.String str56 = strConsumerRecord49.toString();
        long long57 = strConsumerRecord49.checksum();
        java.io.Serializable serializable58 = strConsumerRecord49.value();
        int int59 = strConsumerRecord49.partition();
        java.util.Optional<java.lang.Integer> intOptional60 = strConsumerRecord49.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (int) (byte) 0, (long) '#', (long) ' ', timestampType29, (java.lang.Long) (-1L), (int) ' ', (int) (short) 1, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", (java.io.Serializable) 10, headers43, intOptional60);
        java.lang.Class<?> wildcardClass62 = intOptional60.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.reflect.Type> serializableConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.reflect.Type>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 1, (long) '#', (java.io.Serializable) wildcardClass14, (java.lang.reflect.Type) wildcardClass62);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable11 + "' != '" + (short) 10 + "'", serializable11, (short) 10);
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str13, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(wildcardClass14);
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + (-1L) + "'", long25 == (-1L));
        org.junit.Assert.assertTrue("'" + int26 + "' != '" + 100 + "'", int26 == 100);
        org.junit.Assert.assertEquals("'" + str27 + "' != '" + "hi!" + "'", str27, "hi!");
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + (-1) + "'", int28 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType29 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType29.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + (-1) + "'", int41 == (-1));
        org.junit.Assert.assertTrue("'" + long42 + "' != '" + (-1L) + "'", long42 == (-1L));
        org.junit.Assert.assertNotNull(headers43);
        org.junit.Assert.assertTrue("'" + timestampType50 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType50.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType51 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType51.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType52 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType52.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "" + "'", str53, "");
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + (-1L) + "'", long54 == (-1L));
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + 52L + "'", long55 == 52L);
        org.junit.Assert.assertEquals("'" + str56 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str56, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long57 + "' != '" + (-1L) + "'", long57 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable58 + "' != '" + (short) 10 + "'", serializable58, (short) 10);
        org.junit.Assert.assertTrue("'" + int59 + "' != '" + 100 + "'", int59 == 100);
        org.junit.Assert.assertNotNull(intOptional60);
        org.junit.Assert.assertNotNull(wildcardClass62);
    }

    @Test
    public void test00315() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00315");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord21.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType23 = strConsumerRecord21.timestampType();
        java.lang.String str24 = strConsumerRecord21.toString();
        int int25 = strConsumerRecord21.partition();
        org.apache.kafka.common.record.TimestampType timestampType26 = strConsumerRecord21.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (short) 10, (long) (byte) 0, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) timestampType26);
        int int28 = strConsumerRecord27.partition();
        int int29 = strConsumerRecord27.partition();
        org.apache.kafka.common.record.TimestampType timestampType30 = strConsumerRecord27.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long44 = strConsumerRecord43.timestamp();
        long long45 = strConsumerRecord43.checksum();
        java.util.Optional<java.lang.Integer> intOptional46 = strConsumerRecord43.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType47 = strConsumerRecord43.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Comparable<java.lang.String>> timestampTypeConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (short) 1, (long) (byte) 1, timestampType47, (java.lang.Comparable<java.lang.String>) "hi!");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (int) (byte) 10, (long) ' ', (long) 97, timestampType30, (long) (short) 100, (int) (short) 100, 52, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (byte) 1);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long61 = strConsumerRecord60.timestamp();
        long long62 = strConsumerRecord60.checksum();
        long long63 = strConsumerRecord60.timestamp();
        java.lang.String str64 = strConsumerRecord60.topic();
        long long65 = strConsumerRecord60.timestamp();
        java.io.Serializable serializable66 = strConsumerRecord60.value();
        org.apache.kafka.common.record.TimestampType timestampType67 = strConsumerRecord60.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.kafka.common.record.TimestampType> strConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.kafka.common.record.TimestampType>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (int) (byte) -1, (long) (byte) 100, 0L, timestampType30, (long) (byte) 10, 97, (int) ' ', "ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = null), partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 52, serialized key size = 97, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", timestampType67);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType78 = strConsumerRecord77.timestampType();
        int int79 = strConsumerRecord77.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional80 = strConsumerRecord77.leaderEpoch();
        java.lang.String str81 = strConsumerRecord77.toString();
        long long82 = strConsumerRecord77.checksum();
        long long83 = strConsumerRecord77.timestamp();
        java.util.Optional<java.lang.Integer> intOptional84 = strConsumerRecord77.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord90 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType91 = strConsumerRecord90.timestampType();
        int int92 = strConsumerRecord90.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType93 = strConsumerRecord90.timestampType();
        java.lang.String str94 = strConsumerRecord90.toString();
        java.util.Optional<java.lang.Integer> intOptional95 = strConsumerRecord90.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType96 = strConsumerRecord90.timestampType();
        java.lang.String str97 = strConsumerRecord90.topic();
        org.apache.kafka.common.record.TimestampType timestampType98 = strConsumerRecord90.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.Object> intOptionalConsumerRecord99 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.Object>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", 52, (long) 0, (long) (byte) 10, timestampType67, (long) 35, 0, 0, intOptional84, (java.lang.Object) strConsumerRecord90);
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str24 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str24, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + 100 + "'", int25 == 100);
        org.junit.Assert.assertTrue("'" + timestampType26 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType26.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 10 + "'", int28 == 10);
        org.junit.Assert.assertTrue("'" + int29 + "' != '" + 10 + "'", int29 == 10);
        org.junit.Assert.assertTrue("'" + timestampType30 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType30.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + (-1L) + "'", long44 == (-1L));
        org.junit.Assert.assertTrue("'" + long45 + "' != '" + (-1L) + "'", long45 == (-1L));
        org.junit.Assert.assertNotNull(intOptional46);
        org.junit.Assert.assertTrue("'" + timestampType47 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType47.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long61 + "' != '" + (-1L) + "'", long61 == (-1L));
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + (-1L) + "'", long62 == (-1L));
        org.junit.Assert.assertTrue("'" + long63 + "' != '" + (-1L) + "'", long63 == (-1L));
        org.junit.Assert.assertEquals("'" + str64 + "' != '" + "hi!" + "'", str64, "hi!");
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + (-1L) + "'", long65 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable66 + "' != '" + (short) 10 + "'", serializable66, (short) 10);
        org.junit.Assert.assertTrue("'" + timestampType67 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType67.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType78 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType78.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int79 + "' != '" + (-1) + "'", int79 == (-1));
        org.junit.Assert.assertNotNull(intOptional80);
        org.junit.Assert.assertEquals("'" + str81 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str81, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long82 + "' != '" + (-1L) + "'", long82 == (-1L));
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + (-1L) + "'", long83 == (-1L));
        org.junit.Assert.assertNotNull(intOptional84);
        org.junit.Assert.assertTrue("'" + timestampType91 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType91.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int92 + "' != '" + (-1) + "'", int92 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType93 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType93.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str94 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str94, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional95);
        org.junit.Assert.assertTrue("'" + timestampType96 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType96.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str97 + "' != '" + "hi!" + "'", str97, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType98 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType98.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test00316() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00316");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int9 = strConsumerRecord8.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord8.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str17 = strConsumerRecord16.topic();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord16.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord8, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType18);
        java.lang.String str20 = strConsumerRecord8.topic();
        long long21 = strConsumerRecord8.offset();
        long long22 = strConsumerRecord8.offset();
        java.lang.String str23 = strConsumerRecord8.toString();
        org.apache.kafka.common.header.Headers headers24 = strConsumerRecord8.headers();
        long long25 = strConsumerRecord8.checksum();
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 52L + "'", long22 == 52L);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str23, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(headers24);
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + (-1L) + "'", long25 == (-1L));
    }

    @Test
    public void test00317() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00317");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, java.lang.reflect.GenericDeclaration> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.reflect.GenericDeclaration> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.reflect.GenericDeclaration>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00318() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00318");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, java.lang.CharSequence> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.CharSequence> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.CharSequence>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00319() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00319");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord17.timestampType();
        java.lang.String str21 = strConsumerRecord17.key();
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType33 = strConsumerRecord32.timestampType();
        java.lang.Class<?> wildcardClass34 = strConsumerRecord32.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType22, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass34);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str46 = strConsumerRecord45.topic();
        java.lang.Class<?> wildcardClass47 = strConsumerRecord45.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) -1, 100L, (long) 0, timestampType22, (long) (short) 1, (int) '#', 0, "hi!", (java.io.Serializable) wildcardClass47);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long59 = strConsumerRecord58.timestamp();
        int int60 = strConsumerRecord58.partition();
        java.lang.String str61 = strConsumerRecord58.topic();
        long long62 = strConsumerRecord58.offset();
        java.lang.Class<?> wildcardClass63 = strConsumerRecord58.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers70 = strConsumerRecord69.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long77 = strConsumerRecord76.timestamp();
        long long78 = strConsumerRecord76.checksum();
        long long79 = strConsumerRecord76.timestamp();
        java.util.Optional<java.lang.Integer> intOptional80 = strConsumerRecord76.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (short) 1, (long) (byte) 100, (long) 100, timestampType22, (java.lang.Long) 100L, (int) 'a', (int) (short) 10, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass63, headers70, intOptional80);
        long long82 = strConsumerRecord81.offset();
        org.apache.kafka.common.header.Headers headers83 = strConsumerRecord81.headers();
        long long84 = strConsumerRecord81.offset();
        long long85 = strConsumerRecord81.timestamp();
        java.lang.Class<?> wildcardClass86 = strConsumerRecord81.getClass();
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "" + "'", str21, "");
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType33 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType33.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass34);
        org.junit.Assert.assertEquals("'" + str46 + "' != '" + "hi!" + "'", str46, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass47);
        org.junit.Assert.assertTrue("'" + long59 + "' != '" + (-1L) + "'", long59 == (-1L));
        org.junit.Assert.assertTrue("'" + int60 + "' != '" + 100 + "'", int60 == 100);
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "hi!" + "'", str61, "hi!");
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + 52L + "'", long62 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass63);
        org.junit.Assert.assertNotNull(headers70);
        org.junit.Assert.assertTrue("'" + long77 + "' != '" + (-1L) + "'", long77 == (-1L));
        org.junit.Assert.assertTrue("'" + long78 + "' != '" + (-1L) + "'", long78 == (-1L));
        org.junit.Assert.assertTrue("'" + long79 + "' != '" + (-1L) + "'", long79 == (-1L));
        org.junit.Assert.assertNotNull(intOptional80);
        org.junit.Assert.assertTrue("'" + long82 + "' != '" + 100L + "'", long82 == 100L);
        org.junit.Assert.assertNotNull(headers83);
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + 100L + "'", long84 == 100L);
        org.junit.Assert.assertTrue("'" + long85 + "' != '" + 100L + "'", long85 == 100L);
        org.junit.Assert.assertNotNull(wildcardClass86);
    }

    @Test
    public void test00320() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00320");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long14 = strConsumerRecord13.timestamp();
        int int15 = strConsumerRecord13.partition();
        java.lang.String str16 = strConsumerRecord13.topic();
        long long17 = strConsumerRecord13.offset();
        java.io.Serializable serializable18 = strConsumerRecord13.value();
        java.lang.String str19 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType31 = strConsumerRecord30.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 0, (long) '4', (long) (byte) -1, timestampType20, (long) 10, (int) (short) 0, 0, "hi!", (java.io.Serializable) timestampType31);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType50 = strConsumerRecord49.timestampType();
        int int51 = strConsumerRecord49.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType52 = strConsumerRecord49.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType52, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) (short) 10, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", (java.io.Serializable) "");
        java.lang.String str60 = strConsumerRecord59.key();
        long long61 = strConsumerRecord59.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int72 = strConsumerRecord71.serializedValueSize();
        int int73 = strConsumerRecord71.partition();
        long long74 = strConsumerRecord71.offset();
        long long75 = strConsumerRecord71.timestamp();
        int int76 = strConsumerRecord71.serializedKeySize();
        java.lang.String str77 = strConsumerRecord71.key();
        org.apache.kafka.common.header.Headers headers78 = strConsumerRecord71.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.CharSequence> strComparableConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.CharSequence>("", (int) (byte) 100, (long) (byte) -1, (java.lang.Comparable<java.lang.String>) "", (java.lang.CharSequence) "");
        java.lang.Class<?> wildcardClass89 = strComparableConsumerRecord88.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord90 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", (int) (short) 1, (long) '#', "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)", (java.io.Serializable) wildcardClass89);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.GenericDeclaration> headerIterableConsumerRecord91 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (-1), 1L, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers78, (java.lang.reflect.GenericDeclaration) wildcardClass89);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.String> strConsumerRecordConsumerRecord92 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.String>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 100, NoTimestampType = 0, serialized key size = 35, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) (short) 100, (long) 10, (long) (byte) -1, timestampType20, (java.lang.Long) 0L, (int) '4', 0, strConsumerRecord59, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 1, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = #)", headers78);
        java.lang.Class<?> wildcardClass93 = headers78.getClass();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "hi!" + "'", str16, "hi!");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertEquals("'" + serializable18 + "' != '" + (short) 10 + "'", serializable18, (short) 10);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType50 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType50.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + (-1) + "'", int51 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType52 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType52.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str60 + "' != '" + "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)" + "'", str60, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)");
        org.junit.Assert.assertTrue("'" + long61 + "' != '" + (-1L) + "'", long61 == (-1L));
        org.junit.Assert.assertTrue("'" + int72 + "' != '" + (-1) + "'", int72 == (-1));
        org.junit.Assert.assertTrue("'" + int73 + "' != '" + 100 + "'", int73 == 100);
        org.junit.Assert.assertTrue("'" + long74 + "' != '" + 52L + "'", long74 == 52L);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + (-1L) + "'", long75 == (-1L));
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + (-1) + "'", int76 == (-1));
        org.junit.Assert.assertEquals("'" + str77 + "' != '" + "" + "'", str77, "");
        org.junit.Assert.assertNotNull(headers78);
        org.junit.Assert.assertNotNull(wildcardClass89);
        org.junit.Assert.assertNotNull(wildcardClass93);
    }

    @Test
    public void test00321() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00321");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str26 = strConsumerRecord25.topic();
        org.apache.kafka.common.record.TimestampType timestampType27 = strConsumerRecord25.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int39 = strConsumerRecord38.serializedValueSize();
        int int40 = strConsumerRecord38.partition();
        org.apache.kafka.common.header.Headers headers41 = strConsumerRecord38.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int48 = strConsumerRecord47.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional49 = strConsumerRecord47.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType27, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers41, intOptional49);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int62 = strConsumerRecord61.serializedValueSize();
        int int63 = strConsumerRecord61.partition();
        org.apache.kafka.common.header.Headers headers64 = strConsumerRecord61.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType27, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers64);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (short) -1, (long) '4', 0L, timestampType27, (long) (byte) 10, (-1), 0, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 1.0f);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers83 = strConsumerRecord82.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord89 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long90 = strConsumerRecord89.timestamp();
        long long91 = strConsumerRecord89.checksum();
        java.util.Optional<java.lang.Integer> intOptional92 = strConsumerRecord89.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord93 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 0, 0L, (long) '#', timestampType27, (java.lang.Long) 100L, 0, (int) (short) 100, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", headers83, intOptional92);
        java.lang.Class<?> wildcardClass94 = timestampType27.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord95 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", 32, (long) 'a', "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (java.io.Serializable) wildcardClass94);
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "hi!" + "'", str26, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType27 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType27.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + (-1) + "'", int39 == (-1));
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + 100 + "'", int40 == 100);
        org.junit.Assert.assertNotNull(headers41);
        org.junit.Assert.assertTrue("'" + int48 + "' != '" + (-1) + "'", int48 == (-1));
        org.junit.Assert.assertNotNull(intOptional49);
        org.junit.Assert.assertTrue("'" + int62 + "' != '" + (-1) + "'", int62 == (-1));
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 100 + "'", int63 == 100);
        org.junit.Assert.assertNotNull(headers64);
        org.junit.Assert.assertNotNull(headers83);
        org.junit.Assert.assertTrue("'" + long90 + "' != '" + (-1L) + "'", long90 == (-1L));
        org.junit.Assert.assertTrue("'" + long91 + "' != '" + (-1L) + "'", long91 == (-1L));
        org.junit.Assert.assertNotNull(intOptional92);
        org.junit.Assert.assertNotNull(wildcardClass94);
    }

    @Test
    public void test00322() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00322");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.common.header.Headers> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.common.header.Headers> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.common.header.Headers>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00323() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00323");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional7 = strConsumerRecord5.leaderEpoch();
        java.lang.String str8 = strConsumerRecord5.topic();
        java.io.Serializable serializable9 = strConsumerRecord5.value();
        long long10 = strConsumerRecord5.timestamp();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertEquals("'" + serializable9 + "' != '" + (short) 10 + "'", serializable9, (short) 10);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
    }

    @Test
    public void test00324() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00324");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>("ConsumerRecord(topic = , partition = 35, leaderEpoch = null, offset = 10, NoTimestampType = 1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value =  )", (int) (short) 10, (long) (short) 1, "ConsumerRecord(topic = , partition = 35, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), value = )", (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = 52, serialized key size = 35, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)");
    }

    @Test
    public void test00325() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00325");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        org.apache.kafka.common.header.Headers headers7 = strConsumerRecord5.headers();
        int int8 = strConsumerRecord5.serializedKeySize();
        org.apache.kafka.common.header.Headers headers9 = strConsumerRecord5.headers();
        long long10 = strConsumerRecord5.checksum();
        long long11 = strConsumerRecord5.timestamp();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertNotNull(headers7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNotNull(headers9);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
    }

    @Test
    public void test00326() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00326");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType7 = strConsumerRecord5.timestampType();
        java.lang.String str8 = strConsumerRecord5.toString();
        int int9 = strConsumerRecord5.partition();
        int int10 = strConsumerRecord5.partition();
        org.apache.kafka.common.header.Headers headers11 = strConsumerRecord5.headers();
        int int12 = strConsumerRecord5.serializedKeySize();
        java.lang.String str13 = strConsumerRecord5.toString();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str8, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + 100 + "'", int9 == 100);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 100 + "'", int10 == 100);
        org.junit.Assert.assertNotNull(headers11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str13, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
    }

    @Test
    public void test00327() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00327");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, java.lang.Object> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.Object> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.Object>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00328() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00328");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        long long7 = strConsumerRecord5.checksum();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType9 = strConsumerRecord5.timestampType();
        java.lang.String str10 = strConsumerRecord5.topic();
        java.util.Optional<java.lang.Integer> intOptional11 = strConsumerRecord5.leaderEpoch();
        long long12 = strConsumerRecord5.checksum();
        java.lang.String str13 = strConsumerRecord5.toString();
        java.lang.String str14 = strConsumerRecord5.topic();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertTrue("'" + timestampType9 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType9.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "hi!" + "'", str10, "hi!");
        org.junit.Assert.assertNotNull(intOptional11);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str13, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
    }

    @Test
    public void test00329() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00329");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.lang.Object> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.Object> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.Object>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00330() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00330");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord17.timestampType();
        java.lang.String str21 = strConsumerRecord17.key();
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType33 = strConsumerRecord32.timestampType();
        java.lang.Class<?> wildcardClass34 = strConsumerRecord32.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType22, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass34);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType53 = strConsumerRecord52.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) 10, 0L, "hi!", (java.io.Serializable) timestampType53);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType65 = strConsumerRecord64.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int72 = strConsumerRecord71.serializedValueSize();
        int int73 = strConsumerRecord71.partition();
        org.apache.kafka.common.header.Headers headers74 = strConsumerRecord71.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) ' ', 0L, (long) (byte) 10, timestampType53, (java.lang.Long) 0L, 10, (-1), "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (java.io.Serializable) timestampType65, headers74);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int82 = strConsumerRecord81.serializedValueSize();
        int int83 = strConsumerRecord81.partition();
        long long84 = strConsumerRecord81.offset();
        java.lang.String str85 = strConsumerRecord81.key();
        org.apache.kafka.common.record.TimestampType timestampType86 = strConsumerRecord81.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> timestampTypeEnumConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (-1), 100L, (long) (short) 1, timestampType22, (long) (byte) 1, (int) (byte) 10, (int) (short) 1, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType65, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType86);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) (byte) -1, (long) (short) 0, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (java.io.Serializable) "hi!");
        org.apache.kafka.common.record.TimestampType timestampType89 = strConsumerRecord88.timestampType();
        long long90 = strConsumerRecord88.offset();
        java.lang.Class<?> wildcardClass91 = strConsumerRecord88.getClass();
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "" + "'", str21, "");
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType33 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType33.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass34);
        org.junit.Assert.assertTrue("'" + timestampType53 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType53.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType65 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType65.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int72 + "' != '" + (-1) + "'", int72 == (-1));
        org.junit.Assert.assertTrue("'" + int73 + "' != '" + 100 + "'", int73 == 100);
        org.junit.Assert.assertNotNull(headers74);
        org.junit.Assert.assertTrue("'" + int82 + "' != '" + (-1) + "'", int82 == (-1));
        org.junit.Assert.assertTrue("'" + int83 + "' != '" + 100 + "'", int83 == 100);
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + 52L + "'", long84 == 52L);
        org.junit.Assert.assertEquals("'" + str85 + "' != '" + "" + "'", str85, "");
        org.junit.Assert.assertTrue("'" + timestampType86 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType86.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType89 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType89.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long90 + "' != '" + 0L + "'", long90 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass91);
    }

    @Test
    public void test00331() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00331");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        org.apache.kafka.common.header.Headers headers10 = strConsumerRecord5.headers();
        long long11 = strConsumerRecord5.checksum();
        int int12 = strConsumerRecord5.serializedKeySize();
        int int13 = strConsumerRecord5.serializedValueSize();
        long long14 = strConsumerRecord5.offset();
        int int15 = strConsumerRecord5.serializedValueSize();
        java.lang.String str16 = strConsumerRecord5.topic();
        long long17 = strConsumerRecord5.checksum();
        long long18 = strConsumerRecord5.offset();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "hi!" + "'", str16, "hi!");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 52L + "'", long18 == 52L);
    }

    @Test
    public void test00332() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00332");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.reflect.GenericDeclaration> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.reflect.GenericDeclaration> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.reflect.GenericDeclaration>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00333() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00333");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType26 = strConsumerRecord25.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str44 = strConsumerRecord43.topic();
        org.apache.kafka.common.record.TimestampType timestampType45 = strConsumerRecord43.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord35, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType45);
        java.lang.String str47 = strConsumerRecord35.topic();
        java.lang.Class<?> wildcardClass48 = strConsumerRecord35.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object> timestampTypeConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object>("hi!", (int) (short) 100, 1L, 100L, timestampType16, (long) (short) -1, (int) (byte) -1, (int) (byte) -1, timestampType26, (java.lang.Object) wildcardClass48);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) -1, (long) '#', "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass48);
        java.lang.String str51 = strConsumerRecord50.toString();
        java.lang.Class<?> wildcardClass52 = strConsumerRecord50.getClass();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType26 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType26.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertEquals("'" + str44 + "' != '" + "hi!" + "'", str44, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType45 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType45.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str47 + "' != '" + "hi!" + "'", str47, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass48);
        org.junit.Assert.assertEquals("'" + str51 + "' != '" + "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)" + "'", str51, "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)");
        org.junit.Assert.assertNotNull(wildcardClass52);
    }

    @Test
    public void test00334() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00334");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        int int15 = strConsumerRecord13.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long26 = strConsumerRecord25.timestamp();
        int int27 = strConsumerRecord25.partition();
        java.lang.String str28 = strConsumerRecord25.topic();
        long long29 = strConsumerRecord25.offset();
        java.lang.Class<?> wildcardClass30 = strConsumerRecord25.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int37 = strConsumerRecord36.serializedValueSize();
        int int38 = strConsumerRecord36.partition();
        org.apache.kafka.common.header.Headers headers39 = strConsumerRecord36.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType46 = strConsumerRecord45.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType47 = strConsumerRecord45.timestampType();
        org.apache.kafka.common.header.Headers headers48 = strConsumerRecord45.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str59 = strConsumerRecord58.topic();
        org.apache.kafka.common.record.TimestampType timestampType60 = strConsumerRecord58.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int72 = strConsumerRecord71.serializedValueSize();
        int int73 = strConsumerRecord71.partition();
        org.apache.kafka.common.header.Headers headers74 = strConsumerRecord71.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int81 = strConsumerRecord80.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional82 = strConsumerRecord80.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType60, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers74, intOptional82);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers> annotatedElementConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers>("hi!", (int) (short) 1, 1L, 100L, timestampType16, (java.lang.Long) 1L, 100, (int) (byte) 10, (java.lang.reflect.AnnotatedElement) wildcardClass30, headers39, headers48, intOptional82);
        java.lang.Class<?> wildcardClass85 = annotatedElementConsumerRecord84.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0), partition = 32, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)", (-1), 52L, "", (java.io.Serializable) wildcardClass85);
        java.util.Optional<java.lang.Integer> intOptional87 = strConsumerRecord86.leaderEpoch();
        org.apache.kafka.common.header.Headers headers88 = strConsumerRecord86.headers();
        long long89 = strConsumerRecord86.timestamp();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + (-1L) + "'", long26 == (-1L));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + 100 + "'", int27 == 100);
        org.junit.Assert.assertEquals("'" + str28 + "' != '" + "hi!" + "'", str28, "hi!");
        org.junit.Assert.assertTrue("'" + long29 + "' != '" + 52L + "'", long29 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass30);
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + (-1) + "'", int37 == (-1));
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + 100 + "'", int38 == 100);
        org.junit.Assert.assertNotNull(headers39);
        org.junit.Assert.assertTrue("'" + timestampType46 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType46.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType47 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType47.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers48);
        org.junit.Assert.assertEquals("'" + str59 + "' != '" + "hi!" + "'", str59, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType60 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType60.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int72 + "' != '" + (-1) + "'", int72 == (-1));
        org.junit.Assert.assertTrue("'" + int73 + "' != '" + 100 + "'", int73 == 100);
        org.junit.Assert.assertNotNull(headers74);
        org.junit.Assert.assertTrue("'" + int81 + "' != '" + (-1) + "'", int81 == (-1));
        org.junit.Assert.assertNotNull(intOptional82);
        org.junit.Assert.assertNotNull(wildcardClass85);
        org.junit.Assert.assertNotNull(intOptional87);
        org.junit.Assert.assertNotNull(headers88);
        org.junit.Assert.assertTrue("'" + long89 + "' != '" + (-1L) + "'", long89 == (-1L));
    }

    @Test
    public void test00335() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00335");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.timestamp();
        int int10 = strConsumerRecord5.serializedKeySize();
        java.lang.String str11 = strConsumerRecord5.key();
        int int12 = strConsumerRecord5.partition();
        java.lang.String str13 = strConsumerRecord5.toString();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str13, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
    }

    @Test
    public void test00336() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00336");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int10 = strConsumerRecord9.serializedValueSize();
        int int11 = strConsumerRecord9.partition();
        long long12 = strConsumerRecord9.offset();
        long long13 = strConsumerRecord9.offset();
        org.apache.kafka.common.header.Headers headers14 = strConsumerRecord9.headers();
        long long15 = strConsumerRecord9.checksum();
        int int16 = strConsumerRecord9.serializedKeySize();
        java.lang.Class<?> wildcardClass17 = strConsumerRecord9.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", (int) ' ', (long) (byte) 100, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (java.io.Serializable) wildcardClass17);
        java.io.Serializable serializable19 = strConsumerRecord18.value();
        java.lang.Class<?> wildcardClass20 = serializable19.getClass();
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertNotNull(headers14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + (-1) + "'", int16 == (-1));
        org.junit.Assert.assertNotNull(wildcardClass17);
        org.junit.Assert.assertNotNull(serializable19);
        org.junit.Assert.assertNotNull(wildcardClass20);
    }

    @Test
    public void test00337() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00337");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str18 = strConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int31 = strConsumerRecord30.serializedValueSize();
        int int32 = strConsumerRecord30.partition();
        org.apache.kafka.common.header.Headers headers33 = strConsumerRecord30.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int40 = strConsumerRecord39.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional41 = strConsumerRecord39.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType19, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers33, intOptional41);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int54 = strConsumerRecord53.serializedValueSize();
        int int55 = strConsumerRecord53.partition();
        org.apache.kafka.common.header.Headers headers56 = strConsumerRecord53.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType19, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers56);
        long long58 = strConsumerRecord57.offset();
        java.lang.String str59 = strConsumerRecord57.topic();
        long long60 = strConsumerRecord57.offset();
        int int61 = strConsumerRecord57.serializedValueSize();
        int int62 = strConsumerRecord57.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional63 = strConsumerRecord57.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType64 = strConsumerRecord57.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers74 = strConsumerRecord73.headers();
        int int75 = strConsumerRecord73.partition();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.CharSequence> strComparableConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.CharSequence>("", (int) (byte) 100, (long) (byte) -1, (java.lang.Comparable<java.lang.String>) "", (java.lang.CharSequence) "");
        java.lang.Class<?> wildcardClass86 = strComparableConsumerRecord85.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", (int) (short) 1, (long) '#', "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)", (java.io.Serializable) wildcardClass86);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord93 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long94 = strConsumerRecord93.timestamp();
        long long95 = strConsumerRecord93.checksum();
        long long96 = strConsumerRecord93.timestamp();
        org.apache.kafka.common.header.Headers headers97 = strConsumerRecord93.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.reflect.AnnotatedElement> strConsumerRecordConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", 100, (long) (short) 100, 10L, timestampType64, (java.lang.Long) 35L, (int) (byte) 0, (int) (short) 10, strConsumerRecord73, (java.lang.reflect.AnnotatedElement) wildcardClass86, headers97);
        long long99 = strConsumerRecord73.checksum();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "hi!" + "'", str18, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + (-1) + "'", int31 == (-1));
        org.junit.Assert.assertTrue("'" + int32 + "' != '" + 100 + "'", int32 == 100);
        org.junit.Assert.assertNotNull(headers33);
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + (-1) + "'", int40 == (-1));
        org.junit.Assert.assertNotNull(intOptional41);
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + (-1) + "'", int54 == (-1));
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + 100 + "'", int55 == 100);
        org.junit.Assert.assertNotNull(headers56);
        org.junit.Assert.assertTrue("'" + long58 + "' != '" + 1L + "'", long58 == 1L);
        org.junit.Assert.assertEquals("'" + str59 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str59, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + 1L + "'", long60 == 1L);
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + 1 + "'", int61 == 1);
        org.junit.Assert.assertTrue("'" + int62 + "' != '" + 1 + "'", int62 == 1);
        org.junit.Assert.assertNotNull(intOptional63);
        org.junit.Assert.assertTrue("'" + timestampType64 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType64.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers74);
        org.junit.Assert.assertTrue("'" + int75 + "' != '" + 1 + "'", int75 == 1);
        org.junit.Assert.assertNotNull(wildcardClass86);
        org.junit.Assert.assertTrue("'" + long94 + "' != '" + (-1L) + "'", long94 == (-1L));
        org.junit.Assert.assertTrue("'" + long95 + "' != '" + (-1L) + "'", long95 == (-1L));
        org.junit.Assert.assertTrue("'" + long96 + "' != '" + (-1L) + "'", long96 == (-1L));
        org.junit.Assert.assertNotNull(headers97);
        org.junit.Assert.assertTrue("'" + long99 + "' != '" + (-1L) + "'", long99 == (-1L));
    }

    @Test
    public void test00338() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00338");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        java.lang.String str11 = strConsumerRecord5.toString();
        org.apache.kafka.common.header.Headers headers12 = strConsumerRecord5.headers();
        org.apache.kafka.common.record.TimestampType timestampType13 = strConsumerRecord5.timestampType();
        int int14 = strConsumerRecord5.partition();
        java.io.Serializable serializable15 = strConsumerRecord5.value();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str11, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertTrue("'" + timestampType13 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType13.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 100 + "'", int14 == 100);
        org.junit.Assert.assertEquals("'" + serializable15 + "' != '" + (short) 10 + "'", serializable15, (short) 10);
    }

    @Test
    public void test00339() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00339");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord9.timestampType();
        java.lang.String str13 = strConsumerRecord9.key();
        long long14 = strConsumerRecord9.timestamp();
        long long15 = strConsumerRecord9.offset();
        java.lang.String str16 = strConsumerRecord9.toString();
        java.io.Serializable serializable17 = strConsumerRecord9.value();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str32 = strConsumerRecord31.topic();
        org.apache.kafka.common.record.TimestampType timestampType33 = strConsumerRecord31.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int45 = strConsumerRecord44.serializedValueSize();
        int int46 = strConsumerRecord44.partition();
        org.apache.kafka.common.header.Headers headers47 = strConsumerRecord44.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int54 = strConsumerRecord53.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional55 = strConsumerRecord53.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType33, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers47, intOptional55);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long64 = strConsumerRecord63.timestamp();
        long long65 = strConsumerRecord63.checksum();
        long long66 = strConsumerRecord63.timestamp();
        java.util.Optional<java.lang.Integer> intOptional67 = strConsumerRecord63.leaderEpoch();
        org.apache.kafka.common.header.Headers headers68 = strConsumerRecord63.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.CharSequence> serializableConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.CharSequence>("", (-1), (long) 100, 35L, timestampType18, (java.lang.Long) 0L, 35, 10, (java.io.Serializable) '#', (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", headers68);
        java.lang.Class<?> wildcardClass70 = timestampType18.getClass();
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str16, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + serializable17 + "' != '" + (short) 10 + "'", serializable17, (short) 10);
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "hi!" + "'", str32, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType33 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType33.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int45 + "' != '" + (-1) + "'", int45 == (-1));
        org.junit.Assert.assertTrue("'" + int46 + "' != '" + 100 + "'", int46 == 100);
        org.junit.Assert.assertNotNull(headers47);
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + (-1) + "'", int54 == (-1));
        org.junit.Assert.assertNotNull(intOptional55);
        org.junit.Assert.assertTrue("'" + long64 + "' != '" + (-1L) + "'", long64 == (-1L));
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + (-1L) + "'", long65 == (-1L));
        org.junit.Assert.assertTrue("'" + long66 + "' != '" + (-1L) + "'", long66 == (-1L));
        org.junit.Assert.assertNotNull(intOptional67);
        org.junit.Assert.assertNotNull(headers68);
        org.junit.Assert.assertNotNull(wildcardClass70);
    }

    @Test
    public void test00340() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00340");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00341() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00341");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional7 = strConsumerRecord5.leaderEpoch();
        java.lang.String str8 = strConsumerRecord5.topic();
        java.lang.String str9 = strConsumerRecord5.toString();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        java.lang.String str11 = strConsumerRecord5.toString();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str11, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
    }

    @Test
    public void test00342() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00342");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        java.lang.String str9 = strConsumerRecord5.toString();
        int int10 = strConsumerRecord5.partition();
        int int11 = strConsumerRecord5.serializedValueSize();
        java.lang.String str12 = strConsumerRecord5.topic();
        int int13 = strConsumerRecord5.serializedKeySize();
        java.lang.String str14 = strConsumerRecord5.key();
        int int15 = strConsumerRecord5.serializedKeySize();
        java.io.Serializable serializable16 = strConsumerRecord5.value();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 100 + "'", int10 == 100);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertEquals("'" + serializable16 + "' != '" + (short) 10 + "'", serializable16, (short) 10);
    }

    @Test
    public void test00343() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00343");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType7 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.key();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        int int11 = strConsumerRecord5.partition();
        java.io.Serializable serializable12 = strConsumerRecord5.value();
        java.lang.String str13 = strConsumerRecord5.topic();
        java.lang.String str14 = strConsumerRecord5.key();
        long long15 = strConsumerRecord5.checksum();
        java.io.Serializable serializable16 = strConsumerRecord5.value();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "" + "'", str9, "");
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertEquals("'" + serializable12 + "' != '" + (short) 10 + "'", serializable12, (short) 10);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable16 + "' != '" + (short) 10 + "'", serializable16, (short) 10);
    }

    @Test
    public void test00344() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00344");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int17 = strConsumerRecord16.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional18 = strConsumerRecord16.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str25 = strConsumerRecord24.topic();
        org.apache.kafka.common.record.TimestampType timestampType26 = strConsumerRecord24.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord16, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType26);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) -1, 100L, (long) 10, timestampType26, 0L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 0.0f);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int44 = strConsumerRecord43.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional45 = strConsumerRecord43.leaderEpoch();
        java.lang.String str46 = strConsumerRecord43.topic();
        org.apache.kafka.common.record.TimestampType timestampType47 = strConsumerRecord43.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers54 = strConsumerRecord53.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int64 = strConsumerRecord63.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional65 = strConsumerRecord63.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str72 = strConsumerRecord71.topic();
        org.apache.kafka.common.record.TimestampType timestampType73 = strConsumerRecord71.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord63, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType73);
        int int75 = strConsumerRecord63.serializedValueSize();
        java.lang.String str76 = strConsumerRecord63.key();
        java.lang.String str77 = strConsumerRecord63.key();
        java.util.Optional<java.lang.Integer> intOptional78 = strConsumerRecord63.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", 10, (long) (byte) 1, (long) (short) 1, timestampType26, (java.lang.Long) 0L, (int) '#', 100, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", (java.io.Serializable) timestampType47, headers54, intOptional78);
        int int80 = strConsumerRecord79.partition();
        java.lang.Class<?> wildcardClass81 = strConsumerRecord79.getClass();
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + (-1) + "'", int17 == (-1));
        org.junit.Assert.assertNotNull(intOptional18);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "hi!" + "'", str25, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType26 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType26.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int44 + "' != '" + (-1) + "'", int44 == (-1));
        org.junit.Assert.assertNotNull(intOptional45);
        org.junit.Assert.assertEquals("'" + str46 + "' != '" + "hi!" + "'", str46, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType47 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType47.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers54);
        org.junit.Assert.assertTrue("'" + int64 + "' != '" + (-1) + "'", int64 == (-1));
        org.junit.Assert.assertNotNull(intOptional65);
        org.junit.Assert.assertEquals("'" + str72 + "' != '" + "hi!" + "'", str72, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType73 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType73.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int75 + "' != '" + (-1) + "'", int75 == (-1));
        org.junit.Assert.assertEquals("'" + str76 + "' != '" + "" + "'", str76, "");
        org.junit.Assert.assertEquals("'" + str77 + "' != '" + "" + "'", str77, "");
        org.junit.Assert.assertNotNull(intOptional78);
        org.junit.Assert.assertTrue("'" + int80 + "' != '" + 10 + "'", int80 == 10);
        org.junit.Assert.assertNotNull(wildcardClass81);
    }

    @Test
    public void test00345() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00345");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord17.timestampType();
        int int19 = strConsumerRecord17.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType20, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", 0, 1L, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (java.io.Serializable) '#');
        org.apache.kafka.common.record.TimestampType timestampType28 = strConsumerRecord27.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long47 = strConsumerRecord46.timestamp();
        int int48 = strConsumerRecord46.partition();
        java.lang.String str49 = strConsumerRecord46.topic();
        long long50 = strConsumerRecord46.offset();
        java.io.Serializable serializable51 = strConsumerRecord46.value();
        java.lang.String str52 = strConsumerRecord46.topic();
        org.apache.kafka.common.record.TimestampType timestampType53 = strConsumerRecord46.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long65 = strConsumerRecord64.timestamp();
        int int66 = strConsumerRecord64.partition();
        java.lang.String str67 = strConsumerRecord64.topic();
        long long68 = strConsumerRecord64.offset();
        java.io.Serializable serializable69 = strConsumerRecord64.value();
        long long70 = strConsumerRecord64.checksum();
        org.apache.kafka.common.header.Headers headers71 = strConsumerRecord64.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '4', (-1L), (long) 0, timestampType53, (java.lang.Long) 10L, (int) (short) 10, 100, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (java.io.Serializable) ' ', headers71);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long83 = strConsumerRecord82.timestamp();
        long long84 = strConsumerRecord82.timestamp();
        java.io.Serializable serializable85 = strConsumerRecord82.value();
        org.apache.kafka.common.record.TimestampType timestampType86 = strConsumerRecord82.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (int) (short) 10, (long) (-1), (long) (short) -1, timestampType53, (long) 100, 52, (int) (short) 10, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (java.io.Serializable) timestampType86);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.common.record.TimestampType> charSequenceConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.common.record.TimestampType>("ConsumerRecord(topic = , partition = 35, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), value = )", 52, (long) '#', (long) (byte) 0, timestampType28, 100L, 0, (int) (short) 100, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 35, leaderEpoch = null, offset = 10, NoTimestampType = 1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value =  )", timestampType53);
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType28 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType28.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + (-1L) + "'", long47 == (-1L));
        org.junit.Assert.assertTrue("'" + int48 + "' != '" + 100 + "'", int48 == 100);
        org.junit.Assert.assertEquals("'" + str49 + "' != '" + "hi!" + "'", str49, "hi!");
        org.junit.Assert.assertTrue("'" + long50 + "' != '" + 52L + "'", long50 == 52L);
        org.junit.Assert.assertEquals("'" + serializable51 + "' != '" + (short) 10 + "'", serializable51, (short) 10);
        org.junit.Assert.assertEquals("'" + str52 + "' != '" + "hi!" + "'", str52, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType53 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType53.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + (-1L) + "'", long65 == (-1L));
        org.junit.Assert.assertTrue("'" + int66 + "' != '" + 100 + "'", int66 == 100);
        org.junit.Assert.assertEquals("'" + str67 + "' != '" + "hi!" + "'", str67, "hi!");
        org.junit.Assert.assertTrue("'" + long68 + "' != '" + 52L + "'", long68 == 52L);
        org.junit.Assert.assertEquals("'" + serializable69 + "' != '" + (short) 10 + "'", serializable69, (short) 10);
        org.junit.Assert.assertTrue("'" + long70 + "' != '" + (-1L) + "'", long70 == (-1L));
        org.junit.Assert.assertNotNull(headers71);
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + (-1L) + "'", long83 == (-1L));
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + (-1L) + "'", long84 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable85 + "' != '" + (short) 10 + "'", serializable85, (short) 10);
        org.junit.Assert.assertTrue("'" + timestampType86 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType86.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test00346() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00346");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int17 = strConsumerRecord16.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional18 = strConsumerRecord16.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str25 = strConsumerRecord24.topic();
        org.apache.kafka.common.record.TimestampType timestampType26 = strConsumerRecord24.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord16, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType26);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType), value = 0)", (int) '#', 52L, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (java.io.Serializable) "hi!");
        org.apache.kafka.common.record.TimestampType timestampType29 = strConsumerRecord28.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType44 = strConsumerRecord43.timestampType();
        int int45 = strConsumerRecord43.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType46 = strConsumerRecord43.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", 1, 52L, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (java.io.Serializable) timestampType46);
        org.apache.kafka.common.record.TimestampType timestampType48 = strConsumerRecord47.timestampType();
        java.lang.Class<?> wildcardClass49 = timestampType48.getClass();
        org.apache.kafka.common.record.TimestampType timestampType54 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType64 = strConsumerRecord63.timestampType();
        int int65 = strConsumerRecord63.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional66 = strConsumerRecord63.leaderEpoch();
        java.lang.String str67 = strConsumerRecord63.toString();
        java.io.Serializable serializable68 = strConsumerRecord63.value();
        org.apache.kafka.common.header.Headers headers69 = strConsumerRecord63.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers77 = strConsumerRecord76.headers();
        org.apache.kafka.common.header.Headers headers78 = strConsumerRecord76.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long85 = strConsumerRecord84.timestamp();
        long long86 = strConsumerRecord84.timestamp();
        java.util.Optional<java.lang.Integer> intOptional87 = strConsumerRecord84.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.lang.Comparable<java.lang.String>> headersConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) '4', (long) (short) -1, 0L, timestampType54, (java.lang.Long) 0L, 0, 97, headers69, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", headers78, intOptional87);
        java.util.Optional<java.lang.Integer> intOptional89 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord90 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (int) (byte) 10, (long) 97, (long) 32, timestampType29, (java.lang.Long) 100L, (int) (short) 1, 100, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (java.io.Serializable) wildcardClass49, headers69, intOptional89);
        java.lang.Class<?> wildcardClass91 = strConsumerRecord90.getClass();
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + (-1) + "'", int17 == (-1));
        org.junit.Assert.assertNotNull(intOptional18);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "hi!" + "'", str25, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType26 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType26.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType29 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType29.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType44 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType44.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int45 + "' != '" + (-1) + "'", int45 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType46 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType46.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType48 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType48.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass49);
        org.junit.Assert.assertTrue("'" + timestampType64 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType64.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int65 + "' != '" + (-1) + "'", int65 == (-1));
        org.junit.Assert.assertNotNull(intOptional66);
        org.junit.Assert.assertEquals("'" + str67 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str67, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + serializable68 + "' != '" + (short) 10 + "'", serializable68, (short) 10);
        org.junit.Assert.assertNotNull(headers69);
        org.junit.Assert.assertNotNull(headers77);
        org.junit.Assert.assertNotNull(headers78);
        org.junit.Assert.assertTrue("'" + long85 + "' != '" + (-1L) + "'", long85 == (-1L));
        org.junit.Assert.assertTrue("'" + long86 + "' != '" + (-1L) + "'", long86 == (-1L));
        org.junit.Assert.assertNotNull(intOptional87);
        org.junit.Assert.assertNotNull(wildcardClass91);
    }

    @Test
    public void test00347() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00347");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str14 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType26 = strConsumerRecord25.timestampType();
        int int27 = strConsumerRecord25.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType28 = strConsumerRecord25.timestampType();
        java.lang.String str29 = strConsumerRecord25.toString();
        java.util.Optional<java.lang.Integer> intOptional30 = strConsumerRecord25.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType31 = strConsumerRecord25.timestampType();
        java.lang.Class<?> wildcardClass32 = timestampType31.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int42 = strConsumerRecord41.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional43 = strConsumerRecord41.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str50 = strConsumerRecord49.topic();
        org.apache.kafka.common.record.TimestampType timestampType51 = strConsumerRecord49.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord41, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType51);
        org.apache.kafka.common.header.Headers headers53 = strConsumerRecord41.headers();
        org.apache.kafka.common.header.Headers headers54 = strConsumerRecord41.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int64 = strConsumerRecord63.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional65 = strConsumerRecord63.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str72 = strConsumerRecord71.topic();
        org.apache.kafka.common.record.TimestampType timestampType73 = strConsumerRecord71.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord63, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType73);
        java.lang.String str75 = strConsumerRecord63.topic();
        long long76 = strConsumerRecord63.offset();
        long long77 = strConsumerRecord63.offset();
        java.lang.String str78 = strConsumerRecord63.toString();
        java.lang.String str79 = strConsumerRecord63.key();
        long long80 = strConsumerRecord63.checksum();
        org.apache.kafka.common.header.Headers headers81 = strConsumerRecord63.headers();
        java.util.Optional<java.lang.Integer> intOptional82 = strConsumerRecord63.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0)", 10, 1L, 100L, timestampType15, (java.lang.Long) 0L, 0, (int) (byte) 10, "ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0)", (java.io.Serializable) wildcardClass32, headers54, intOptional82);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 32, (long) '4', "ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 100, NoTimestampType = 0, serialized key size = 35, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (java.io.Serializable) "ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0)");
        org.apache.kafka.common.header.Headers headers85 = strConsumerRecord84.headers();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType26 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType26.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType28 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType28.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str29 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str29, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional30);
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass32);
        org.junit.Assert.assertTrue("'" + int42 + "' != '" + (-1) + "'", int42 == (-1));
        org.junit.Assert.assertNotNull(intOptional43);
        org.junit.Assert.assertEquals("'" + str50 + "' != '" + "hi!" + "'", str50, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType51 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType51.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers53);
        org.junit.Assert.assertNotNull(headers54);
        org.junit.Assert.assertTrue("'" + int64 + "' != '" + (-1) + "'", int64 == (-1));
        org.junit.Assert.assertNotNull(intOptional65);
        org.junit.Assert.assertEquals("'" + str72 + "' != '" + "hi!" + "'", str72, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType73 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType73.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str75 + "' != '" + "hi!" + "'", str75, "hi!");
        org.junit.Assert.assertTrue("'" + long76 + "' != '" + 52L + "'", long76 == 52L);
        org.junit.Assert.assertTrue("'" + long77 + "' != '" + 52L + "'", long77 == 52L);
        org.junit.Assert.assertEquals("'" + str78 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str78, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + str79 + "' != '" + "" + "'", str79, "");
        org.junit.Assert.assertTrue("'" + long80 + "' != '" + (-1L) + "'", long80 == (-1L));
        org.junit.Assert.assertNotNull(headers81);
        org.junit.Assert.assertNotNull(intOptional82);
        org.junit.Assert.assertNotNull(headers85);
    }

    @Test
    public void test00348() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00348");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType13 = strConsumerRecord12.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord12.timestampType();
        java.lang.String str15 = strConsumerRecord12.toString();
        int int16 = strConsumerRecord12.partition();
        org.apache.kafka.common.record.TimestampType timestampType17 = strConsumerRecord12.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType36 = strConsumerRecord35.timestampType();
        int int37 = strConsumerRecord35.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType38 = strConsumerRecord35.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType38, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long54 = strConsumerRecord53.timestamp();
        int int55 = strConsumerRecord53.partition();
        java.io.Serializable serializable56 = strConsumerRecord53.value();
        java.lang.Class<?> wildcardClass57 = serializable56.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long64 = strConsumerRecord63.timestamp();
        int int65 = strConsumerRecord63.partition();
        java.lang.String str66 = strConsumerRecord63.topic();
        long long67 = strConsumerRecord63.offset();
        java.lang.Class<?> wildcardClass68 = strConsumerRecord63.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration> typeConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration>("hi!", (int) (short) 0, (long) (byte) 1, 10L, timestampType38, (long) (byte) 10, (int) 'a', (int) (short) -1, (java.lang.reflect.Type) wildcardClass57, (java.lang.reflect.GenericDeclaration) wildcardClass68);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) '4', (long) (byte) 0, 1L, timestampType17, (long) (short) -1, 0, (int) (short) -1, "hi!", (java.io.Serializable) timestampType38);
        org.apache.kafka.common.header.Headers headers71 = strConsumerRecord70.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.String> headerIterableConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.String>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)", 35, 0L, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers71, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = null)");
        org.junit.Assert.assertTrue("'" + timestampType13 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType13.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str15, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 100 + "'", int16 == 100);
        org.junit.Assert.assertTrue("'" + timestampType17 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType17.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType36 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType36.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + (-1) + "'", int37 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType38 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType38.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + (-1L) + "'", long54 == (-1L));
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + 100 + "'", int55 == 100);
        org.junit.Assert.assertEquals("'" + serializable56 + "' != '" + (short) 10 + "'", serializable56, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass57);
        org.junit.Assert.assertTrue("'" + long64 + "' != '" + (-1L) + "'", long64 == (-1L));
        org.junit.Assert.assertTrue("'" + int65 + "' != '" + 100 + "'", int65 == 100);
        org.junit.Assert.assertEquals("'" + str66 + "' != '" + "hi!" + "'", str66, "hi!");
        org.junit.Assert.assertTrue("'" + long67 + "' != '" + 52L + "'", long67 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass68);
        org.junit.Assert.assertNotNull(headers71);
    }

    @Test
    public void test00349() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00349");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        java.lang.String str7 = strConsumerRecord5.topic();
        java.lang.String str8 = strConsumerRecord5.key();
        int int9 = strConsumerRecord5.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord5.leaderEpoch();
        int int11 = strConsumerRecord5.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "hi!" + "'", str7, "hi!");
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "" + "'", str8, "");
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
    }

    @Test
    public void test00350() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00350");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        org.apache.kafka.common.header.Headers headers8 = strConsumerRecord5.headers();
        java.util.Optional<java.lang.Integer> intOptional9 = strConsumerRecord5.leaderEpoch();
        long long10 = strConsumerRecord5.checksum();
        java.lang.Class<?> wildcardClass11 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertNotNull(intOptional9);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass11);
    }

    @Test
    public void test00351() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00351");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int21 = strConsumerRecord20.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional22 = strConsumerRecord20.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str29 = strConsumerRecord28.topic();
        org.apache.kafka.common.record.TimestampType timestampType30 = strConsumerRecord28.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord20, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType30);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) -1, 100L, (long) 10, timestampType30, 0L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 0.0f);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int48 = strConsumerRecord47.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional49 = strConsumerRecord47.leaderEpoch();
        java.lang.String str50 = strConsumerRecord47.topic();
        org.apache.kafka.common.record.TimestampType timestampType51 = strConsumerRecord47.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers58 = strConsumerRecord57.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int68 = strConsumerRecord67.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional69 = strConsumerRecord67.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str76 = strConsumerRecord75.topic();
        org.apache.kafka.common.record.TimestampType timestampType77 = strConsumerRecord75.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord67, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType77);
        int int79 = strConsumerRecord67.serializedValueSize();
        java.lang.String str80 = strConsumerRecord67.key();
        java.lang.String str81 = strConsumerRecord67.key();
        java.util.Optional<java.lang.Integer> intOptional82 = strConsumerRecord67.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", 10, (long) (byte) 1, (long) (short) 1, timestampType30, (java.lang.Long) 0L, (int) '#', 100, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", (java.io.Serializable) timestampType51, headers58, intOptional82);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord89 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) 1, (long) 'a', (long) (short) 1, timestampType30, (long) 10, (int) '#', (int) (byte) 100, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (java.io.Serializable) "");
        long long90 = strConsumerRecord89.offset();
        java.lang.Class<?> wildcardClass91 = strConsumerRecord89.getClass();
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertNotNull(intOptional22);
        org.junit.Assert.assertEquals("'" + str29 + "' != '" + "hi!" + "'", str29, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType30 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType30.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int48 + "' != '" + (-1) + "'", int48 == (-1));
        org.junit.Assert.assertNotNull(intOptional49);
        org.junit.Assert.assertEquals("'" + str50 + "' != '" + "hi!" + "'", str50, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType51 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType51.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers58);
        org.junit.Assert.assertTrue("'" + int68 + "' != '" + (-1) + "'", int68 == (-1));
        org.junit.Assert.assertNotNull(intOptional69);
        org.junit.Assert.assertEquals("'" + str76 + "' != '" + "hi!" + "'", str76, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType77 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType77.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int79 + "' != '" + (-1) + "'", int79 == (-1));
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "" + "'", str80, "");
        org.junit.Assert.assertEquals("'" + str81 + "' != '" + "" + "'", str81, "");
        org.junit.Assert.assertNotNull(intOptional82);
        org.junit.Assert.assertTrue("'" + long90 + "' != '" + 97L + "'", long90 == 97L);
        org.junit.Assert.assertNotNull(wildcardClass91);
    }

    @Test
    public void test00352() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00352");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long10 = strConsumerRecord9.timestamp();
        long long11 = strConsumerRecord9.checksum();
        long long12 = strConsumerRecord9.checksum();
        org.apache.kafka.common.record.TimestampType timestampType13 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long24 = strConsumerRecord23.timestamp();
        int int25 = strConsumerRecord23.partition();
        java.lang.String str26 = strConsumerRecord23.topic();
        java.lang.Class<?> wildcardClass27 = strConsumerRecord23.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long34 = strConsumerRecord33.timestamp();
        long long35 = strConsumerRecord33.checksum();
        long long36 = strConsumerRecord33.checksum();
        int int37 = strConsumerRecord33.serializedValueSize();
        org.apache.kafka.common.header.Headers headers38 = strConsumerRecord33.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str53 = strConsumerRecord52.topic();
        org.apache.kafka.common.record.TimestampType timestampType54 = strConsumerRecord52.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int66 = strConsumerRecord65.serializedValueSize();
        int int67 = strConsumerRecord65.partition();
        org.apache.kafka.common.header.Headers headers68 = strConsumerRecord65.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int75 = strConsumerRecord74.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional76 = strConsumerRecord74.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType54, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers68, intOptional76);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int89 = strConsumerRecord88.serializedValueSize();
        int int90 = strConsumerRecord88.partition();
        org.apache.kafka.common.header.Headers headers91 = strConsumerRecord88.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord92 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType54, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers91);
        long long93 = strConsumerRecord92.offset();
        java.lang.String str94 = strConsumerRecord92.topic();
        long long95 = strConsumerRecord92.offset();
        int int96 = strConsumerRecord92.serializedValueSize();
        int int97 = strConsumerRecord92.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional98 = strConsumerRecord92.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord99 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (int) (short) 10, (long) 1, (long) (byte) -1, timestampType13, (java.lang.Long) 0L, (int) (short) 0, (-1), "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (java.io.Serializable) wildcardClass27, headers38, intOptional98);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType13 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType13.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + (-1L) + "'", long24 == (-1L));
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + 100 + "'", int25 == 100);
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "hi!" + "'", str26, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass27);
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + (-1L) + "'", long35 == (-1L));
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + (-1L) + "'", long36 == (-1L));
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + (-1) + "'", int37 == (-1));
        org.junit.Assert.assertNotNull(headers38);
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "hi!" + "'", str53, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType54 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType54.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int66 + "' != '" + (-1) + "'", int66 == (-1));
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + 100 + "'", int67 == 100);
        org.junit.Assert.assertNotNull(headers68);
        org.junit.Assert.assertTrue("'" + int75 + "' != '" + (-1) + "'", int75 == (-1));
        org.junit.Assert.assertNotNull(intOptional76);
        org.junit.Assert.assertTrue("'" + int89 + "' != '" + (-1) + "'", int89 == (-1));
        org.junit.Assert.assertTrue("'" + int90 + "' != '" + 100 + "'", int90 == 100);
        org.junit.Assert.assertNotNull(headers91);
        org.junit.Assert.assertTrue("'" + long93 + "' != '" + 1L + "'", long93 == 1L);
        org.junit.Assert.assertEquals("'" + str94 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str94, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long95 + "' != '" + 1L + "'", long95 == 1L);
        org.junit.Assert.assertTrue("'" + int96 + "' != '" + 1 + "'", int96 == 1);
        org.junit.Assert.assertTrue("'" + int97 + "' != '" + 1 + "'", int97 == 1);
        org.junit.Assert.assertNotNull(intOptional98);
    }

    @Test
    public void test00353() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00353");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long10 = strConsumerRecord9.timestamp();
        long long11 = strConsumerRecord9.checksum();
        long long12 = strConsumerRecord9.checksum();
        org.apache.kafka.common.record.TimestampType timestampType13 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType24 = strConsumerRecord23.timestampType();
        long long25 = strConsumerRecord23.offset();
        org.apache.kafka.common.record.TimestampType timestampType26 = strConsumerRecord23.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType37 = strConsumerRecord36.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType38 = strConsumerRecord36.timestampType();
        java.lang.String str39 = strConsumerRecord36.toString();
        int int40 = strConsumerRecord36.partition();
        org.apache.kafka.common.record.TimestampType timestampType41 = strConsumerRecord36.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType60 = strConsumerRecord59.timestampType();
        int int61 = strConsumerRecord59.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType62 = strConsumerRecord59.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType62, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long78 = strConsumerRecord77.timestamp();
        int int79 = strConsumerRecord77.partition();
        java.io.Serializable serializable80 = strConsumerRecord77.value();
        java.lang.Class<?> wildcardClass81 = serializable80.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long88 = strConsumerRecord87.timestamp();
        int int89 = strConsumerRecord87.partition();
        java.lang.String str90 = strConsumerRecord87.topic();
        long long91 = strConsumerRecord87.offset();
        java.lang.Class<?> wildcardClass92 = strConsumerRecord87.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration> typeConsumerRecord93 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration>("hi!", (int) (short) 0, (long) (byte) 1, 10L, timestampType62, (long) (byte) 10, (int) 'a', (int) (short) -1, (java.lang.reflect.Type) wildcardClass81, (java.lang.reflect.GenericDeclaration) wildcardClass92);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord94 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) '4', (long) (byte) 0, 1L, timestampType41, (long) (short) -1, 0, (int) (short) -1, "hi!", (java.io.Serializable) timestampType62);
        org.apache.kafka.common.header.Headers headers95 = strConsumerRecord94.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = 52, serialized key size = 35, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) (short) 1, (long) 97, (long) (short) -1, timestampType13, (java.lang.Long) 35L, (int) (byte) 100, 35, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (java.io.Serializable) timestampType26, headers95);
        org.apache.kafka.common.header.Headers headers97 = strConsumerRecord96.headers();
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType13 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType13.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType24 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType24.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + 52L + "'", long25 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType26 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType26.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType37 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType37.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType38 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType38.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str39 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str39, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + 100 + "'", int40 == 100);
        org.junit.Assert.assertTrue("'" + timestampType41 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType41.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType60 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType60.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + (-1) + "'", int61 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType62 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType62.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long78 + "' != '" + (-1L) + "'", long78 == (-1L));
        org.junit.Assert.assertTrue("'" + int79 + "' != '" + 100 + "'", int79 == 100);
        org.junit.Assert.assertEquals("'" + serializable80 + "' != '" + (short) 10 + "'", serializable80, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass81);
        org.junit.Assert.assertTrue("'" + long88 + "' != '" + (-1L) + "'", long88 == (-1L));
        org.junit.Assert.assertTrue("'" + int89 + "' != '" + 100 + "'", int89 == 100);
        org.junit.Assert.assertEquals("'" + str90 + "' != '" + "hi!" + "'", str90, "hi!");
        org.junit.Assert.assertTrue("'" + long91 + "' != '" + 52L + "'", long91 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass92);
        org.junit.Assert.assertNotNull(headers95);
        org.junit.Assert.assertNotNull(headers97);
    }

    @Test
    public void test00354() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00354");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        java.io.Serializable serializable9 = strConsumerRecord5.value();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertEquals("'" + serializable9 + "' != '" + (short) 10 + "'", serializable9, (short) 10);
    }

    @Test
    public void test00355() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00355");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        long long10 = strConsumerRecord5.checksum();
        long long11 = strConsumerRecord5.checksum();
        java.util.Optional<java.lang.Integer> intOptional12 = strConsumerRecord5.leaderEpoch();
        java.lang.String str13 = strConsumerRecord5.topic();
        java.lang.String str14 = strConsumerRecord5.key();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
    }

    @Test
    public void test00356() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00356");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        int int7 = strConsumerRecord5.partition();
        java.lang.String str8 = strConsumerRecord5.topic();
        long long9 = strConsumerRecord5.offset();
        java.io.Serializable serializable10 = strConsumerRecord5.value();
        java.lang.String str11 = strConsumerRecord5.topic();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord5.timestampType();
        long long13 = strConsumerRecord5.offset();
        int int14 = strConsumerRecord5.serializedValueSize();
        java.lang.String str15 = strConsumerRecord5.key();
        java.lang.String str16 = strConsumerRecord5.key();
        java.util.Optional<java.lang.Integer> intOptional17 = strConsumerRecord5.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertEquals("'" + serializable10 + "' != '" + (short) 10 + "'", serializable10, (short) 10);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "hi!" + "'", str11, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "" + "'", str15, "");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertNotNull(intOptional17);
    }

    @Test
    public void test00357() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00357");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        long long7 = strConsumerRecord5.checksum();
        long long8 = strConsumerRecord5.timestamp();
        java.lang.String str9 = strConsumerRecord5.topic();
        long long10 = strConsumerRecord5.timestamp();
        java.io.Serializable serializable11 = strConsumerRecord5.value();
        org.apache.kafka.common.header.Headers headers12 = strConsumerRecord5.headers();
        int int13 = strConsumerRecord5.partition();
        long long14 = strConsumerRecord5.checksum();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + (-1L) + "'", long8 == (-1L));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "hi!" + "'", str9, "hi!");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable11 + "' != '" + (short) 10 + "'", serializable11, (short) 10);
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 100 + "'", int13 == 100);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
    }

    @Test
    public void test00358() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00358");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int9 = strConsumerRecord8.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord8.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str17 = strConsumerRecord16.topic();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord16.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord8, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType18);
        java.lang.String str20 = strConsumerRecord8.topic();
        java.lang.String str21 = strConsumerRecord8.key();
        int int22 = strConsumerRecord8.serializedValueSize();
        java.lang.Class<?> wildcardClass23 = strConsumerRecord8.getClass();
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "" + "'", str21, "");
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertNotNull(wildcardClass23);
    }

    @Test
    public void test00359() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00359");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long14 = strConsumerRecord13.timestamp();
        int int15 = strConsumerRecord13.partition();
        java.lang.String str16 = strConsumerRecord13.topic();
        long long17 = strConsumerRecord13.offset();
        java.io.Serializable serializable18 = strConsumerRecord13.value();
        java.lang.String str19 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType31 = strConsumerRecord30.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 0, (long) '4', (long) (byte) -1, timestampType20, (long) 10, (int) (short) 0, 0, "hi!", (java.io.Serializable) timestampType31);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 100, (long) 0, "", (java.io.Serializable) (byte) -1);
        java.lang.String str34 = strConsumerRecord33.toString();
        java.util.Optional<java.lang.Integer> intOptional35 = strConsumerRecord33.leaderEpoch();
        long long36 = strConsumerRecord33.checksum();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord33.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "hi!" + "'", str16, "hi!");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertEquals("'" + serializable18 + "' != '" + (short) 10 + "'", serializable18, (short) 10);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str34 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)" + "'", str34, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)");
        org.junit.Assert.assertNotNull(intOptional35);
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + (-1L) + "'", long36 == (-1L));
        org.junit.Assert.assertNotNull(intOptional37);
    }

    @Test
    public void test00360() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00360");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int17 = strConsumerRecord16.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional18 = strConsumerRecord16.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str25 = strConsumerRecord24.topic();
        org.apache.kafka.common.record.TimestampType timestampType26 = strConsumerRecord24.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord16, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType26);
        java.lang.String str28 = strConsumerRecord16.topic();
        long long29 = strConsumerRecord16.offset();
        long long30 = strConsumerRecord16.offset();
        java.lang.String str31 = strConsumerRecord16.toString();
        int int32 = strConsumerRecord16.serializedKeySize();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long39 = strConsumerRecord38.timestamp();
        int int40 = strConsumerRecord38.partition();
        java.io.Serializable serializable41 = strConsumerRecord38.value();
        java.lang.Class<?> wildcardClass42 = serializable41.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long49 = strConsumerRecord48.timestamp();
        long long50 = strConsumerRecord48.checksum();
        java.util.Optional<java.lang.Integer> intOptional51 = strConsumerRecord48.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType52 = strConsumerRecord48.timestampType();
        java.lang.String str53 = strConsumerRecord48.topic();
        long long54 = strConsumerRecord48.checksum();
        long long55 = strConsumerRecord48.timestamp();
        java.lang.String str56 = strConsumerRecord48.toString();
        org.apache.kafka.common.header.Headers headers57 = strConsumerRecord48.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers64 = strConsumerRecord63.headers();
        java.io.Serializable serializable65 = strConsumerRecord63.value();
        java.lang.String str66 = strConsumerRecord63.key();
        java.lang.String str67 = strConsumerRecord63.key();
        int int68 = strConsumerRecord63.partition();
        java.util.Optional<java.lang.Integer> intOptional69 = strConsumerRecord63.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.reflect.GenericDeclaration> strConsumerRecordConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", 10, (long) (short) -1, (long) (byte) 100, timestampType4, (java.lang.Long) (-1L), 100, (-1), strConsumerRecord16, (java.lang.reflect.GenericDeclaration) wildcardClass42, headers57, intOptional69);
        java.lang.Class<?> wildcardClass71 = strConsumerRecord16.getClass();
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + (-1) + "'", int17 == (-1));
        org.junit.Assert.assertNotNull(intOptional18);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "hi!" + "'", str25, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType26 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType26.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str28 + "' != '" + "hi!" + "'", str28, "hi!");
        org.junit.Assert.assertTrue("'" + long29 + "' != '" + 52L + "'", long29 == 52L);
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + 52L + "'", long30 == 52L);
        org.junit.Assert.assertEquals("'" + str31 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str31, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int32 + "' != '" + (-1) + "'", int32 == (-1));
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + (-1L) + "'", long39 == (-1L));
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + 100 + "'", int40 == 100);
        org.junit.Assert.assertEquals("'" + serializable41 + "' != '" + (short) 10 + "'", serializable41, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass42);
        org.junit.Assert.assertTrue("'" + long49 + "' != '" + (-1L) + "'", long49 == (-1L));
        org.junit.Assert.assertTrue("'" + long50 + "' != '" + (-1L) + "'", long50 == (-1L));
        org.junit.Assert.assertNotNull(intOptional51);
        org.junit.Assert.assertTrue("'" + timestampType52 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType52.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "hi!" + "'", str53, "hi!");
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + (-1L) + "'", long54 == (-1L));
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + (-1L) + "'", long55 == (-1L));
        org.junit.Assert.assertEquals("'" + str56 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str56, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(headers57);
        org.junit.Assert.assertNotNull(headers64);
        org.junit.Assert.assertEquals("'" + serializable65 + "' != '" + (short) 0 + "'", serializable65, (short) 0);
        org.junit.Assert.assertEquals("'" + str66 + "' != '" + "hi!" + "'", str66, "hi!");
        org.junit.Assert.assertEquals("'" + str67 + "' != '" + "hi!" + "'", str67, "hi!");
        org.junit.Assert.assertTrue("'" + int68 + "' != '" + 1 + "'", int68 == 1);
        org.junit.Assert.assertNotNull(intOptional69);
        org.junit.Assert.assertNotNull(wildcardClass71);
    }

    @Test
    public void test00361() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00361");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType13 = strConsumerRecord12.timestampType();
        int int14 = strConsumerRecord12.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord12.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType)", (int) (byte) 1, (long) (-1), "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) timestampType15);
        java.lang.Class<?> wildcardClass17 = strConsumerRecord16.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.lang.Comparable<java.lang.String>> annotatedElementConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.lang.Comparable<java.lang.String>>("", (int) 'a', 10L, (java.lang.reflect.AnnotatedElement) wildcardClass17, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = 52, serialized key size = 35, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)");
        org.junit.Assert.assertTrue("'" + timestampType13 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType13.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass17);
    }

    @Test
    public void test00362() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00362");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int13 = strConsumerRecord12.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional14 = strConsumerRecord12.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str21 = strConsumerRecord20.topic();
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord20.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord12, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType22);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType), value = 0)", (int) '#', 52L, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (java.io.Serializable) "hi!");
        org.apache.kafka.common.record.TimestampType timestampType25 = strConsumerRecord24.timestampType();
        java.lang.String str26 = strConsumerRecord24.key();
        int int27 = strConsumerRecord24.partition();
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertNotNull(intOptional14);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "hi!" + "'", str21, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType25 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType25.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)" + "'", str26, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)");
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + 35 + "'", int27 == 35);
    }

    @Test
    public void test00363() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00363");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        java.lang.String str9 = strConsumerRecord5.toString();
        long long10 = strConsumerRecord5.checksum();
        int int11 = strConsumerRecord5.partition();
        int int12 = strConsumerRecord5.serializedKeySize();
        long long13 = strConsumerRecord5.timestamp();
        int int14 = strConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
    }

    @Test
    public void test00364() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00364");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord17.timestampType();
        int int19 = strConsumerRecord17.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional20 = strConsumerRecord17.leaderEpoch();
        java.lang.String str21 = strConsumerRecord17.toString();
        java.io.Serializable serializable22 = strConsumerRecord17.value();
        org.apache.kafka.common.header.Headers headers23 = strConsumerRecord17.headers();
        org.apache.kafka.common.record.TimestampType timestampType24 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long35 = strConsumerRecord34.timestamp();
        long long36 = strConsumerRecord34.timestamp();
        java.io.Serializable serializable37 = strConsumerRecord34.value();
        org.apache.kafka.common.record.TimestampType timestampType38 = strConsumerRecord34.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int45 = strConsumerRecord44.serializedValueSize();
        int int46 = strConsumerRecord44.serializedValueSize();
        long long47 = strConsumerRecord44.offset();
        java.lang.String str48 = strConsumerRecord44.key();
        int int49 = strConsumerRecord44.serializedKeySize();
        long long50 = strConsumerRecord44.offset();
        java.lang.String str51 = strConsumerRecord44.topic();
        org.apache.kafka.common.header.Headers headers52 = strConsumerRecord44.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int59 = strConsumerRecord58.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional60 = strConsumerRecord58.leaderEpoch();
        java.lang.String str61 = strConsumerRecord58.topic();
        java.lang.String str62 = strConsumerRecord58.toString();
        java.util.Optional<java.lang.Integer> intOptional63 = strConsumerRecord58.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = 100, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 100)", 32, (long) '4', 10L, timestampType24, (java.lang.Long) 10L, 0, (int) (byte) 1, "ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = null), partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 52, serialized key size = 97, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (java.io.Serializable) timestampType38, headers52, intOptional63);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int78 = strConsumerRecord77.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional79 = strConsumerRecord77.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str86 = strConsumerRecord85.topic();
        org.apache.kafka.common.record.TimestampType timestampType87 = strConsumerRecord85.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord77, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType87);
        int int89 = strConsumerRecord77.serializedValueSize();
        java.lang.String str90 = strConsumerRecord77.key();
        java.lang.String str91 = strConsumerRecord77.key();
        org.apache.kafka.common.record.TimestampType timestampType92 = strConsumerRecord77.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord93 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 35, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), value = )", 1, (long) 0, (long) ' ', timestampType38, 32L, (int) (byte) 10, (int) (short) 0, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = 52, serialized key size = 35, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (java.io.Serializable) timestampType92);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord94 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType)", (int) (short) -1, 0L, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) timestampType92);
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str21, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + serializable22 + "' != '" + (short) 10 + "'", serializable22, (short) 10);
        org.junit.Assert.assertNotNull(headers23);
        org.junit.Assert.assertTrue("'" + timestampType24 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType24.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + (-1L) + "'", long35 == (-1L));
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + (-1L) + "'", long36 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable37 + "' != '" + (short) 10 + "'", serializable37, (short) 10);
        org.junit.Assert.assertTrue("'" + timestampType38 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType38.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int45 + "' != '" + (-1) + "'", int45 == (-1));
        org.junit.Assert.assertTrue("'" + int46 + "' != '" + (-1) + "'", int46 == (-1));
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 52L + "'", long47 == 52L);
        org.junit.Assert.assertEquals("'" + str48 + "' != '" + "" + "'", str48, "");
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + (-1) + "'", int49 == (-1));
        org.junit.Assert.assertTrue("'" + long50 + "' != '" + 52L + "'", long50 == 52L);
        org.junit.Assert.assertEquals("'" + str51 + "' != '" + "hi!" + "'", str51, "hi!");
        org.junit.Assert.assertNotNull(headers52);
        org.junit.Assert.assertTrue("'" + int59 + "' != '" + (-1) + "'", int59 == (-1));
        org.junit.Assert.assertNotNull(intOptional60);
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "hi!" + "'", str61, "hi!");
        org.junit.Assert.assertEquals("'" + str62 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str62, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional63);
        org.junit.Assert.assertTrue("'" + int78 + "' != '" + (-1) + "'", int78 == (-1));
        org.junit.Assert.assertNotNull(intOptional79);
        org.junit.Assert.assertEquals("'" + str86 + "' != '" + "hi!" + "'", str86, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType87 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType87.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int89 + "' != '" + (-1) + "'", int89 == (-1));
        org.junit.Assert.assertEquals("'" + str90 + "' != '" + "" + "'", str90, "");
        org.junit.Assert.assertEquals("'" + str91 + "' != '" + "" + "'", str91, "");
        org.junit.Assert.assertTrue("'" + timestampType92 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType92.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test00365() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00365");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        int int9 = strConsumerRecord5.serializedValueSize();
        int int10 = strConsumerRecord5.serializedValueSize();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
    }

    @Test
    public void test00366() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00366");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int13 = strConsumerRecord12.serializedValueSize();
        int int14 = strConsumerRecord12.partition();
        long long15 = strConsumerRecord12.offset();
        long long16 = strConsumerRecord12.offset();
        org.apache.kafka.common.record.TimestampType timestampType17 = strConsumerRecord12.timestampType();
        java.lang.String str18 = strConsumerRecord12.toString();
        int int19 = strConsumerRecord12.serializedValueSize();
        java.io.Serializable serializable20 = strConsumerRecord12.value();
        java.io.Serializable serializable21 = strConsumerRecord12.value();
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord12.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType29 = strConsumerRecord28.timestampType();
        int int30 = strConsumerRecord28.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType31 = strConsumerRecord28.timestampType();
        java.lang.String str32 = strConsumerRecord28.toString();
        java.util.Optional<java.lang.Integer> intOptional33 = strConsumerRecord28.leaderEpoch();
        long long34 = strConsumerRecord28.offset();
        java.util.Optional<java.lang.Integer> intOptional35 = strConsumerRecord28.leaderEpoch();
        org.apache.kafka.common.header.Headers headers36 = strConsumerRecord28.headers();
        long long37 = strConsumerRecord28.checksum();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>> timestampTypeConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", 97, 35L, timestampType22, strConsumerRecord28);
        org.apache.kafka.common.header.Headers headers39 = strConsumerRecord28.headers();
        int int40 = strConsumerRecord28.partition();
        org.apache.kafka.common.record.TimestampType timestampType41 = strConsumerRecord28.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) -1, (long) ' ', "", (java.io.Serializable) timestampType41);
        java.lang.Class<?> wildcardClass43 = strConsumerRecord42.getClass();
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 100 + "'", int14 == 100);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 52L + "'", long16 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType17 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType17.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str18, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertEquals("'" + serializable20 + "' != '" + (short) 10 + "'", serializable20, (short) 10);
        org.junit.Assert.assertEquals("'" + serializable21 + "' != '" + (short) 10 + "'", serializable21, (short) 10);
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType29 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType29.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str32, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional33);
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + 52L + "'", long34 == 52L);
        org.junit.Assert.assertNotNull(intOptional35);
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertTrue("'" + long37 + "' != '" + (-1L) + "'", long37 == (-1L));
        org.junit.Assert.assertNotNull(headers39);
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + 100 + "'", int40 == 100);
        org.junit.Assert.assertTrue("'" + timestampType41 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType41.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass43);
    }

    @Test
    public void test00367() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00367");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        java.lang.String str9 = strConsumerRecord5.toString();
        int int10 = strConsumerRecord5.partition();
        int int11 = strConsumerRecord5.serializedValueSize();
        java.lang.String str12 = strConsumerRecord5.topic();
        int int13 = strConsumerRecord5.serializedKeySize();
        int int14 = strConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 100 + "'", int10 == 100);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
    }

    @Test
    public void test00368() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00368");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        int int10 = strConsumerRecord5.partition();
        java.lang.String str11 = strConsumerRecord5.toString();
        long long12 = strConsumerRecord5.checksum();
        int int13 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord5.timestampType();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 100 + "'", int10 == 100);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str11, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test00369() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00369");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        long long7 = strConsumerRecord5.checksum();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        long long9 = strConsumerRecord5.timestamp();
        int int10 = strConsumerRecord5.partition();
        int int11 = strConsumerRecord5.serializedKeySize();
        java.lang.Class<?> wildcardClass12 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 100 + "'", int10 == 100);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertNotNull(wildcardClass12);
    }

    @Test
    public void test00370() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00370");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, java.lang.reflect.Type> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.reflect.Type> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.reflect.Type>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00371() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00371");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str14 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int27 = strConsumerRecord26.serializedValueSize();
        int int28 = strConsumerRecord26.partition();
        org.apache.kafka.common.header.Headers headers29 = strConsumerRecord26.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType15, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers29, intOptional37);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int50 = strConsumerRecord49.serializedValueSize();
        int int51 = strConsumerRecord49.partition();
        org.apache.kafka.common.header.Headers headers52 = strConsumerRecord49.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType15, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers52);
        long long54 = strConsumerRecord53.offset();
        java.lang.String str55 = strConsumerRecord53.topic();
        long long56 = strConsumerRecord53.offset();
        org.apache.kafka.common.header.Headers headers57 = strConsumerRecord53.headers();
        java.util.Optional<java.lang.Integer> intOptional58 = strConsumerRecord53.leaderEpoch();
        long long59 = strConsumerRecord53.timestamp();
        int int60 = strConsumerRecord53.serializedValueSize();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 100 + "'", int28 == 100);
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + (-1) + "'", int50 == (-1));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 100 + "'", int51 == 100);
        org.junit.Assert.assertNotNull(headers52);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + 1L + "'", long54 == 1L);
        org.junit.Assert.assertEquals("'" + str55 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str55, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + 1L + "'", long56 == 1L);
        org.junit.Assert.assertNotNull(headers57);
        org.junit.Assert.assertNotNull(intOptional58);
        org.junit.Assert.assertTrue("'" + long59 + "' != '" + 0L + "'", long59 == 0L);
        org.junit.Assert.assertTrue("'" + int60 + "' != '" + 1 + "'", int60 == 1);
    }

    @Test
    public void test00372() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00372");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long14 = strConsumerRecord13.timestamp();
        int int15 = strConsumerRecord13.partition();
        java.lang.String str16 = strConsumerRecord13.topic();
        long long17 = strConsumerRecord13.offset();
        java.io.Serializable serializable18 = strConsumerRecord13.value();
        java.lang.String str19 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType31 = strConsumerRecord30.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 0, (long) '4', (long) (byte) -1, timestampType20, (long) 10, (int) (short) 0, 0, "hi!", (java.io.Serializable) timestampType31);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType47 = strConsumerRecord46.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType48 = strConsumerRecord46.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType49 = strConsumerRecord46.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType59 = strConsumerRecord58.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int69 = strConsumerRecord68.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional70 = strConsumerRecord68.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str77 = strConsumerRecord76.topic();
        org.apache.kafka.common.record.TimestampType timestampType78 = strConsumerRecord76.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord68, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType78);
        java.lang.String str80 = strConsumerRecord68.topic();
        java.lang.Class<?> wildcardClass81 = strConsumerRecord68.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object> timestampTypeConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object>("hi!", (int) (short) 100, 1L, 100L, timestampType49, (long) (short) -1, (int) (byte) -1, (int) (byte) -1, timestampType59, (java.lang.Object) wildcardClass81);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 1, (long) (-1), 100L, timestampType20, (long) 1, (int) (byte) 1, 0, "", (java.io.Serializable) timestampType49);
        long long84 = strConsumerRecord83.checksum();
        java.lang.String str85 = strConsumerRecord83.toString();
        long long86 = strConsumerRecord83.offset();
        java.lang.Class<?> wildcardClass87 = strConsumerRecord83.getClass();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "hi!" + "'", str16, "hi!");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertEquals("'" + serializable18 + "' != '" + (short) 10 + "'", serializable18, (short) 10);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType47 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType47.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType48 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType48.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType49 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType49.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType59 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType59.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int69 + "' != '" + (-1) + "'", int69 == (-1));
        org.junit.Assert.assertNotNull(intOptional70);
        org.junit.Assert.assertEquals("'" + str77 + "' != '" + "hi!" + "'", str77, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType78 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType78.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "hi!" + "'", str80, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass81);
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + 1L + "'", long84 == 1L);
        org.junit.Assert.assertEquals("'" + str85 + "' != '" + "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType)" + "'", str85, "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType)");
        org.junit.Assert.assertTrue("'" + long86 + "' != '" + (-1L) + "'", long86 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass87);
    }

    @Test
    public void test00373() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00373");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.CharSequence> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.CharSequence> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.CharSequence>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00374() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00374");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType7 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.key();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        int int11 = strConsumerRecord5.partition();
        java.io.Serializable serializable12 = strConsumerRecord5.value();
        org.apache.kafka.common.header.Headers headers13 = strConsumerRecord5.headers();
        int int14 = strConsumerRecord5.serializedValueSize();
        java.lang.String str15 = strConsumerRecord5.key();
        int int16 = strConsumerRecord5.partition();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "" + "'", str9, "");
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertEquals("'" + serializable12 + "' != '" + (short) 10 + "'", serializable12, (short) 10);
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "" + "'", str15, "");
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 100 + "'", int16 == 100);
    }

    @Test
    public void test00375() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00375");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.toString();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        int int11 = strConsumerRecord5.serializedKeySize();
        int int12 = strConsumerRecord5.serializedKeySize();
        java.lang.Class<?> wildcardClass13 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNotNull(wildcardClass13);
    }

    @Test
    public void test00376() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00376");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        long long7 = strConsumerRecord5.timestamp();
        org.apache.kafka.common.header.Headers headers8 = strConsumerRecord5.headers();
        int int9 = strConsumerRecord5.partition();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord5.leaderEpoch();
        java.lang.Class<?> wildcardClass11 = intOptional10.getClass();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + 100 + "'", int9 == 100);
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertNotNull(wildcardClass11);
    }

    @Test
    public void test00377() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00377");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.toString();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord5.leaderEpoch();
        long long11 = strConsumerRecord5.offset();
        int int12 = strConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional13 = strConsumerRecord5.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional14 = strConsumerRecord5.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional15 = strConsumerRecord5.leaderEpoch();
        java.lang.String str16 = strConsumerRecord5.key();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNotNull(intOptional14);
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
    }

    @Test
    public void test00378() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00378");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str18 = strConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int31 = strConsumerRecord30.serializedValueSize();
        int int32 = strConsumerRecord30.partition();
        org.apache.kafka.common.header.Headers headers33 = strConsumerRecord30.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int40 = strConsumerRecord39.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional41 = strConsumerRecord39.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType19, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers33, intOptional41);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int54 = strConsumerRecord53.serializedValueSize();
        int int55 = strConsumerRecord53.partition();
        org.apache.kafka.common.header.Headers headers56 = strConsumerRecord53.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType19, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (short) -1, (long) '4', 0L, timestampType19, (long) (byte) 10, (-1), 0, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 1.0f);
        java.lang.String str64 = strConsumerRecord63.topic();
        java.io.Serializable serializable65 = strConsumerRecord63.value();
        int int66 = strConsumerRecord63.partition();
        java.lang.Class<?> wildcardClass67 = strConsumerRecord63.getClass();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "hi!" + "'", str18, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + (-1) + "'", int31 == (-1));
        org.junit.Assert.assertTrue("'" + int32 + "' != '" + 100 + "'", int32 == 100);
        org.junit.Assert.assertNotNull(headers33);
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + (-1) + "'", int40 == (-1));
        org.junit.Assert.assertNotNull(intOptional41);
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + (-1) + "'", int54 == (-1));
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + 100 + "'", int55 == 100);
        org.junit.Assert.assertNotNull(headers56);
        org.junit.Assert.assertEquals("'" + str64 + "' != '" + "" + "'", str64, "");
        org.junit.Assert.assertEquals("'" + serializable65 + "' != '" + 1.0f + "'", serializable65, 1.0f);
        org.junit.Assert.assertTrue("'" + int66 + "' != '" + (-1) + "'", int66 == (-1));
        org.junit.Assert.assertNotNull(wildcardClass67);
    }

    @Test
    public void test00379() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00379");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, org.apache.kafka.common.record.TimestampType> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, org.apache.kafka.common.record.TimestampType> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, org.apache.kafka.common.record.TimestampType>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00380() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00380");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        java.lang.String str17 = strConsumerRecord13.key();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType29 = strConsumerRecord28.timestampType();
        java.lang.Class<?> wildcardClass30 = strConsumerRecord28.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType18, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass30);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str42 = strConsumerRecord41.topic();
        java.lang.Class<?> wildcardClass43 = strConsumerRecord41.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) -1, 100L, (long) 0, timestampType18, (long) (short) 1, (int) '#', 0, "hi!", (java.io.Serializable) wildcardClass43);
        long long45 = strConsumerRecord44.offset();
        int int46 = strConsumerRecord44.serializedKeySize();
        long long47 = strConsumerRecord44.timestamp();
        java.lang.Class<?> wildcardClass48 = strConsumerRecord44.getClass();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType29 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType29.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass30);
        org.junit.Assert.assertEquals("'" + str42 + "' != '" + "hi!" + "'", str42, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass43);
        org.junit.Assert.assertTrue("'" + long45 + "' != '" + 100L + "'", long45 == 100L);
        org.junit.Assert.assertTrue("'" + int46 + "' != '" + 35 + "'", int46 == 35);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 0L + "'", long47 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass48);
    }

    @Test
    public void test00381() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00381");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        int int7 = strConsumerRecord5.partition();
        java.lang.String str8 = strConsumerRecord5.topic();
        long long9 = strConsumerRecord5.offset();
        java.io.Serializable serializable10 = strConsumerRecord5.value();
        java.lang.String str11 = strConsumerRecord5.topic();
        java.io.Serializable serializable12 = strConsumerRecord5.value();
        int int13 = strConsumerRecord5.serializedKeySize();
        java.lang.Class<?> wildcardClass14 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertEquals("'" + serializable10 + "' != '" + (short) 10 + "'", serializable10, (short) 10);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "hi!" + "'", str11, "hi!");
        org.junit.Assert.assertEquals("'" + serializable12 + "' != '" + (short) 10 + "'", serializable12, (short) 10);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertNotNull(wildcardClass14);
    }

    @Test
    public void test00382() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00382");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers13 = strConsumerRecord12.headers();
        org.apache.kafka.common.header.Headers headers14 = strConsumerRecord12.headers();
        int int15 = strConsumerRecord12.serializedKeySize();
        org.apache.kafka.common.header.Headers headers16 = strConsumerRecord12.headers();
        org.apache.kafka.common.header.Headers headers17 = strConsumerRecord12.headers();
        long long18 = strConsumerRecord12.timestamp();
        int int19 = strConsumerRecord12.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord12.timestampType();
        java.lang.Iterable<org.apache.kafka.common.header.Header> headerIterable21 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Iterable<org.apache.kafka.common.header.Header>> timestampTypeEnumConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Iterable<org.apache.kafka.common.header.Header>>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) (byte) 1, 0L, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType20, headerIterable21);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int37 = strConsumerRecord36.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional38 = strConsumerRecord36.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str45 = strConsumerRecord44.topic();
        org.apache.kafka.common.record.TimestampType timestampType46 = strConsumerRecord44.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord36, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType46);
        java.lang.String str48 = strConsumerRecord36.topic();
        long long49 = strConsumerRecord36.offset();
        long long50 = strConsumerRecord36.offset();
        java.lang.String str51 = strConsumerRecord36.toString();
        int int52 = strConsumerRecord36.serializedKeySize();
        java.lang.String str53 = strConsumerRecord36.topic();
        int int54 = strConsumerRecord36.serializedValueSize();
        org.apache.kafka.common.header.Headers headers55 = strConsumerRecord36.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers62 = strConsumerRecord61.headers();
        java.io.Serializable serializable63 = strConsumerRecord61.value();
        java.lang.String str64 = strConsumerRecord61.key();
        int int65 = strConsumerRecord61.serializedValueSize();
        java.lang.String str66 = strConsumerRecord61.key();
        java.util.Optional<java.lang.Integer> intOptional67 = strConsumerRecord61.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = 100, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 100)", (int) (byte) 1, (long) 1, 0L, timestampType20, (java.lang.Long) 0L, (-1), 35, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 1, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = #)", (java.io.Serializable) (-1.0d), headers55, intOptional67);
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertNotNull(headers14);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertNotNull(headers17);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + (-1) + "'", int37 == (-1));
        org.junit.Assert.assertNotNull(intOptional38);
        org.junit.Assert.assertEquals("'" + str45 + "' != '" + "hi!" + "'", str45, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType46 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType46.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str48 + "' != '" + "hi!" + "'", str48, "hi!");
        org.junit.Assert.assertTrue("'" + long49 + "' != '" + 52L + "'", long49 == 52L);
        org.junit.Assert.assertTrue("'" + long50 + "' != '" + 52L + "'", long50 == 52L);
        org.junit.Assert.assertEquals("'" + str51 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str51, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int52 + "' != '" + (-1) + "'", int52 == (-1));
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "hi!" + "'", str53, "hi!");
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + (-1) + "'", int54 == (-1));
        org.junit.Assert.assertNotNull(headers55);
        org.junit.Assert.assertNotNull(headers62);
        org.junit.Assert.assertEquals("'" + serializable63 + "' != '" + (short) 0 + "'", serializable63, (short) 0);
        org.junit.Assert.assertEquals("'" + str64 + "' != '" + "hi!" + "'", str64, "hi!");
        org.junit.Assert.assertTrue("'" + int65 + "' != '" + (-1) + "'", int65 == (-1));
        org.junit.Assert.assertEquals("'" + str66 + "' != '" + "hi!" + "'", str66, "hi!");
        org.junit.Assert.assertNotNull(intOptional67);
    }

    @Test
    public void test00383() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00383");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        int int10 = strConsumerRecord5.partition();
        java.lang.String str11 = strConsumerRecord5.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = strConsumerRecord5.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional13 = strConsumerRecord5.leaderEpoch();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 100 + "'", int10 == 100);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str11, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNotNull(intOptional13);
    }

    @Test
    public void test00384() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00384");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str14 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int27 = strConsumerRecord26.serializedValueSize();
        int int28 = strConsumerRecord26.partition();
        org.apache.kafka.common.header.Headers headers29 = strConsumerRecord26.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType15, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers29, intOptional37);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int50 = strConsumerRecord49.serializedValueSize();
        int int51 = strConsumerRecord49.partition();
        org.apache.kafka.common.header.Headers headers52 = strConsumerRecord49.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType15, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers52);
        long long54 = strConsumerRecord53.checksum();
        java.io.Serializable serializable55 = strConsumerRecord53.value();
        java.util.Optional<java.lang.Integer> intOptional56 = strConsumerRecord53.leaderEpoch();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 100 + "'", int28 == 100);
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + (-1) + "'", int50 == (-1));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 100 + "'", int51 == 100);
        org.junit.Assert.assertNotNull(headers52);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + 52L + "'", long54 == 52L);
        org.junit.Assert.assertEquals("'" + serializable55 + "' != '" + (-1.0d) + "'", serializable55, (-1.0d));
        org.junit.Assert.assertNotNull(intOptional56);
    }

    @Test
    public void test00385() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00385");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (int) (short) -1, 0L, (long) 100, timestampType4, 100L, 32, (int) (short) 0, "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType)", (java.io.Serializable) 0);
    }

    @Test
    public void test00386() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00386");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int17 = strConsumerRecord16.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional18 = strConsumerRecord16.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str25 = strConsumerRecord24.topic();
        org.apache.kafka.common.record.TimestampType timestampType26 = strConsumerRecord24.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord16, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType26);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) -1, 100L, (long) 10, timestampType26, 0L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 0.0f);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType43 = strConsumerRecord42.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType44 = strConsumerRecord42.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType45 = strConsumerRecord42.timestampType();
        java.lang.Object obj46 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object> timestampTypeConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object>("", 0, (long) (byte) 100, (long) (byte) -1, timestampType26, (long) (byte) 100, (int) (short) 10, (int) (short) -1, timestampType45, obj46);
        java.lang.Class<?> wildcardClass48 = timestampTypeConsumerRecord47.getClass();
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + (-1) + "'", int17 == (-1));
        org.junit.Assert.assertNotNull(intOptional18);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "hi!" + "'", str25, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType26 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType26.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType43 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType43.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType44 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType44.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType45 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType45.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass48);
    }

    @Test
    public void test00387() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00387");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord5.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord5.timestampType();
        java.lang.Class<?> wildcardClass12 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass12);
    }

    @Test
    public void test00388() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00388");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        int int7 = strConsumerRecord5.partition();
        java.lang.String str8 = strConsumerRecord5.topic();
        int int9 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        int int11 = strConsumerRecord5.partition();
        java.lang.Class<?> wildcardClass12 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertNotNull(wildcardClass12);
    }

    @Test
    public void test00389() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00389");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        java.lang.String str16 = strConsumerRecord13.toString();
        int int17 = strConsumerRecord13.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType37 = strConsumerRecord36.timestampType();
        int int38 = strConsumerRecord36.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType39 = strConsumerRecord36.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType39, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long55 = strConsumerRecord54.timestamp();
        int int56 = strConsumerRecord54.partition();
        java.io.Serializable serializable57 = strConsumerRecord54.value();
        java.lang.Class<?> wildcardClass58 = serializable57.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long65 = strConsumerRecord64.timestamp();
        int int66 = strConsumerRecord64.partition();
        java.lang.String str67 = strConsumerRecord64.topic();
        long long68 = strConsumerRecord64.offset();
        java.lang.Class<?> wildcardClass69 = strConsumerRecord64.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration> typeConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration>("hi!", (int) (short) 0, (long) (byte) 1, 10L, timestampType39, (long) (byte) 10, (int) 'a', (int) (short) -1, (java.lang.reflect.Type) wildcardClass58, (java.lang.reflect.GenericDeclaration) wildcardClass69);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) '4', (long) (byte) 0, 1L, timestampType18, (long) (short) -1, 0, (int) (short) -1, "hi!", (java.io.Serializable) timestampType39);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers82 = strConsumerRecord81.headers();
        org.apache.kafka.common.header.Headers headers83 = strConsumerRecord81.headers();
        java.lang.Class<?> wildcardClass84 = headers83.getClass();
        org.apache.kafka.common.header.Headers headers85 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 1, serialized key size = 35, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), value = NoTimestampType)", 52, (long) (short) 100, 32L, timestampType18, (java.lang.Long) 52L, 97, 10, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 1, serialized key size = 35, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), value = NoTimestampType)", (java.io.Serializable) wildcardClass84, headers85);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str16, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 100 + "'", int17 == 100);
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType37 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType37.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + (-1) + "'", int38 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType39 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType39.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + (-1L) + "'", long55 == (-1L));
        org.junit.Assert.assertTrue("'" + int56 + "' != '" + 100 + "'", int56 == 100);
        org.junit.Assert.assertEquals("'" + serializable57 + "' != '" + (short) 10 + "'", serializable57, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass58);
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + (-1L) + "'", long65 == (-1L));
        org.junit.Assert.assertTrue("'" + int66 + "' != '" + 100 + "'", int66 == 100);
        org.junit.Assert.assertEquals("'" + str67 + "' != '" + "hi!" + "'", str67, "hi!");
        org.junit.Assert.assertTrue("'" + long68 + "' != '" + 52L + "'", long68 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass69);
        org.junit.Assert.assertNotNull(headers82);
        org.junit.Assert.assertNotNull(headers83);
        org.junit.Assert.assertNotNull(wildcardClass84);
    }

    @Test
    public void test00390() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00390");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long14 = strConsumerRecord13.timestamp();
        int int15 = strConsumerRecord13.partition();
        java.lang.String str16 = strConsumerRecord13.topic();
        long long17 = strConsumerRecord13.offset();
        java.io.Serializable serializable18 = strConsumerRecord13.value();
        java.lang.String str19 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType31 = strConsumerRecord30.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 0, (long) '4', (long) (byte) -1, timestampType20, (long) 10, (int) (short) 0, 0, "hi!", (java.io.Serializable) timestampType31);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType47 = strConsumerRecord46.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType48 = strConsumerRecord46.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType49 = strConsumerRecord46.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType59 = strConsumerRecord58.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int69 = strConsumerRecord68.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional70 = strConsumerRecord68.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str77 = strConsumerRecord76.topic();
        org.apache.kafka.common.record.TimestampType timestampType78 = strConsumerRecord76.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord68, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType78);
        java.lang.String str80 = strConsumerRecord68.topic();
        java.lang.Class<?> wildcardClass81 = strConsumerRecord68.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object> timestampTypeConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object>("hi!", (int) (short) 100, 1L, 100L, timestampType49, (long) (short) -1, (int) (byte) -1, (int) (byte) -1, timestampType59, (java.lang.Object) wildcardClass81);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 1, (long) (-1), 100L, timestampType20, (long) 1, (int) (byte) 1, 0, "", (java.io.Serializable) timestampType49);
        long long84 = strConsumerRecord83.checksum();
        java.lang.String str85 = strConsumerRecord83.toString();
        long long86 = strConsumerRecord83.offset();
        java.io.Serializable serializable87 = strConsumerRecord83.value();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "hi!" + "'", str16, "hi!");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertEquals("'" + serializable18 + "' != '" + (short) 10 + "'", serializable18, (short) 10);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType47 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType47.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType48 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType48.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType49 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType49.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType59 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType59.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int69 + "' != '" + (-1) + "'", int69 == (-1));
        org.junit.Assert.assertNotNull(intOptional70);
        org.junit.Assert.assertEquals("'" + str77 + "' != '" + "hi!" + "'", str77, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType78 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType78.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "hi!" + "'", str80, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass81);
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + 1L + "'", long84 == 1L);
        org.junit.Assert.assertEquals("'" + str85 + "' != '" + "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType)" + "'", str85, "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType)");
        org.junit.Assert.assertTrue("'" + long86 + "' != '" + (-1L) + "'", long86 == (-1L));
        org.junit.Assert.assertTrue("'" + serializable87 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", serializable87.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test00391() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00391");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, java.lang.reflect.Type> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.reflect.Type> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.reflect.Type>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00392() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00392");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType9 = strConsumerRecord8.timestampType();
        long long10 = strConsumerRecord8.offset();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord8.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int25 = strConsumerRecord24.serializedValueSize();
        int int26 = strConsumerRecord24.partition();
        long long27 = strConsumerRecord24.offset();
        java.lang.String str28 = strConsumerRecord24.key();
        org.apache.kafka.common.record.TimestampType timestampType29 = strConsumerRecord24.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = 100, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 100)", 0, (long) 52, (long) 35, timestampType29, (long) (byte) -1, (int) 'a', (int) (short) 10, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (java.io.Serializable) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = 52, serialized key size = 35, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int45 = strConsumerRecord44.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional46 = strConsumerRecord44.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str53 = strConsumerRecord52.topic();
        org.apache.kafka.common.record.TimestampType timestampType54 = strConsumerRecord52.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord44, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType54);
        java.lang.String str56 = strConsumerRecord44.topic();
        long long57 = strConsumerRecord44.offset();
        long long58 = strConsumerRecord44.offset();
        java.lang.String str59 = strConsumerRecord44.toString();
        int int60 = strConsumerRecord44.serializedKeySize();
        java.lang.String str61 = strConsumerRecord44.topic();
        int int62 = strConsumerRecord44.serializedValueSize();
        org.apache.kafka.common.header.Headers headers63 = strConsumerRecord44.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Iterable<org.apache.kafka.common.header.Header>> timestampTypeConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Iterable<org.apache.kafka.common.header.Header>>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = null), partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 52, serialized key size = 97, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 0, 32L, timestampType29, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers63);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, org.apache.kafka.common.header.Headers> timestampTypeEnumConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, org.apache.kafka.common.header.Headers>("hi!", (int) (byte) 10, 0L, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType11, headers63);
        org.junit.Assert.assertTrue("'" + timestampType9 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType9.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 52L + "'", long10 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + (-1) + "'", int25 == (-1));
        org.junit.Assert.assertTrue("'" + int26 + "' != '" + 100 + "'", int26 == 100);
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + 52L + "'", long27 == 52L);
        org.junit.Assert.assertEquals("'" + str28 + "' != '" + "" + "'", str28, "");
        org.junit.Assert.assertTrue("'" + timestampType29 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType29.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int45 + "' != '" + (-1) + "'", int45 == (-1));
        org.junit.Assert.assertNotNull(intOptional46);
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "hi!" + "'", str53, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType54 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType54.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str56 + "' != '" + "hi!" + "'", str56, "hi!");
        org.junit.Assert.assertTrue("'" + long57 + "' != '" + 52L + "'", long57 == 52L);
        org.junit.Assert.assertTrue("'" + long58 + "' != '" + 52L + "'", long58 == 52L);
        org.junit.Assert.assertEquals("'" + str59 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str59, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int60 + "' != '" + (-1) + "'", int60 == (-1));
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "hi!" + "'", str61, "hi!");
        org.junit.Assert.assertTrue("'" + int62 + "' != '" + (-1) + "'", int62 == (-1));
        org.junit.Assert.assertNotNull(headers63);
    }

    @Test
    public void test00393() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00393");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, java.lang.Iterable<org.apache.kafka.common.header.Header>> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.Iterable<org.apache.kafka.common.header.Header>> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.Iterable<org.apache.kafka.common.header.Header>>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00394() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00394");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        java.lang.String str8 = strConsumerRecord5.topic();
        org.apache.kafka.common.record.TimestampType timestampType9 = strConsumerRecord5.timestampType();
        java.io.Serializable serializable10 = strConsumerRecord5.value();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType9 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType9.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + serializable10 + "' != '" + (short) 10 + "'", serializable10, (short) 10);
    }

    @Test
    public void test00395() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00395");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str14 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int27 = strConsumerRecord26.serializedValueSize();
        int int28 = strConsumerRecord26.partition();
        org.apache.kafka.common.header.Headers headers29 = strConsumerRecord26.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType15, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers29, intOptional37);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int50 = strConsumerRecord49.serializedValueSize();
        int int51 = strConsumerRecord49.partition();
        org.apache.kafka.common.header.Headers headers52 = strConsumerRecord49.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType15, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers52);
        long long54 = strConsumerRecord53.offset();
        java.lang.String str55 = strConsumerRecord53.topic();
        long long56 = strConsumerRecord53.offset();
        int int57 = strConsumerRecord53.serializedValueSize();
        int int58 = strConsumerRecord53.serializedKeySize();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 100 + "'", int28 == 100);
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + (-1) + "'", int50 == (-1));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 100 + "'", int51 == 100);
        org.junit.Assert.assertNotNull(headers52);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + 1L + "'", long54 == 1L);
        org.junit.Assert.assertEquals("'" + str55 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str55, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + 1L + "'", long56 == 1L);
        org.junit.Assert.assertTrue("'" + int57 + "' != '" + 1 + "'", int57 == 1);
        org.junit.Assert.assertTrue("'" + int58 + "' != '" + 100 + "'", int58 == 100);
    }

    @Test
    public void test00396() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00396");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00397() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00397");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        org.apache.kafka.common.header.Headers headers7 = strConsumerRecord5.headers();
        int int8 = strConsumerRecord5.serializedKeySize();
        org.apache.kafka.common.header.Headers headers9 = strConsumerRecord5.headers();
        int int10 = strConsumerRecord5.partition();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertNotNull(headers7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNotNull(headers9);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 1 + "'", int10 == 1);
    }

    @Test
    public void test00398() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00398");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str22 = strConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = strConsumerRecord21.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int35 = strConsumerRecord34.serializedValueSize();
        int int36 = strConsumerRecord34.partition();
        org.apache.kafka.common.header.Headers headers37 = strConsumerRecord34.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int44 = strConsumerRecord43.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional45 = strConsumerRecord43.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType23, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers37, intOptional45);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int58 = strConsumerRecord57.serializedValueSize();
        int int59 = strConsumerRecord57.partition();
        org.apache.kafka.common.header.Headers headers60 = strConsumerRecord57.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType23, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers60);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (short) -1, (long) '4', 0L, timestampType23, (long) (byte) 10, (-1), 0, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 1.0f);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers79 = strConsumerRecord78.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long86 = strConsumerRecord85.timestamp();
        long long87 = strConsumerRecord85.checksum();
        java.util.Optional<java.lang.Integer> intOptional88 = strConsumerRecord85.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord89 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 0, 0L, (long) '#', timestampType23, (java.lang.Long) 100L, 0, (int) (short) 100, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", headers79, intOptional88);
        int int90 = strConsumerRecord89.serializedValueSize();
        long long91 = strConsumerRecord89.checksum();
        long long92 = strConsumerRecord89.checksum();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "hi!" + "'", str22, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int35 + "' != '" + (-1) + "'", int35 == (-1));
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + 100 + "'", int36 == 100);
        org.junit.Assert.assertNotNull(headers37);
        org.junit.Assert.assertTrue("'" + int44 + "' != '" + (-1) + "'", int44 == (-1));
        org.junit.Assert.assertNotNull(intOptional45);
        org.junit.Assert.assertTrue("'" + int58 + "' != '" + (-1) + "'", int58 == (-1));
        org.junit.Assert.assertTrue("'" + int59 + "' != '" + 100 + "'", int59 == 100);
        org.junit.Assert.assertNotNull(headers60);
        org.junit.Assert.assertNotNull(headers79);
        org.junit.Assert.assertTrue("'" + long86 + "' != '" + (-1L) + "'", long86 == (-1L));
        org.junit.Assert.assertTrue("'" + long87 + "' != '" + (-1L) + "'", long87 == (-1L));
        org.junit.Assert.assertNotNull(intOptional88);
        org.junit.Assert.assertTrue("'" + int90 + "' != '" + 100 + "'", int90 == 100);
        org.junit.Assert.assertTrue("'" + long91 + "' != '" + 100L + "'", long91 == 100L);
        org.junit.Assert.assertTrue("'" + long92 + "' != '" + 100L + "'", long92 == 100L);
    }

    @Test
    public void test00399() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00399");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", 35, 32L, (long) (short) 10, timestampType15, (long) (short) 100, (int) '#', 0, "", (java.io.Serializable) true);
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord21.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType37 = strConsumerRecord36.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType38 = strConsumerRecord36.timestampType();
        java.lang.String str39 = strConsumerRecord36.toString();
        int int40 = strConsumerRecord36.partition();
        org.apache.kafka.common.record.TimestampType timestampType41 = strConsumerRecord36.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType60 = strConsumerRecord59.timestampType();
        int int61 = strConsumerRecord59.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType62 = strConsumerRecord59.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType62, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long78 = strConsumerRecord77.timestamp();
        int int79 = strConsumerRecord77.partition();
        java.io.Serializable serializable80 = strConsumerRecord77.value();
        java.lang.Class<?> wildcardClass81 = serializable80.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long88 = strConsumerRecord87.timestamp();
        int int89 = strConsumerRecord87.partition();
        java.lang.String str90 = strConsumerRecord87.topic();
        long long91 = strConsumerRecord87.offset();
        java.lang.Class<?> wildcardClass92 = strConsumerRecord87.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration> typeConsumerRecord93 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration>("hi!", (int) (short) 0, (long) (byte) 1, 10L, timestampType62, (long) (byte) 10, (int) 'a', (int) (short) -1, (java.lang.reflect.Type) wildcardClass81, (java.lang.reflect.GenericDeclaration) wildcardClass92);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord94 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) '4', (long) (byte) 0, 1L, timestampType41, (long) (short) -1, 0, (int) (short) -1, "hi!", (java.io.Serializable) timestampType62);
        org.apache.kafka.common.header.Headers headers95 = strConsumerRecord94.headers();
        java.lang.String str96 = strConsumerRecord94.key();
        org.apache.kafka.common.header.Headers headers97 = strConsumerRecord94.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.Iterable<org.apache.kafka.common.header.Header>> strConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.Iterable<org.apache.kafka.common.header.Header>>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", (int) (short) 100, 10L, 97L, timestampType22, (long) 10, (int) '#', (int) (short) 100, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType), value = NoTimestampType)", (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers97);
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType37 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType37.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType38 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType38.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str39 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str39, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + 100 + "'", int40 == 100);
        org.junit.Assert.assertTrue("'" + timestampType41 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType41.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType60 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType60.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + (-1) + "'", int61 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType62 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType62.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long78 + "' != '" + (-1L) + "'", long78 == (-1L));
        org.junit.Assert.assertTrue("'" + int79 + "' != '" + 100 + "'", int79 == 100);
        org.junit.Assert.assertEquals("'" + serializable80 + "' != '" + (short) 10 + "'", serializable80, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass81);
        org.junit.Assert.assertTrue("'" + long88 + "' != '" + (-1L) + "'", long88 == (-1L));
        org.junit.Assert.assertTrue("'" + int89 + "' != '" + 100 + "'", int89 == 100);
        org.junit.Assert.assertEquals("'" + str90 + "' != '" + "hi!" + "'", str90, "hi!");
        org.junit.Assert.assertTrue("'" + long91 + "' != '" + 52L + "'", long91 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass92);
        org.junit.Assert.assertNotNull(headers95);
        org.junit.Assert.assertEquals("'" + str96 + "' != '" + "hi!" + "'", str96, "hi!");
        org.junit.Assert.assertNotNull(headers97);
    }

    @Test
    public void test00400() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00400");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.io.Serializable serializable9 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int22 = strConsumerRecord21.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional23 = strConsumerRecord21.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str30 = strConsumerRecord29.topic();
        org.apache.kafka.common.record.TimestampType timestampType31 = strConsumerRecord29.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord21, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType31);
        java.lang.String str33 = strConsumerRecord21.topic();
        long long34 = strConsumerRecord21.offset();
        long long35 = strConsumerRecord21.offset();
        org.apache.kafka.common.header.Headers headers36 = strConsumerRecord21.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType47 = strConsumerRecord46.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType48 = strConsumerRecord46.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType49 = strConsumerRecord46.timestampType();
        java.lang.String str50 = strConsumerRecord46.key();
        org.apache.kafka.common.record.TimestampType timestampType51 = strConsumerRecord46.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType62 = strConsumerRecord61.timestampType();
        java.lang.Class<?> wildcardClass63 = strConsumerRecord61.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType51, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass63);
        int int65 = strConsumerRecord64.partition();
        long long66 = strConsumerRecord64.checksum();
        org.apache.kafka.common.record.TimestampType timestampType67 = strConsumerRecord64.timestampType();
        org.apache.kafka.common.header.Headers headers68 = strConsumerRecord64.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.common.header.Headers> headerIterableConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.common.header.Headers>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 100, NoTimestampType = 0, serialized key size = 35, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) 'a', (long) 35, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers36, headers68);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers76 = strConsumerRecord75.headers();
        java.io.Serializable serializable77 = strConsumerRecord75.value();
        java.lang.String str78 = strConsumerRecord75.key();
        java.lang.String str79 = strConsumerRecord75.key();
        int int80 = strConsumerRecord75.partition();
        java.util.Optional<java.lang.Integer> intOptional81 = strConsumerRecord75.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 97, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 1)", 35, (long) (byte) 1, 10L, timestampType4, (java.lang.Long) 0L, (int) (byte) 100, 97, "ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0)", serializable9, headers36, intOptional81);
        java.lang.String str83 = strConsumerRecord82.topic();
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertNotNull(intOptional23);
        org.junit.Assert.assertEquals("'" + str30 + "' != '" + "hi!" + "'", str30, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "hi!" + "'", str33, "hi!");
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + 52L + "'", long34 == 52L);
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + 52L + "'", long35 == 52L);
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertTrue("'" + timestampType47 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType47.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType48 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType48.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType49 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType49.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str50 + "' != '" + "" + "'", str50, "");
        org.junit.Assert.assertTrue("'" + timestampType51 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType51.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType62 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType62.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass63);
        org.junit.Assert.assertTrue("'" + int65 + "' != '" + 100 + "'", int65 == 100);
        org.junit.Assert.assertTrue("'" + long66 + "' != '" + 52L + "'", long66 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType67 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType67.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers68);
        org.junit.Assert.assertNotNull(headers76);
        org.junit.Assert.assertEquals("'" + serializable77 + "' != '" + (short) 0 + "'", serializable77, (short) 0);
        org.junit.Assert.assertEquals("'" + str78 + "' != '" + "hi!" + "'", str78, "hi!");
        org.junit.Assert.assertEquals("'" + str79 + "' != '" + "hi!" + "'", str79, "hi!");
        org.junit.Assert.assertTrue("'" + int80 + "' != '" + 1 + "'", int80 == 1);
        org.junit.Assert.assertNotNull(intOptional81);
        org.junit.Assert.assertEquals("'" + str83 + "' != '" + "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 97, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 1)" + "'", str83, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 97, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 1)");
    }

    @Test
    public void test00401() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00401");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str14 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int27 = strConsumerRecord26.serializedValueSize();
        int int28 = strConsumerRecord26.partition();
        org.apache.kafka.common.header.Headers headers29 = strConsumerRecord26.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType15, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers29, intOptional37);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int50 = strConsumerRecord49.serializedValueSize();
        int int51 = strConsumerRecord49.partition();
        org.apache.kafka.common.header.Headers headers52 = strConsumerRecord49.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType15, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers52);
        long long54 = strConsumerRecord53.offset();
        java.io.Serializable serializable55 = strConsumerRecord53.value();
        long long56 = strConsumerRecord53.timestamp();
        java.lang.String str57 = strConsumerRecord53.toString();
        java.io.Serializable serializable58 = strConsumerRecord53.value();
        long long59 = strConsumerRecord53.timestamp();
        long long60 = strConsumerRecord53.timestamp();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 100 + "'", int28 == 100);
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + (-1) + "'", int50 == (-1));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 100 + "'", int51 == 100);
        org.junit.Assert.assertNotNull(headers52);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + 1L + "'", long54 == 1L);
        org.junit.Assert.assertEquals("'" + serializable55 + "' != '" + (-1.0d) + "'", serializable55, (-1.0d));
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + 0L + "'", long56 == 0L);
        org.junit.Assert.assertEquals("'" + str57 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)" + "'", str57, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)");
        org.junit.Assert.assertEquals("'" + serializable58 + "' != '" + (-1.0d) + "'", serializable58, (-1.0d));
        org.junit.Assert.assertTrue("'" + long59 + "' != '" + 0L + "'", long59 == 0L);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + 0L + "'", long60 == 0L);
    }

    @Test
    public void test00402() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00402");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long21 = strConsumerRecord20.timestamp();
        int int22 = strConsumerRecord20.partition();
        java.lang.String str23 = strConsumerRecord20.topic();
        long long24 = strConsumerRecord20.offset();
        java.io.Serializable serializable25 = strConsumerRecord20.value();
        java.lang.String str26 = strConsumerRecord20.topic();
        org.apache.kafka.common.record.TimestampType timestampType27 = strConsumerRecord20.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType38 = strConsumerRecord37.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 0, (long) '4', (long) (byte) -1, timestampType27, (long) 10, (int) (short) 0, 0, "hi!", (java.io.Serializable) timestampType38);
        org.apache.kafka.common.record.TimestampType timestampType40 = strConsumerRecord39.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long51 = strConsumerRecord50.timestamp();
        int int52 = strConsumerRecord50.partition();
        java.lang.String str53 = strConsumerRecord50.topic();
        long long54 = strConsumerRecord50.offset();
        java.io.Serializable serializable55 = strConsumerRecord50.value();
        java.lang.String str56 = strConsumerRecord50.topic();
        org.apache.kafka.common.record.TimestampType timestampType57 = strConsumerRecord50.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int64 = strConsumerRecord63.serializedValueSize();
        int int65 = strConsumerRecord63.partition();
        int int66 = strConsumerRecord63.partition();
        org.apache.kafka.common.header.Headers headers67 = strConsumerRecord63.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (int) (short) -1, (long) '4', (long) 10, timestampType40, (java.lang.Long) 100L, (int) (byte) 10, 0, "", (java.io.Serializable) timestampType57, headers67);
        java.lang.Class<?> wildcardClass69 = strConsumerRecord68.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 10, serialized key size = 10, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 52), partition = 0, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), value = 1)", 10, 10L, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 97, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 1)", (java.io.Serializable) wildcardClass69);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.Comparable<java.lang.String>> typeConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (-1), 1L, (java.lang.reflect.Type) wildcardClass69, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 100 + "'", int22 == 100);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "hi!" + "'", str23, "hi!");
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 52L + "'", long24 == 52L);
        org.junit.Assert.assertEquals("'" + serializable25 + "' != '" + (short) 10 + "'", serializable25, (short) 10);
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "hi!" + "'", str26, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType27 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType27.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType38 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType38.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType40 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType40.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + (-1L) + "'", long51 == (-1L));
        org.junit.Assert.assertTrue("'" + int52 + "' != '" + 100 + "'", int52 == 100);
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "hi!" + "'", str53, "hi!");
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + 52L + "'", long54 == 52L);
        org.junit.Assert.assertEquals("'" + serializable55 + "' != '" + (short) 10 + "'", serializable55, (short) 10);
        org.junit.Assert.assertEquals("'" + str56 + "' != '" + "hi!" + "'", str56, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType57 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType57.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int64 + "' != '" + (-1) + "'", int64 == (-1));
        org.junit.Assert.assertTrue("'" + int65 + "' != '" + 100 + "'", int65 == 100);
        org.junit.Assert.assertTrue("'" + int66 + "' != '" + 100 + "'", int66 == 100);
        org.junit.Assert.assertNotNull(headers67);
        org.junit.Assert.assertNotNull(wildcardClass69);
    }

    @Test
    public void test00403() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00403");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord21.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType23 = strConsumerRecord21.timestampType();
        java.lang.String str24 = strConsumerRecord21.toString();
        int int25 = strConsumerRecord21.partition();
        org.apache.kafka.common.record.TimestampType timestampType26 = strConsumerRecord21.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (short) 10, (long) (byte) 0, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) timestampType26);
        int int28 = strConsumerRecord27.partition();
        int int29 = strConsumerRecord27.partition();
        org.apache.kafka.common.record.TimestampType timestampType30 = strConsumerRecord27.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long44 = strConsumerRecord43.timestamp();
        long long45 = strConsumerRecord43.checksum();
        java.util.Optional<java.lang.Integer> intOptional46 = strConsumerRecord43.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType47 = strConsumerRecord43.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Comparable<java.lang.String>> timestampTypeConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (short) 1, (long) (byte) 1, timestampType47, (java.lang.Comparable<java.lang.String>) "hi!");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (int) (byte) 10, (long) ' ', (long) 97, timestampType30, (long) (short) 100, (int) (short) 100, 52, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (byte) 1);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long61 = strConsumerRecord60.timestamp();
        long long62 = strConsumerRecord60.checksum();
        long long63 = strConsumerRecord60.timestamp();
        java.lang.String str64 = strConsumerRecord60.topic();
        long long65 = strConsumerRecord60.timestamp();
        java.io.Serializable serializable66 = strConsumerRecord60.value();
        org.apache.kafka.common.record.TimestampType timestampType67 = strConsumerRecord60.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.kafka.common.record.TimestampType> strConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.kafka.common.record.TimestampType>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (int) (byte) -1, (long) (byte) 100, 0L, timestampType30, (long) (byte) 10, 97, (int) ' ', "ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = null), partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 52, serialized key size = 97, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", timestampType67);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType79 = strConsumerRecord78.timestampType();
        int int80 = strConsumerRecord78.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional81 = strConsumerRecord78.leaderEpoch();
        java.lang.String str82 = strConsumerRecord78.toString();
        long long83 = strConsumerRecord78.timestamp();
        java.lang.String str84 = strConsumerRecord78.topic();
        org.apache.kafka.common.header.Headers headers85 = strConsumerRecord78.headers();
        int int86 = strConsumerRecord78.partition();
        java.lang.Class<?> wildcardClass87 = strConsumerRecord78.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.reflect.Type> strComparableConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.reflect.Type>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 100.0)", (int) ' ', (long) (short) 0, (long) 52, timestampType30, (long) (short) 1, 100, (int) 'a', (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (java.lang.reflect.Type) wildcardClass87);
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str24 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str24, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + 100 + "'", int25 == 100);
        org.junit.Assert.assertTrue("'" + timestampType26 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType26.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 10 + "'", int28 == 10);
        org.junit.Assert.assertTrue("'" + int29 + "' != '" + 10 + "'", int29 == 10);
        org.junit.Assert.assertTrue("'" + timestampType30 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType30.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + (-1L) + "'", long44 == (-1L));
        org.junit.Assert.assertTrue("'" + long45 + "' != '" + (-1L) + "'", long45 == (-1L));
        org.junit.Assert.assertNotNull(intOptional46);
        org.junit.Assert.assertTrue("'" + timestampType47 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType47.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long61 + "' != '" + (-1L) + "'", long61 == (-1L));
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + (-1L) + "'", long62 == (-1L));
        org.junit.Assert.assertTrue("'" + long63 + "' != '" + (-1L) + "'", long63 == (-1L));
        org.junit.Assert.assertEquals("'" + str64 + "' != '" + "hi!" + "'", str64, "hi!");
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + (-1L) + "'", long65 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable66 + "' != '" + (short) 10 + "'", serializable66, (short) 10);
        org.junit.Assert.assertTrue("'" + timestampType67 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType67.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType79 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType79.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int80 + "' != '" + (-1) + "'", int80 == (-1));
        org.junit.Assert.assertNotNull(intOptional81);
        org.junit.Assert.assertEquals("'" + str82 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str82, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + (-1L) + "'", long83 == (-1L));
        org.junit.Assert.assertEquals("'" + str84 + "' != '" + "hi!" + "'", str84, "hi!");
        org.junit.Assert.assertNotNull(headers85);
        org.junit.Assert.assertTrue("'" + int86 + "' != '" + 100 + "'", int86 == 100);
        org.junit.Assert.assertNotNull(wildcardClass87);
    }

    @Test
    public void test00404() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00404");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType7 = strConsumerRecord5.timestampType();
        java.lang.String str8 = strConsumerRecord5.toString();
        int int9 = strConsumerRecord5.partition();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        int int11 = strConsumerRecord5.serializedValueSize();
        java.lang.String str12 = strConsumerRecord5.topic();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str8, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + 100 + "'", int9 == 100);
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
    }

    @Test
    public void test00405() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00405");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        java.lang.String str17 = strConsumerRecord13.key();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType29 = strConsumerRecord28.timestampType();
        java.lang.Class<?> wildcardClass30 = strConsumerRecord28.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType18, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass30);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int42 = strConsumerRecord41.serializedValueSize();
        int int43 = strConsumerRecord41.partition();
        long long44 = strConsumerRecord41.offset();
        java.lang.String str45 = strConsumerRecord41.key();
        org.apache.kafka.common.record.TimestampType timestampType46 = strConsumerRecord41.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str57 = strConsumerRecord56.topic();
        org.apache.kafka.common.record.TimestampType timestampType58 = strConsumerRecord56.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int70 = strConsumerRecord69.serializedValueSize();
        int int71 = strConsumerRecord69.partition();
        org.apache.kafka.common.header.Headers headers72 = strConsumerRecord69.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int79 = strConsumerRecord78.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional80 = strConsumerRecord78.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType58, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers72, intOptional80);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 97, (long) 1, (long) (short) 0, timestampType18, (java.lang.Long) 100L, (-1), 0, "hi!", (java.io.Serializable) timestampType46, headers72);
        int int83 = strConsumerRecord82.serializedKeySize();
        java.lang.String str84 = strConsumerRecord82.key();
        java.lang.String str85 = strConsumerRecord82.topic();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType29 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType29.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass30);
        org.junit.Assert.assertTrue("'" + int42 + "' != '" + (-1) + "'", int42 == (-1));
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + 100 + "'", int43 == 100);
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + 52L + "'", long44 == 52L);
        org.junit.Assert.assertEquals("'" + str45 + "' != '" + "" + "'", str45, "");
        org.junit.Assert.assertTrue("'" + timestampType46 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType46.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str57 + "' != '" + "hi!" + "'", str57, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType58 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType58.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int70 + "' != '" + (-1) + "'", int70 == (-1));
        org.junit.Assert.assertTrue("'" + int71 + "' != '" + 100 + "'", int71 == 100);
        org.junit.Assert.assertNotNull(headers72);
        org.junit.Assert.assertTrue("'" + int79 + "' != '" + (-1) + "'", int79 == (-1));
        org.junit.Assert.assertNotNull(intOptional80);
        org.junit.Assert.assertTrue("'" + int83 + "' != '" + (-1) + "'", int83 == (-1));
        org.junit.Assert.assertEquals("'" + str84 + "' != '" + "hi!" + "'", str84, "hi!");
        org.junit.Assert.assertEquals("'" + str85 + "' != '" + "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)" + "'", str85, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)");
    }

    @Test
    public void test00406() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00406");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        long long7 = strConsumerRecord5.offset();
        long long8 = strConsumerRecord5.offset();
        java.io.Serializable serializable9 = strConsumerRecord5.value();
        int int10 = strConsumerRecord5.serializedValueSize();
        int int11 = strConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + 52L + "'", long7 == 52L);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertEquals("'" + serializable9 + "' != '" + (short) 10 + "'", serializable9, (short) 10);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
    }

    @Test
    public void test00407() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00407");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.io.Serializable> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.io.Serializable> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.io.Serializable>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00408() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00408");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        java.lang.String str17 = strConsumerRecord13.key();
        long long18 = strConsumerRecord13.timestamp();
        long long19 = strConsumerRecord13.offset();
        java.lang.String str20 = strConsumerRecord13.toString();
        java.io.Serializable serializable21 = strConsumerRecord13.value();
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str33 = strConsumerRecord32.topic();
        java.lang.Class<?> wildcardClass34 = strConsumerRecord32.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord40 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers41 = strConsumerRecord40.headers();
        org.apache.kafka.common.header.Headers headers42 = strConsumerRecord40.headers();
        java.util.Optional<java.lang.Integer> intOptional43 = strConsumerRecord40.leaderEpoch();
        long long44 = strConsumerRecord40.offset();
        org.apache.kafka.common.header.Headers headers45 = strConsumerRecord40.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long56 = strConsumerRecord55.timestamp();
        int int57 = strConsumerRecord55.partition();
        java.lang.String str58 = strConsumerRecord55.topic();
        long long59 = strConsumerRecord55.offset();
        java.io.Serializable serializable60 = strConsumerRecord55.value();
        java.lang.String str61 = strConsumerRecord55.topic();
        org.apache.kafka.common.record.TimestampType timestampType62 = strConsumerRecord55.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType73 = strConsumerRecord72.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 0, (long) '4', (long) (byte) -1, timestampType62, (long) 10, (int) (short) 0, 0, "hi!", (java.io.Serializable) timestampType73);
        org.apache.kafka.common.record.TimestampType timestampType75 = strConsumerRecord74.timestampType();
        java.util.Optional<java.lang.Integer> intOptional76 = strConsumerRecord74.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 100, (long) (short) 0, (long) 1, timestampType22, (java.lang.Long) 10L, 0, (int) (short) 100, "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType)", (java.io.Serializable) wildcardClass34, headers45, intOptional76);
        org.apache.kafka.common.record.TimestampType timestampType78 = strConsumerRecord77.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int89 = strConsumerRecord88.serializedValueSize();
        int int90 = strConsumerRecord88.partition();
        long long91 = strConsumerRecord88.offset();
        long long92 = strConsumerRecord88.offset();
        org.apache.kafka.common.record.TimestampType timestampType93 = strConsumerRecord88.timestampType();
        java.lang.String str94 = strConsumerRecord88.toString();
        org.apache.kafka.common.header.Headers headers95 = strConsumerRecord88.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.Iterable<org.apache.kafka.common.header.Header>> strConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.Iterable<org.apache.kafka.common.header.Header>>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = null)", (int) '4', (long) (short) 10, (long) (byte) 0, timestampType78, (long) (short) 10, (int) (byte) -1, (int) ' ', "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType), value = NoTimestampType)", (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers95);
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str20, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + serializable21 + "' != '" + (short) 10 + "'", serializable21, (short) 10);
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "hi!" + "'", str33, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass34);
        org.junit.Assert.assertNotNull(headers41);
        org.junit.Assert.assertNotNull(headers42);
        org.junit.Assert.assertNotNull(intOptional43);
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + 1L + "'", long44 == 1L);
        org.junit.Assert.assertNotNull(headers45);
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + (-1L) + "'", long56 == (-1L));
        org.junit.Assert.assertTrue("'" + int57 + "' != '" + 100 + "'", int57 == 100);
        org.junit.Assert.assertEquals("'" + str58 + "' != '" + "hi!" + "'", str58, "hi!");
        org.junit.Assert.assertTrue("'" + long59 + "' != '" + 52L + "'", long59 == 52L);
        org.junit.Assert.assertEquals("'" + serializable60 + "' != '" + (short) 10 + "'", serializable60, (short) 10);
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "hi!" + "'", str61, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType62 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType62.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType73 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType73.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType75 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType75.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(intOptional76);
        org.junit.Assert.assertTrue("'" + timestampType78 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType78.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int89 + "' != '" + (-1) + "'", int89 == (-1));
        org.junit.Assert.assertTrue("'" + int90 + "' != '" + 100 + "'", int90 == 100);
        org.junit.Assert.assertTrue("'" + long91 + "' != '" + 52L + "'", long91 == 52L);
        org.junit.Assert.assertTrue("'" + long92 + "' != '" + 52L + "'", long92 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType93 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType93.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str94 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str94, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(headers95);
    }

    @Test
    public void test00409() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00409");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int9 = strConsumerRecord8.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord8.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str17 = strConsumerRecord16.topic();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord16.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord8, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType18);
        java.lang.String str20 = strConsumerRecord8.topic();
        long long21 = strConsumerRecord8.offset();
        java.lang.String str22 = strConsumerRecord8.topic();
        java.lang.String str23 = strConsumerRecord8.topic();
        int int24 = strConsumerRecord8.serializedKeySize();
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "hi!" + "'", str22, "hi!");
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "hi!" + "'", str23, "hi!");
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
    }

    @Test
    public void test00410() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00410");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str6 = strConsumerRecord5.topic();
        java.lang.String str7 = strConsumerRecord5.topic();
        int int8 = strConsumerRecord5.partition();
        long long9 = strConsumerRecord5.offset();
        long long10 = strConsumerRecord5.offset();
        java.lang.String str11 = strConsumerRecord5.toString();
        java.lang.Class<?> wildcardClass12 = strConsumerRecord5.getClass();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "hi!" + "'", str6, "hi!");
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "hi!" + "'", str7, "hi!");
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 100 + "'", int8 == 100);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 52L + "'", long10 == 52L);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str11, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(wildcardClass12);
    }

    @Test
    public void test00411() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00411");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType26 = strConsumerRecord25.timestampType();
        int int27 = strConsumerRecord25.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType28 = strConsumerRecord25.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType28, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", 100, (long) 0, 1L, timestampType11, (long) (short) 1, (int) (byte) 1, (int) (short) 1, "hi!", (java.io.Serializable) '#');
        long long36 = strConsumerRecord35.timestamp();
        java.lang.String str37 = strConsumerRecord35.toString();
        int int38 = strConsumerRecord35.partition();
        java.lang.String str39 = strConsumerRecord35.key();
        java.util.Optional<java.lang.Integer> intOptional40 = strConsumerRecord35.leaderEpoch();
        java.lang.String str41 = strConsumerRecord35.key();
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType26 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType26.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType28 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType28.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + 1L + "'", long36 == 1L);
        org.junit.Assert.assertEquals("'" + str37 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 1, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = #)" + "'", str37, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 1, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = #)");
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + 100 + "'", int38 == 100);
        org.junit.Assert.assertEquals("'" + str39 + "' != '" + "hi!" + "'", str39, "hi!");
        org.junit.Assert.assertNotNull(intOptional40);
        org.junit.Assert.assertEquals("'" + str41 + "' != '" + "hi!" + "'", str41, "hi!");
    }

    @Test
    public void test00412() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00412");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.lang.Iterable<org.apache.kafka.common.header.Header>> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.Iterable<org.apache.kafka.common.header.Header>> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.Iterable<org.apache.kafka.common.header.Header>>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00413() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00413");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str18 = strConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int31 = strConsumerRecord30.serializedValueSize();
        int int32 = strConsumerRecord30.partition();
        org.apache.kafka.common.header.Headers headers33 = strConsumerRecord30.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int40 = strConsumerRecord39.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional41 = strConsumerRecord39.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType19, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers33, intOptional41);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int54 = strConsumerRecord53.serializedValueSize();
        int int55 = strConsumerRecord53.partition();
        org.apache.kafka.common.header.Headers headers56 = strConsumerRecord53.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType19, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (short) -1, (long) '4', 0L, timestampType19, (long) (byte) 10, (-1), 0, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 1.0f);
        int int64 = strConsumerRecord63.serializedValueSize();
        int int65 = strConsumerRecord63.partition();
        int int66 = strConsumerRecord63.partition();
        long long67 = strConsumerRecord63.checksum();
        long long68 = strConsumerRecord63.offset();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "hi!" + "'", str18, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + (-1) + "'", int31 == (-1));
        org.junit.Assert.assertTrue("'" + int32 + "' != '" + 100 + "'", int32 == 100);
        org.junit.Assert.assertNotNull(headers33);
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + (-1) + "'", int40 == (-1));
        org.junit.Assert.assertNotNull(intOptional41);
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + (-1) + "'", int54 == (-1));
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + 100 + "'", int55 == 100);
        org.junit.Assert.assertNotNull(headers56);
        org.junit.Assert.assertTrue("'" + int64 + "' != '" + 0 + "'", int64 == 0);
        org.junit.Assert.assertTrue("'" + int65 + "' != '" + (-1) + "'", int65 == (-1));
        org.junit.Assert.assertTrue("'" + int66 + "' != '" + (-1) + "'", int66 == (-1));
        org.junit.Assert.assertTrue("'" + long67 + "' != '" + 10L + "'", long67 == 10L);
        org.junit.Assert.assertTrue("'" + long68 + "' != '" + 52L + "'", long68 == 52L);
    }

    @Test
    public void test00414() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00414");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.util.Optional<java.lang.Integer>> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.util.Optional<java.lang.Integer>> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.util.Optional<java.lang.Integer>>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00415() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00415");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional7 = strConsumerRecord5.leaderEpoch();
        java.lang.String str8 = strConsumerRecord5.topic();
        java.lang.String str9 = strConsumerRecord5.toString();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        int int11 = strConsumerRecord5.serializedKeySize();
        int int12 = strConsumerRecord5.partition();
        java.io.Serializable serializable13 = strConsumerRecord5.value();
        java.util.Optional<java.lang.Integer> intOptional14 = strConsumerRecord5.leaderEpoch();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
        org.junit.Assert.assertEquals("'" + serializable13 + "' != '" + (short) 10 + "'", serializable13, (short) 10);
        org.junit.Assert.assertNotNull(intOptional14);
    }

    @Test
    public void test00416() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00416");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, java.lang.String> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.String> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.String>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00417() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00417");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        org.apache.kafka.common.header.Headers headers10 = strConsumerRecord5.headers();
        long long11 = strConsumerRecord5.checksum();
        int int12 = strConsumerRecord5.serializedKeySize();
        int int13 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord5.timestampType();
        int int15 = strConsumerRecord5.serializedKeySize();
        long long16 = strConsumerRecord5.offset();
        int int17 = strConsumerRecord5.partition();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 52L + "'", long16 == 52L);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 100 + "'", int17 == 100);
    }

    @Test
    public void test00418() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00418");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        java.io.Serializable serializable7 = strConsumerRecord5.value();
        java.lang.String str8 = strConsumerRecord5.key();
        org.apache.kafka.common.header.Headers headers9 = strConsumerRecord5.headers();
        org.apache.kafka.common.header.Headers headers10 = strConsumerRecord5.headers();
        java.lang.String str11 = strConsumerRecord5.topic();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertEquals("'" + serializable7 + "' != '" + (short) 0 + "'", serializable7, (short) 0);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertNotNull(headers9);
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
    }

    @Test
    public void test00419() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00419");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType7 = strConsumerRecord5.timestampType();
        java.lang.String str8 = strConsumerRecord5.toString();
        int int9 = strConsumerRecord5.partition();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        int int11 = strConsumerRecord5.serializedValueSize();
        long long12 = strConsumerRecord5.checksum();
        org.apache.kafka.common.header.Headers headers13 = strConsumerRecord5.headers();
        java.lang.String str14 = strConsumerRecord5.key();
        int int15 = strConsumerRecord5.partition();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str8, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + 100 + "'", int9 == 100);
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
    }

    @Test
    public void test00420() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00420");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedValueSize();
        int int8 = strConsumerRecord5.serializedKeySize();
        java.lang.String str9 = strConsumerRecord5.topic();
        long long10 = strConsumerRecord5.offset();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "hi!" + "'", str9, "hi!");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 52L + "'", long10 == 52L);
    }

    @Test
    public void test00421() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00421");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long23 = strConsumerRecord22.timestamp();
        int int24 = strConsumerRecord22.partition();
        org.apache.kafka.common.record.TimestampType timestampType25 = strConsumerRecord22.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType40 = strConsumerRecord39.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) 10, 0L, "hi!", (java.io.Serializable) timestampType40);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType52 = strConsumerRecord51.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int59 = strConsumerRecord58.serializedValueSize();
        int int60 = strConsumerRecord58.partition();
        org.apache.kafka.common.header.Headers headers61 = strConsumerRecord58.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord62 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) ' ', 0L, (long) (byte) 10, timestampType40, (java.lang.Long) 0L, 10, (-1), "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (java.io.Serializable) timestampType52, headers61);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 0, 52L, (long) '#', timestampType12, (java.lang.Long) 0L, (int) (short) 10, (int) (short) -1, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (java.io.Serializable) timestampType25, headers61);
        java.lang.Class<?> wildcardClass64 = timestampType25.getClass();
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long23 + "' != '" + (-1L) + "'", long23 == (-1L));
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + 100 + "'", int24 == 100);
        org.junit.Assert.assertTrue("'" + timestampType25 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType25.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType40 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType40.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType52 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType52.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int59 + "' != '" + (-1) + "'", int59 == (-1));
        org.junit.Assert.assertTrue("'" + int60 + "' != '" + 100 + "'", int60 == 100);
        org.junit.Assert.assertNotNull(headers61);
        org.junit.Assert.assertNotNull(wildcardClass64);
    }

    @Test
    public void test00422() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00422");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int9 = strConsumerRecord8.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord8.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str17 = strConsumerRecord16.topic();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord16.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord8, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType18);
        java.lang.String str20 = strConsumerRecord8.topic();
        long long21 = strConsumerRecord8.offset();
        long long22 = strConsumerRecord8.offset();
        java.lang.String str23 = strConsumerRecord8.toString();
        java.lang.String str24 = strConsumerRecord8.key();
        long long25 = strConsumerRecord8.checksum();
        org.apache.kafka.common.header.Headers headers26 = strConsumerRecord8.headers();
        java.util.Optional<java.lang.Integer> intOptional27 = strConsumerRecord8.leaderEpoch();
        java.lang.String str28 = strConsumerRecord8.toString();
        java.lang.String str29 = strConsumerRecord8.toString();
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 52L + "'", long22 == 52L);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str23, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + str24 + "' != '" + "" + "'", str24, "");
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + (-1L) + "'", long25 == (-1L));
        org.junit.Assert.assertNotNull(headers26);
        org.junit.Assert.assertNotNull(intOptional27);
        org.junit.Assert.assertEquals("'" + str28 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str28, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + str29 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str29, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
    }

    @Test
    public void test00423() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00423");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        int int7 = strConsumerRecord5.partition();
        java.lang.String str8 = strConsumerRecord5.topic();
        int int9 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        java.io.Serializable serializable11 = strConsumerRecord5.value();
        java.lang.String str12 = strConsumerRecord5.topic();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + serializable11 + "' != '" + (short) 10 + "'", serializable11, (short) 10);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
    }

    @Test
    public void test00424() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00424");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        java.lang.String str17 = strConsumerRecord13.key();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType29 = strConsumerRecord28.timestampType();
        java.lang.Class<?> wildcardClass30 = strConsumerRecord28.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType18, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass30);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str42 = strConsumerRecord41.topic();
        java.lang.Class<?> wildcardClass43 = strConsumerRecord41.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) -1, 100L, (long) 0, timestampType18, (long) (short) 1, (int) '#', 0, "hi!", (java.io.Serializable) wildcardClass43);
        long long45 = strConsumerRecord44.offset();
        int int46 = strConsumerRecord44.serializedKeySize();
        long long47 = strConsumerRecord44.timestamp();
        java.lang.String str48 = strConsumerRecord44.key();
        int int49 = strConsumerRecord44.partition();
        int int50 = strConsumerRecord44.partition();
        java.util.Optional<java.lang.Integer> intOptional51 = strConsumerRecord44.leaderEpoch();
        long long52 = strConsumerRecord44.timestamp();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType29 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType29.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass30);
        org.junit.Assert.assertEquals("'" + str42 + "' != '" + "hi!" + "'", str42, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass43);
        org.junit.Assert.assertTrue("'" + long45 + "' != '" + 100L + "'", long45 == 100L);
        org.junit.Assert.assertTrue("'" + int46 + "' != '" + 35 + "'", int46 == 35);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 0L + "'", long47 == 0L);
        org.junit.Assert.assertEquals("'" + str48 + "' != '" + "hi!" + "'", str48, "hi!");
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + (-1) + "'", int49 == (-1));
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + (-1) + "'", int50 == (-1));
        org.junit.Assert.assertNotNull(intOptional51);
        org.junit.Assert.assertTrue("'" + long52 + "' != '" + 0L + "'", long52 == 0L);
    }

    @Test
    public void test00425() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00425");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        java.lang.String str8 = strConsumerRecord5.topic();
        long long9 = strConsumerRecord5.checksum();
        long long10 = strConsumerRecord5.offset();
        org.apache.kafka.common.header.Headers headers11 = strConsumerRecord5.headers();
        java.io.Serializable serializable12 = strConsumerRecord5.value();
        java.lang.String str13 = strConsumerRecord5.key();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 52L + "'", long10 == 52L);
        org.junit.Assert.assertNotNull(headers11);
        org.junit.Assert.assertEquals("'" + serializable12 + "' != '" + (short) 10 + "'", serializable12, (short) 10);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
    }

    @Test
    public void test00426() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00426");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional7 = strConsumerRecord5.leaderEpoch();
        java.lang.String str8 = strConsumerRecord5.key();
        org.apache.kafka.common.header.Headers headers9 = strConsumerRecord5.headers();
        long long10 = strConsumerRecord5.offset();
        long long11 = strConsumerRecord5.checksum();
        int int12 = strConsumerRecord5.partition();
        java.lang.String str13 = strConsumerRecord5.topic();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "" + "'", str8, "");
        org.junit.Assert.assertNotNull(headers9);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 52L + "'", long10 == 52L);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
    }

    @Test
    public void test00427() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00427");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        int int15 = strConsumerRecord13.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional16 = strConsumerRecord13.leaderEpoch();
        java.lang.String str17 = strConsumerRecord13.toString();
        java.io.Serializable serializable18 = strConsumerRecord13.value();
        org.apache.kafka.common.header.Headers headers19 = strConsumerRecord13.headers();
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long31 = strConsumerRecord30.timestamp();
        long long32 = strConsumerRecord30.timestamp();
        java.io.Serializable serializable33 = strConsumerRecord30.value();
        org.apache.kafka.common.record.TimestampType timestampType34 = strConsumerRecord30.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord40 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int41 = strConsumerRecord40.serializedValueSize();
        int int42 = strConsumerRecord40.serializedValueSize();
        long long43 = strConsumerRecord40.offset();
        java.lang.String str44 = strConsumerRecord40.key();
        int int45 = strConsumerRecord40.serializedKeySize();
        long long46 = strConsumerRecord40.offset();
        java.lang.String str47 = strConsumerRecord40.topic();
        org.apache.kafka.common.header.Headers headers48 = strConsumerRecord40.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int55 = strConsumerRecord54.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional56 = strConsumerRecord54.leaderEpoch();
        java.lang.String str57 = strConsumerRecord54.topic();
        java.lang.String str58 = strConsumerRecord54.toString();
        java.util.Optional<java.lang.Integer> intOptional59 = strConsumerRecord54.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = 100, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 100)", 32, (long) '4', 10L, timestampType20, (java.lang.Long) 10L, 0, (int) (byte) 1, "ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = null), partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 52, serialized key size = 97, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (java.io.Serializable) timestampType34, headers48, intOptional59);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '4', (long) 1, "ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0), partition = 32, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)", (java.io.Serializable) (byte) 1);
        int int62 = strConsumerRecord61.serializedValueSize();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str17, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + serializable18 + "' != '" + (short) 10 + "'", serializable18, (short) 10);
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long31 + "' != '" + (-1L) + "'", long31 == (-1L));
        org.junit.Assert.assertTrue("'" + long32 + "' != '" + (-1L) + "'", long32 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable33 + "' != '" + (short) 10 + "'", serializable33, (short) 10);
        org.junit.Assert.assertTrue("'" + timestampType34 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType34.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + (-1) + "'", int41 == (-1));
        org.junit.Assert.assertTrue("'" + int42 + "' != '" + (-1) + "'", int42 == (-1));
        org.junit.Assert.assertTrue("'" + long43 + "' != '" + 52L + "'", long43 == 52L);
        org.junit.Assert.assertEquals("'" + str44 + "' != '" + "" + "'", str44, "");
        org.junit.Assert.assertTrue("'" + int45 + "' != '" + (-1) + "'", int45 == (-1));
        org.junit.Assert.assertTrue("'" + long46 + "' != '" + 52L + "'", long46 == 52L);
        org.junit.Assert.assertEquals("'" + str47 + "' != '" + "hi!" + "'", str47, "hi!");
        org.junit.Assert.assertNotNull(headers48);
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + (-1) + "'", int55 == (-1));
        org.junit.Assert.assertNotNull(intOptional56);
        org.junit.Assert.assertEquals("'" + str57 + "' != '" + "hi!" + "'", str57, "hi!");
        org.junit.Assert.assertEquals("'" + str58 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str58, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional59);
        org.junit.Assert.assertTrue("'" + int62 + "' != '" + (-1) + "'", int62 == (-1));
    }

    @Test
    public void test00428() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00428");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        java.lang.String str16 = strConsumerRecord13.toString();
        int int17 = strConsumerRecord13.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (short) 10, (long) (byte) 0, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) timestampType18);
        int int20 = strConsumerRecord19.partition();
        int int21 = strConsumerRecord19.partition();
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord19.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str44 = strConsumerRecord43.topic();
        org.apache.kafka.common.record.TimestampType timestampType45 = strConsumerRecord43.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord35, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType45);
        java.lang.String str47 = strConsumerRecord35.topic();
        long long48 = strConsumerRecord35.timestamp();
        int int49 = strConsumerRecord35.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType50 = strConsumerRecord35.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int57 = strConsumerRecord56.serializedValueSize();
        int int58 = strConsumerRecord56.partition();
        long long59 = strConsumerRecord56.offset();
        long long60 = strConsumerRecord56.offset();
        org.apache.kafka.common.header.Headers headers61 = strConsumerRecord56.headers();
        long long62 = strConsumerRecord56.checksum();
        int int63 = strConsumerRecord56.serializedKeySize();
        org.apache.kafka.common.header.Headers headers64 = strConsumerRecord56.headers();
        long long65 = strConsumerRecord56.checksum();
        int int66 = strConsumerRecord56.serializedValueSize();
        org.apache.kafka.common.header.Headers headers67 = strConsumerRecord56.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> serializableConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 100, NoTimestampType = 0, serialized key size = 35, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 0, (long) (short) 100, (long) 0, timestampType22, (java.lang.Long) 10L, (int) ' ', 35, (java.io.Serializable) "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType), value = 0)", (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType50, headers67);
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str16, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 100 + "'", int17 == 100);
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 10 + "'", int20 == 10);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 10 + "'", int21 == 10);
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertEquals("'" + str44 + "' != '" + "hi!" + "'", str44, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType45 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType45.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str47 + "' != '" + "hi!" + "'", str47, "hi!");
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + (-1) + "'", int49 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType50 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType50.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int57 + "' != '" + (-1) + "'", int57 == (-1));
        org.junit.Assert.assertTrue("'" + int58 + "' != '" + 100 + "'", int58 == 100);
        org.junit.Assert.assertTrue("'" + long59 + "' != '" + 52L + "'", long59 == 52L);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + 52L + "'", long60 == 52L);
        org.junit.Assert.assertNotNull(headers61);
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + (-1L) + "'", long62 == (-1L));
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + (-1) + "'", int63 == (-1));
        org.junit.Assert.assertNotNull(headers64);
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + (-1L) + "'", long65 == (-1L));
        org.junit.Assert.assertTrue("'" + int66 + "' != '" + (-1) + "'", int66 == (-1));
        org.junit.Assert.assertNotNull(headers67);
    }

    @Test
    public void test00429() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00429");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        org.apache.kafka.common.header.Headers headers7 = strConsumerRecord5.headers();
        int int8 = strConsumerRecord5.serializedKeySize();
        org.apache.kafka.common.header.Headers headers9 = strConsumerRecord5.headers();
        java.lang.String str10 = strConsumerRecord5.key();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord5.timestampType();
        java.lang.String str13 = strConsumerRecord5.key();
        java.lang.String str14 = strConsumerRecord5.topic();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertNotNull(headers7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNotNull(headers9);
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "hi!" + "'", str10, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
    }

    @Test
    public void test00430() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00430");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.io.Serializable serializable9 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", 100, (long) (short) 10, (long) 100, timestampType4, (long) 35, (int) (byte) 10, (int) (short) 10, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = 52, serialized key size = 35, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)", serializable9);
    }

    @Test
    public void test00431() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00431");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        java.lang.String str11 = strConsumerRecord5.key();
        java.lang.String str12 = strConsumerRecord5.toString();
        int int13 = strConsumerRecord5.partition();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str12, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 100 + "'", int13 == 100);
    }

    @Test
    public void test00432() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00432");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord9.timestampType();
        java.lang.String str13 = strConsumerRecord9.key();
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers26 = strConsumerRecord25.headers();
        org.apache.kafka.common.header.Headers headers27 = strConsumerRecord25.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int37 = strConsumerRecord36.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional38 = strConsumerRecord36.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str45 = strConsumerRecord44.topic();
        org.apache.kafka.common.record.TimestampType timestampType46 = strConsumerRecord44.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord36, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType46);
        int int48 = strConsumerRecord36.serializedValueSize();
        java.lang.String str49 = strConsumerRecord36.key();
        java.lang.String str50 = strConsumerRecord36.key();
        java.util.Optional<java.lang.Integer> intOptional51 = strConsumerRecord36.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) ' ', (long) (byte) 100, timestampType14, (java.lang.Long) 0L, 0, (int) (short) -1, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", (java.io.Serializable) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", headers27, intOptional51);
        org.apache.kafka.common.record.TimestampType timestampType53 = strConsumerRecord52.timestampType();
        int int54 = strConsumerRecord52.serializedKeySize();
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers26);
        org.junit.Assert.assertNotNull(headers27);
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + (-1) + "'", int37 == (-1));
        org.junit.Assert.assertNotNull(intOptional38);
        org.junit.Assert.assertEquals("'" + str45 + "' != '" + "hi!" + "'", str45, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType46 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType46.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int48 + "' != '" + (-1) + "'", int48 == (-1));
        org.junit.Assert.assertEquals("'" + str49 + "' != '" + "" + "'", str49, "");
        org.junit.Assert.assertEquals("'" + str50 + "' != '" + "" + "'", str50, "");
        org.junit.Assert.assertNotNull(intOptional51);
        org.junit.Assert.assertTrue("'" + timestampType53 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType53.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + 0 + "'", int54 == 0);
    }

    @Test
    public void test00433() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00433");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long17 = strConsumerRecord16.timestamp();
        int int18 = strConsumerRecord16.partition();
        java.lang.String str19 = strConsumerRecord16.topic();
        long long20 = strConsumerRecord16.offset();
        java.io.Serializable serializable21 = strConsumerRecord16.value();
        java.lang.String str22 = strConsumerRecord16.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = strConsumerRecord16.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType34 = strConsumerRecord33.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 0, (long) '4', (long) (byte) -1, timestampType23, (long) 10, (int) (short) 0, 0, "hi!", (java.io.Serializable) timestampType34);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 100, (long) 0, "", (java.io.Serializable) (byte) -1);
        java.lang.String str37 = strConsumerRecord36.toString();
        java.util.Optional<java.lang.Integer> intOptional38 = strConsumerRecord36.leaderEpoch();
        int int39 = strConsumerRecord36.partition();
        int int40 = strConsumerRecord36.partition();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.CharSequence> objConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.CharSequence>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType), value = 0), partition = 35, leaderEpoch = null, offset = 97, NoTimestampType = 100, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = 10)", (int) (short) -1, (long) 35, (java.lang.Object) int40, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 10, serialized key size = 10, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 52), partition = 0, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), value = 1)");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 100 + "'", int18 == 100);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 52L + "'", long20 == 52L);
        org.junit.Assert.assertEquals("'" + serializable21 + "' != '" + (short) 10 + "'", serializable21, (short) 10);
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "hi!" + "'", str22, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType34 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType34.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str37 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)" + "'", str37, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)");
        org.junit.Assert.assertNotNull(intOptional38);
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + 100 + "'", int39 == 100);
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + 100 + "'", int40 == 100);
    }

    @Test
    public void test00434() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00434");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        long long7 = strConsumerRecord5.checksum();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        long long9 = strConsumerRecord5.offset();
        long long10 = strConsumerRecord5.offset();
        long long11 = strConsumerRecord5.timestamp();
        int int12 = strConsumerRecord5.partition();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 52L + "'", long10 == 52L);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
    }

    @Test
    public void test00435() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00435");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00436() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00436");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int13 = strConsumerRecord12.serializedValueSize();
        int int14 = strConsumerRecord12.partition();
        java.lang.String str15 = strConsumerRecord12.topic();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord12.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (-1), (long) 100, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", (java.io.Serializable) timestampType16);
        long long18 = strConsumerRecord17.checksum();
        org.apache.kafka.common.header.Headers headers19 = strConsumerRecord17.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int26 = strConsumerRecord25.serializedValueSize();
        int int27 = strConsumerRecord25.partition();
        long long28 = strConsumerRecord25.offset();
        long long29 = strConsumerRecord25.offset();
        org.apache.kafka.common.record.TimestampType timestampType30 = strConsumerRecord25.timestampType();
        java.io.Serializable serializable31 = strConsumerRecord25.value();
        java.lang.Class<?> wildcardClass32 = strConsumerRecord25.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable> headersConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 1, leaderEpoch = null, offset = 100, NoTimestampType = 100, serialized key size = 97, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 0, (long) (short) 1, headers19, (java.io.Serializable) wildcardClass32);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 100 + "'", int14 == 100);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertTrue("'" + int26 + "' != '" + (-1) + "'", int26 == (-1));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + 100 + "'", int27 == 100);
        org.junit.Assert.assertTrue("'" + long28 + "' != '" + 52L + "'", long28 == 52L);
        org.junit.Assert.assertTrue("'" + long29 + "' != '" + 52L + "'", long29 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType30 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType30.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + serializable31 + "' != '" + (short) 10 + "'", serializable31, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass32);
    }

    @Test
    public void test00437() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00437");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0)", (int) (short) 1, 52L, "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType), value = 0)", (java.io.Serializable) "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)");
        long long6 = strConsumerRecord5.timestamp();
        java.lang.String str7 = strConsumerRecord5.key();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType), value = 0)" + "'", str7, "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType), value = 0)");
    }

    @Test
    public void test00438() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00438");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        int int7 = strConsumerRecord5.partition();
        java.io.Serializable serializable8 = strConsumerRecord5.value();
        java.util.Optional<java.lang.Integer> intOptional9 = strConsumerRecord5.leaderEpoch();
        org.apache.kafka.common.header.Headers headers10 = strConsumerRecord5.headers();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord5.timestampType();
        int int12 = strConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + serializable8 + "' != '" + (short) 10 + "'", serializable8, (short) 10);
        org.junit.Assert.assertNotNull(intOptional9);
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
    }

    @Test
    public void test00439() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00439");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int9 = strConsumerRecord8.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord8.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str17 = strConsumerRecord16.topic();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord16.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord8, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType18);
        int int20 = strConsumerRecord8.serializedValueSize();
        java.io.Serializable serializable21 = strConsumerRecord8.value();
        java.lang.String str22 = strConsumerRecord8.toString();
        int int23 = strConsumerRecord8.partition();
        java.lang.Class<?> wildcardClass24 = strConsumerRecord8.getClass();
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + (-1) + "'", int20 == (-1));
        org.junit.Assert.assertEquals("'" + serializable21 + "' != '" + (short) 10 + "'", serializable21, (short) 10);
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str22, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 100 + "'", int23 == 100);
        org.junit.Assert.assertNotNull(wildcardClass24);
    }

    @Test
    public void test00440() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00440");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        java.lang.String str9 = strConsumerRecord5.toString();
        int int10 = strConsumerRecord5.serializedValueSize();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
    }

    @Test
    public void test00441() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00441");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        java.lang.String str9 = strConsumerRecord5.toString();
        long long10 = strConsumerRecord5.checksum();
        int int11 = strConsumerRecord5.partition();
        long long12 = strConsumerRecord5.offset();
        java.lang.String str13 = strConsumerRecord5.toString();
        java.lang.String str14 = strConsumerRecord5.toString();
        java.util.Optional<java.lang.Integer> intOptional15 = strConsumerRecord5.leaderEpoch();
        java.lang.String str16 = strConsumerRecord5.topic();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str13, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str14, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "hi!" + "'", str16, "hi!");
    }

    @Test
    public void test00442() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00442");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        java.lang.String str9 = strConsumerRecord5.toString();
        int int10 = strConsumerRecord5.partition();
        long long11 = strConsumerRecord5.timestamp();
        long long12 = strConsumerRecord5.checksum();
        java.util.Optional<java.lang.Integer> intOptional13 = strConsumerRecord5.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord5.timestampType();
        int int15 = strConsumerRecord5.serializedKeySize();
        int int16 = strConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 100 + "'", int10 == 100);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + (-1) + "'", int16 == (-1));
    }

    @Test
    public void test00443() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00443");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        java.lang.String str8 = strConsumerRecord5.topic();
        long long9 = strConsumerRecord5.checksum();
        long long10 = strConsumerRecord5.offset();
        java.lang.String str11 = strConsumerRecord5.topic();
        int int12 = strConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 52L + "'", long10 == 52L);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "hi!" + "'", str11, "hi!");
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
    }

    @Test
    public void test00444() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00444");
        java.io.Serializable serializable4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", (int) (byte) -1, 35L, "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)", serializable4);
        long long6 = strConsumerRecord5.timestamp();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
    }

    @Test
    public void test00445() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00445");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        int int7 = strConsumerRecord5.partition();
        java.lang.String str8 = strConsumerRecord5.topic();
        int int9 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        java.io.Serializable serializable11 = strConsumerRecord5.value();
        long long12 = strConsumerRecord5.timestamp();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + serializable11 + "' != '" + (short) 10 + "'", serializable11, (short) 10);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
    }

    @Test
    public void test00446() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00446");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long13 = strConsumerRecord12.timestamp();
        int int14 = strConsumerRecord12.partition();
        java.lang.String str15 = strConsumerRecord12.topic();
        long long16 = strConsumerRecord12.offset();
        java.io.Serializable serializable17 = strConsumerRecord12.value();
        java.lang.String str18 = strConsumerRecord12.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord12.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType30 = strConsumerRecord29.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 0, (long) '4', (long) (byte) -1, timestampType19, (long) 10, (int) (short) 0, 0, "hi!", (java.io.Serializable) timestampType30);
        org.apache.kafka.common.record.TimestampType timestampType32 = strConsumerRecord31.timestampType();
        java.util.Optional<java.lang.Integer> intOptional33 = strConsumerRecord31.leaderEpoch();
        int int34 = strConsumerRecord31.serializedKeySize();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Comparable<java.lang.String>> objConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType), value = 0), partition = 35, leaderEpoch = null, offset = 97, NoTimestampType = 100, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = 10)", 52, (long) 52, (java.lang.Object) int34, (java.lang.Comparable<java.lang.String>) "hi!");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 100 + "'", int14 == 100);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 52L + "'", long16 == 52L);
        org.junit.Assert.assertEquals("'" + serializable17 + "' != '" + (short) 10 + "'", serializable17, (short) 10);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "hi!" + "'", str18, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType30 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType30.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType32 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType32.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(intOptional33);
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + 0 + "'", int34 == 0);
    }

    @Test
    public void test00447() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00447");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        long long7 = strConsumerRecord5.offset();
        org.apache.kafka.common.header.Headers headers8 = strConsumerRecord5.headers();
        long long9 = strConsumerRecord5.checksum();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        int int11 = strConsumerRecord5.serializedKeySize();
        long long12 = strConsumerRecord5.checksum();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + 52L + "'", long7 == 52L);
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
    }

    @Test
    public void test00448() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00448");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        java.lang.String str7 = strConsumerRecord5.topic();
        int int8 = strConsumerRecord5.serializedValueSize();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "hi!" + "'", str7, "hi!");
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
    }

    @Test
    public void test00449() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00449");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int9 = strConsumerRecord8.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord8.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str17 = strConsumerRecord16.topic();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord16.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord8, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType18);
        java.lang.String str20 = strConsumerRecord8.topic();
        long long21 = strConsumerRecord8.offset();
        long long22 = strConsumerRecord8.offset();
        java.lang.String str23 = strConsumerRecord8.toString();
        int int24 = strConsumerRecord8.serializedKeySize();
        java.lang.String str25 = strConsumerRecord8.topic();
        java.lang.String str26 = strConsumerRecord8.toString();
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 52L + "'", long22 == 52L);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str23, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "hi!" + "'", str25, "hi!");
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str26, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
    }

    @Test
    public void test00450() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00450");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord9.timestampType();
        java.lang.String str13 = strConsumerRecord9.key();
        long long14 = strConsumerRecord9.timestamp();
        long long15 = strConsumerRecord9.offset();
        java.lang.String str16 = strConsumerRecord9.toString();
        long long17 = strConsumerRecord9.checksum();
        java.io.Serializable serializable18 = strConsumerRecord9.value();
        java.io.Serializable serializable19 = strConsumerRecord9.value();
        java.io.Serializable serializable20 = strConsumerRecord9.value();
        org.apache.kafka.common.record.TimestampType timestampType21 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType36 = strConsumerRecord35.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType37 = strConsumerRecord35.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType38 = strConsumerRecord35.timestampType();
        java.lang.String str39 = strConsumerRecord35.key();
        org.apache.kafka.common.record.TimestampType timestampType40 = strConsumerRecord35.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType51 = strConsumerRecord50.timestampType();
        java.lang.Class<?> wildcardClass52 = strConsumerRecord50.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 100, (long) (-1), (long) '4', timestampType40, (long) '4', (int) '#', 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass52);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str60 = strConsumerRecord59.topic();
        org.apache.kafka.common.record.TimestampType timestampType61 = strConsumerRecord59.timestampType();
        org.apache.kafka.common.header.Headers headers62 = strConsumerRecord59.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType69 = strConsumerRecord68.timestampType();
        int int70 = strConsumerRecord68.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional71 = strConsumerRecord68.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0), partition = 32, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)", 52, 32L, (long) 32, timestampType21, (java.lang.Long) 32L, (int) (short) 10, 52, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0), partition = 10, leaderEpoch = null, offset = 100, NoTimestampType = 32, serialized key size = -1, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = hi!)", (java.io.Serializable) "hi!", headers62, intOptional71);
        int int73 = strConsumerRecord72.serializedKeySize();
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str16, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable18 + "' != '" + (short) 10 + "'", serializable18, (short) 10);
        org.junit.Assert.assertEquals("'" + serializable19 + "' != '" + (short) 10 + "'", serializable19, (short) 10);
        org.junit.Assert.assertEquals("'" + serializable20 + "' != '" + (short) 10 + "'", serializable20, (short) 10);
        org.junit.Assert.assertTrue("'" + timestampType21 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType21.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType36 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType36.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType37 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType37.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType38 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType38.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str39 + "' != '" + "" + "'", str39, "");
        org.junit.Assert.assertTrue("'" + timestampType40 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType40.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType51 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType51.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass52);
        org.junit.Assert.assertEquals("'" + str60 + "' != '" + "hi!" + "'", str60, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType61 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType61.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers62);
        org.junit.Assert.assertTrue("'" + timestampType69 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType69.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int70 + "' != '" + (-1) + "'", int70 == (-1));
        org.junit.Assert.assertNotNull(intOptional71);
        org.junit.Assert.assertTrue("'" + int73 + "' != '" + 10 + "'", int73 == 10);
    }

    @Test
    public void test00451() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00451");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedValueSize();
        java.lang.String str8 = strConsumerRecord5.key();
        java.io.Serializable serializable9 = strConsumerRecord5.value();
        long long10 = strConsumerRecord5.checksum();
        java.lang.String str11 = strConsumerRecord5.toString();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "" + "'", str8, "");
        org.junit.Assert.assertEquals("'" + serializable9 + "' != '" + (short) 10 + "'", serializable9, (short) 10);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str11, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
    }

    @Test
    public void test00452() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00452");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int10 = strConsumerRecord9.serializedValueSize();
        int int11 = strConsumerRecord9.partition();
        long long12 = strConsumerRecord9.offset();
        long long13 = strConsumerRecord9.offset();
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord9.timestampType();
        java.io.Serializable serializable15 = strConsumerRecord9.value();
        java.lang.Class<?> wildcardClass16 = strConsumerRecord9.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 10, serialized key size = 10, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 52)", (int) '4', (long) 'a', "ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = null), partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 52, serialized key size = 97, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (java.io.Serializable) wildcardClass16);
        int int18 = strConsumerRecord17.partition();
        long long19 = strConsumerRecord17.checksum();
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + serializable15 + "' != '" + (short) 10 + "'", serializable15, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass16);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 52 + "'", int18 == 52);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
    }

    @Test
    public void test00453() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00453");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord15 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) 10, 0L, "hi!", (java.io.Serializable) timestampType14);
        java.lang.String str16 = strConsumerRecord15.topic();
        org.apache.kafka.common.record.TimestampType timestampType17 = strConsumerRecord15.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType28 = strConsumerRecord27.timestampType();
        int int29 = strConsumerRecord27.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType30 = strConsumerRecord27.timestampType();
        java.lang.String str31 = strConsumerRecord27.toString();
        java.util.Optional<java.lang.Integer> intOptional32 = strConsumerRecord27.leaderEpoch();
        long long33 = strConsumerRecord27.offset();
        org.apache.kafka.common.record.TimestampType timestampType34 = strConsumerRecord27.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord40 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long41 = strConsumerRecord40.timestamp();
        int int42 = strConsumerRecord40.partition();
        java.lang.String str43 = strConsumerRecord40.topic();
        long long44 = strConsumerRecord40.offset();
        org.apache.kafka.common.header.Headers headers45 = strConsumerRecord40.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", 97, 0L, (long) (short) 100, timestampType17, (java.lang.Long) 52L, (int) (byte) 100, 32, "", (java.io.Serializable) timestampType34, headers45);
        java.lang.Class<?> wildcardClass47 = timestampType17.getClass();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str16, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + timestampType17 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType17.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType28 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType28.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int29 + "' != '" + (-1) + "'", int29 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType30 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType30.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str31 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str31, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional32);
        org.junit.Assert.assertTrue("'" + long33 + "' != '" + 52L + "'", long33 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType34 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType34.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long41 + "' != '" + (-1L) + "'", long41 == (-1L));
        org.junit.Assert.assertTrue("'" + int42 + "' != '" + 100 + "'", int42 == 100);
        org.junit.Assert.assertEquals("'" + str43 + "' != '" + "hi!" + "'", str43, "hi!");
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + 52L + "'", long44 == 52L);
        org.junit.Assert.assertNotNull(headers45);
        org.junit.Assert.assertNotNull(wildcardClass47);
    }

    @Test
    public void test00454() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00454");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, java.io.Serializable> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.io.Serializable> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.io.Serializable>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00455() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00455");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        int int7 = strConsumerRecord5.partition();
        java.lang.String str8 = strConsumerRecord5.topic();
        long long9 = strConsumerRecord5.offset();
        java.io.Serializable serializable10 = strConsumerRecord5.value();
        java.lang.String str11 = strConsumerRecord5.topic();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord5.timestampType();
        long long13 = strConsumerRecord5.offset();
        org.apache.kafka.common.header.Headers headers14 = strConsumerRecord5.headers();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertEquals("'" + serializable10 + "' != '" + (short) 10 + "'", serializable10, (short) 10);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "hi!" + "'", str11, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertNotNull(headers14);
    }

    @Test
    public void test00456() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00456");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long18 = strConsumerRecord17.timestamp();
        int int19 = strConsumerRecord17.partition();
        java.lang.String str20 = strConsumerRecord17.topic();
        long long21 = strConsumerRecord17.offset();
        java.io.Serializable serializable22 = strConsumerRecord17.value();
        java.lang.String str23 = strConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType24 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType35 = strConsumerRecord34.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 0, (long) '4', (long) (byte) -1, timestampType24, (long) 10, (int) (short) 0, 0, "hi!", (java.io.Serializable) timestampType35);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType51 = strConsumerRecord50.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType52 = strConsumerRecord50.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord66 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType67 = strConsumerRecord66.timestampType();
        int int68 = strConsumerRecord66.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType69 = strConsumerRecord66.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType69, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", 100, (long) 0, 1L, timestampType52, (long) (short) 1, (int) (byte) 1, (int) (short) 1, "hi!", (java.io.Serializable) '#');
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) '4', (long) (byte) 1, (long) '#', timestampType35, (long) (short) 100, 0, (int) ' ', "hi!", (java.io.Serializable) 1L);
        java.io.Serializable serializable82 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int89 = strConsumerRecord88.serializedValueSize();
        int int90 = strConsumerRecord88.partition();
        int int91 = strConsumerRecord88.partition();
        org.apache.kafka.common.header.Headers headers92 = strConsumerRecord88.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord93 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) -1, (long) ' ', (long) '4', timestampType35, (java.lang.Long) (-1L), (int) (byte) 1, (int) '4', "", serializable82, headers92);
        org.apache.kafka.common.header.Headers headers94 = strConsumerRecord93.headers();
        int int95 = strConsumerRecord93.serializedValueSize();
        java.io.Serializable serializable96 = strConsumerRecord93.value();
        java.lang.String str97 = strConsumerRecord93.key();
        java.lang.String str98 = strConsumerRecord93.topic();
        java.lang.String str99 = strConsumerRecord93.topic();
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 100 + "'", int19 == 100);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertEquals("'" + serializable22 + "' != '" + (short) 10 + "'", serializable22, (short) 10);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "hi!" + "'", str23, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType24 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType24.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType35 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType35.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType51 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType51.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType52 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType52.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType67 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType67.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int68 + "' != '" + (-1) + "'", int68 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType69 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType69.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int89 + "' != '" + (-1) + "'", int89 == (-1));
        org.junit.Assert.assertTrue("'" + int90 + "' != '" + 100 + "'", int90 == 100);
        org.junit.Assert.assertTrue("'" + int91 + "' != '" + 100 + "'", int91 == 100);
        org.junit.Assert.assertNotNull(headers92);
        org.junit.Assert.assertNotNull(headers94);
        org.junit.Assert.assertTrue("'" + int95 + "' != '" + 52 + "'", int95 == 52);
        org.junit.Assert.assertNull(serializable96);
        org.junit.Assert.assertEquals("'" + str97 + "' != '" + "" + "'", str97, "");
        org.junit.Assert.assertEquals("'" + str98 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str98, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + str99 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str99, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
    }

    @Test
    public void test00457() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00457");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str6 = strConsumerRecord5.topic();
        java.lang.String str7 = strConsumerRecord5.topic();
        int int8 = strConsumerRecord5.partition();
        java.util.Optional<java.lang.Integer> intOptional9 = strConsumerRecord5.leaderEpoch();
        java.lang.String str10 = strConsumerRecord5.key();
        java.lang.String str11 = strConsumerRecord5.toString();
        java.lang.String str12 = strConsumerRecord5.toString();
        java.util.Optional<java.lang.Integer> intOptional13 = strConsumerRecord5.leaderEpoch();
        org.apache.kafka.common.header.Headers headers14 = strConsumerRecord5.headers();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "hi!" + "'", str6, "hi!");
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "hi!" + "'", str7, "hi!");
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 100 + "'", int8 == 100);
        org.junit.Assert.assertNotNull(intOptional9);
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "" + "'", str10, "");
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str11, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str12, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNotNull(headers14);
    }

    @Test
    public void test00458() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00458");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        int int7 = strConsumerRecord5.partition();
        java.lang.String str8 = strConsumerRecord5.topic();
        long long9 = strConsumerRecord5.offset();
        java.io.Serializable serializable10 = strConsumerRecord5.value();
        java.lang.String str11 = strConsumerRecord5.topic();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord5.timestampType();
        long long13 = strConsumerRecord5.offset();
        java.lang.String str14 = strConsumerRecord5.toString();
        long long15 = strConsumerRecord5.offset();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertEquals("'" + serializable10 + "' != '" + (short) 10 + "'", serializable10, (short) 10);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "hi!" + "'", str11, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str14, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
    }

    @Test
    public void test00459() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00459");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType26 = strConsumerRecord25.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str44 = strConsumerRecord43.topic();
        org.apache.kafka.common.record.TimestampType timestampType45 = strConsumerRecord43.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord35, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType45);
        java.lang.String str47 = strConsumerRecord35.topic();
        java.lang.Class<?> wildcardClass48 = strConsumerRecord35.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object> timestampTypeConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Object>("hi!", (int) (short) 100, 1L, 100L, timestampType16, (long) (short) -1, (int) (byte) -1, (int) (byte) -1, timestampType26, (java.lang.Object) wildcardClass48);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) -1, (long) '#', "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) wildcardClass48);
        java.lang.String str51 = strConsumerRecord50.key();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType26 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType26.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertEquals("'" + str44 + "' != '" + "hi!" + "'", str44, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType45 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType45.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str47 + "' != '" + "hi!" + "'", str47, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass48);
        org.junit.Assert.assertEquals("'" + str51 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str51, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
    }

    @Test
    public void test00460() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00460");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long10 = strConsumerRecord9.timestamp();
        long long11 = strConsumerRecord9.offset();
        long long12 = strConsumerRecord9.offset();
        java.lang.String str13 = strConsumerRecord9.key();
        int int14 = strConsumerRecord9.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord9.timestampType();
        java.io.Serializable serializable20 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 10, 52L, (long) (short) 1, timestampType15, 10L, (int) '4', (int) (short) 1, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", serializable20);
        java.lang.String str22 = strConsumerRecord21.toString();
        java.io.Serializable serializable23 = strConsumerRecord21.value();
        java.util.Optional<java.lang.Integer> intOptional24 = strConsumerRecord21.leaderEpoch();
        java.lang.Class<?> wildcardClass25 = strConsumerRecord21.getClass();
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)" + "'", str22, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)");
        org.junit.Assert.assertNull(serializable23);
        org.junit.Assert.assertNotNull(intOptional24);
        org.junit.Assert.assertNotNull(wildcardClass25);
    }

    @Test
    public void test00461() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00461");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType7 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.key();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        int int11 = strConsumerRecord5.partition();
        java.io.Serializable serializable12 = strConsumerRecord5.value();
        java.lang.String str13 = strConsumerRecord5.key();
        int int14 = strConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional15 = strConsumerRecord5.leaderEpoch();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "" + "'", str9, "");
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertEquals("'" + serializable12 + "' != '" + (short) 10 + "'", serializable12, (short) 10);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertNotNull(intOptional15);
    }

    @Test
    public void test00462() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00462");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        long long9 = strConsumerRecord5.offset();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        java.lang.String str11 = strConsumerRecord5.toString();
        int int12 = strConsumerRecord5.serializedValueSize();
        java.io.Serializable serializable13 = strConsumerRecord5.value();
        java.io.Serializable serializable14 = strConsumerRecord5.value();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord5.timestampType();
        java.lang.String str16 = strConsumerRecord5.toString();
        java.lang.Class<?> wildcardClass17 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str11, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertEquals("'" + serializable13 + "' != '" + (short) 10 + "'", serializable13, (short) 10);
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + (short) 10 + "'", serializable14, (short) 10);
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str16, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(wildcardClass17);
    }

    @Test
    public void test00463() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00463");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long14 = strConsumerRecord13.timestamp();
        int int15 = strConsumerRecord13.partition();
        java.io.Serializable serializable16 = strConsumerRecord13.value();
        org.apache.kafka.common.record.TimestampType timestampType17 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0)", (int) (byte) 0, (long) 100, "hi!", (java.io.Serializable) timestampType17);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 10, serialized key size = 10, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 52)", (int) (byte) 10, 32L, (long) (short) 100, timestampType17, 1L, 0, (int) (short) 1, "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType), value = 0)", (java.io.Serializable) "ConsumerRecord(topic = , partition = 35, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), value = )");
        long long25 = strConsumerRecord24.checksum();
        java.lang.Class<?> wildcardClass26 = strConsumerRecord24.getClass();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertEquals("'" + serializable16 + "' != '" + (short) 10 + "'", serializable16, (short) 10);
        org.junit.Assert.assertTrue("'" + timestampType17 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType17.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + 1L + "'", long25 == 1L);
        org.junit.Assert.assertNotNull(wildcardClass26);
    }

    @Test
    public void test00464() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00464");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, org.apache.kafka.common.header.Headers> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, org.apache.kafka.common.header.Headers> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, org.apache.kafka.common.header.Headers>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00465() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00465");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.Comparable<java.lang.String>> strComparableConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.Comparable<java.lang.String>>("hi!", 97, (long) (short) 1, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)");
        java.lang.Class<?> wildcardClass10 = strComparableConsumerRecord9.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.reflect.GenericDeclaration> strComparableConsumerRecord11 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (int) (short) 1, (long) 0, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0)", (java.lang.reflect.GenericDeclaration) wildcardClass10);
        org.junit.Assert.assertNotNull(wildcardClass10);
    }

    @Test
    public void test00466() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00466");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        long long7 = strConsumerRecord5.checksum();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        int int9 = strConsumerRecord5.serializedValueSize();
        java.io.Serializable serializable10 = strConsumerRecord5.value();
        org.apache.kafka.common.header.Headers headers11 = strConsumerRecord5.headers();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertEquals("'" + serializable10 + "' != '" + (short) 10 + "'", serializable10, (short) 10);
        org.junit.Assert.assertNotNull(headers11);
    }

    @Test
    public void test00467() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00467");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType21 = strConsumerRecord20.timestampType();
        int int22 = strConsumerRecord20.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType23 = strConsumerRecord20.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType23, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", 0, 1L, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (java.io.Serializable) '#');
        org.apache.kafka.common.record.TimestampType timestampType31 = strConsumerRecord30.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int42 = strConsumerRecord41.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional43 = strConsumerRecord41.leaderEpoch();
        java.lang.String str44 = strConsumerRecord41.key();
        long long45 = strConsumerRecord41.offset();
        java.lang.String str46 = strConsumerRecord41.toString();
        org.apache.kafka.common.record.TimestampType timestampType47 = strConsumerRecord41.timestampType();
        java.lang.String str48 = strConsumerRecord41.toString();
        java.util.Optional<java.lang.Integer> intOptional49 = strConsumerRecord41.leaderEpoch();
        java.lang.Class<?> wildcardClass50 = strConsumerRecord41.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = null)", 0, (long) '4', (long) (short) -1, timestampType31, (long) 100, (int) (byte) 10, 52, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0), partition = 10, leaderEpoch = null, offset = 100, NoTimestampType = 32, serialized key size = -1, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = hi!)", (java.io.Serializable) wildcardClass50);
        org.apache.kafka.common.header.Headers headers52 = strConsumerRecord51.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.lang.String> headersConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.lang.String>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) '4', (long) (byte) 1, headers52, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType21 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType21.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int42 + "' != '" + (-1) + "'", int42 == (-1));
        org.junit.Assert.assertNotNull(intOptional43);
        org.junit.Assert.assertEquals("'" + str44 + "' != '" + "" + "'", str44, "");
        org.junit.Assert.assertTrue("'" + long45 + "' != '" + 52L + "'", long45 == 52L);
        org.junit.Assert.assertEquals("'" + str46 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str46, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + timestampType47 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType47.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str48 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str48, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional49);
        org.junit.Assert.assertNotNull(wildcardClass50);
        org.junit.Assert.assertNotNull(headers52);
    }

    @Test
    public void test00468() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00468");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.util.Optional<java.lang.Integer>> strConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.util.Optional<java.lang.Integer>> strConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>, java.util.Optional<java.lang.Integer>>(strConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00469() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00469");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str18 = strConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int31 = strConsumerRecord30.serializedValueSize();
        int int32 = strConsumerRecord30.partition();
        org.apache.kafka.common.header.Headers headers33 = strConsumerRecord30.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int40 = strConsumerRecord39.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional41 = strConsumerRecord39.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType19, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers33, intOptional41);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int54 = strConsumerRecord53.serializedValueSize();
        int int55 = strConsumerRecord53.partition();
        org.apache.kafka.common.header.Headers headers56 = strConsumerRecord53.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType19, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) (byte) 10, (long) (short) 1, timestampType19, (long) '#', (int) (short) 10, 10, "hi!", (java.io.Serializable) ' ');
        java.io.Serializable serializable64 = strConsumerRecord63.value();
        org.apache.kafka.common.record.TimestampType timestampType65 = strConsumerRecord63.timestampType();
        java.io.Serializable serializable66 = strConsumerRecord63.value();
        java.io.Serializable serializable67 = strConsumerRecord63.value();
        java.lang.String str68 = strConsumerRecord63.toString();
        int int69 = strConsumerRecord63.partition();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "hi!" + "'", str18, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + (-1) + "'", int31 == (-1));
        org.junit.Assert.assertTrue("'" + int32 + "' != '" + 100 + "'", int32 == 100);
        org.junit.Assert.assertNotNull(headers33);
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + (-1) + "'", int40 == (-1));
        org.junit.Assert.assertNotNull(intOptional41);
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + (-1) + "'", int54 == (-1));
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + 100 + "'", int55 == 100);
        org.junit.Assert.assertNotNull(headers56);
        org.junit.Assert.assertEquals("'" + serializable64 + "' != '" + ' ' + "'", serializable64, ' ');
        org.junit.Assert.assertTrue("'" + timestampType65 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType65.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + serializable66 + "' != '" + ' ' + "'", serializable66, ' ');
        org.junit.Assert.assertEquals("'" + serializable67 + "' != '" + ' ' + "'", serializable67, ' ');
        org.junit.Assert.assertEquals("'" + str68 + "' != '" + "ConsumerRecord(topic = , partition = 35, leaderEpoch = null, offset = 10, NoTimestampType = 1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value =  )" + "'", str68, "ConsumerRecord(topic = , partition = 35, leaderEpoch = null, offset = 10, NoTimestampType = 1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value =  )");
        org.junit.Assert.assertTrue("'" + int69 + "' != '" + 35 + "'", int69 == 35);
    }

    @Test
    public void test00470() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00470");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        int int7 = strConsumerRecord5.partition();
        java.lang.String str8 = strConsumerRecord5.topic();
        long long9 = strConsumerRecord5.offset();
        java.io.Serializable serializable10 = strConsumerRecord5.value();
        java.lang.String str11 = strConsumerRecord5.topic();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord5.timestampType();
        long long13 = strConsumerRecord5.offset();
        long long14 = strConsumerRecord5.timestamp();
        java.util.Optional<java.lang.Integer> intOptional15 = strConsumerRecord5.leaderEpoch();
        java.lang.String str16 = strConsumerRecord5.toString();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertEquals("'" + serializable10 + "' != '" + (short) 10 + "'", serializable10, (short) 10);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "hi!" + "'", str11, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str16, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
    }

    @Test
    public void test00471() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00471");
        java.lang.Enum<org.apache.kafka.common.record.TimestampType> timestampTypeEnum3 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord17.timestampType();
        int int19 = strConsumerRecord17.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType20 = strConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long30 = strConsumerRecord29.timestamp();
        int int31 = strConsumerRecord29.partition();
        java.lang.String str32 = strConsumerRecord29.topic();
        long long33 = strConsumerRecord29.offset();
        java.lang.Class<?> wildcardClass34 = strConsumerRecord29.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord40 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int41 = strConsumerRecord40.serializedValueSize();
        int int42 = strConsumerRecord40.partition();
        org.apache.kafka.common.header.Headers headers43 = strConsumerRecord40.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType50 = strConsumerRecord49.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType51 = strConsumerRecord49.timestampType();
        org.apache.kafka.common.header.Headers headers52 = strConsumerRecord49.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord62 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str63 = strConsumerRecord62.topic();
        org.apache.kafka.common.record.TimestampType timestampType64 = strConsumerRecord62.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int76 = strConsumerRecord75.serializedValueSize();
        int int77 = strConsumerRecord75.partition();
        org.apache.kafka.common.header.Headers headers78 = strConsumerRecord75.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int85 = strConsumerRecord84.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional86 = strConsumerRecord84.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType64, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers78, intOptional86);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers> annotatedElementConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers>("hi!", (int) (short) 1, 1L, 100L, timestampType20, (java.lang.Long) 1L, 100, (int) (byte) 10, (java.lang.reflect.AnnotatedElement) wildcardClass34, headers43, headers52, intOptional86);
        java.lang.Class<?> wildcardClass89 = annotatedElementConsumerRecord88.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord90 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = -1.0), partition = 32, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)", (-1), 52L, "", (java.io.Serializable) wildcardClass89);
        java.util.Optional<java.lang.Integer> intOptional91 = strConsumerRecord90.leaderEpoch();
        org.apache.kafka.common.header.Headers headers92 = strConsumerRecord90.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Iterable<org.apache.kafka.common.header.Header>> timestampTypeEnumConsumerRecord93 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Iterable<org.apache.kafka.common.header.Header>>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 97, (long) 10, timestampTypeEnum3, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers92);
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 100 + "'", int31 == 100);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "hi!" + "'", str32, "hi!");
        org.junit.Assert.assertTrue("'" + long33 + "' != '" + 52L + "'", long33 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass34);
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + (-1) + "'", int41 == (-1));
        org.junit.Assert.assertTrue("'" + int42 + "' != '" + 100 + "'", int42 == 100);
        org.junit.Assert.assertNotNull(headers43);
        org.junit.Assert.assertTrue("'" + timestampType50 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType50.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType51 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType51.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers52);
        org.junit.Assert.assertEquals("'" + str63 + "' != '" + "hi!" + "'", str63, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType64 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType64.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + (-1) + "'", int76 == (-1));
        org.junit.Assert.assertTrue("'" + int77 + "' != '" + 100 + "'", int77 == 100);
        org.junit.Assert.assertNotNull(headers78);
        org.junit.Assert.assertTrue("'" + int85 + "' != '" + (-1) + "'", int85 == (-1));
        org.junit.Assert.assertNotNull(intOptional86);
        org.junit.Assert.assertNotNull(wildcardClass89);
        org.junit.Assert.assertNotNull(intOptional91);
        org.junit.Assert.assertNotNull(headers92);
    }

    @Test
    public void test00472() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00472");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long14 = strConsumerRecord13.timestamp();
        int int15 = strConsumerRecord13.partition();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType)", (int) (byte) 10, (long) (byte) -1, "ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0)", (java.io.Serializable) timestampType16);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int38 = strConsumerRecord37.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional39 = strConsumerRecord37.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str46 = strConsumerRecord45.topic();
        org.apache.kafka.common.record.TimestampType timestampType47 = strConsumerRecord45.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord37, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType47);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) (byte) -1, 100L, (long) 10, timestampType47, 0L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) 0.0f);
        java.lang.String str55 = strConsumerRecord54.key();
        org.apache.kafka.common.record.TimestampType timestampType56 = strConsumerRecord54.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType71 = strConsumerRecord70.timestampType();
        int int72 = strConsumerRecord70.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType73 = strConsumerRecord70.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType73, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = -1)", (int) (short) 0, (long) 10, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>> serializableConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>>("ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType)", (int) (short) -1, (long) (byte) -1, (java.io.Serializable) timestampType56, strConsumerRecord80);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long88 = strConsumerRecord87.timestamp();
        long long89 = strConsumerRecord87.checksum();
        long long90 = strConsumerRecord87.timestamp();
        java.lang.String str91 = strConsumerRecord87.topic();
        long long92 = strConsumerRecord87.timestamp();
        java.io.Serializable serializable93 = strConsumerRecord87.value();
        org.apache.kafka.common.header.Headers headers94 = strConsumerRecord87.headers();
        long long95 = strConsumerRecord87.checksum();
        org.apache.kafka.common.header.Headers headers96 = strConsumerRecord87.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord97 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = null), partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 52, serialized key size = 97, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) (byte) 0, (long) (short) 10, (long) (-1), timestampType16, (java.lang.Long) 35L, (int) '4', (int) (short) 100, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = 1.0), partition = 10, leaderEpoch = null, offset = 100, NoTimestampType = 32, serialized key size = -1, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = hi!)", (java.io.Serializable) (byte) -1, headers96);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + (-1) + "'", int38 == (-1));
        org.junit.Assert.assertNotNull(intOptional39);
        org.junit.Assert.assertEquals("'" + str46 + "' != '" + "hi!" + "'", str46, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType47 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType47.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str55 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str55, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + timestampType56 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType56.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType71 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType71.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int72 + "' != '" + (-1) + "'", int72 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType73 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType73.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long88 + "' != '" + (-1L) + "'", long88 == (-1L));
        org.junit.Assert.assertTrue("'" + long89 + "' != '" + (-1L) + "'", long89 == (-1L));
        org.junit.Assert.assertTrue("'" + long90 + "' != '" + (-1L) + "'", long90 == (-1L));
        org.junit.Assert.assertEquals("'" + str91 + "' != '" + "hi!" + "'", str91, "hi!");
        org.junit.Assert.assertTrue("'" + long92 + "' != '" + (-1L) + "'", long92 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable93 + "' != '" + (short) 10 + "'", serializable93, (short) 10);
        org.junit.Assert.assertNotNull(headers94);
        org.junit.Assert.assertTrue("'" + long95 + "' != '" + (-1L) + "'", long95 == (-1L));
        org.junit.Assert.assertNotNull(headers96);
    }

    @Test
    public void test00473() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00473");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str6 = strConsumerRecord5.topic();
        java.lang.String str7 = strConsumerRecord5.topic();
        int int8 = strConsumerRecord5.partition();
        java.util.Optional<java.lang.Integer> intOptional9 = strConsumerRecord5.leaderEpoch();
        java.lang.String str10 = strConsumerRecord5.key();
        java.lang.String str11 = strConsumerRecord5.toString();
        java.lang.String str12 = strConsumerRecord5.toString();
        java.lang.Class<?> wildcardClass13 = strConsumerRecord5.getClass();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "hi!" + "'", str6, "hi!");
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "hi!" + "'", str7, "hi!");
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 100 + "'", int8 == 100);
        org.junit.Assert.assertNotNull(intOptional9);
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "" + "'", str10, "");
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str11, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str12, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(wildcardClass13);
    }

    @Test
    public void test00474() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00474");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str14 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int27 = strConsumerRecord26.serializedValueSize();
        int int28 = strConsumerRecord26.partition();
        org.apache.kafka.common.header.Headers headers29 = strConsumerRecord26.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType15, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers29, intOptional37);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int50 = strConsumerRecord49.serializedValueSize();
        int int51 = strConsumerRecord49.partition();
        org.apache.kafka.common.header.Headers headers52 = strConsumerRecord49.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType15, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers52);
        long long54 = strConsumerRecord53.offset();
        java.io.Serializable serializable55 = strConsumerRecord53.value();
        java.io.Serializable serializable56 = strConsumerRecord53.value();
        java.util.Optional<java.lang.Integer> intOptional57 = strConsumerRecord53.leaderEpoch();
        long long58 = strConsumerRecord53.offset();
        long long59 = strConsumerRecord53.timestamp();
        int int60 = strConsumerRecord53.serializedValueSize();
        java.lang.String str61 = strConsumerRecord53.topic();
        int int62 = strConsumerRecord53.serializedValueSize();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 100 + "'", int28 == 100);
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + (-1) + "'", int50 == (-1));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 100 + "'", int51 == 100);
        org.junit.Assert.assertNotNull(headers52);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + 1L + "'", long54 == 1L);
        org.junit.Assert.assertEquals("'" + serializable55 + "' != '" + (-1.0d) + "'", serializable55, (-1.0d));
        org.junit.Assert.assertEquals("'" + serializable56 + "' != '" + (-1.0d) + "'", serializable56, (-1.0d));
        org.junit.Assert.assertNotNull(intOptional57);
        org.junit.Assert.assertTrue("'" + long58 + "' != '" + 1L + "'", long58 == 1L);
        org.junit.Assert.assertTrue("'" + long59 + "' != '" + 0L + "'", long59 == 0L);
        org.junit.Assert.assertTrue("'" + int60 + "' != '" + 1 + "'", int60 == 1);
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str61, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int62 + "' != '" + 1 + "'", int62 == 1);
    }

    @Test
    public void test00475() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00475");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord9.timestampType();
        java.lang.String str13 = strConsumerRecord9.key();
        long long14 = strConsumerRecord9.timestamp();
        long long15 = strConsumerRecord9.offset();
        java.lang.String str16 = strConsumerRecord9.toString();
        long long17 = strConsumerRecord9.checksum();
        java.lang.String str18 = strConsumerRecord9.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord9.timestampType();
        java.io.Serializable serializable24 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long35 = strConsumerRecord34.timestamp();
        int int36 = strConsumerRecord34.partition();
        org.apache.kafka.common.record.TimestampType timestampType37 = strConsumerRecord34.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str57 = strConsumerRecord56.topic();
        org.apache.kafka.common.record.TimestampType timestampType58 = strConsumerRecord56.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int70 = strConsumerRecord69.serializedValueSize();
        int int71 = strConsumerRecord69.partition();
        org.apache.kafka.common.header.Headers headers72 = strConsumerRecord69.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int79 = strConsumerRecord78.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional80 = strConsumerRecord78.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType58, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers72, intOptional80);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord92 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int93 = strConsumerRecord92.serializedValueSize();
        int int94 = strConsumerRecord92.partition();
        org.apache.kafka.common.header.Headers headers95 = strConsumerRecord92.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType58, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers95);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord97 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (short) 0, (long) '4', (long) 1, timestampType37, (java.lang.Long) 100L, (int) (byte) -1, (int) '#', "hi!", (java.io.Serializable) 10.0d, headers95);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) ' ', (long) (short) 1, 0L, timestampType19, (java.lang.Long) 100L, (-1), (-1), "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = 0, serialized key size = 100, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 100)", serializable24, headers95);
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str16, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "hi!" + "'", str18, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + (-1L) + "'", long35 == (-1L));
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + 100 + "'", int36 == 100);
        org.junit.Assert.assertTrue("'" + timestampType37 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType37.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str57 + "' != '" + "hi!" + "'", str57, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType58 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType58.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int70 + "' != '" + (-1) + "'", int70 == (-1));
        org.junit.Assert.assertTrue("'" + int71 + "' != '" + 100 + "'", int71 == 100);
        org.junit.Assert.assertNotNull(headers72);
        org.junit.Assert.assertTrue("'" + int79 + "' != '" + (-1) + "'", int79 == (-1));
        org.junit.Assert.assertNotNull(intOptional80);
        org.junit.Assert.assertTrue("'" + int93 + "' != '" + (-1) + "'", int93 == (-1));
        org.junit.Assert.assertTrue("'" + int94 + "' != '" + 100 + "'", int94 == 100);
        org.junit.Assert.assertNotNull(headers95);
    }

    @Test
    public void test00476() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00476");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        java.lang.String str17 = strConsumerRecord13.key();
        long long18 = strConsumerRecord13.timestamp();
        long long19 = strConsumerRecord13.offset();
        java.lang.String str20 = strConsumerRecord13.topic();
        long long21 = strConsumerRecord13.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType33 = strConsumerRecord32.timestampType();
        int int34 = strConsumerRecord32.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType35 = strConsumerRecord32.timestampType();
        java.lang.String str36 = strConsumerRecord32.toString();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord32.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType38 = strConsumerRecord32.timestampType();
        java.lang.Class<?> wildcardClass39 = timestampType38.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType50 = strConsumerRecord49.timestampType();
        int int51 = strConsumerRecord49.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType52 = strConsumerRecord49.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = -1, NoTimestampType = 100, serialized key size = 1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = NoTimestampType)", (int) (byte) 1, (long) (-1), "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) timestampType52);
        org.apache.kafka.common.header.Headers headers54 = strConsumerRecord53.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.GenericDeclaration> charSequenceConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = 1, serialized key size = 35, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), value = NoTimestampType)", (int) '#', (long) 0, 100L, timestampType22, (java.lang.Long) (-1L), (int) (byte) 100, (int) ' ', (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = null), partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = 52, serialized key size = 97, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (java.lang.reflect.GenericDeclaration) wildcardClass39, headers54);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str66 = strConsumerRecord65.topic();
        java.io.Serializable serializable67 = strConsumerRecord65.value();
        java.lang.String str68 = strConsumerRecord65.topic();
        org.apache.kafka.common.record.TimestampType timestampType69 = strConsumerRecord65.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 52, leaderEpoch = null, offset = 0, NoTimestampType = 1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (int) (byte) 100, 35L, (long) 35, timestampType22, 52L, (-1), 32, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 97, NoTimestampType = 0, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 1)", (java.io.Serializable) timestampType69);
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType33 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType33.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + (-1) + "'", int34 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType35 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType35.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str36 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str36, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertTrue("'" + timestampType38 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType38.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass39);
        org.junit.Assert.assertTrue("'" + timestampType50 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType50.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + (-1) + "'", int51 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType52 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType52.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers54);
        org.junit.Assert.assertEquals("'" + str66 + "' != '" + "hi!" + "'", str66, "hi!");
        org.junit.Assert.assertEquals("'" + serializable67 + "' != '" + (short) 10 + "'", serializable67, (short) 10);
        org.junit.Assert.assertEquals("'" + str68 + "' != '" + "hi!" + "'", str68, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType69 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType69.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test00477() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00477");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int10 = strConsumerRecord9.serializedValueSize();
        int int11 = strConsumerRecord9.partition();
        long long12 = strConsumerRecord9.offset();
        long long13 = strConsumerRecord9.offset();
        org.apache.kafka.common.header.Headers headers14 = strConsumerRecord9.headers();
        long long15 = strConsumerRecord9.checksum();
        long long16 = strConsumerRecord9.checksum();
        org.apache.kafka.common.header.Headers headers17 = strConsumerRecord9.headers();
        org.apache.kafka.common.header.Headers headers18 = strConsumerRecord9.headers();
        org.apache.kafka.common.record.TimestampType timestampType19 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str34 = strConsumerRecord33.topic();
        org.apache.kafka.common.record.TimestampType timestampType35 = strConsumerRecord33.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int47 = strConsumerRecord46.serializedValueSize();
        int int48 = strConsumerRecord46.partition();
        org.apache.kafka.common.header.Headers headers49 = strConsumerRecord46.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int56 = strConsumerRecord55.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional57 = strConsumerRecord55.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType35, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers49, intOptional57);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (int) '#', (long) 0, (long) (short) 10, timestampType19, 0L, 0, (int) (byte) 10, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0), partition = 100, leaderEpoch = null, offset = -1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = null)", (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType35);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 100 + "'", int11 == 100);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertNotNull(headers14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertNotNull(headers17);
        org.junit.Assert.assertNotNull(headers18);
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str34 + "' != '" + "hi!" + "'", str34, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType35 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType35.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int47 + "' != '" + (-1) + "'", int47 == (-1));
        org.junit.Assert.assertTrue("'" + int48 + "' != '" + 100 + "'", int48 == 100);
        org.junit.Assert.assertNotNull(headers49);
        org.junit.Assert.assertTrue("'" + int56 + "' != '" + (-1) + "'", int56 == (-1));
        org.junit.Assert.assertNotNull(intOptional57);
    }

    @Test
    public void test00478() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00478");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        java.io.Serializable serializable7 = strConsumerRecord5.value();
        java.lang.String str8 = strConsumerRecord5.key();
        java.lang.String str9 = strConsumerRecord5.key();
        java.lang.String str10 = strConsumerRecord5.key();
        java.util.Optional<java.lang.Integer> intOptional11 = strConsumerRecord5.leaderEpoch();
        java.lang.Class<?> wildcardClass12 = intOptional11.getClass();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertEquals("'" + serializable7 + "' != '" + (short) 0 + "'", serializable7, (short) 0);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "hi!" + "'", str9, "hi!");
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "hi!" + "'", str10, "hi!");
        org.junit.Assert.assertNotNull(intOptional11);
        org.junit.Assert.assertNotNull(wildcardClass12);
    }

    @Test
    public void test00479() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00479");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        int int15 = strConsumerRecord13.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType16 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) ' ', 0L, (long) (short) 0, timestampType16, (long) (byte) -1, (int) '#', 100, "", (java.io.Serializable) 1.0d);
        org.apache.kafka.common.record.TimestampType timestampType23 = strConsumerRecord22.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType38 = strConsumerRecord37.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType39 = strConsumerRecord37.timestampType();
        java.io.Serializable serializable44 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int51 = strConsumerRecord50.serializedValueSize();
        int int52 = strConsumerRecord50.partition();
        long long53 = strConsumerRecord50.offset();
        long long54 = strConsumerRecord50.offset();
        org.apache.kafka.common.record.TimestampType timestampType55 = strConsumerRecord50.timestampType();
        java.lang.String str56 = strConsumerRecord50.toString();
        org.apache.kafka.common.header.Headers headers57 = strConsumerRecord50.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int64 = strConsumerRecord63.serializedValueSize();
        int int65 = strConsumerRecord63.partition();
        long long66 = strConsumerRecord63.offset();
        long long67 = strConsumerRecord63.offset();
        org.apache.kafka.common.header.Headers headers68 = strConsumerRecord63.headers();
        long long69 = strConsumerRecord63.checksum();
        int int70 = strConsumerRecord63.serializedKeySize();
        int int71 = strConsumerRecord63.serializedValueSize();
        long long72 = strConsumerRecord63.offset();
        java.util.Optional<java.lang.Integer> intOptional73 = strConsumerRecord63.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", 0, 35L, 100L, timestampType39, (java.lang.Long) 52L, 10, (int) (byte) 10, "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord)", serializable44, headers57, intOptional73);
        int int75 = strConsumerRecord74.partition();
        java.lang.Class<?> wildcardClass76 = strConsumerRecord74.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", (int) (short) 0, 10L, (long) '4', timestampType23, (long) 'a', (int) 'a', (int) (short) 10, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", (java.io.Serializable) wildcardClass76);
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType38 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType38.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType39 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType39.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + (-1) + "'", int51 == (-1));
        org.junit.Assert.assertTrue("'" + int52 + "' != '" + 100 + "'", int52 == 100);
        org.junit.Assert.assertTrue("'" + long53 + "' != '" + 52L + "'", long53 == 52L);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + 52L + "'", long54 == 52L);
        org.junit.Assert.assertTrue("'" + timestampType55 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType55.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str56 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str56, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(headers57);
        org.junit.Assert.assertTrue("'" + int64 + "' != '" + (-1) + "'", int64 == (-1));
        org.junit.Assert.assertTrue("'" + int65 + "' != '" + 100 + "'", int65 == 100);
        org.junit.Assert.assertTrue("'" + long66 + "' != '" + 52L + "'", long66 == 52L);
        org.junit.Assert.assertTrue("'" + long67 + "' != '" + 52L + "'", long67 == 52L);
        org.junit.Assert.assertNotNull(headers68);
        org.junit.Assert.assertTrue("'" + long69 + "' != '" + (-1L) + "'", long69 == (-1L));
        org.junit.Assert.assertTrue("'" + int70 + "' != '" + (-1) + "'", int70 == (-1));
        org.junit.Assert.assertTrue("'" + int71 + "' != '" + (-1) + "'", int71 == (-1));
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + 52L + "'", long72 == 52L);
        org.junit.Assert.assertNotNull(intOptional73);
        org.junit.Assert.assertTrue("'" + int75 + "' != '" + 0 + "'", int75 == 0);
        org.junit.Assert.assertNotNull(wildcardClass76);
    }

    @Test
    public void test00480() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00480");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedValueSize();
        java.lang.String str8 = strConsumerRecord5.key();
        java.io.Serializable serializable9 = strConsumerRecord5.value();
        java.lang.Class<?> wildcardClass10 = strConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "" + "'", str8, "");
        org.junit.Assert.assertEquals("'" + serializable9 + "' != '" + (short) 10 + "'", serializable9, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass10);
    }

    @Test
    public void test00481() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00481");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        int int7 = strConsumerRecord5.partition();
        long long8 = strConsumerRecord5.offset();
        java.lang.String str9 = strConsumerRecord5.key();
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord5.timestampType();
        java.io.Serializable serializable11 = strConsumerRecord5.value();
        java.lang.Class<?> wildcardClass12 = serializable11.getClass();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "" + "'", str9, "");
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + serializable11 + "' != '" + (short) 10 + "'", serializable11, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass12);
    }

    @Test
    public void test00482() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00482");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType7 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.key();
        long long10 = strConsumerRecord5.timestamp();
        long long11 = strConsumerRecord5.offset();
        java.lang.String str12 = strConsumerRecord5.toString();
        long long13 = strConsumerRecord5.checksum();
        java.io.Serializable serializable14 = strConsumerRecord5.value();
        java.io.Serializable serializable15 = strConsumerRecord5.value();
        java.io.Serializable serializable16 = strConsumerRecord5.value();
        org.apache.kafka.common.header.Headers headers17 = strConsumerRecord5.headers();
        long long18 = strConsumerRecord5.checksum();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "" + "'", str9, "");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str12, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + (short) 10 + "'", serializable14, (short) 10);
        org.junit.Assert.assertEquals("'" + serializable15 + "' != '" + (short) 10 + "'", serializable15, (short) 10);
        org.junit.Assert.assertEquals("'" + serializable16 + "' != '" + (short) 10 + "'", serializable16, (short) 10);
        org.junit.Assert.assertNotNull(headers17);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
    }

    @Test
    public void test00483() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00483");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        org.apache.kafka.common.header.Headers headers7 = strConsumerRecord5.headers();
        int int8 = strConsumerRecord5.serializedKeySize();
        org.apache.kafka.common.header.Headers headers9 = strConsumerRecord5.headers();
        java.lang.String str10 = strConsumerRecord5.key();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord5.timestampType();
        java.lang.String str13 = strConsumerRecord5.key();
        org.apache.kafka.common.header.Headers headers14 = strConsumerRecord5.headers();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertNotNull(headers7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNotNull(headers9);
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "hi!" + "'", str10, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertNotNull(headers14);
    }

    @Test
    public void test00484() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00484");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        java.io.Serializable serializable7 = strConsumerRecord5.value();
        java.util.Optional<java.lang.Integer> intOptional8 = strConsumerRecord5.leaderEpoch();
        int int9 = strConsumerRecord5.serializedKeySize();
        java.io.Serializable serializable10 = strConsumerRecord5.value();
        long long11 = strConsumerRecord5.checksum();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + serializable7 + "' != '" + (short) 10 + "'", serializable7, (short) 10);
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertEquals("'" + serializable10 + "' != '" + (short) 10 + "'", serializable10, (short) 10);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
    }

    @Test
    public void test00485() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00485");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType22 = strConsumerRecord21.timestampType();
        int int23 = strConsumerRecord21.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType24 = strConsumerRecord21.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType24, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long40 = strConsumerRecord39.timestamp();
        int int41 = strConsumerRecord39.partition();
        java.io.Serializable serializable42 = strConsumerRecord39.value();
        java.lang.Class<?> wildcardClass43 = serializable42.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long50 = strConsumerRecord49.timestamp();
        int int51 = strConsumerRecord49.partition();
        java.lang.String str52 = strConsumerRecord49.topic();
        long long53 = strConsumerRecord49.offset();
        java.lang.Class<?> wildcardClass54 = strConsumerRecord49.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration> typeConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration>("hi!", (int) (short) 0, (long) (byte) 1, 10L, timestampType24, (long) (byte) 10, (int) 'a', (int) (short) -1, (java.lang.reflect.Type) wildcardClass43, (java.lang.reflect.GenericDeclaration) wildcardClass54);
        java.io.Serializable serializable60 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 100, 0L, 0L, timestampType24, (long) 10, (int) '#', 10, "hi!", serializable60);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord62 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = 0)", (int) (byte) 100, (long) (short) -1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", serializable60);
        long long63 = strConsumerRecord62.timestamp();
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType24 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType24.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + 100 + "'", int41 == 100);
        org.junit.Assert.assertEquals("'" + serializable42 + "' != '" + (short) 10 + "'", serializable42, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass43);
        org.junit.Assert.assertTrue("'" + long50 + "' != '" + (-1L) + "'", long50 == (-1L));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 100 + "'", int51 == 100);
        org.junit.Assert.assertEquals("'" + str52 + "' != '" + "hi!" + "'", str52, "hi!");
        org.junit.Assert.assertTrue("'" + long53 + "' != '" + 52L + "'", long53 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass54);
        org.junit.Assert.assertTrue("'" + long63 + "' != '" + (-1L) + "'", long63 == (-1L));
    }

    @Test
    public void test00486() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00486");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional7 = strConsumerRecord5.leaderEpoch();
        java.lang.String str8 = strConsumerRecord5.key();
        long long9 = strConsumerRecord5.offset();
        java.lang.String str10 = strConsumerRecord5.toString();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord5.timestampType();
        java.lang.String str12 = strConsumerRecord5.toString();
        java.util.Optional<java.lang.Integer> intOptional13 = strConsumerRecord5.leaderEpoch();
        int int14 = strConsumerRecord5.serializedKeySize();
        java.io.Serializable serializable15 = strConsumerRecord5.value();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "" + "'", str8, "");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 52L + "'", long9 == 52L);
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str10, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str12, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertEquals("'" + serializable15 + "' != '" + (short) 10 + "'", serializable15, (short) 10);
    }

    @Test
    public void test00487() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00487");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long6 = strConsumerRecord5.timestamp();
        long long7 = strConsumerRecord5.offset();
        org.apache.kafka.common.header.Headers headers8 = strConsumerRecord5.headers();
        java.util.Optional<java.lang.Integer> intOptional9 = strConsumerRecord5.leaderEpoch();
        int int10 = strConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + 52L + "'", long7 == 52L);
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertNotNull(intOptional9);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
    }

    @Test
    public void test00488() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00488");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str14 = strConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int27 = strConsumerRecord26.serializedValueSize();
        int int28 = strConsumerRecord26.partition();
        org.apache.kafka.common.header.Headers headers29 = strConsumerRecord26.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int36 = strConsumerRecord35.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional37 = strConsumerRecord35.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) '#', (long) 0, 0L, timestampType15, (java.lang.Long) 1L, (int) (short) -1, (int) (short) 100, "hi!", (java.io.Serializable) 1.0f, headers29, intOptional37);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int50 = strConsumerRecord49.serializedValueSize();
        int int51 = strConsumerRecord49.partition();
        org.apache.kafka.common.header.Headers headers52 = strConsumerRecord49.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", 10, (long) (short) 1, (long) 0, timestampType15, (java.lang.Long) 52L, (int) (byte) 100, (int) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.io.Serializable) (-1.0d), headers52);
        long long54 = strConsumerRecord53.offset();
        java.lang.String str55 = strConsumerRecord53.topic();
        org.apache.kafka.common.record.TimestampType timestampType56 = strConsumerRecord53.timestampType();
        java.lang.String str57 = strConsumerRecord53.topic();
        int int58 = strConsumerRecord53.serializedKeySize();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 100 + "'", int28 == 100);
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + (-1) + "'", int50 == (-1));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 100 + "'", int51 == 100);
        org.junit.Assert.assertNotNull(headers52);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + 1L + "'", long54 == 1L);
        org.junit.Assert.assertEquals("'" + str55 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str55, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + timestampType56 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType56.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str57 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str57, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int58 + "' != '" + 100 + "'", int58 == 100);
    }

    @Test
    public void test00489() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00489");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int9 = strConsumerRecord8.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord8.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        java.lang.String str17 = strConsumerRecord16.topic();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord16.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("hi!", (int) '#', (long) (short) -1, (java.lang.Object) strConsumerRecord8, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType18);
        java.lang.String str20 = strConsumerRecord8.topic();
        long long21 = strConsumerRecord8.offset();
        long long22 = strConsumerRecord8.offset();
        java.lang.String str23 = strConsumerRecord8.toString();
        java.lang.String str24 = strConsumerRecord8.key();
        long long25 = strConsumerRecord8.checksum();
        org.apache.kafka.common.header.Headers headers26 = strConsumerRecord8.headers();
        java.util.Optional<java.lang.Integer> intOptional27 = strConsumerRecord8.leaderEpoch();
        java.lang.String str28 = strConsumerRecord8.toString();
        java.io.Serializable serializable29 = strConsumerRecord8.value();
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 52L + "'", long22 == 52L);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str23, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + str24 + "' != '" + "" + "'", str24, "");
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + (-1L) + "'", long25 == (-1L));
        org.junit.Assert.assertNotNull(headers26);
        org.junit.Assert.assertNotNull(intOptional27);
        org.junit.Assert.assertEquals("'" + str28 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str28, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertEquals("'" + serializable29 + "' != '" + (short) 10 + "'", serializable29, (short) 10);
    }

    @Test
    public void test00490() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00490");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType8 = strConsumerRecord5.timestampType();
        java.lang.String str9 = strConsumerRecord5.toString();
        java.util.Optional<java.lang.Integer> intOptional10 = strConsumerRecord5.leaderEpoch();
        long long11 = strConsumerRecord5.offset();
        java.util.Optional<java.lang.Integer> intOptional12 = strConsumerRecord5.leaderEpoch();
        org.apache.kafka.common.header.Headers headers13 = strConsumerRecord5.headers();
        long long14 = strConsumerRecord5.checksum();
        long long15 = strConsumerRecord5.offset();
        java.lang.String str16 = strConsumerRecord5.toString();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str9, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str16, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
    }

    @Test
    public void test00491() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00491");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        int int11 = strConsumerRecord9.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType12 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", 1, 52L, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = NoTimestampType)", (java.io.Serializable) timestampType12);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        java.io.Serializable serializable15 = strConsumerRecord13.value();
        java.util.Optional<java.lang.Integer> intOptional16 = strConsumerRecord13.leaderEpoch();
        long long17 = strConsumerRecord13.timestamp();
        java.lang.Class<?> wildcardClass18 = strConsumerRecord13.getClass();
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + serializable15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", serializable15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass18);
    }

    @Test
    public void test00492() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00492");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType26 = strConsumerRecord25.timestampType();
        int int27 = strConsumerRecord25.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType28 = strConsumerRecord25.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType28, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", 100, (long) 0, 1L, timestampType11, (long) (short) 1, (int) (byte) 1, (int) (short) 1, "hi!", (java.io.Serializable) '#');
        long long36 = strConsumerRecord35.timestamp();
        java.lang.String str37 = strConsumerRecord35.toString();
        int int38 = strConsumerRecord35.partition();
        java.lang.Class<?> wildcardClass39 = strConsumerRecord35.getClass();
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType26 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType26.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType28 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType28.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + 1L + "'", long36 == 1L);
        org.junit.Assert.assertEquals("'" + str37 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 1, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = #)" + "'", str37, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 1, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = #)");
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + 100 + "'", int38 == 100);
        org.junit.Assert.assertNotNull(wildcardClass39);
    }

    @Test
    public void test00493() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00493");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers6 = strConsumerRecord5.headers();
        java.io.Serializable serializable7 = strConsumerRecord5.value();
        java.lang.String str8 = strConsumerRecord5.key();
        org.apache.kafka.common.header.Headers headers9 = strConsumerRecord5.headers();
        org.apache.kafka.common.header.Headers headers10 = strConsumerRecord5.headers();
        int int11 = strConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertEquals("'" + serializable7 + "' != '" + (short) 0 + "'", serializable7, (short) 0);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertNotNull(headers9);
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
    }

    @Test
    public void test00494() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00494");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType6 = strConsumerRecord5.timestampType();
        int int7 = strConsumerRecord5.serializedKeySize();
        int int8 = strConsumerRecord5.partition();
        java.io.Serializable serializable9 = strConsumerRecord5.value();
        int int10 = strConsumerRecord5.serializedKeySize();
        java.io.Serializable serializable11 = strConsumerRecord5.value();
        java.lang.String str12 = strConsumerRecord5.topic();
        long long13 = strConsumerRecord5.offset();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 100 + "'", int8 == 100);
        org.junit.Assert.assertEquals("'" + serializable9 + "' != '" + (short) 10 + "'", serializable9, (short) 10);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
        org.junit.Assert.assertEquals("'" + serializable11 + "' != '" + (short) 10 + "'", serializable11, (short) 10);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
    }

    @Test
    public void test00495() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00495");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType11 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", 35, 32L, (long) (short) 10, timestampType11, (long) (short) 100, (int) '#', 0, "", (java.io.Serializable) true);
        int int18 = strConsumerRecord17.serializedKeySize();
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 35 + "'", int18 == 35);
    }

    @Test
    public void test00496() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00496");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, java.lang.String> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.String> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.String>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00497() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00497");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional7 = strConsumerRecord5.leaderEpoch();
        java.lang.String str8 = strConsumerRecord5.topic();
        java.io.Serializable serializable9 = strConsumerRecord5.value();
        long long10 = strConsumerRecord5.checksum();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "hi!" + "'", str8, "hi!");
        org.junit.Assert.assertEquals("'" + serializable9 + "' != '" + (short) 10 + "'", serializable9, (short) 10);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
    }

    @Test
    public void test00498() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00498");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType10 = strConsumerRecord9.timestampType();
        int int11 = strConsumerRecord9.serializedKeySize();
        int int12 = strConsumerRecord9.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType13 = strConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("", (int) (byte) 1, (long) (short) 1, "hi!", (java.io.Serializable) (short) 0);
        org.apache.kafka.common.header.Headers headers25 = strConsumerRecord24.headers();
        org.apache.kafka.common.header.Headers headers26 = strConsumerRecord24.headers();
        int int27 = strConsumerRecord24.serializedKeySize();
        org.apache.kafka.common.header.Headers headers28 = strConsumerRecord24.headers();
        org.apache.kafka.common.header.Headers headers29 = strConsumerRecord24.headers();
        long long30 = strConsumerRecord24.timestamp();
        int int31 = strConsumerRecord24.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType32 = strConsumerRecord24.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), partition = 1, leaderEpoch = null, offset = 100, NoTimestampType = 100, serialized key size = 97, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10), value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) (byte) 10, (long) (short) 100, (long) 32, timestampType14, (long) (byte) -1, 32, (-1), "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = 1, serialized key size = 52, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = class org.apache.kafka.clients.consumer.ConsumerRecord), value = null)", (java.io.Serializable) timestampType32);
        org.apache.kafka.common.record.TimestampType timestampType34 = strConsumerRecord33.timestampType();
        java.lang.Class<?> wildcardClass35 = timestampType34.getClass();
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType13 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType13.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers25);
        org.junit.Assert.assertNotNull(headers26);
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertNotNull(headers28);
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + (-1) + "'", int31 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType32 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType32.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType34 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType34.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass35);
    }

    @Test
    public void test00499() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00499");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        int int6 = strConsumerRecord5.serializedValueSize();
        long long7 = strConsumerRecord5.timestamp();
        org.apache.kafka.common.header.Headers headers8 = strConsumerRecord5.headers();
        java.lang.String str9 = strConsumerRecord5.key();
        int int10 = strConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "" + "'", str9, "");
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
    }

    @Test
    public void test00500() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00500");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType14 = strConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = strConsumerRecord13.timestampType();
        java.lang.String str16 = strConsumerRecord13.toString();
        int int17 = strConsumerRecord13.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = strConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType37 = strConsumerRecord36.timestampType();
        int int38 = strConsumerRecord36.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType39 = strConsumerRecord36.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("", 100, (long) '#', (long) (byte) 0, timestampType39, (long) (short) 10, 0, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (java.lang.Comparable<java.lang.String>) "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long55 = strConsumerRecord54.timestamp();
        int int56 = strConsumerRecord54.partition();
        java.io.Serializable serializable57 = strConsumerRecord54.value();
        java.lang.Class<?> wildcardClass58 = serializable57.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        long long65 = strConsumerRecord64.timestamp();
        int int66 = strConsumerRecord64.partition();
        java.lang.String str67 = strConsumerRecord64.topic();
        long long68 = strConsumerRecord64.offset();
        java.lang.Class<?> wildcardClass69 = strConsumerRecord64.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration> typeConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration>("hi!", (int) (short) 0, (long) (byte) 1, 10L, timestampType39, (long) (byte) 10, (int) 'a', (int) (short) -1, (java.lang.reflect.Type) wildcardClass58, (java.lang.reflect.GenericDeclaration) wildcardClass69);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)", (int) '4', (long) (byte) 0, 1L, timestampType18, (long) (short) -1, 0, (int) (short) -1, "hi!", (java.io.Serializable) timestampType39);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (byte) 100, (long) '4', "", (java.io.Serializable) (short) 10);
        org.apache.kafka.common.record.TimestampType timestampType82 = strConsumerRecord81.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType83 = strConsumerRecord81.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType84 = strConsumerRecord81.timestampType();
        java.lang.String str85 = strConsumerRecord81.key();
        long long86 = strConsumerRecord81.timestamp();
        long long87 = strConsumerRecord81.offset();
        java.lang.String str88 = strConsumerRecord81.toString();
        long long89 = strConsumerRecord81.checksum();
        java.io.Serializable serializable90 = strConsumerRecord81.value();
        java.io.Serializable serializable91 = strConsumerRecord81.value();
        java.io.Serializable serializable92 = strConsumerRecord81.value();
        java.lang.String str93 = strConsumerRecord81.topic();
        org.apache.kafka.common.record.TimestampType timestampType94 = strConsumerRecord81.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord95 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("hi!", (int) (short) 1, 1L, 35L, timestampType39, (long) '4', 32, 0, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 1, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = #)", (java.io.Serializable) timestampType94);
        java.lang.String str96 = strConsumerRecord95.key();
        org.apache.kafka.common.header.Headers headers97 = strConsumerRecord95.headers();
        java.lang.Class<?> wildcardClass98 = headers97.getClass();
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str16, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 100 + "'", int17 == 100);
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType37 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType37.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + (-1) + "'", int38 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType39 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType39.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + (-1L) + "'", long55 == (-1L));
        org.junit.Assert.assertTrue("'" + int56 + "' != '" + 100 + "'", int56 == 100);
        org.junit.Assert.assertEquals("'" + serializable57 + "' != '" + (short) 10 + "'", serializable57, (short) 10);
        org.junit.Assert.assertNotNull(wildcardClass58);
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + (-1L) + "'", long65 == (-1L));
        org.junit.Assert.assertTrue("'" + int66 + "' != '" + 100 + "'", int66 == 100);
        org.junit.Assert.assertEquals("'" + str67 + "' != '" + "hi!" + "'", str67, "hi!");
        org.junit.Assert.assertTrue("'" + long68 + "' != '" + 52L + "'", long68 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass69);
        org.junit.Assert.assertTrue("'" + timestampType82 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType82.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType83 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType83.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType84 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType84.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str85 + "' != '" + "" + "'", str85, "");
        org.junit.Assert.assertTrue("'" + long86 + "' != '" + (-1L) + "'", long86 == (-1L));
        org.junit.Assert.assertTrue("'" + long87 + "' != '" + 52L + "'", long87 == 52L);
        org.junit.Assert.assertEquals("'" + str88 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)" + "'", str88, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = 10)");
        org.junit.Assert.assertTrue("'" + long89 + "' != '" + (-1L) + "'", long89 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable90 + "' != '" + (short) 10 + "'", serializable90, (short) 10);
        org.junit.Assert.assertEquals("'" + serializable91 + "' != '" + (short) 10 + "'", serializable91, (short) 10);
        org.junit.Assert.assertEquals("'" + serializable92 + "' != '" + (short) 10 + "'", serializable92, (short) 10);
        org.junit.Assert.assertEquals("'" + str93 + "' != '" + "hi!" + "'", str93, "hi!");
        org.junit.Assert.assertTrue("'" + timestampType94 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType94.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str96 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 1, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = #)" + "'", str96, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 1, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = #)");
        org.junit.Assert.assertNotNull(headers97);
        org.junit.Assert.assertNotNull(wildcardClass98);
    }
}

