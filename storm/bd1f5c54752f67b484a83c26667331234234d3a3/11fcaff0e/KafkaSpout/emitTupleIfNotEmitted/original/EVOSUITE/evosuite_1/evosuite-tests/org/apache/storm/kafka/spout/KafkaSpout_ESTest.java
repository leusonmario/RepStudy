/*
 * This file was automatically generated by EvoSuite
 * Sun Oct 31 23:09:08 GMT 2021
 */

package org.apache.storm.kafka.spout;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.shaded.org.mockito.Mockito.*;
import static org.evosuite.runtime.EvoAssertions.*;
import clojure.lang.APersistentMap;
import clojure.lang.ArrayChunk;
import clojure.lang.ArraySeq;
import clojure.lang.ChunkedCons;
import clojure.lang.EnumerationSeq;
import clojure.lang.IPersistentMap;
import clojure.lang.ISeq;
import clojure.lang.Keyword;
import clojure.lang.PersistentArrayMap;
import clojure.lang.PersistentHashMap;
import clojure.lang.PersistentList;
import clojure.lang.PersistentStructMap;
import clojure.lang.PersistentTreeMap;
import clojure.lang.PersistentVector;
import clojure.lang.Repeat;
import clojure.lang.StringSeq;
import java.security.Principal;
import java.sql.JDBCType;
import java.util.AbstractMap;
import java.util.Enumeration;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import java.util.concurrent.ForkJoinTask;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.function.Consumer;
import java.util.regex.Pattern;
import org.apache.derby.iapi.sql.depend.ProviderList;
import org.apache.derby.impl.sql.catalog.DataDictionaryImpl;
import org.apache.derby.impl.sql.compile.GenerationClauseNode;
import org.apache.derby.impl.sql.compile.QueryTreeNode;
import org.apache.hadoop.fs.DelegationTokenRenewer;
import org.apache.hadoop.hdfs.web.HsftpFileSystem;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.security.token.delegation.web.DelegationTokenIdentifier;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.OffsetAndMetadata;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.header.internals.RecordHeader;
import org.apache.kafka.common.record.TimestampType;
import org.apache.kafka.common.serialization.Deserializer;
import org.apache.storm.generated.Nimbus;
import org.apache.storm.generated.SpoutSpec;
import org.apache.storm.generated.StormTopology;
import org.apache.storm.kafka.spout.KafkaSpout;
import org.apache.storm.kafka.spout.KafkaSpoutConfig;
import org.apache.storm.kafka.spout.KafkaSpoutMessageId;
import org.apache.storm.kafka.spout.KafkaSpoutRetryService;
import org.apache.storm.kafka.spout.KafkaSpoutStream;
import org.apache.storm.kafka.spout.KafkaSpoutStreams;
import org.apache.storm.kafka.spout.KafkaSpoutStreamsNamedTopics;
import org.apache.storm.kafka.spout.KafkaSpoutStreamsWildcardTopics;
import org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder;
import org.apache.storm.kafka.spout.internal.KafkaConsumerFactory;
import org.apache.storm.kafka.spout.internal.KafkaConsumerFactoryDefault;
import org.apache.storm.spout.SpoutOutputCollector;
import org.apache.storm.task.GeneralTopologyContext;
import org.apache.storm.task.TopologyContext;
import org.apache.storm.topology.OutputFieldsDeclarer;
import org.apache.storm.topology.OutputFieldsGetter;
import org.apache.storm.tuple.Fields;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.System;
import org.evosuite.runtime.ViolatedAssumptionAnswer;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class KafkaSpout_ESTest extends KafkaSpout_ESTest_scaffolding {

  @Test(timeout = 11000)
  public void test00()  throws Throwable  {
      KafkaSpoutConfig<Object, KafkaSpoutMessageId> kafkaSpoutConfig0 = (KafkaSpoutConfig<Object, KafkaSpoutMessageId>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((Map) null).when(kafkaSpoutConfig0).getKafkaProps();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      doReturn((Deserializer) null).when(kafkaSpoutConfig0).getKeyDeserializer();
      doReturn((Deserializer) null).when(kafkaSpoutConfig0).getValueDeserializer();
      KafkaSpout<Object, KafkaSpoutMessageId> kafkaSpout0 = new KafkaSpout<Object, KafkaSpoutMessageId>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      kafkaSpout0.nextTuple();
      // Undeclared exception!
      try { 
        kafkaSpout0.activate();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.util.HashMap", e);
      }
  }

  @Test(timeout = 11000)
  public void test01()  throws Throwable  {
      KafkaSpoutConfig<Object, KafkaSpoutStreamsWildcardTopics> kafkaSpoutConfig0 = (KafkaSpoutConfig<Object, KafkaSpoutStreamsWildcardTopics>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaConsumerFactoryDefault<Object, KafkaSpoutStreamsWildcardTopics> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<Object, KafkaSpoutStreamsWildcardTopics>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<Object, KafkaSpoutStreamsWildcardTopics> kafkaSpout0 = new KafkaSpout<Object, KafkaSpoutStreamsWildcardTopics>(kafkaSpoutConfig0, kafkaConsumerFactoryDefault0);
      assertNotNull(kafkaSpout0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.fail(kafkaConsumerFactoryDefault0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // org.apache.storm.kafka.spout.internal.KafkaConsumerFactoryDefault cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test02()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = null;
      boolean boolean0 = true;
      boolean boolean1 = true;
      boolean boolean2 = FileSystemHandling.setPermissions(evoSuiteFile0, boolean0, boolean1, boolean0);
      assertFalse(boolean2 == boolean0);
      assertFalse(boolean2 == boolean1);
      assertFalse(boolean2);
      
      String string0 = ".46m&`~6CCwub7@ zr";
      Object[] objectArray0 = new Object[8];
      objectArray0[0] = (Object) string0;
      objectArray0[1] = (Object) string0;
      objectArray0[2] = (Object) string0;
      objectArray0[3] = (Object) evoSuiteFile0;
      objectArray0[4] = (Object) evoSuiteFile0;
      objectArray0[5] = (Object) string0;
      objectArray0[6] = (Object) string0;
      objectArray0[7] = (Object) evoSuiteFile0;
      PersistentArrayMap persistentArrayMap0 = PersistentArrayMap.createAsIfByAssoc(objectArray0);
      assertEquals(2, persistentArrayMap0.capacity());
      assertEquals(2, persistentArrayMap0.count());
      assertNotNull(persistentArrayMap0);
      assertEquals(8, objectArray0.length);
      
      StormTopology stormTopology0 = null;
      IPersistentMap iPersistentMap0 = null;
      PersistentArrayMap persistentArrayMap1 = persistentArrayMap0.withMeta(iPersistentMap0);
      assertTrue(persistentArrayMap1.equals((Object)persistentArrayMap0));
      assertEquals(2, persistentArrayMap1.capacity());
      assertEquals(2, persistentArrayMap1.count());
      assertEquals(2, persistentArrayMap0.capacity());
      assertEquals(2, persistentArrayMap0.count());
      assertNotNull(persistentArrayMap1);
      assertNotSame(persistentArrayMap1, persistentArrayMap0);
      assertNotSame(persistentArrayMap0, persistentArrayMap1);
      assertEquals(8, objectArray0.length);
      
      Repeat repeat0 = Repeat.create(objectArray0[4]);
      assertFalse(repeat0.isEmpty());
      assertNotNull(repeat0);
      assertEquals(8, objectArray0.length);
      
      // Undeclared exception!
      try { 
        PersistentTreeMap.create((ISeq) repeat0);
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
      }
  }

  @Test(timeout = 11000)
  public void test03()  throws Throwable  {
      KafkaSpoutConfig<KafkaSpoutStreamsWildcardTopics, Nimbus.beginCreateBlob_result._Fields> kafkaSpoutConfig0 = (KafkaSpoutConfig<KafkaSpoutStreamsWildcardTopics, Nimbus.beginCreateBlob_result._Fields>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutConfig.FirstPollOffsetStrategy) null).when(kafkaSpoutConfig0).getFirstPollOffsetStrategy();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      doReturn(0).when(kafkaSpoutConfig0).getMaxTupleRetries();
      doReturn(0L).when(kafkaSpoutConfig0).getOffsetsCommitPeriodMs();
      doReturn((KafkaSpoutRetryService) null).when(kafkaSpoutConfig0).getRetryService();
      doReturn((KafkaSpoutTuplesBuilder) null).when(kafkaSpoutConfig0).getTuplesBuilder();
      doReturn(false).when(kafkaSpoutConfig0).isConsumerAutoCommitMode();
      KafkaConsumerFactory<KafkaSpoutStreamsWildcardTopics, Nimbus.beginCreateBlob_result._Fields> kafkaConsumerFactory0 = null;
      KafkaSpout<KafkaSpoutStreamsWildcardTopics, Nimbus.beginCreateBlob_result._Fields> kafkaSpout0 = new KafkaSpout<KafkaSpoutStreamsWildcardTopics, Nimbus.beginCreateBlob_result._Fields>(kafkaSpoutConfig0, kafkaConsumerFactory0);
      assertNotNull(kafkaSpout0);
      
      PersistentArrayMap persistentArrayMap0 = PersistentArrayMap.EMPTY;
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentArrayMap0.capacity());
      assertNotNull(persistentArrayMap0);
      
      StormTopology stormTopology0 = new StormTopology(persistentArrayMap0, persistentArrayMap0, persistentArrayMap0);
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentArrayMap0.capacity());
      assertTrue(stormTopology0.is_set_bolts());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertTrue(stormTopology0.is_set_state_spouts());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertTrue(stormTopology0.is_set_spouts());
      assertNotNull(stormTopology0);
      
      String string0 = "}W60xb5ND&U$Nu<Q|!";
      String string1 = "clojure.core$loop$fn__4973";
      int int0 = (-128);
      Integer integer0 = new Integer(int0);
      assertTrue(integer0.equals((Object)int0));
      assertNotNull(integer0);
      assertEquals((-128), (int)integer0);
      
      int int1 = (-33);
      Integer integer1 = new Integer(int1);
      assertFalse(int1 == int0);
      assertFalse(integer1.equals((Object)integer0));
      assertFalse(integer1.equals((Object)int0));
      assertTrue(integer1.equals((Object)int1));
      assertNotNull(integer1);
      assertEquals((-33), (int)integer1);
      
      APersistentMap.KeySeq aPersistentMap_KeySeq0 = APersistentMap.KeySeq.createFromMap(persistentArrayMap0);
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentArrayMap0.capacity());
      assertNull(aPersistentMap_KeySeq0);
      
      Map<String, Object> map0 = null;
      boolean boolean0 = true;
      AtomicBoolean atomicBoolean0 = new AtomicBoolean(boolean0);
      assertEquals("true", atomicBoolean0.toString());
      assertTrue(atomicBoolean0.get());
      assertNotNull(atomicBoolean0);
      
      TopologyContext topologyContext0 = new TopologyContext(stormTopology0, stormTopology0.metaDataMap, persistentArrayMap0, persistentArrayMap0, persistentArrayMap0, string0, string1, string0, integer0, integer1, aPersistentMap_KeySeq0, persistentArrayMap0, persistentArrayMap0, map0, persistentArrayMap0, atomicBoolean0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string0));
      assertFalse(int0 == int1);
      assertTrue(integer0.equals((Object)int0));
      assertFalse(integer0.equals((Object)int1));
      assertFalse(integer0.equals((Object)integer1));
      assertFalse(int1 == int0);
      assertFalse(integer1.equals((Object)integer0));
      assertFalse(integer1.equals((Object)int0));
      assertTrue(integer1.equals((Object)int1));
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentArrayMap0.capacity());
      assertTrue(stormTopology0.is_set_bolts());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertTrue(stormTopology0.is_set_state_spouts());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertTrue(stormTopology0.is_set_spouts());
      assertEquals("true", atomicBoolean0.toString());
      assertTrue(atomicBoolean0.get());
      assertEquals("/home/CIN/lmps2/semantic-conflict-study/SMAT/output-test-dest/storm/bd1f5c54752f67b484a83c26667331234234d3a3/evosuite_1/}W60xb5ND&U$Nu<Q|!", topologyContext0.getPIDDir());
      assertEquals("clojure.core$loop$fn__4973", topologyContext0.getCodeDir());
      assertEquals((-128), topologyContext0.getThisTaskId());
      assertEquals((-33), (int)topologyContext0.getThisWorkerPort());
      assertEquals("}W60xb5ND&U$Nu<Q|!", topologyContext0.getStormId());
      assertNull(topologyContext0.getThisComponentId());
      assertNotNull(topologyContext0);
      
      SpoutOutputCollector spoutOutputCollector0 = null;
      kafkaSpout0.open(persistentArrayMap0, topologyContext0, spoutOutputCollector0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string0));
      assertFalse(int0 == int1);
      assertTrue(integer0.equals((Object)int0));
      assertFalse(integer0.equals((Object)int1));
      assertFalse(integer0.equals((Object)integer1));
      assertFalse(int1 == int0);
      assertFalse(integer1.equals((Object)integer0));
      assertFalse(integer1.equals((Object)int0));
      assertTrue(integer1.equals((Object)int1));
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentArrayMap0.capacity());
      assertTrue(stormTopology0.is_set_bolts());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertTrue(stormTopology0.is_set_state_spouts());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertTrue(stormTopology0.is_set_spouts());
      assertEquals("true", atomicBoolean0.toString());
      assertTrue(atomicBoolean0.get());
      assertEquals("/home/CIN/lmps2/semantic-conflict-study/SMAT/output-test-dest/storm/bd1f5c54752f67b484a83c26667331234234d3a3/evosuite_1/}W60xb5ND&U$Nu<Q|!", topologyContext0.getPIDDir());
      assertEquals("clojure.core$loop$fn__4973", topologyContext0.getCodeDir());
      assertEquals((-128), topologyContext0.getThisTaskId());
      assertEquals((-33), (int)topologyContext0.getThisWorkerPort());
      assertEquals("}W60xb5ND&U$Nu<Q|!", topologyContext0.getStormId());
      assertNull(topologyContext0.getThisComponentId());
      assertNotSame(string0, string1);
      assertNotSame(string1, string0);
  }

  @Test(timeout = 11000)
  public void test04()  throws Throwable  {
      KafkaConsumerFactoryDefault<TopicPartition, Object> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<TopicPartition, Object>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<TopicPartition, Nimbus.beginCreateBlob_result._Fields> kafkaSpoutConfig0 = (KafkaSpoutConfig<TopicPartition, Nimbus.beginCreateBlob_result._Fields>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<TopicPartition, Nimbus.beginCreateBlob_result._Fields> kafkaSpout0 = new KafkaSpout<TopicPartition, Nimbus.beginCreateBlob_result._Fields>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.ack(kafkaConsumerFactoryDefault0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // org.apache.storm.kafka.spout.internal.KafkaConsumerFactoryDefault cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test05()  throws Throwable  {
      String string0 = "T1wd";
      GenerationClauseNode generationClauseNode0 = new GenerationClauseNode();
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertNull(generationClauseNode0.getColumnName());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      assertNull(generationClauseNode0.getSchemaName());
      assertNull(generationClauseNode0.getTableName());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.isCloneable());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertNull(generationClauseNode0.getExpressionText());
      assertFalse(generationClauseNode0.isParameterNode());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertNotNull(generationClauseNode0);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      
      ProviderList providerList0 = generationClauseNode0.getAuxiliaryProviderList();
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertNull(generationClauseNode0.getColumnName());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      assertNull(generationClauseNode0.getSchemaName());
      assertNull(generationClauseNode0.getTableName());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.isCloneable());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertNull(generationClauseNode0.getExpressionText());
      assertFalse(generationClauseNode0.isParameterNode());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertNull(providerList0);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      
      String[] stringArray0 = new String[1];
      stringArray0[0] = string0;
      Fields fields0 = new Fields(stringArray0);
      assertEquals(1, fields0.size());
      assertNotNull(fields0);
      assertEquals(1, stringArray0.length);
      
      Pattern pattern0 = Pattern.compile(string0, generationClauseNode0.AUTOINCREMENT_CREATE_MODIFY);
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertNull(generationClauseNode0.getColumnName());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      assertNull(generationClauseNode0.getSchemaName());
      assertNull(generationClauseNode0.getTableName());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.isCloneable());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertNull(generationClauseNode0.getExpressionText());
      assertFalse(generationClauseNode0.isParameterNode());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertEquals("T1wd", pattern0.pattern());
      assertEquals("T1wd", pattern0.toString());
      assertEquals(3, pattern0.flags());
      assertNotNull(pattern0);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      
      KafkaSpoutStream kafkaSpoutStream0 = new KafkaSpoutStream(fields0, pattern0);
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertNull(generationClauseNode0.getColumnName());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      assertNull(generationClauseNode0.getSchemaName());
      assertNull(generationClauseNode0.getTableName());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.isCloneable());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertNull(generationClauseNode0.getExpressionText());
      assertFalse(generationClauseNode0.isParameterNode());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertEquals(1, fields0.size());
      assertEquals("T1wd", pattern0.pattern());
      assertEquals("T1wd", pattern0.toString());
      assertEquals(3, pattern0.flags());
      assertNull(kafkaSpoutStream0.getTopic());
      assertNotNull(kafkaSpoutStream0);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertEquals(1, stringArray0.length);
      
      KafkaSpoutStreamsWildcardTopics kafkaSpoutStreamsWildcardTopics0 = new KafkaSpoutStreamsWildcardTopics(kafkaSpoutStream0);
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertNull(generationClauseNode0.getColumnName());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      assertNull(generationClauseNode0.getSchemaName());
      assertNull(generationClauseNode0.getTableName());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.isCloneable());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertNull(generationClauseNode0.getExpressionText());
      assertFalse(generationClauseNode0.isParameterNode());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertEquals(1, fields0.size());
      assertEquals("T1wd", pattern0.pattern());
      assertEquals("T1wd", pattern0.toString());
      assertEquals(3, pattern0.flags());
      assertNull(kafkaSpoutStream0.getTopic());
      assertNotNull(kafkaSpoutStreamsWildcardTopics0);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertEquals(1, stringArray0.length);
      
      KafkaSpoutConfig<Integer, Keyword> kafkaSpoutConfig0 = (KafkaSpoutConfig<Integer, Keyword>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(stringArray0[0]).when(kafkaSpoutConfig0).getConsumerGroupId();
      doReturn(providerList0).when(kafkaSpoutConfig0).getKafkaProps();
      doReturn(kafkaSpoutStreamsWildcardTopics0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      doReturn(pattern0).when(kafkaSpoutConfig0).getTopicWildcardPattern();
      KafkaConsumerFactoryDefault<Integer, Keyword> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<Integer, Keyword>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      String string1 = ", committedOffset=";
      KafkaSpout<Integer, Keyword> kafkaSpout0 = new KafkaSpout<Integer, Keyword>(kafkaSpoutConfig0, kafkaConsumerFactoryDefault0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertNull(generationClauseNode0.getColumnName());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      assertNull(generationClauseNode0.getSchemaName());
      assertNull(generationClauseNode0.getTableName());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.isCloneable());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertNull(generationClauseNode0.getExpressionText());
      assertFalse(generationClauseNode0.isParameterNode());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertEquals(1, fields0.size());
      assertEquals("T1wd", pattern0.pattern());
      assertEquals("T1wd", pattern0.toString());
      assertEquals(3, pattern0.flags());
      assertNull(kafkaSpoutStream0.getTopic());
      assertNotNull(kafkaSpout0);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertEquals(1, stringArray0.length);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.getComponentConfiguration();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test06()  throws Throwable  {
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<OffsetAndMetadata, DelegationTokenIdentifier> kafkaSpoutConfig0 = (KafkaSpoutConfig<OffsetAndMetadata, DelegationTokenIdentifier>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig.FirstPollOffsetStrategy kafkaSpoutConfig_FirstPollOffsetStrategy0 = KafkaSpoutConfig.FirstPollOffsetStrategy.EARLIEST;
      KafkaSpoutStreams kafkaSpoutStreams1 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutRetryService kafkaSpoutRetryService0 = mock(KafkaSpoutRetryService.class, new ViolatedAssumptionAnswer());
      KafkaSpoutTuplesBuilder<ConsumerRecord<Integer, Object>, KafkaSpoutMessageId> kafkaSpoutTuplesBuilder0 = (KafkaSpoutTuplesBuilder<ConsumerRecord<Integer, Object>, KafkaSpoutMessageId>) mock(KafkaSpoutTuplesBuilder.class, new ViolatedAssumptionAnswer());
      boolean boolean0 = true;
      KafkaSpoutConfig<ConsumerRecord<Integer, Object>, KafkaSpoutMessageId> kafkaSpoutConfig1 = (KafkaSpoutConfig<ConsumerRecord<Integer, Object>, KafkaSpoutMessageId>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutConfig_FirstPollOffsetStrategy0).when(kafkaSpoutConfig1).getFirstPollOffsetStrategy();
      doReturn(kafkaSpoutStreams1).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      doReturn(kafkaSpoutConfig0.DEFAULT_MAX_RETRIES).when(kafkaSpoutConfig1).getMaxTupleRetries();
      doReturn(kafkaSpoutRetryService0).when(kafkaSpoutConfig1).getRetryService();
      doReturn(kafkaSpoutTuplesBuilder0).when(kafkaSpoutConfig1).getTuplesBuilder();
      doReturn(boolean0).when(kafkaSpoutConfig1).isConsumerAutoCommitMode();
      KafkaConsumerFactoryDefault<ConsumerRecord<Integer, Object>, KafkaSpoutMessageId> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<ConsumerRecord<Integer, Object>, KafkaSpoutMessageId>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<ConsumerRecord<Integer, Object>, KafkaSpoutMessageId> kafkaSpout0 = new KafkaSpout<ConsumerRecord<Integer, Object>, KafkaSpoutMessageId>(kafkaSpoutConfig1, kafkaConsumerFactoryDefault0);
      assertNotNull(kafkaSpout0);
      
      PersistentArrayMap persistentArrayMap0 = PersistentArrayMap.EMPTY;
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertNotNull(persistentArrayMap0);
      
      StormTopology stormTopology0 = new StormTopology(persistentArrayMap0, persistentArrayMap0, persistentArrayMap0);
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertTrue(stormTopology0.is_set_state_spouts());
      assertTrue(stormTopology0.is_set_spouts());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertTrue(stormTopology0.is_set_bolts());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertNotNull(stormTopology0);
      
      String string0 = "NI|d0l>_M7|";
      String string1 = " [N%!ao<V=z}e";
      JDBCType jDBCType0 = JDBCType.INTEGER;
      Integer integer0 = jDBCType0.getVendorTypeNumber();
      assertNotNull(integer0);
      assertEquals(4, (int)integer0);
      
      PersistentList persistentList0 = new PersistentList(stormTopology0);
      assertEquals(1, persistentList0.count());
      assertFalse(persistentList0.isEmpty());
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertTrue(stormTopology0.is_set_state_spouts());
      assertTrue(stormTopology0.is_set_spouts());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertTrue(stormTopology0.is_set_bolts());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertNotNull(persistentList0);
      
      AtomicBoolean atomicBoolean0 = new AtomicBoolean(boolean0);
      assertTrue(atomicBoolean0.get());
      assertEquals("true", atomicBoolean0.toString());
      assertNotNull(atomicBoolean0);
      
      TopologyContext topologyContext0 = new TopologyContext(stormTopology0, persistentArrayMap0, persistentArrayMap0, persistentArrayMap0, persistentArrayMap0, string0, string0, string1, integer0, (Integer) kafkaSpoutConfig1.DEFAULT_MAX_RETRIES, persistentList0, persistentArrayMap0, persistentArrayMap0, persistentArrayMap0, persistentArrayMap0, atomicBoolean0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string0));
      assertEquals(1, persistentList0.count());
      assertFalse(persistentList0.isEmpty());
      assertTrue(atomicBoolean0.get());
      assertEquals("true", atomicBoolean0.toString());
      assertNull(topologyContext0.getThisComponentId());
      assertEquals("/home/CIN/lmps2/semantic-conflict-study/SMAT/output-test-dest/storm/bd1f5c54752f67b484a83c26667331234234d3a3/evosuite_1/ [N%!ao<V=z}e", topologyContext0.getPIDDir());
      assertEquals("NI|d0l>_M7|", topologyContext0.getCodeDir());
      assertEquals(Integer.MAX_VALUE, (int)topologyContext0.getThisWorkerPort());
      assertEquals(4, topologyContext0.getThisTaskId());
      assertEquals("NI|d0l>_M7|", topologyContext0.getStormId());
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertTrue(stormTopology0.is_set_state_spouts());
      assertTrue(stormTopology0.is_set_spouts());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertTrue(stormTopology0.is_set_bolts());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertNotNull(topologyContext0);
      
      KafkaSpoutStreams kafkaSpoutStreams2 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<DelegationTokenIdentifier, DelegationTokenIdentifier> kafkaSpoutConfig2 = (KafkaSpoutConfig<DelegationTokenIdentifier, DelegationTokenIdentifier>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams2).when(kafkaSpoutConfig2).getKafkaSpoutStreams();
      KafkaConsumerFactoryDefault<DelegationTokenIdentifier, DelegationTokenIdentifier> kafkaConsumerFactoryDefault1 = new KafkaConsumerFactoryDefault<DelegationTokenIdentifier, DelegationTokenIdentifier>();
      assertNotNull(kafkaConsumerFactoryDefault1);
      
      KafkaSpout<DelegationTokenIdentifier, DelegationTokenIdentifier> kafkaSpout1 = new KafkaSpout<DelegationTokenIdentifier, DelegationTokenIdentifier>(kafkaSpoutConfig2, kafkaConsumerFactoryDefault1);
      assertNotNull(kafkaSpout1);
      
      SpoutOutputCollector spoutOutputCollector0 = kafkaSpout1.collector;
      assertNull(spoutOutputCollector0);
      
      kafkaSpout0.open(persistentArrayMap0, topologyContext0, spoutOutputCollector0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string0));
      assertEquals(1, persistentList0.count());
      assertFalse(persistentList0.isEmpty());
      assertTrue(atomicBoolean0.get());
      assertEquals("true", atomicBoolean0.toString());
      assertNull(topologyContext0.getThisComponentId());
      assertEquals("/home/CIN/lmps2/semantic-conflict-study/SMAT/output-test-dest/storm/bd1f5c54752f67b484a83c26667331234234d3a3/evosuite_1/ [N%!ao<V=z}e", topologyContext0.getPIDDir());
      assertEquals("NI|d0l>_M7|", topologyContext0.getCodeDir());
      assertEquals(Integer.MAX_VALUE, (int)topologyContext0.getThisWorkerPort());
      assertEquals(4, topologyContext0.getThisTaskId());
      assertEquals("NI|d0l>_M7|", topologyContext0.getStormId());
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertTrue(stormTopology0.is_set_state_spouts());
      assertTrue(stormTopology0.is_set_spouts());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertTrue(stormTopology0.is_set_bolts());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertNotSame(string0, string1);
      assertNotSame(string1, string0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.deactivate();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test07()  throws Throwable  {
      String[] stringArray0 = new String[2];
      String string0 = "#n";
      stringArray0[0] = string0;
      String string1 = "{y2a7\\-K";
      Fields fields0 = new Fields(stringArray0);
      assertEquals(2, fields0.size());
      assertNotNull(fields0);
      assertEquals(2, stringArray0.length);
      
      Pattern pattern0 = Pattern.compile(string0);
      assertFalse(string0.equals((Object)string1));
      assertEquals("#n", pattern0.toString());
      assertEquals(0, pattern0.flags());
      assertEquals("#n", pattern0.pattern());
      assertNotNull(pattern0);
      assertNotSame(string0, string1);
      
      KafkaSpoutStream kafkaSpoutStream0 = new KafkaSpoutStream(fields0, string1, pattern0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string0));
      assertEquals(2, fields0.size());
      assertEquals("#n", pattern0.toString());
      assertEquals(0, pattern0.flags());
      assertEquals("#n", pattern0.pattern());
      assertNull(kafkaSpoutStream0.getTopic());
      assertNotNull(kafkaSpoutStream0);
      assertEquals(2, stringArray0.length);
      
      KafkaSpoutStreamsWildcardTopics kafkaSpoutStreamsWildcardTopics0 = new KafkaSpoutStreamsWildcardTopics(kafkaSpoutStream0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string0));
      assertEquals(2, fields0.size());
      assertEquals("#n", pattern0.toString());
      assertEquals(0, pattern0.flags());
      assertEquals("#n", pattern0.pattern());
      assertNull(kafkaSpoutStream0.getTopic());
      assertNotNull(kafkaSpoutStreamsWildcardTopics0);
      assertEquals(2, stringArray0.length);
      
      KafkaSpoutConfig<Object, Principal> kafkaSpoutConfig0 = (KafkaSpoutConfig<Object, Principal>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreamsWildcardTopics0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<Object, Principal> kafkaSpout0 = new KafkaSpout<Object, Principal>(kafkaSpoutConfig0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string0));
      assertEquals(2, fields0.size());
      assertEquals("#n", pattern0.toString());
      assertEquals(0, pattern0.flags());
      assertEquals("#n", pattern0.pattern());
      assertNull(kafkaSpoutStream0.getTopic());
      assertNotNull(kafkaSpout0);
      assertEquals(2, stringArray0.length);
      
      OutputFieldsGetter outputFieldsGetter0 = new OutputFieldsGetter();
      assertNotNull(outputFieldsGetter0);
      
      kafkaSpout0.declareOutputFields(outputFieldsGetter0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string0));
      assertEquals(2, fields0.size());
      assertEquals("#n", pattern0.toString());
      assertEquals(0, pattern0.flags());
      assertEquals("#n", pattern0.pattern());
      assertNull(kafkaSpoutStream0.getTopic());
      assertNotSame(string0, string1);
      assertNotSame(string1, string0);
      assertEquals(2, stringArray0.length);
  }

  @Test(timeout = 11000)
  public void test08()  throws Throwable  {
      KafkaSpoutConfig<OffsetAndMetadata, Object> kafkaSpoutConfig0 = (KafkaSpoutConfig<OffsetAndMetadata, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaConsumerFactoryDefault<OffsetAndMetadata, Object> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<OffsetAndMetadata, Object>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<OffsetAndMetadata, Object> kafkaSpout0 = new KafkaSpout<OffsetAndMetadata, Object>(kafkaSpoutConfig0, kafkaConsumerFactoryDefault0);
      assertNotNull(kafkaSpout0);
      
      kafkaSpout0.nextTuple();
      KafkaSpoutConfig<Principal, Object> kafkaSpoutConfig1 = (KafkaSpoutConfig<Principal, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<Principal, Object> kafkaSpout1 = new KafkaSpout<Principal, Object>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      Object[] objectArray0 = new Object[7];
      objectArray0[1] = (Object) kafkaSpout1;
      PersistentArrayMap persistentArrayMap0 = new PersistentArrayMap(objectArray0);
      assertEquals(3, persistentArrayMap0.capacity());
      assertEquals(3, persistentArrayMap0.count());
      assertNotNull(persistentArrayMap0);
      assertEquals(7, objectArray0.length);
      
      ConsumerRecords<Principal, Object> consumerRecords0 = new ConsumerRecords<Principal, Object>(persistentArrayMap0);
      assertEquals(3, persistentArrayMap0.capacity());
      assertEquals(3, persistentArrayMap0.count());
      assertFalse(consumerRecords0.isEmpty());
      assertNotNull(consumerRecords0);
      assertEquals(7, objectArray0.length);
      
      // Undeclared exception!
      try { 
        kafkaSpout1.setWaitingToEmit(consumerRecords0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // org.apache.storm.kafka.spout.KafkaSpout cannot be cast to java.util.List
         //
         verifyException("org.apache.kafka.clients.consumer.ConsumerRecords", e);
      }
  }

  @Test(timeout = 11000)
  public void test09()  throws Throwable  {
      KafkaSpoutConfig<Integer, TopicPartition> kafkaSpoutConfig0 = null;
      KafkaSpout<Integer, TopicPartition> kafkaSpout0 = null;
      try {
        kafkaSpout0 = new KafkaSpout<Integer, TopicPartition>(kafkaSpoutConfig0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test10()  throws Throwable  {
      KafkaSpoutConfig<Keyword, Integer> kafkaSpoutConfig0 = (KafkaSpoutConfig<Keyword, Integer>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<Keyword, Integer> kafkaSpout0 = new KafkaSpout<Keyword, Integer>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
  }

  @Test(timeout = 11000)
  public void test11()  throws Throwable  {
      KafkaSpoutConfig<Object, TopicPartition> kafkaSpoutConfig0 = (KafkaSpoutConfig<Object, TopicPartition>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaConsumerFactoryDefault<Object, TopicPartition> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<Object, TopicPartition>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<Object, TopicPartition> kafkaSpout0 = new KafkaSpout<Object, TopicPartition>(kafkaSpoutConfig0, kafkaConsumerFactoryDefault0);
      assertNotNull(kafkaSpout0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.fail(kafkaConsumerFactoryDefault0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // org.apache.storm.kafka.spout.internal.KafkaConsumerFactoryDefault cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test12()  throws Throwable  {
      KafkaSpoutConfig<String, Nimbus.beginCreateBlob_result._Fields> kafkaSpoutConfig0 = (KafkaSpoutConfig<String, Nimbus.beginCreateBlob_result._Fields>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaConsumerFactoryDefault<String, Nimbus.beginCreateBlob_result._Fields> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<String, Nimbus.beginCreateBlob_result._Fields>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<String, Nimbus.beginCreateBlob_result._Fields> kafkaSpout0 = new KafkaSpout<String, Nimbus.beginCreateBlob_result._Fields>(kafkaSpoutConfig0, kafkaConsumerFactoryDefault0);
      assertNotNull(kafkaSpout0);
      
      String string0 = kafkaSpout0.toString();
      assertNotNull(string0);
      assertEquals("KafkaSpout{acked=null, emitted=null}", string0);
  }

  @Test(timeout = 11000)
  public void test13()  throws Throwable  {
      KafkaSpoutConfig<Object, Integer> kafkaSpoutConfig0 = (KafkaSpoutConfig<Object, Integer>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((String) null).when(kafkaSpoutConfig0).getConsumerGroupId();
      doReturn((Map) null).when(kafkaSpoutConfig0).getKafkaProps();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<Object, Integer> kafkaSpout0 = new KafkaSpout<Object, Integer>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.getComponentConfiguration();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test14()  throws Throwable  {
      KafkaSpoutConfig<String, Nimbus.beginCreateBlob_result._Fields> kafkaSpoutConfig0 = (KafkaSpoutConfig<String, Nimbus.beginCreateBlob_result._Fields>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((String) null).when(kafkaSpoutConfig0).getConsumerGroupId();
      doReturn((Map) null).when(kafkaSpoutConfig0).getKafkaProps();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaConsumerFactoryDefault<String, Nimbus.beginCreateBlob_result._Fields> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<String, Nimbus.beginCreateBlob_result._Fields>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<String, Nimbus.beginCreateBlob_result._Fields> kafkaSpout0 = new KafkaSpout<String, Nimbus.beginCreateBlob_result._Fields>(kafkaSpoutConfig0, kafkaConsumerFactoryDefault0);
      assertNotNull(kafkaSpout0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.getComponentConfiguration();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test15()  throws Throwable  {
      KafkaSpoutConfig<TopicPartition, Integer> kafkaSpoutConfig0 = (KafkaSpoutConfig<TopicPartition, Integer>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<TopicPartition, Integer> kafkaSpout0 = new KafkaSpout<TopicPartition, Integer>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "o vo#P8^g8AW%";
      // Undeclared exception!
      try { 
        kafkaSpout0.fail(string0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // java.lang.String cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test16()  throws Throwable  {
      KafkaSpoutConfig.FirstPollOffsetStrategy[] kafkaSpoutConfig_FirstPollOffsetStrategyArray0 = KafkaSpoutConfig.FirstPollOffsetStrategy.values();
      assertNotNull(kafkaSpoutConfig_FirstPollOffsetStrategyArray0);
      assertEquals(4, kafkaSpoutConfig_FirstPollOffsetStrategyArray0.length);
      
      KafkaSpoutConfig<AbstractMap.SimpleEntry<Integer, KafkaSpoutStreamsWildcardTopics>, String> kafkaSpoutConfig0 = null;
      KafkaSpout<AbstractMap.SimpleEntry<Integer, KafkaSpoutStreamsWildcardTopics>, String> kafkaSpout0 = null;
      try {
        kafkaSpout0 = new KafkaSpout<AbstractMap.SimpleEntry<Integer, KafkaSpoutStreamsWildcardTopics>, String>(kafkaSpoutConfig0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test17()  throws Throwable  {
      KafkaSpoutConfig<KafkaSpoutMessageId, KafkaSpoutStreamsNamedTopics> kafkaSpoutConfig0 = (KafkaSpoutConfig<KafkaSpoutMessageId, KafkaSpoutStreamsNamedTopics>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutMessageId, KafkaSpoutStreamsNamedTopics> kafkaSpout0 = new KafkaSpout<KafkaSpoutMessageId, KafkaSpoutStreamsNamedTopics>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      KafkaSpoutConfig<DelegationTokenIdentifier, DelegationTokenIdentifier> kafkaSpoutConfig1 = (KafkaSpoutConfig<DelegationTokenIdentifier, DelegationTokenIdentifier>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaConsumerFactoryDefault<DelegationTokenIdentifier, DelegationTokenIdentifier> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<DelegationTokenIdentifier, DelegationTokenIdentifier>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<DelegationTokenIdentifier, DelegationTokenIdentifier> kafkaSpout1 = new KafkaSpout<DelegationTokenIdentifier, DelegationTokenIdentifier>(kafkaSpoutConfig1, kafkaConsumerFactoryDefault0);
      assertNotNull(kafkaSpout1);
      
      SpoutOutputCollector spoutOutputCollector0 = kafkaSpout1.collector;
      assertNull(spoutOutputCollector0);
      
      kafkaSpout0.collector = spoutOutputCollector0;
      ConsumerRecords<KafkaSpoutMessageId, KafkaSpoutStreamsNamedTopics> consumerRecords0 = null;
      // Undeclared exception!
      try { 
        kafkaSpout0.setWaitingToEmit(consumerRecords0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test18()  throws Throwable  {
      KafkaSpoutConfig.FirstPollOffsetStrategy[] kafkaSpoutConfig_FirstPollOffsetStrategyArray0 = KafkaSpoutConfig.FirstPollOffsetStrategy.values();
      assertNotNull(kafkaSpoutConfig_FirstPollOffsetStrategyArray0);
      assertEquals(4, kafkaSpoutConfig_FirstPollOffsetStrategyArray0.length);
      
      KafkaSpoutConfig<KafkaSpoutMessageId, Object> kafkaSpoutConfig0 = (KafkaSpoutConfig<KafkaSpoutMessageId, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((Map) null).when(kafkaSpoutConfig0).getKafkaProps();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      doReturn((Deserializer) null).when(kafkaSpoutConfig0).getKeyDeserializer();
      doReturn((Deserializer) null).when(kafkaSpoutConfig0).getValueDeserializer();
      KafkaConsumerFactoryDefault<KafkaSpoutMessageId, Object> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<KafkaSpoutMessageId, Object>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<KafkaSpoutMessageId, Object> kafkaSpout0 = new KafkaSpout<KafkaSpoutMessageId, Object>(kafkaSpoutConfig0, kafkaConsumerFactoryDefault0);
      assertNotNull(kafkaSpout0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.activate();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.util.HashMap", e);
      }
  }

  @Test(timeout = 11000)
  public void test19()  throws Throwable  {
      KafkaSpoutConfig<String, DelegationTokenRenewer.RenewAction<HsftpFileSystem>> kafkaSpoutConfig0 = (KafkaSpoutConfig<String, DelegationTokenRenewer.RenewAction<HsftpFileSystem>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<String, DelegationTokenRenewer.RenewAction<HsftpFileSystem>> kafkaSpout0 = new KafkaSpout<String, DelegationTokenRenewer.RenewAction<HsftpFileSystem>>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.deactivate();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test20()  throws Throwable  {
      KafkaSpoutConfig<Object, KafkaSpout<OffsetAndMetadata, KafkaSpoutStreamsWildcardTopics>> kafkaSpoutConfig0 = (KafkaSpoutConfig<Object, KafkaSpout<OffsetAndMetadata, KafkaSpoutStreamsWildcardTopics>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaConsumerFactoryDefault<Object, KafkaSpout<OffsetAndMetadata, KafkaSpoutStreamsWildcardTopics>> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<Object, KafkaSpout<OffsetAndMetadata, KafkaSpoutStreamsWildcardTopics>>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<Object, KafkaSpout<OffsetAndMetadata, KafkaSpoutStreamsWildcardTopics>> kafkaSpout0 = new KafkaSpout<Object, KafkaSpout<OffsetAndMetadata, KafkaSpoutStreamsWildcardTopics>>(kafkaSpoutConfig0, kafkaConsumerFactoryDefault0);
      assertNotNull(kafkaSpout0);
      
      String string0 = kafkaSpout0.toString();
      assertNotNull(string0);
      assertEquals("KafkaSpout{acked=null, emitted=null}", string0);
      
      KafkaSpoutConfig<OffsetAndMetadata, Object> kafkaSpoutConfig1 = (KafkaSpoutConfig<OffsetAndMetadata, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((Map) null).when(kafkaSpoutConfig1).getKafkaProps();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      doReturn((Deserializer) null).when(kafkaSpoutConfig1).getKeyDeserializer();
      doReturn((Deserializer) null).when(kafkaSpoutConfig1).getValueDeserializer();
      KafkaSpout<OffsetAndMetadata, Object> kafkaSpout1 = new KafkaSpout<OffsetAndMetadata, Object>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      // Undeclared exception!
      try { 
        kafkaSpout1.activate();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.util.HashMap", e);
      }
  }

  @Test(timeout = 11000)
  public void test21()  throws Throwable  {
      KafkaSpoutConfig.FirstPollOffsetStrategy[] kafkaSpoutConfig_FirstPollOffsetStrategyArray0 = KafkaSpoutConfig.FirstPollOffsetStrategy.values();
      assertNotNull(kafkaSpoutConfig_FirstPollOffsetStrategyArray0);
      assertEquals(4, kafkaSpoutConfig_FirstPollOffsetStrategyArray0.length);
      
      KafkaSpoutConfig<Nimbus.beginCreateBlob_result._Fields, Principal> kafkaSpoutConfig0 = (KafkaSpoutConfig<Nimbus.beginCreateBlob_result._Fields, Principal>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<Nimbus.beginCreateBlob_result._Fields, Principal> kafkaSpout0 = new KafkaSpout<Nimbus.beginCreateBlob_result._Fields, Principal>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.deactivate();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test22()  throws Throwable  {
      KafkaSpoutConfig<String, KafkaSpoutMessageId> kafkaSpoutConfig0 = (KafkaSpoutConfig<String, KafkaSpoutMessageId>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaConsumerFactoryDefault<String, KafkaSpoutMessageId> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<String, KafkaSpoutMessageId>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<String, KafkaSpoutMessageId> kafkaSpout0 = new KafkaSpout<String, KafkaSpoutMessageId>(kafkaSpoutConfig0, kafkaConsumerFactoryDefault0);
      assertNotNull(kafkaSpout0);
      
      Object object0 = null;
      // Undeclared exception!
      try { 
        kafkaSpout0.ack(object0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
      }
  }

  @Test(timeout = 11000)
  public void test23()  throws Throwable  {
      KafkaSpoutConfig<Integer, Object> kafkaSpoutConfig0 = (KafkaSpoutConfig<Integer, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<Integer, Object> kafkaSpout0 = new KafkaSpout<Integer, Object>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.close();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test24()  throws Throwable  {
      KafkaSpoutConfig<ConsumerRecord<Integer, HsftpFileSystem>, Keyword> kafkaSpoutConfig0 = (KafkaSpoutConfig<ConsumerRecord<Integer, HsftpFileSystem>, Keyword>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<ConsumerRecord<Integer, HsftpFileSystem>, Keyword> kafkaSpout0 = new KafkaSpout<ConsumerRecord<Integer, HsftpFileSystem>, Keyword>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      Text text0 = org.apache.hadoop.hive.thrift.DelegationTokenIdentifier.HIVE_DELEGATION_KIND;
      assertEquals(21, text0.getLength());
      assertNotNull(text0);
      assertEquals(1048576, Text.DEFAULT_MAX_LEN);
      
      DelegationTokenIdentifier delegationTokenIdentifier0 = new DelegationTokenIdentifier(text0);
      assertEquals(21, text0.getLength());
      assertEquals(0L, delegationTokenIdentifier0.getIssueDate());
      assertEquals(0, delegationTokenIdentifier0.getSequenceNumber());
      assertEquals(0L, delegationTokenIdentifier0.getMaxDate());
      assertEquals(0, delegationTokenIdentifier0.getMasterKeyId());
      assertNotNull(delegationTokenIdentifier0);
      assertEquals(1048576, Text.DEFAULT_MAX_LEN);
      
      delegationTokenIdentifier0.setOwner(text0);
      assertEquals(21, text0.getLength());
      assertEquals(0L, delegationTokenIdentifier0.getIssueDate());
      assertEquals(0, delegationTokenIdentifier0.getSequenceNumber());
      assertEquals(0L, delegationTokenIdentifier0.getMaxDate());
      assertEquals(0, delegationTokenIdentifier0.getMasterKeyId());
      assertEquals(1048576, Text.DEFAULT_MAX_LEN);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.ack(delegationTokenIdentifier0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // org.apache.hadoop.security.token.delegation.web.DelegationTokenIdentifier cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test25()  throws Throwable  {
      KafkaSpoutConfig.FirstPollOffsetStrategy[] kafkaSpoutConfig_FirstPollOffsetStrategyArray0 = KafkaSpoutConfig.FirstPollOffsetStrategy.values();
      assertNotNull(kafkaSpoutConfig_FirstPollOffsetStrategyArray0);
      assertEquals(4, kafkaSpoutConfig_FirstPollOffsetStrategyArray0.length);
      
      KafkaSpoutConfig<Object, KafkaSpout<String, String>> kafkaSpoutConfig0 = (KafkaSpoutConfig<Object, KafkaSpout<String, String>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaConsumerFactoryDefault<Object, KafkaSpout<String, String>> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<Object, KafkaSpout<String, String>>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<Object, KafkaSpout<String, String>> kafkaSpout0 = new KafkaSpout<Object, KafkaSpout<String, String>>(kafkaSpoutConfig0, kafkaConsumerFactoryDefault0);
      assertNotNull(kafkaSpout0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.close();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test26()  throws Throwable  {
      KafkaSpoutConfig<KafkaSpoutMessageId, Nimbus.beginCreateBlob_result._Fields> kafkaSpoutConfig0 = null;
      KafkaConsumerFactoryDefault<KafkaSpoutMessageId, Nimbus.beginCreateBlob_result._Fields> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<KafkaSpoutMessageId, Nimbus.beginCreateBlob_result._Fields>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<KafkaSpoutMessageId, Nimbus.beginCreateBlob_result._Fields> kafkaSpout0 = null;
      try {
        kafkaSpout0 = new KafkaSpout<KafkaSpoutMessageId, Nimbus.beginCreateBlob_result._Fields>(kafkaSpoutConfig0, kafkaConsumerFactoryDefault0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test27()  throws Throwable  {
      KafkaSpoutConfig<KafkaSpoutStreamsWildcardTopics, Nimbus.beginCreateBlob_result._Fields> kafkaSpoutConfig0 = (KafkaSpoutConfig<KafkaSpoutStreamsWildcardTopics, Nimbus.beginCreateBlob_result._Fields>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutStreamsWildcardTopics, Nimbus.beginCreateBlob_result._Fields> kafkaSpout0 = new KafkaSpout<KafkaSpoutStreamsWildcardTopics, Nimbus.beginCreateBlob_result._Fields>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      kafkaSpout0.nextTuple();
  }

  @Test(timeout = 11000)
  public void test28()  throws Throwable  {
      KafkaSpoutConfig<Object, Principal> kafkaSpoutConfig0 = (KafkaSpoutConfig<Object, Principal>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<Object, Principal> kafkaSpout0 = new KafkaSpout<Object, Principal>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      OutputFieldsGetter outputFieldsGetter0 = new OutputFieldsGetter();
      assertNotNull(outputFieldsGetter0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.declareOutputFields(outputFieldsGetter0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test29()  throws Throwable  {
      KafkaSpoutConfig<HsftpFileSystem, HsftpFileSystem> kafkaSpoutConfig0 = (KafkaSpoutConfig<HsftpFileSystem, HsftpFileSystem>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<HsftpFileSystem, HsftpFileSystem> kafkaSpout0 = new KafkaSpout<HsftpFileSystem, HsftpFileSystem>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      OutputFieldsGetter outputFieldsGetter0 = new OutputFieldsGetter();
      assertNotNull(outputFieldsGetter0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.declareOutputFields(outputFieldsGetter0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test30()  throws Throwable  {
      KafkaSpoutConfig<HsftpFileSystem, ConsumerRecord<KafkaSpoutStreamsWildcardTopics, Integer>> kafkaSpoutConfig0 = (KafkaSpoutConfig<HsftpFileSystem, ConsumerRecord<KafkaSpoutStreamsWildcardTopics, Integer>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaConsumerFactoryDefault<HsftpFileSystem, ConsumerRecord<KafkaSpoutStreamsWildcardTopics, Integer>> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<HsftpFileSystem, ConsumerRecord<KafkaSpoutStreamsWildcardTopics, Integer>>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<HsftpFileSystem, ConsumerRecord<KafkaSpoutStreamsWildcardTopics, Integer>> kafkaSpout0 = new KafkaSpout<HsftpFileSystem, ConsumerRecord<KafkaSpoutStreamsWildcardTopics, Integer>>(kafkaSpoutConfig0, kafkaConsumerFactoryDefault0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "*y H;c t2jQS";
      long long0 = (-920L);
      TimestampType timestampType0 = TimestampType.NO_TIMESTAMP_TYPE;
      long long1 = 0L;
      Optional<Integer> optional0 = Optional.ofNullable((Integer) kafkaSpoutConfig0.DEFAULT_MAX_RETRIES);
      assertNotNull(optional0);
      
      String string1 = "aZA";
      OffsetAndMetadata offsetAndMetadata0 = new OffsetAndMetadata(long1, optional0, string1);
      assertFalse(long1 == long0);
      assertFalse(string1.equals((Object)string0));
      assertEquals("aZA", offsetAndMetadata0.metadata());
      assertEquals(0L, offsetAndMetadata0.offset());
      assertNotNull(offsetAndMetadata0);
      
      TopicPartition topicPartition0 = new TopicPartition(string0, kafkaSpoutConfig0.DEFAULT_MAX_RETRIES);
      assertFalse(string0.equals((Object)string1));
      assertEquals("*y H;c t2jQS", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertNotNull(topicPartition0);
      
      long long2 = 1899L;
      KafkaSpoutMessageId kafkaSpoutMessageId0 = new KafkaSpoutMessageId(topicPartition0, long2);
      assertFalse(string0.equals((Object)string1));
      assertFalse(long2 == long0);
      assertFalse(long2 == long1);
      assertEquals("*y H;c t2jQS", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals(1899L, kafkaSpoutMessageId0.offset());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals(Integer.MAX_VALUE, kafkaSpoutMessageId0.partition());
      assertEquals("*y H;c t2jQS", kafkaSpoutMessageId0.topic());
      assertNotNull(kafkaSpoutMessageId0);
      
      ConsumerRecord<OffsetAndMetadata, KafkaSpoutMessageId> consumerRecord0 = new ConsumerRecord<OffsetAndMetadata, KafkaSpoutMessageId>(string0, kafkaSpoutConfig0.DEFAULT_MAX_RETRIES, long0, long0, timestampType0, long0, kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS, kafkaSpoutConfig0.DEFAULT_MAX_RETRIES, offsetAndMetadata0, kafkaSpoutMessageId0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(long0 == long1);
      assertFalse(long0 == long2);
      assertFalse(long1 == long2);
      assertFalse(long1 == long0);
      assertFalse(string1.equals((Object)string0));
      assertFalse(long2 == long0);
      assertFalse(long2 == long1);
      assertEquals("aZA", offsetAndMetadata0.metadata());
      assertEquals(0L, offsetAndMetadata0.offset());
      assertEquals("*y H;c t2jQS", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals(1899L, kafkaSpoutMessageId0.offset());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals(Integer.MAX_VALUE, kafkaSpoutMessageId0.partition());
      assertEquals("*y H;c t2jQS", kafkaSpoutMessageId0.topic());
      assertEquals(TimestampType.NO_TIMESTAMP_TYPE, consumerRecord0.timestampType());
      assertEquals((-920L), consumerRecord0.offset());
      assertEquals("*y H;c t2jQS", consumerRecord0.topic());
      assertEquals(Integer.MAX_VALUE, consumerRecord0.serializedValueSize());
      assertEquals(Integer.MAX_VALUE, consumerRecord0.partition());
      assertEquals((-920L), consumerRecord0.timestamp());
      assertEquals(10000000, consumerRecord0.serializedKeySize());
      assertNotNull(consumerRecord0);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      
      KafkaSpoutMessageId kafkaSpoutMessageId1 = new KafkaSpoutMessageId(consumerRecord0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(long0 == long1);
      assertFalse(long0 == long2);
      assertFalse(long1 == long2);
      assertFalse(long1 == long0);
      assertFalse(string1.equals((Object)string0));
      assertFalse(long2 == long0);
      assertFalse(long2 == long1);
      assertFalse(kafkaSpoutMessageId1.equals((Object)kafkaSpoutMessageId0));
      assertEquals("aZA", offsetAndMetadata0.metadata());
      assertEquals(0L, offsetAndMetadata0.offset());
      assertEquals("*y H;c t2jQS", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals(1899L, kafkaSpoutMessageId0.offset());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals(Integer.MAX_VALUE, kafkaSpoutMessageId0.partition());
      assertEquals("*y H;c t2jQS", kafkaSpoutMessageId0.topic());
      assertEquals(TimestampType.NO_TIMESTAMP_TYPE, consumerRecord0.timestampType());
      assertEquals((-920L), consumerRecord0.offset());
      assertEquals("*y H;c t2jQS", consumerRecord0.topic());
      assertEquals(Integer.MAX_VALUE, consumerRecord0.serializedValueSize());
      assertEquals(Integer.MAX_VALUE, consumerRecord0.partition());
      assertEquals((-920L), consumerRecord0.timestamp());
      assertEquals(10000000, consumerRecord0.serializedKeySize());
      assertEquals(0, kafkaSpoutMessageId1.numFails());
      assertEquals((-920L), kafkaSpoutMessageId1.offset());
      assertEquals("*y H;c t2jQS", kafkaSpoutMessageId1.topic());
      assertEquals(Integer.MAX_VALUE, kafkaSpoutMessageId1.partition());
      assertNotNull(kafkaSpoutMessageId1);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.fail(kafkaSpoutMessageId1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
      }
  }

  @Test(timeout = 11000)
  public void test31()  throws Throwable  {
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<KafkaSpoutStreamsNamedTopics, Object> kafkaSpoutConfig0 = (KafkaSpoutConfig<KafkaSpoutStreamsNamedTopics, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutStreamsNamedTopics, Object> kafkaSpout0 = new KafkaSpout<KafkaSpoutStreamsNamedTopics, Object>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "clojure.walk";
      Object[] objectArray0 = new Object[7];
      objectArray0[1] = (Object) kafkaSpoutStreams0;
      objectArray0[2] = objectArray0[1];
      objectArray0[3] = (Object) string0;
      objectArray0[4] = (Object) kafkaSpoutStreams0;
      objectArray0[5] = (Object) kafkaSpout0;
      objectArray0[6] = (Object) kafkaSpout0;
      PersistentArrayMap persistentArrayMap0 = new PersistentArrayMap(objectArray0);
      assertEquals(3, persistentArrayMap0.capacity());
      assertEquals(3, persistentArrayMap0.count());
      assertNotNull(persistentArrayMap0);
      assertEquals(7, objectArray0.length);
      
      KafkaSpoutStreams kafkaSpoutStreams1 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      Deserializer<ForkJoinTask<TopicPartition>> deserializer0 = (Deserializer<ForkJoinTask<TopicPartition>>) mock(Deserializer.class, new ViolatedAssumptionAnswer());
      Deserializer<ForkJoinTask<KafkaSpoutMessageId>> deserializer1 = (Deserializer<ForkJoinTask<KafkaSpoutMessageId>>) mock(Deserializer.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<ForkJoinTask<TopicPartition>, ForkJoinTask<KafkaSpoutMessageId>> kafkaSpoutConfig1 = (KafkaSpoutConfig<ForkJoinTask<TopicPartition>, ForkJoinTask<KafkaSpoutMessageId>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(string0).when(kafkaSpoutConfig1).getConsumerGroupId();
      doReturn(persistentArrayMap0, persistentArrayMap0).when(kafkaSpoutConfig1).getKafkaProps();
      doReturn(kafkaSpoutStreams1).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      doReturn(deserializer0).when(kafkaSpoutConfig1).getKeyDeserializer();
      doReturn(deserializer1).when(kafkaSpoutConfig1).getValueDeserializer();
      KafkaConsumerFactoryDefault<ForkJoinTask<TopicPartition>, ForkJoinTask<KafkaSpoutMessageId>> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<ForkJoinTask<TopicPartition>, ForkJoinTask<KafkaSpoutMessageId>>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<ForkJoinTask<TopicPartition>, ForkJoinTask<KafkaSpoutMessageId>> kafkaSpout1 = new KafkaSpout<ForkJoinTask<TopicPartition>, ForkJoinTask<KafkaSpoutMessageId>>(kafkaSpoutConfig1, kafkaConsumerFactoryDefault0);
      assertEquals(3, persistentArrayMap0.capacity());
      assertEquals(3, persistentArrayMap0.count());
      assertNotNull(kafkaSpout1);
      assertEquals(7, objectArray0.length);
      
      Map<String, Object> map0 = kafkaSpout1.getComponentConfiguration();
      assertEquals(2, map0.size());
      assertFalse(map0.isEmpty());
      assertEquals(3, persistentArrayMap0.capacity());
      assertEquals(3, persistentArrayMap0.count());
      assertNotNull(map0);
      assertEquals(7, objectArray0.length);
      
      // Undeclared exception!
      try { 
        kafkaSpout1.activate();
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 7
         //
         verifyException("clojure.lang.PersistentArrayMap$Iter", e);
      }
  }

  @Test(timeout = 11000)
  public void test32()  throws Throwable  {
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<OffsetAndMetadata, DelegationTokenIdentifier> kafkaSpoutConfig0 = (KafkaSpoutConfig<OffsetAndMetadata, DelegationTokenIdentifier>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaConsumerFactoryDefault<OffsetAndMetadata, DelegationTokenIdentifier> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<OffsetAndMetadata, DelegationTokenIdentifier>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<OffsetAndMetadata, DelegationTokenIdentifier> kafkaSpout0 = new KafkaSpout<OffsetAndMetadata, DelegationTokenIdentifier>(kafkaSpoutConfig0, kafkaConsumerFactoryDefault0);
      assertNotNull(kafkaSpout0);
      
      KafkaSpoutConfig.FirstPollOffsetStrategy kafkaSpoutConfig_FirstPollOffsetStrategy0 = KafkaSpoutConfig.FirstPollOffsetStrategy.EARLIEST;
      KafkaSpoutStreams kafkaSpoutStreams1 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutRetryService kafkaSpoutRetryService0 = mock(KafkaSpoutRetryService.class, new ViolatedAssumptionAnswer());
      KafkaSpoutTuplesBuilder<ConsumerRecord<Integer, Object>, KafkaSpoutMessageId> kafkaSpoutTuplesBuilder0 = (KafkaSpoutTuplesBuilder<ConsumerRecord<Integer, Object>, KafkaSpoutMessageId>) mock(KafkaSpoutTuplesBuilder.class, new ViolatedAssumptionAnswer());
      boolean boolean0 = true;
      KafkaSpoutConfig<ConsumerRecord<Integer, Object>, KafkaSpoutMessageId> kafkaSpoutConfig1 = (KafkaSpoutConfig<ConsumerRecord<Integer, Object>, KafkaSpoutMessageId>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutConfig_FirstPollOffsetStrategy0).when(kafkaSpoutConfig1).getFirstPollOffsetStrategy();
      doReturn(kafkaSpoutStreams1).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      doReturn(kafkaSpoutConfig0.DEFAULT_MAX_RETRIES).when(kafkaSpoutConfig1).getMaxTupleRetries();
      doReturn(kafkaSpoutRetryService0).when(kafkaSpoutConfig1).getRetryService();
      doReturn(kafkaSpoutTuplesBuilder0).when(kafkaSpoutConfig1).getTuplesBuilder();
      doReturn(boolean0).when(kafkaSpoutConfig1).isConsumerAutoCommitMode();
      KafkaConsumerFactoryDefault<ConsumerRecord<Integer, Object>, KafkaSpoutMessageId> kafkaConsumerFactoryDefault1 = new KafkaConsumerFactoryDefault<ConsumerRecord<Integer, Object>, KafkaSpoutMessageId>();
      assertNotNull(kafkaConsumerFactoryDefault1);
      
      KafkaSpout<ConsumerRecord<Integer, Object>, KafkaSpoutMessageId> kafkaSpout1 = new KafkaSpout<ConsumerRecord<Integer, Object>, KafkaSpoutMessageId>(kafkaSpoutConfig1, kafkaConsumerFactoryDefault1);
      assertNotNull(kafkaSpout1);
      
      PersistentArrayMap persistentArrayMap0 = PersistentArrayMap.EMPTY;
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertNotNull(persistentArrayMap0);
      
      StormTopology stormTopology0 = new StormTopology(persistentArrayMap0, persistentArrayMap0, persistentArrayMap0);
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertTrue(stormTopology0.is_set_bolts());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertTrue(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertTrue(stormTopology0.is_set_spouts());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertNotNull(stormTopology0);
      
      String string0 = "NI|d0l>_M7|";
      String string1 = "";
      String string2 = " [N%!ao<V=z}e";
      JDBCType jDBCType0 = JDBCType.INTEGER;
      Integer integer0 = jDBCType0.getVendorTypeNumber();
      assertNotNull(integer0);
      assertEquals(4, (int)integer0);
      
      PersistentList persistentList0 = new PersistentList(stormTopology0);
      assertEquals(1, persistentList0.count());
      assertFalse(persistentList0.isEmpty());
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertTrue(stormTopology0.is_set_bolts());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertTrue(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertTrue(stormTopology0.is_set_spouts());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertNotNull(persistentList0);
      
      PersistentList persistentList1 = persistentList0.withMeta(persistentArrayMap0);
      assertEquals(1, persistentList0.count());
      assertFalse(persistentList0.isEmpty());
      assertEquals(1, persistentList1.count());
      assertFalse(persistentList1.isEmpty());
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertTrue(stormTopology0.is_set_bolts());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertTrue(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertTrue(stormTopology0.is_set_spouts());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertNotNull(persistentList1);
      assertNotSame(persistentList0, persistentList1);
      assertNotSame(persistentList1, persistentList0);
      
      boolean boolean1 = false;
      AtomicBoolean atomicBoolean0 = new AtomicBoolean(boolean1);
      assertFalse(boolean1 == boolean0);
      assertFalse(atomicBoolean0.get());
      assertEquals("false", atomicBoolean0.toString());
      assertNotNull(atomicBoolean0);
      
      TopologyContext topologyContext0 = new TopologyContext(stormTopology0, persistentArrayMap0, persistentArrayMap0, persistentArrayMap0, persistentArrayMap0, string0, string1, string2, integer0, (Integer) kafkaSpoutConfig1.DEFAULT_MAX_RETRIES, persistentList1, persistentArrayMap0, persistentArrayMap0, persistentArrayMap0, persistentArrayMap0, atomicBoolean0);
      assertFalse(boolean0 == boolean1);
      assertFalse(string0.equals((Object)string2));
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string0));
      assertFalse(string1.equals((Object)string2));
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertFalse(boolean1 == boolean0);
      assertEquals(1, persistentList0.count());
      assertFalse(persistentList0.isEmpty());
      assertEquals(1, persistentList1.count());
      assertFalse(persistentList1.isEmpty());
      assertFalse(atomicBoolean0.get());
      assertEquals("false", atomicBoolean0.toString());
      assertNull(topologyContext0.getThisComponentId());
      assertEquals(Integer.MAX_VALUE, (int)topologyContext0.getThisWorkerPort());
      assertEquals("", topologyContext0.getCodeDir());
      assertEquals("NI|d0l>_M7|", topologyContext0.getStormId());
      assertEquals(4, topologyContext0.getThisTaskId());
      assertEquals("/home/CIN/lmps2/semantic-conflict-study/SMAT/output-test-dest/storm/bd1f5c54752f67b484a83c26667331234234d3a3/evosuite_1/ [N%!ao<V=z}e", topologyContext0.getPIDDir());
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertTrue(stormTopology0.is_set_bolts());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertTrue(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertTrue(stormTopology0.is_set_spouts());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertNotNull(topologyContext0);
      
      KafkaSpoutStreams kafkaSpoutStreams2 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<DelegationTokenIdentifier, DelegationTokenIdentifier> kafkaSpoutConfig2 = (KafkaSpoutConfig<DelegationTokenIdentifier, DelegationTokenIdentifier>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams2).when(kafkaSpoutConfig2).getKafkaSpoutStreams();
      KafkaConsumerFactoryDefault<DelegationTokenIdentifier, DelegationTokenIdentifier> kafkaConsumerFactoryDefault2 = new KafkaConsumerFactoryDefault<DelegationTokenIdentifier, DelegationTokenIdentifier>();
      assertNotNull(kafkaConsumerFactoryDefault2);
      
      KafkaSpout<DelegationTokenIdentifier, DelegationTokenIdentifier> kafkaSpout2 = new KafkaSpout<DelegationTokenIdentifier, DelegationTokenIdentifier>(kafkaSpoutConfig2, kafkaConsumerFactoryDefault2);
      assertNotNull(kafkaSpout2);
      
      SpoutOutputCollector spoutOutputCollector0 = kafkaSpout2.collector;
      assertNull(spoutOutputCollector0);
      
      kafkaSpout1.open(persistentArrayMap0, topologyContext0, spoutOutputCollector0);
      assertFalse(boolean0 == boolean1);
      assertFalse(string0.equals((Object)string2));
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string0));
      assertFalse(string1.equals((Object)string2));
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertFalse(boolean1 == boolean0);
      assertEquals(1, persistentList0.count());
      assertFalse(persistentList0.isEmpty());
      assertEquals(1, persistentList1.count());
      assertFalse(persistentList1.isEmpty());
      assertFalse(atomicBoolean0.get());
      assertEquals("false", atomicBoolean0.toString());
      assertNull(topologyContext0.getThisComponentId());
      assertEquals(Integer.MAX_VALUE, (int)topologyContext0.getThisWorkerPort());
      assertEquals("", topologyContext0.getCodeDir());
      assertEquals("NI|d0l>_M7|", topologyContext0.getStormId());
      assertEquals(4, topologyContext0.getThisTaskId());
      assertEquals("/home/CIN/lmps2/semantic-conflict-study/SMAT/output-test-dest/storm/bd1f5c54752f67b484a83c26667331234234d3a3/evosuite_1/ [N%!ao<V=z}e", topologyContext0.getPIDDir());
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertTrue(stormTopology0.is_set_bolts());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertTrue(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertTrue(stormTopology0.is_set_spouts());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertNotSame(string0, string2);
      assertNotSame(string0, string1);
      assertNotSame(string1, string0);
      assertNotSame(string1, string2);
      assertNotSame(string2, string1);
      assertNotSame(string2, string0);
      assertNotSame(persistentList0, persistentList1);
      assertNotSame(persistentList1, persistentList0);
      
      // Undeclared exception!
      try { 
        kafkaSpout1.deactivate();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test33()  throws Throwable  {
      KafkaSpoutConfig<Integer, String> kafkaSpoutConfig0 = (KafkaSpoutConfig<Integer, String>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutConfig.FirstPollOffsetStrategy) null).when(kafkaSpoutConfig0).getFirstPollOffsetStrategy();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      doReturn(0).when(kafkaSpoutConfig0).getMaxTupleRetries();
      doReturn(0L).when(kafkaSpoutConfig0).getOffsetsCommitPeriodMs();
      doReturn((KafkaSpoutRetryService) null).when(kafkaSpoutConfig0).getRetryService();
      doReturn((KafkaSpoutTuplesBuilder) null).when(kafkaSpoutConfig0).getTuplesBuilder();
      doReturn(false).when(kafkaSpoutConfig0).isConsumerAutoCommitMode();
      KafkaConsumerFactoryDefault<Integer, String> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<Integer, String>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<Integer, String> kafkaSpout0 = new KafkaSpout<Integer, String>(kafkaSpoutConfig0, kafkaConsumerFactoryDefault0);
      assertNotNull(kafkaSpout0);
      
      Object[] objectArray0 = new Object[0];
      PersistentArrayMap persistentArrayMap0 = PersistentArrayMap.createWithCheck(objectArray0);
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertNotNull(persistentArrayMap0);
      assertEquals(0, objectArray0.length);
      
      PersistentHashMap persistentHashMap0 = PersistentHashMap.create((IPersistentMap) persistentArrayMap0, objectArray0);
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentHashMap0.count());
      assertNotNull(persistentHashMap0);
      assertEquals(0, objectArray0.length);
      
      StormTopology stormTopology0 = new StormTopology();
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertFalse(stormTopology0.is_set_spouts());
      assertFalse(stormTopology0.is_set_bolts());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertNotNull(stormTopology0);
      
      String string0 = "";
      String string1 = "7.HB+";
      String string2 = "clojure.core$find_field";
      PersistentVector persistentVector0 = PersistentVector.create((Iterable) persistentHashMap0);
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentHashMap0.count());
      assertEquals(0, persistentVector0.count());
      assertNotNull(persistentVector0);
      assertEquals(5, persistentVector0.shift);
      assertEquals(0, objectArray0.length);
      
      Fields fields0 = new Fields(persistentVector0);
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentHashMap0.count());
      assertEquals(0, persistentVector0.count());
      assertEquals(0, fields0.size());
      assertNotNull(fields0);
      assertEquals(5, persistentVector0.shift);
      assertEquals(0, objectArray0.length);
      
      int int0 = 368;
      Pattern pattern0 = Pattern.compile(string2, int0);
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertEquals("clojure.core$find_field", pattern0.pattern());
      assertEquals("clojure.core$find_field", pattern0.toString());
      assertEquals(368, pattern0.flags());
      assertNotNull(pattern0);
      assertNotSame(string2, string1);
      assertNotSame(string2, string0);
      
      KafkaSpoutStream kafkaSpoutStream0 = new KafkaSpoutStream(fields0, string1, pattern0);
      assertFalse(string1.equals((Object)string2));
      assertFalse(string1.equals((Object)string0));
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentHashMap0.count());
      assertEquals(0, persistentVector0.count());
      assertEquals(0, fields0.size());
      assertEquals("clojure.core$find_field", pattern0.pattern());
      assertEquals("clojure.core$find_field", pattern0.toString());
      assertEquals(368, pattern0.flags());
      assertNull(kafkaSpoutStream0.getTopic());
      assertNotNull(kafkaSpoutStream0);
      assertEquals(5, persistentVector0.shift);
      assertEquals(0, objectArray0.length);
      
      KafkaSpoutStreamsWildcardTopics kafkaSpoutStreamsWildcardTopics0 = new KafkaSpoutStreamsWildcardTopics(kafkaSpoutStream0);
      assertFalse(string1.equals((Object)string2));
      assertFalse(string1.equals((Object)string0));
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentHashMap0.count());
      assertEquals(0, persistentVector0.count());
      assertEquals(0, fields0.size());
      assertEquals("clojure.core$find_field", pattern0.pattern());
      assertEquals("clojure.core$find_field", pattern0.toString());
      assertEquals(368, pattern0.flags());
      assertNull(kafkaSpoutStream0.getTopic());
      assertNotNull(kafkaSpoutStreamsWildcardTopics0);
      assertEquals(5, persistentVector0.shift);
      assertEquals(0, objectArray0.length);
      
      PersistentVector persistentVector1 = persistentVector0.cons(kafkaSpoutStreamsWildcardTopics0);
      assertFalse(persistentVector1.equals((Object)persistentVector0));
      assertFalse(string1.equals((Object)string2));
      assertFalse(string1.equals((Object)string0));
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertEquals(1, persistentVector1.count());
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentHashMap0.count());
      assertEquals(0, persistentVector0.count());
      assertEquals(0, fields0.size());
      assertEquals("clojure.core$find_field", pattern0.pattern());
      assertEquals("clojure.core$find_field", pattern0.toString());
      assertEquals(368, pattern0.flags());
      assertNull(kafkaSpoutStream0.getTopic());
      assertNotNull(persistentVector1);
      assertEquals(5, persistentVector1.shift);
      assertEquals(5, persistentVector0.shift);
      assertNotSame(persistentVector1, persistentVector0);
      assertNotSame(string1, string2);
      assertNotSame(string1, string0);
      assertNotSame(string2, string1);
      assertNotSame(string2, string0);
      assertNotSame(persistentVector0, persistentVector1);
      assertEquals(0, objectArray0.length);
      
      PersistentArrayMap persistentArrayMap1 = persistentArrayMap0.withMeta(persistentHashMap0);
      assertTrue(persistentArrayMap1.equals((Object)persistentArrayMap0));
      assertEquals(0, persistentArrayMap1.count());
      assertEquals(0, persistentArrayMap1.capacity());
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentHashMap0.count());
      assertNotNull(persistentArrayMap1);
      assertNotSame(persistentArrayMap1, persistentArrayMap0);
      assertNotSame(persistentArrayMap0, persistentArrayMap1);
      assertEquals(0, objectArray0.length);
      
      boolean boolean0 = true;
      AtomicBoolean atomicBoolean0 = new AtomicBoolean(boolean0);
      assertTrue(atomicBoolean0.get());
      assertEquals("true", atomicBoolean0.toString());
      assertNotNull(atomicBoolean0);
      
      TopologyContext topologyContext0 = new TopologyContext(stormTopology0, stormTopology0.metaDataMap, persistentHashMap0, persistentArrayMap0, persistentHashMap0, string0, string1, string2, (Integer) kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS, (Integer) kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS, persistentVector1, persistentHashMap0, persistentHashMap0, persistentArrayMap1, persistentHashMap0, atomicBoolean0);
      assertTrue(persistentArrayMap0.equals((Object)persistentArrayMap1));
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertFalse(string1.equals((Object)string2));
      assertFalse(string1.equals((Object)string0));
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertFalse(persistentVector0.equals((Object)persistentVector1));
      assertFalse(persistentVector1.equals((Object)persistentVector0));
      assertTrue(persistentArrayMap1.equals((Object)persistentArrayMap0));
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentHashMap0.count());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertFalse(stormTopology0.is_set_spouts());
      assertFalse(stormTopology0.is_set_bolts());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertEquals(0, persistentVector0.count());
      assertEquals(0, fields0.size());
      assertEquals("clojure.core$find_field", pattern0.pattern());
      assertEquals("clojure.core$find_field", pattern0.toString());
      assertEquals(368, pattern0.flags());
      assertNull(kafkaSpoutStream0.getTopic());
      assertEquals(1, persistentVector1.count());
      assertEquals(0, persistentArrayMap1.count());
      assertEquals(0, persistentArrayMap1.capacity());
      assertTrue(atomicBoolean0.get());
      assertEquals("true", atomicBoolean0.toString());
      assertEquals(10000000, (int)topologyContext0.getThisWorkerPort());
      assertEquals("", topologyContext0.getStormId());
      assertNull(topologyContext0.getThisComponentId());
      assertEquals("7.HB+", topologyContext0.getCodeDir());
      assertEquals("/home/CIN/lmps2/semantic-conflict-study/SMAT/output-test-dest/storm/bd1f5c54752f67b484a83c26667331234234d3a3/evosuite_1/clojure.core$find_field", topologyContext0.getPIDDir());
      assertEquals(10000000, topologyContext0.getThisTaskId());
      assertNotNull(topologyContext0);
      assertEquals(5, persistentVector0.shift);
      assertEquals(5, persistentVector1.shift);
      assertEquals(0, objectArray0.length);
      
      KafkaSpoutConfig<Object, TopicPartition> kafkaSpoutConfig1 = (KafkaSpoutConfig<Object, TopicPartition>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaConsumerFactoryDefault<Object, TopicPartition> kafkaConsumerFactoryDefault1 = new KafkaConsumerFactoryDefault<Object, TopicPartition>();
      assertNotNull(kafkaConsumerFactoryDefault1);
      
      KafkaSpout<Object, TopicPartition> kafkaSpout1 = new KafkaSpout<Object, TopicPartition>(kafkaSpoutConfig1, kafkaConsumerFactoryDefault1);
      assertNotNull(kafkaSpout1);
      
      SpoutOutputCollector spoutOutputCollector0 = kafkaSpout1.collector;
      assertNull(spoutOutputCollector0);
      
      SpoutOutputCollector spoutOutputCollector1 = new SpoutOutputCollector(spoutOutputCollector0);
      assertNotNull(spoutOutputCollector1);
      
      kafkaSpout0.open(persistentHashMap0, topologyContext0, spoutOutputCollector1);
      assertTrue(persistentArrayMap0.equals((Object)persistentArrayMap1));
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertFalse(string1.equals((Object)string2));
      assertFalse(string1.equals((Object)string0));
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertFalse(persistentVector0.equals((Object)persistentVector1));
      assertFalse(persistentVector1.equals((Object)persistentVector0));
      assertTrue(persistentArrayMap1.equals((Object)persistentArrayMap0));
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentHashMap0.count());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertFalse(stormTopology0.is_set_spouts());
      assertFalse(stormTopology0.is_set_bolts());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertEquals(0, persistentVector0.count());
      assertEquals(0, fields0.size());
      assertEquals("clojure.core$find_field", pattern0.pattern());
      assertEquals("clojure.core$find_field", pattern0.toString());
      assertEquals(368, pattern0.flags());
      assertNull(kafkaSpoutStream0.getTopic());
      assertEquals(1, persistentVector1.count());
      assertEquals(0, persistentArrayMap1.count());
      assertEquals(0, persistentArrayMap1.capacity());
      assertTrue(atomicBoolean0.get());
      assertEquals("true", atomicBoolean0.toString());
      assertEquals(10000000, (int)topologyContext0.getThisWorkerPort());
      assertEquals("", topologyContext0.getStormId());
      assertNull(topologyContext0.getThisComponentId());
      assertEquals("7.HB+", topologyContext0.getCodeDir());
      assertEquals("/home/CIN/lmps2/semantic-conflict-study/SMAT/output-test-dest/storm/bd1f5c54752f67b484a83c26667331234234d3a3/evosuite_1/clojure.core$find_field", topologyContext0.getPIDDir());
      assertEquals(10000000, topologyContext0.getThisTaskId());
      assertEquals(5, persistentVector0.shift);
      assertEquals(5, persistentVector1.shift);
      assertNotSame(persistentArrayMap0, persistentArrayMap1);
      assertNotSame(string0, string1);
      assertNotSame(string0, string2);
      assertNotSame(string1, string2);
      assertNotSame(string1, string0);
      assertNotSame(string2, string1);
      assertNotSame(string2, string0);
      assertNotSame(persistentVector0, persistentVector1);
      assertNotSame(persistentVector1, persistentVector0);
      assertNotSame(persistentArrayMap1, persistentArrayMap0);
      assertEquals(0, objectArray0.length);
  }

  @Test(timeout = 11000)
  public void test34()  throws Throwable  {
      KafkaSpoutConfig<ForkJoinTask<KafkaSpoutStreamsNamedTopics>, KafkaSpoutMessageId> kafkaSpoutConfig0 = (KafkaSpoutConfig<ForkJoinTask<KafkaSpoutStreamsNamedTopics>, KafkaSpoutMessageId>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((Map) null).when(kafkaSpoutConfig0).getKafkaProps();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      doReturn((Deserializer) null).when(kafkaSpoutConfig0).getKeyDeserializer();
      doReturn((Deserializer) null).when(kafkaSpoutConfig0).getValueDeserializer();
      KafkaSpout<ForkJoinTask<KafkaSpoutStreamsNamedTopics>, KafkaSpoutMessageId> kafkaSpout0 = new KafkaSpout<ForkJoinTask<KafkaSpoutStreamsNamedTopics>, KafkaSpoutMessageId>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = kafkaSpout0.toString();
      assertNotNull(string0);
      assertEquals("KafkaSpout{acked=null, emitted=null}", string0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.activate();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.util.HashMap", e);
      }
  }

  @Test(timeout = 11000)
  public void test35()  throws Throwable  {
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<OffsetAndMetadata, OffsetAndMetadata> kafkaSpoutConfig0 = (KafkaSpoutConfig<OffsetAndMetadata, OffsetAndMetadata>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<OffsetAndMetadata, OffsetAndMetadata> kafkaSpout0 = new KafkaSpout<OffsetAndMetadata, OffsetAndMetadata>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      KafkaSpoutConfig<Keyword, TopicPartition> kafkaSpoutConfig1 = null;
      KafkaConsumerFactoryDefault<Keyword, TopicPartition> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<Keyword, TopicPartition>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpoutConfig<Integer, DelegationTokenRenewer.RenewAction<HsftpFileSystem>> kafkaSpoutConfig2 = (KafkaSpoutConfig<Integer, DelegationTokenRenewer.RenewAction<HsftpFileSystem>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((Map) null).when(kafkaSpoutConfig2).getKafkaProps();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig2).getKafkaSpoutStreams();
      doReturn((Deserializer) null).when(kafkaSpoutConfig2).getKeyDeserializer();
      doReturn((Deserializer) null).when(kafkaSpoutConfig2).getValueDeserializer();
      KafkaSpout<Integer, DelegationTokenRenewer.RenewAction<HsftpFileSystem>> kafkaSpout1 = new KafkaSpout<Integer, DelegationTokenRenewer.RenewAction<HsftpFileSystem>>(kafkaSpoutConfig2);
      assertNotNull(kafkaSpout1);
      
      OutputFieldsGetter outputFieldsGetter0 = new OutputFieldsGetter();
      assertNotNull(outputFieldsGetter0);
      
      kafkaSpout0.declareOutputFields(outputFieldsGetter0);
      // Undeclared exception!
      try { 
        kafkaSpout1.activate();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.util.HashMap", e);
      }
  }

  @Test(timeout = 11000)
  public void test36()  throws Throwable  {
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<KafkaSpoutStreamsNamedTopics, Object> kafkaSpoutConfig0 = (KafkaSpoutConfig<KafkaSpoutStreamsNamedTopics, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutStreamsNamedTopics, Object> kafkaSpout0 = new KafkaSpout<KafkaSpoutStreamsNamedTopics, Object>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "rg";
      PersistentArrayMap persistentArrayMap0 = PersistentArrayMap.EMPTY;
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentArrayMap0.capacity());
      assertNotNull(persistentArrayMap0);
      
      KafkaSpoutStreams kafkaSpoutStreams1 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      Deserializer<ForkJoinTask<TopicPartition>> deserializer0 = (Deserializer<ForkJoinTask<TopicPartition>>) mock(Deserializer.class, new ViolatedAssumptionAnswer());
      Deserializer<ForkJoinTask<KafkaSpoutMessageId>> deserializer1 = (Deserializer<ForkJoinTask<KafkaSpoutMessageId>>) mock(Deserializer.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<ForkJoinTask<TopicPartition>, ForkJoinTask<KafkaSpoutMessageId>> kafkaSpoutConfig1 = (KafkaSpoutConfig<ForkJoinTask<TopicPartition>, ForkJoinTask<KafkaSpoutMessageId>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(string0).when(kafkaSpoutConfig1).getConsumerGroupId();
      doReturn(persistentArrayMap0, persistentArrayMap0).when(kafkaSpoutConfig1).getKafkaProps();
      doReturn(kafkaSpoutStreams1).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      doReturn(deserializer0).when(kafkaSpoutConfig1).getKeyDeserializer();
      doReturn(deserializer1).when(kafkaSpoutConfig1).getValueDeserializer();
      KafkaConsumerFactoryDefault<ForkJoinTask<TopicPartition>, ForkJoinTask<KafkaSpoutMessageId>> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<ForkJoinTask<TopicPartition>, ForkJoinTask<KafkaSpoutMessageId>>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<ForkJoinTask<TopicPartition>, ForkJoinTask<KafkaSpoutMessageId>> kafkaSpout1 = new KafkaSpout<ForkJoinTask<TopicPartition>, ForkJoinTask<KafkaSpoutMessageId>>(kafkaSpoutConfig1, kafkaConsumerFactoryDefault0);
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentArrayMap0.capacity());
      assertNotNull(kafkaSpout1);
      
      Map<String, Object> map0 = kafkaSpout1.getComponentConfiguration();
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(2, map0.size());
      assertFalse(map0.isEmpty());
      assertNotNull(map0);
      
      // Undeclared exception!
      try { 
        kafkaSpout1.activate();
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Failed to construct kafka consumer
         //
         verifyException("org.apache.kafka.clients.consumer.KafkaConsumer", e);
      }
  }

  @Test(timeout = 11000)
  public void test37()  throws Throwable  {
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<ForkJoinTask<Nimbus.beginCreateBlob_result._Fields>, Principal> kafkaSpoutConfig0 = (KafkaSpoutConfig<ForkJoinTask<Nimbus.beginCreateBlob_result._Fields>, Principal>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<ForkJoinTask<Nimbus.beginCreateBlob_result._Fields>, Principal> kafkaSpout0 = new KafkaSpout<ForkJoinTask<Nimbus.beginCreateBlob_result._Fields>, Principal>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      OutputFieldsGetter outputFieldsGetter0 = new OutputFieldsGetter();
      assertNotNull(outputFieldsGetter0);
      
      String string0 = "Partitions reassignment. [consumer-group={}, consumer={}, topic-partitions={}]";
      PersistentTreeMap persistentTreeMap0 = null;
      try {  
      persistentTreeMap0 = PersistentTreeMap.EMPTY;
      } catch(NoClassDefFoundError e) {}
  }

  @Test(timeout = 11000)
  public void test38()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = null;
      boolean boolean0 = true;
      boolean boolean1 = true;
      boolean boolean2 = FileSystemHandling.setPermissions(evoSuiteFile0, boolean0, boolean1, boolean0);
      assertFalse(boolean2 == boolean1);
      assertFalse(boolean2 == boolean0);
      assertFalse(boolean2);
      
      String string0 = "T1wd";
      GenerationClauseNode generationClauseNode0 = new GenerationClauseNode();
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertNull(generationClauseNode0.getColumnName());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertFalse(generationClauseNode0.isParameterNode());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertNull(generationClauseNode0.getTableName());
      assertNull(generationClauseNode0.getSchemaName());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      assertFalse(generationClauseNode0.isCloneable());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertNull(generationClauseNode0.getExpressionText());
      assertNotNull(generationClauseNode0);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      
      ProviderList providerList0 = generationClauseNode0.getAuxiliaryProviderList();
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertNull(generationClauseNode0.getColumnName());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertFalse(generationClauseNode0.isParameterNode());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertNull(generationClauseNode0.getTableName());
      assertNull(generationClauseNode0.getSchemaName());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      assertFalse(generationClauseNode0.isCloneable());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertNull(generationClauseNode0.getExpressionText());
      assertNull(providerList0);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      
      String[] stringArray0 = new String[1];
      stringArray0[0] = string0;
      Fields fields0 = new Fields(stringArray0);
      assertEquals(1, fields0.size());
      assertNotNull(fields0);
      assertEquals(1, stringArray0.length);
      
      int int0 = 1;
      Pattern pattern0 = Pattern.compile(string0, int0);
      assertEquals("T1wd", pattern0.toString());
      assertEquals(1, pattern0.flags());
      assertEquals("T1wd", pattern0.pattern());
      assertNotNull(pattern0);
      
      KafkaSpoutStream kafkaSpoutStream0 = new KafkaSpoutStream(fields0, pattern0);
      assertEquals(1, fields0.size());
      assertEquals("T1wd", pattern0.toString());
      assertEquals(1, pattern0.flags());
      assertEquals("T1wd", pattern0.pattern());
      assertNull(kafkaSpoutStream0.getTopic());
      assertNotNull(kafkaSpoutStream0);
      assertEquals(1, stringArray0.length);
      
      KafkaSpoutStreamsWildcardTopics kafkaSpoutStreamsWildcardTopics0 = new KafkaSpoutStreamsWildcardTopics(kafkaSpoutStream0);
      assertEquals(1, fields0.size());
      assertEquals("T1wd", pattern0.toString());
      assertEquals(1, pattern0.flags());
      assertEquals("T1wd", pattern0.pattern());
      assertNull(kafkaSpoutStream0.getTopic());
      assertNotNull(kafkaSpoutStreamsWildcardTopics0);
      assertEquals(1, stringArray0.length);
      
      KafkaSpoutConfig<Integer, Keyword> kafkaSpoutConfig0 = (KafkaSpoutConfig<Integer, Keyword>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreamsWildcardTopics0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      doReturn((Pattern) null).when(kafkaSpoutConfig0).getTopicWildcardPattern();
      KafkaConsumerFactoryDefault<Integer, Keyword> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<Integer, Keyword>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      String string1 = ", committedOffset=";
      boolean boolean3 = FileSystemHandling.createFolder(evoSuiteFile0);
      assertFalse(boolean3 == boolean1);
      assertTrue(boolean3 == boolean2);
      assertFalse(boolean3 == boolean0);
      assertFalse(boolean3);
      
      KafkaSpout<Integer, Keyword> kafkaSpout0 = new KafkaSpout<Integer, Keyword>(kafkaSpoutConfig0, kafkaConsumerFactoryDefault0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertNull(generationClauseNode0.getColumnName());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertFalse(generationClauseNode0.isParameterNode());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertNull(generationClauseNode0.getTableName());
      assertNull(generationClauseNode0.getSchemaName());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      assertFalse(generationClauseNode0.isCloneable());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertNull(generationClauseNode0.getExpressionText());
      assertEquals(1, fields0.size());
      assertEquals("T1wd", pattern0.toString());
      assertEquals(1, pattern0.flags());
      assertEquals("T1wd", pattern0.pattern());
      assertNull(kafkaSpoutStream0.getTopic());
      assertNotNull(kafkaSpout0);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(1, stringArray0.length);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.getComponentConfiguration();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test39()  throws Throwable  {
      String string0 = "";
      GeneralTopologyContext generalTopologyContext0 = null;
      DataDictionaryImpl dataDictionaryImpl0 = new DataDictionaryImpl();
      assertFalse(dataDictionaryImpl0.usesSqlAuthorization());
      assertFalse(dataDictionaryImpl0.isReadOnlyUpgrade());
      assertEquals(0, dataDictionaryImpl0.getCollationTypeOfSystemSchemas());
      assertEquals(0, dataDictionaryImpl0.getCollationTypeOfUserSchemas());
      assertNull(dataDictionaryImpl0.getAuthorizationDatabaseOwner());
      assertEquals(0, dataDictionaryImpl0.getCacheMode());
      assertTrue(dataDictionaryImpl0.doCreateIndexStatsRefresher());
      assertEquals(0, dataDictionaryImpl0.getEngineType());
      assertNotNull(dataDictionaryImpl0);
      
      KafkaSpoutConfig<Object, KafkaSpoutMessageId> kafkaSpoutConfig0 = (KafkaSpoutConfig<Object, KafkaSpoutMessageId>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((String) null).when(kafkaSpoutConfig0).getConsumerGroupId();
      doReturn((Map) null).when(kafkaSpoutConfig0).getKafkaProps();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<Object, KafkaSpoutMessageId> kafkaSpout0 = new KafkaSpout<Object, KafkaSpoutMessageId>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      kafkaSpout0.nextTuple();
      // Undeclared exception!
      try { 
        kafkaSpout0.getComponentConfiguration();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test40()  throws Throwable  {
      Map<String, SpoutSpec> map0 = null;
      KafkaSpoutConfig<Object, KafkaSpoutStreamsWildcardTopics> kafkaSpoutConfig0 = (KafkaSpoutConfig<Object, KafkaSpoutStreamsWildcardTopics>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaConsumerFactoryDefault<Object, KafkaSpoutStreamsWildcardTopics> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<Object, KafkaSpoutStreamsWildcardTopics>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<Object, KafkaSpoutStreamsWildcardTopics> kafkaSpout0 = new KafkaSpout<Object, KafkaSpoutStreamsWildcardTopics>(kafkaSpoutConfig0, kafkaConsumerFactoryDefault0);
      assertNotNull(kafkaSpout0);
  }

  @Test(timeout = 11000)
  public void test41()  throws Throwable  {
      String string0 = "";
      KafkaSpoutConfig<Object, KafkaSpoutMessageId> kafkaSpoutConfig0 = (KafkaSpoutConfig<Object, KafkaSpoutMessageId>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((String) null).when(kafkaSpoutConfig0).getConsumerGroupId();
      doReturn((Map) null).when(kafkaSpoutConfig0).getKafkaProps();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<Object, KafkaSpoutMessageId> kafkaSpout0 = new KafkaSpout<Object, KafkaSpoutMessageId>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      kafkaSpout0.nextTuple();
      // Undeclared exception!
      try { 
        kafkaSpout0.getComponentConfiguration();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test42()  throws Throwable  {
      String string0 = "";
      PersistentStructMap.Def persistentStructMap_Def0 = mock(PersistentStructMap.Def.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<Object, KafkaSpoutMessageId> kafkaSpoutConfig0 = (KafkaSpoutConfig<Object, KafkaSpoutMessageId>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((String) null).when(kafkaSpoutConfig0).getConsumerGroupId();
      doReturn((Map) null).when(kafkaSpoutConfig0).getKafkaProps();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<Object, KafkaSpoutMessageId> kafkaSpout0 = new KafkaSpout<Object, KafkaSpoutMessageId>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      kafkaSpout0.nextTuple();
      // Undeclared exception!
      try { 
        kafkaSpout0.getComponentConfiguration();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test43()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      long long0 = 2000L;
      System.setCurrentTimeMillis(long0);
      KafkaSpoutConfig<OffsetAndMetadata, Object> kafkaSpoutConfig0 = (KafkaSpoutConfig<OffsetAndMetadata, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaConsumerFactoryDefault<OffsetAndMetadata, Object> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<OffsetAndMetadata, Object>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<OffsetAndMetadata, Object> kafkaSpout0 = new KafkaSpout<OffsetAndMetadata, Object>(kafkaSpoutConfig0, kafkaConsumerFactoryDefault0);
      assertNotNull(kafkaSpout0);
      
      kafkaSpout0.nextTuple();
      KafkaSpoutConfig<Principal, Object> kafkaSpoutConfig1 = (KafkaSpoutConfig<Principal, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<Principal, Object> kafkaSpout1 = new KafkaSpout<Principal, Object>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      Object[] objectArray0 = new Object[7];
      Object object0 = new Object();
      assertNotNull(object0);
      
      objectArray0[0] = object0;
      objectArray0[1] = (Object) kafkaSpout1;
      objectArray0[2] = (Object) kafkaSpout0;
      objectArray0[3] = (Object) fileSystemHandling0;
      objectArray0[4] = (Object) kafkaSpoutConfig0;
      Object object1 = new Object();
      assertFalse(object1.equals((Object)object0));
      assertNotNull(object1);
      
      objectArray0[5] = object1;
      objectArray0[6] = (Object) kafkaSpoutConfig0;
      PersistentArrayMap persistentArrayMap0 = new PersistentArrayMap(objectArray0);
      assertEquals(3, persistentArrayMap0.capacity());
      assertEquals(3, persistentArrayMap0.count());
      assertNotNull(persistentArrayMap0);
      assertEquals(7, objectArray0.length);
      
      ConsumerRecords<Principal, Object> consumerRecords0 = new ConsumerRecords<Principal, Object>(persistentArrayMap0);
      assertEquals(3, persistentArrayMap0.capacity());
      assertEquals(3, persistentArrayMap0.count());
      assertFalse(consumerRecords0.isEmpty());
      assertNotNull(consumerRecords0);
      assertEquals(7, objectArray0.length);
      
      // Undeclared exception!
      try { 
        kafkaSpout1.setWaitingToEmit(consumerRecords0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // java.lang.Object cannot be cast to org.apache.kafka.common.TopicPartition
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test44()  throws Throwable  {
      EvoSuiteFile evoSuiteFile0 = null;
      boolean boolean0 = true;
      boolean boolean1 = true;
      boolean boolean2 = FileSystemHandling.setPermissions(evoSuiteFile0, boolean0, boolean1, boolean0);
      assertFalse(boolean2 == boolean1);
      assertFalse(boolean2 == boolean0);
      assertFalse(boolean2);
      
      String string0 = "";
      Object[] objectArray0 = new Object[1];
      objectArray0[0] = (Object) string0;
      PersistentArrayMap persistentArrayMap0 = new PersistentArrayMap(objectArray0);
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertNotNull(persistentArrayMap0);
      assertEquals(1, objectArray0.length);
      
      int int0 = (-862048943);
      KafkaSpoutConfig<Integer, Keyword> kafkaSpoutConfig0 = (KafkaSpoutConfig<Integer, Keyword>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((String) null).when(kafkaSpoutConfig0).getConsumerGroupId();
      doReturn((Map) null).when(kafkaSpoutConfig0).getKafkaProps();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaConsumerFactoryDefault<Integer, Keyword> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<Integer, Keyword>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      String string1 = ", committedOffset=";
      boolean boolean3 = FileSystemHandling.appendStringToFile(evoSuiteFile0, string1);
      assertFalse(string1.equals((Object)string0));
      assertFalse(boolean3 == boolean1);
      assertFalse(boolean3 == boolean0);
      assertTrue(boolean3 == boolean2);
      assertFalse(boolean3);
      assertNotSame(string1, string0);
      
      KafkaSpout<Integer, Keyword> kafkaSpout0 = new KafkaSpout<Integer, Keyword>(kafkaSpoutConfig0, kafkaConsumerFactoryDefault0);
      assertNotNull(kafkaSpout0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.getComponentConfiguration();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test45()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      long long0 = 2000L;
      System.setCurrentTimeMillis(long0);
      KafkaSpoutConfig<OffsetAndMetadata, Object> kafkaSpoutConfig0 = (KafkaSpoutConfig<OffsetAndMetadata, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaConsumerFactoryDefault<OffsetAndMetadata, Object> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<OffsetAndMetadata, Object>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpout<OffsetAndMetadata, Object> kafkaSpout0 = new KafkaSpout<OffsetAndMetadata, Object>(kafkaSpoutConfig0, kafkaConsumerFactoryDefault0);
      assertNotNull(kafkaSpout0);
      
      kafkaSpout0.nextTuple();
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<Principal, Object> kafkaSpoutConfig1 = (KafkaSpoutConfig<Principal, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<Principal, Object> kafkaSpout1 = new KafkaSpout<Principal, Object>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      Object[] objectArray0 = new Object[7];
      Object object0 = new Object();
      assertNotNull(object0);
      
      objectArray0[1] = (Object) kafkaSpout1;
      objectArray0[3] = (Object) fileSystemHandling0;
      objectArray0[4] = (Object) kafkaSpoutConfig0;
      Object object1 = new Object();
      assertFalse(object1.equals((Object)object0));
      assertNotNull(object1);
      
      objectArray0[5] = object1;
      objectArray0[6] = (Object) kafkaSpoutConfig0;
      PersistentArrayMap persistentArrayMap0 = new PersistentArrayMap(objectArray0);
      assertEquals(3, persistentArrayMap0.count());
      assertEquals(3, persistentArrayMap0.capacity());
      assertNotNull(persistentArrayMap0);
      assertEquals(7, objectArray0.length);
      
      ConsumerRecords<Principal, Object> consumerRecords0 = new ConsumerRecords<Principal, Object>(persistentArrayMap0);
      assertEquals(3, persistentArrayMap0.count());
      assertEquals(3, persistentArrayMap0.capacity());
      assertFalse(consumerRecords0.isEmpty());
      assertNotNull(consumerRecords0);
      assertEquals(7, objectArray0.length);
      
      // Undeclared exception!
      try { 
        kafkaSpout1.setWaitingToEmit(consumerRecords0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // org.apache.storm.kafka.spout.KafkaSpout cannot be cast to java.util.List
         //
         verifyException("org.apache.kafka.clients.consumer.ConsumerRecords", e);
      }
  }

  @Test(timeout = 11000)
  public void test46()  throws Throwable  {
      int int0 = 134217746;
      KafkaConsumerFactoryDefault<TopicPartition, Object> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<TopicPartition, Object>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      StormTopology stormTopology0 = new StormTopology();
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertFalse(stormTopology0.is_set_bolts());
      assertFalse(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertFalse(stormTopology0.is_set_spouts());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertNotNull(stormTopology0);
      
      KafkaSpoutConfig<TopicPartition, Nimbus.beginCreateBlob_result._Fields> kafkaSpoutConfig0 = (KafkaSpoutConfig<TopicPartition, Nimbus.beginCreateBlob_result._Fields>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<TopicPartition, Nimbus.beginCreateBlob_result._Fields> kafkaSpout0 = new KafkaSpout<TopicPartition, Nimbus.beginCreateBlob_result._Fields>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.ack(kafkaConsumerFactoryDefault0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // org.apache.storm.kafka.spout.internal.KafkaConsumerFactoryDefault cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test47()  throws Throwable  {
      String[] stringArray0 = new String[2];
      String string0 = "";
      stringArray0[0] = string0;
      String string1 = "{y2a7\\-K";
      EvoSuiteFile evoSuiteFile0 = null;
      boolean boolean0 = FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      assertFalse(boolean0);
      
      stringArray0[1] = string1;
      Fields fields0 = new Fields(stringArray0);
      assertEquals(2, fields0.size());
      assertNotNull(fields0);
      assertEquals(2, stringArray0.length);
      
      String string2 = "xj?~D";
      Pattern pattern0 = Pattern.compile(string0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertEquals(0, pattern0.flags());
      assertEquals("", pattern0.pattern());
      assertEquals("", pattern0.toString());
      assertNotNull(pattern0);
      assertNotSame(string0, string1);
      assertNotSame(string0, string2);
      
      KafkaSpoutStream kafkaSpoutStream0 = new KafkaSpoutStream(fields0, string2, pattern0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertEquals(2, fields0.size());
      assertEquals(0, pattern0.flags());
      assertEquals("", pattern0.pattern());
      assertEquals("", pattern0.toString());
      assertNull(kafkaSpoutStream0.getTopic());
      assertNotNull(kafkaSpoutStream0);
      assertEquals(2, stringArray0.length);
      
      KafkaSpoutStreamsWildcardTopics kafkaSpoutStreamsWildcardTopics0 = new KafkaSpoutStreamsWildcardTopics(kafkaSpoutStream0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertEquals(2, fields0.size());
      assertEquals(0, pattern0.flags());
      assertEquals("", pattern0.pattern());
      assertEquals("", pattern0.toString());
      assertNull(kafkaSpoutStream0.getTopic());
      assertNotNull(kafkaSpoutStreamsWildcardTopics0);
      assertEquals(2, stringArray0.length);
      
      KafkaSpoutConfig<Object, Principal> kafkaSpoutConfig0 = (KafkaSpoutConfig<Object, Principal>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreamsWildcardTopics0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<Object, Principal> kafkaSpout0 = new KafkaSpout<Object, Principal>(kafkaSpoutConfig0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertEquals(2, fields0.size());
      assertEquals(0, pattern0.flags());
      assertEquals("", pattern0.pattern());
      assertEquals("", pattern0.toString());
      assertNull(kafkaSpoutStream0.getTopic());
      assertNotNull(kafkaSpout0);
      assertEquals(2, stringArray0.length);
      
      OutputFieldsGetter outputFieldsGetter0 = new OutputFieldsGetter();
      assertNotNull(outputFieldsGetter0);
      
      outputFieldsGetter0.declareStream(string2, fields0);
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertEquals(2, fields0.size());
      assertNotSame(string2, string1);
      assertNotSame(string2, string0);
      assertEquals(2, stringArray0.length);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.declareOutputFields(outputFieldsGetter0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // Fields for xj?~D already set
         //
         verifyException("org.apache.storm.topology.OutputFieldsGetter", e);
      }
  }

  @Test(timeout = 11000)
  public void test48()  throws Throwable  {
      FileSystemHandling fileSystemHandling0 = new FileSystemHandling();
      assertNotNull(fileSystemHandling0);
      
      long long0 = 2000L;
      System.setCurrentTimeMillis(long0);
      KafkaConsumerFactoryDefault<OffsetAndMetadata, Object> kafkaConsumerFactoryDefault0 = new KafkaConsumerFactoryDefault<OffsetAndMetadata, Object>();
      assertNotNull(kafkaConsumerFactoryDefault0);
      
      KafkaSpoutConfig<Principal, Object> kafkaSpoutConfig0 = (KafkaSpoutConfig<Principal, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<Principal, Object> kafkaSpout0 = new KafkaSpout<Principal, Object>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      Object[] objectArray0 = new Object[7];
      Object object0 = new Object();
      assertNotNull(object0);
      
      objectArray0[5] = objectArray0[4];
      PersistentArrayMap persistentArrayMap0 = new PersistentArrayMap(objectArray0);
      assertEquals(3, persistentArrayMap0.capacity());
      assertEquals(3, persistentArrayMap0.count());
      assertNotNull(persistentArrayMap0);
      assertEquals(7, objectArray0.length);
      
      ConsumerRecords<Principal, Object> consumerRecords0 = new ConsumerRecords<Principal, Object>(persistentArrayMap0);
      assertEquals(3, persistentArrayMap0.capacity());
      assertEquals(3, persistentArrayMap0.count());
      assertFalse(consumerRecords0.isEmpty());
      assertNotNull(consumerRecords0);
      assertEquals(7, objectArray0.length);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.setWaitingToEmit(consumerRecords0);
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 7
         //
         verifyException("clojure.lang.PersistentArrayMap$Iter", e);
      }
  }
}
