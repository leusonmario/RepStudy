/*
 * This file was automatically generated by EvoSuite
 * Sun Oct 31 23:16:16 GMT 2021
 */

package org.apache.storm.kafka.spout;

import org.junit.Test;
import static org.junit.Assert.*;
import static org.evosuite.shaded.org.mockito.Mockito.*;
import static org.evosuite.runtime.EvoAssertions.*;
import clojure.lang.ArraySeq;
import clojure.lang.IPersistentMap;
import clojure.lang.ISeq;
import clojure.lang.LongRange;
import clojure.lang.MapEntry;
import clojure.lang.PersistentArrayMap;
import clojure.lang.PersistentHashMap;
import clojure.lang.PersistentStructMap;
import clojure.lang.PersistentTreeMap;
import clojure.lang.Repeat;
import java.sql.BatchUpdateException;
import java.util.AbstractMap;
import java.util.Comparator;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Optional;
import java.util.Set;
import java.util.TreeMap;
import java.util.concurrent.ForkJoinTask;
import java.util.concurrent.atomic.AtomicBoolean;
import java.util.function.Consumer;
import java.util.function.Supplier;
import java.util.regex.Pattern;
import javax.management.remote.JMXPrincipal;
import org.apache.derby.iapi.sql.depend.ProviderList;
import org.apache.derby.impl.sql.catalog.DataDictionaryImpl;
import org.apache.derby.impl.sql.compile.GenerationClauseNode;
import org.apache.derby.impl.sql.compile.QueryTreeNode;
import org.apache.hadoop.fs.DelegationTokenRenewer;
import org.apache.hadoop.hdfs.web.HftpFileSystem;
import org.apache.hadoop.hive.thrift.DelegationTokenIdentifier;
import org.apache.hadoop.hive.thrift.DelegationTokenSecretManager;
import org.apache.hadoop.io.Text;
import org.apache.kafka.clients.consumer.ConsumerRecord;
import org.apache.kafka.clients.consumer.ConsumerRecords;
import org.apache.kafka.clients.consumer.OffsetAndMetadata;
import org.apache.kafka.common.TopicPartition;
import org.apache.kafka.common.header.Header;
import org.apache.kafka.common.header.Headers;
import org.apache.kafka.common.header.internals.RecordHeader;
import org.apache.kafka.common.header.internals.RecordHeaders;
import org.apache.kafka.common.record.TimestampType;
import org.apache.kafka.common.serialization.Deserializer;
import org.apache.storm.generated.ExecutorSummary;
import org.apache.storm.generated.StormTopology;
import org.apache.storm.kafka.spout.KafkaSpout;
import org.apache.storm.kafka.spout.KafkaSpoutConfig;
import org.apache.storm.kafka.spout.KafkaSpoutMessageId;
import org.apache.storm.kafka.spout.KafkaSpoutRetryService;
import org.apache.storm.kafka.spout.KafkaSpoutStream;
import org.apache.storm.kafka.spout.KafkaSpoutStreams;
import org.apache.storm.kafka.spout.KafkaSpoutStreamsNamedTopics;
import org.apache.storm.kafka.spout.KafkaSpoutStreamsWildcardTopics;
import org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder;
import org.apache.storm.spout.ISpoutOutputCollector;
import org.apache.storm.spout.SpoutOutputCollector;
import org.apache.storm.task.TopologyContext;
import org.apache.storm.topology.OutputFieldsDeclarer;
import org.apache.storm.topology.OutputFieldsGetter;
import org.apache.storm.tuple.Fields;
import org.evosuite.runtime.EvoRunner;
import org.evosuite.runtime.EvoRunnerParameters;
import org.evosuite.runtime.System;
import org.evosuite.runtime.ViolatedAssumptionAnswer;
import org.evosuite.runtime.mock.java.lang.MockThread;
import org.evosuite.runtime.testdata.EvoSuiteFile;
import org.evosuite.runtime.testdata.FileSystemHandling;
import org.junit.runner.RunWith;

@RunWith(EvoRunner.class) @EvoRunnerParameters(mockJVMNonDeterminism = true, useVFS = true, useVNET = true, resetStaticState = true, separateClassLoader = true, useJEE = true) 
public class KafkaSpout_ESTest extends KafkaSpout_ESTest_scaffolding {

  @Test(timeout = 11000)
  public void test00()  throws Throwable  {
      KafkaSpoutConfig.FirstPollOffsetStrategy[] kafkaSpoutConfig_FirstPollOffsetStrategyArray0 = KafkaSpoutConfig.FirstPollOffsetStrategy.values();
      assertEquals(4, kafkaSpoutConfig_FirstPollOffsetStrategyArray0.length);
      assertNotNull(kafkaSpoutConfig_FirstPollOffsetStrategyArray0);
      
      StormTopology stormTopology0 = new StormTopology();
      assertNotNull(stormTopology0);
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertFalse(stormTopology0.is_set_spouts());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_bolts());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_state_spouts());
      
      PersistentArrayMap persistentArrayMap0 = PersistentArrayMap.createAsIfByAssoc(kafkaSpoutConfig_FirstPollOffsetStrategyArray0);
      assertEquals(4, kafkaSpoutConfig_FirstPollOffsetStrategyArray0.length);
      assertNotNull(persistentArrayMap0);
      assertEquals(2, persistentArrayMap0.capacity());
      assertEquals(2, persistentArrayMap0.count());
      
      int int0 = 147;
      Integer integer0 = new Integer(int0);
      assertEquals(147, (int)integer0);
      assertNotNull(integer0);
      assertTrue(integer0.equals((Object)int0));
      
      DataDictionaryImpl dataDictionaryImpl0 = new DataDictionaryImpl();
      assertNotNull(dataDictionaryImpl0);
      assertFalse(dataDictionaryImpl0.usesSqlAuthorization());
      assertEquals(0, dataDictionaryImpl0.getCacheMode());
      assertEquals(0, dataDictionaryImpl0.getEngineType());
      assertFalse(dataDictionaryImpl0.isReadOnlyUpgrade());
      assertTrue(dataDictionaryImpl0.doCreateIndexStatsRefresher());
      assertEquals(0, dataDictionaryImpl0.getCollationTypeOfSystemSchemas());
      assertNull(dataDictionaryImpl0.getAuthorizationDatabaseOwner());
      assertEquals(0, dataDictionaryImpl0.getCollationTypeOfUserSchemas());
      
      KafkaSpoutConfig<TopicPartition, KafkaSpoutMessageId> kafkaSpoutConfig0 = (KafkaSpoutConfig<TopicPartition, KafkaSpoutMessageId>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<TopicPartition, KafkaSpoutMessageId> kafkaSpout0 = new KafkaSpout<TopicPartition, KafkaSpoutMessageId>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      TopicPartition topicPartition0 = null;
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, kafkaSpoutConfig0.DEFAULT_MAX_RETRIES);
      assertNotNull(kafkaSpout_OffsetEntry0);
      
      long long0 = (-114L);
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry1 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry1);
      
      OffsetAndMetadata offsetAndMetadata0 = kafkaSpout_OffsetEntry1.findNextCommitOffset();
      assertNull(offsetAndMetadata0);
      
      kafkaSpout_OffsetEntry0.commit(offsetAndMetadata0);
      boolean boolean0 = kafkaSpout_OffsetEntry0.isEmpty();
      assertTrue(boolean0);
      
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry2 = kafkaSpout0.new OffsetEntry(topicPartition0, kafkaSpoutConfig0.DEFAULT_OFFSET_COMMIT_PERIOD_MS);
      assertNotNull(kafkaSpout_OffsetEntry2);
      
      KafkaSpoutConfig<KafkaSpout.OffsetEntry, KafkaSpout.OffsetEntry> kafkaSpoutConfig1 = (KafkaSpoutConfig<KafkaSpout.OffsetEntry, KafkaSpout.OffsetEntry>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpout.OffsetEntry, KafkaSpout.OffsetEntry> kafkaSpout1 = new KafkaSpout<KafkaSpout.OffsetEntry, KafkaSpout.OffsetEntry>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry3 = kafkaSpout1.new OffsetEntry(topicPartition0, kafkaSpoutConfig0.DEFAULT_MAX_RETRIES);
      assertNotNull(kafkaSpout_OffsetEntry3);
      
      long long1 = (-3293L);
      String string0 = "CQs0dqf\\tuunl#";
      OffsetAndMetadata offsetAndMetadata1 = new OffsetAndMetadata(kafkaSpoutConfig1.DEFAULT_OFFSET_COMMIT_PERIOD_MS, string0);
      assertNotNull(offsetAndMetadata1);
      assertEquals("CQs0dqf\\tuunl#", offsetAndMetadata1.metadata());
      assertEquals(30000L, offsetAndMetadata1.offset());
      
      long long2 = 4L;
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry4 = kafkaSpout0.new OffsetEntry(topicPartition0, long2);
      assertNotNull(kafkaSpout_OffsetEntry4);
      assertFalse(long2 == long0);
      assertFalse(long2 == long1);
      
      long long3 = 3439L;
      KafkaSpoutMessageId kafkaSpoutMessageId0 = new KafkaSpoutMessageId(topicPartition0, long3);
      assertNotNull(kafkaSpoutMessageId0);
      assertFalse(long3 == long2);
      assertFalse(long3 == long0);
      assertFalse(long3 == long1);
      assertEquals(3439L, kafkaSpoutMessageId0.offset());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      
      String string1 = kafkaSpoutMessageId0.toString();
      assertEquals("{topic-partition=null, offset=3439, numFails=0}", string1);
      assertNotNull(string1);
      assertFalse(long3 == long2);
      assertFalse(long3 == long0);
      assertFalse(long3 == long1);
      assertFalse(string1.equals((Object)string0));
      assertNotSame(string1, string0);
      assertEquals(3439L, kafkaSpoutMessageId0.offset());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      
      ThreadGroup threadGroup0 = mock(ThreadGroup.class, new ViolatedAssumptionAnswer());
      MockThread mockThread0 = new MockThread(threadGroup0, string0);
      assertNotNull(mockThread0);
      assertFalse(string0.equals((Object)string1));
      
      String string2 = kafkaSpoutMessageId0.getMetadata(mockThread0);
      assertEquals("{topic-partition=null, offset=3439, numFails=0, thread='CQs0dqf\\tuunl#'}", string2);
      assertNotNull(string2);
      assertFalse(string0.equals((Object)string1));
      assertFalse(long3 == long2);
      assertFalse(long3 == long0);
      assertFalse(long3 == long1);
      assertFalse(string2.equals((Object)string0));
      assertFalse(string2.equals((Object)string1));
      assertNotSame(string0, string1);
      assertNotSame(string0, string2);
      assertNotSame(string2, string0);
      assertNotSame(string2, string1);
      assertEquals(3439L, kafkaSpoutMessageId0.offset());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertFalse(mockThread0.isDaemon());
      assertEquals(0, mockThread0.countStackFrames());
      assertFalse(mockThread0.isInterrupted());
      
      boolean boolean1 = kafkaSpout_OffsetEntry4.contains(kafkaSpoutMessageId0);
      assertFalse(boolean1);
      assertFalse(long2 == long0);
      assertFalse(long2 == long3);
      assertFalse(long2 == long1);
      assertFalse(long3 == long2);
      assertFalse(long3 == long0);
      assertFalse(long3 == long1);
      assertFalse(boolean1 == boolean0);
      assertEquals(3439L, kafkaSpoutMessageId0.offset());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry5 = kafkaSpout1.new OffsetEntry(topicPartition0, kafkaSpoutConfig1.DEFAULT_OFFSET_COMMIT_PERIOD_MS);
      assertNotNull(kafkaSpout_OffsetEntry5);
      
      kafkaSpout_OffsetEntry5.add(kafkaSpoutMessageId0);
      assertFalse(long3 == long2);
      assertFalse(long3 == long0);
      assertFalse(long3 == long1);
      assertEquals(3439L, kafkaSpoutMessageId0.offset());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      
      TreeMap<String, List<Integer>> treeMap0 = new TreeMap<String, List<Integer>>(persistentArrayMap0);
      assertEquals(4, kafkaSpoutConfig_FirstPollOffsetStrategyArray0.length);
      assertNotNull(treeMap0);
      assertEquals(2, treeMap0.size());
      assertEquals(2, persistentArrayMap0.capacity());
      assertEquals(2, persistentArrayMap0.count());
      
      String string3 = "\\'+P*W";
      String string4 = "T}{0S_Sh-^IV";
      KafkaSpoutConfig<String, ExecutorSummary._Fields> kafkaSpoutConfig2 = (KafkaSpoutConfig<String, ExecutorSummary._Fields>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig2).getKafkaSpoutStreams();
      KafkaSpout<String, ExecutorSummary._Fields> kafkaSpout2 = new KafkaSpout<String, ExecutorSummary._Fields>(kafkaSpoutConfig2);
      assertNotNull(kafkaSpout2);
      
      ConsumerRecords<String, ExecutorSummary._Fields> consumerRecords0 = new ConsumerRecords<String, ExecutorSummary._Fields>(persistentArrayMap0);
      assertEquals(4, kafkaSpoutConfig_FirstPollOffsetStrategyArray0.length);
      assertNotNull(consumerRecords0);
      assertEquals(2, persistentArrayMap0.capacity());
      assertEquals(2, persistentArrayMap0.count());
      assertFalse(consumerRecords0.isEmpty());
      
      // Undeclared exception!
      try { 
        kafkaSpout2.setWaitingToEmit(consumerRecords0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // org.apache.storm.kafka.spout.KafkaSpoutConfig$FirstPollOffsetStrategy cannot be cast to org.apache.kafka.common.TopicPartition
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test01()  throws Throwable  {
      StormTopology stormTopology0 = null;
      StormTopology stormTopology1 = null;
      try {
        stormTopology1 = new StormTopology(stormTopology0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.generated.StormTopology", e);
      }
  }

  @Test(timeout = 11000)
  public void test02()  throws Throwable  {
      OutputFieldsGetter outputFieldsGetter0 = new OutputFieldsGetter();
      assertNotNull(outputFieldsGetter0);
      
      String string0 = "~CGKG";
      TreeMap<String, Object> treeMap0 = new TreeMap<String, Object>();
      assertNotNull(treeMap0);
      assertEquals(0, treeMap0.size());
      
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<ConsumerRecord<Integer, DelegationTokenIdentifier>, OffsetAndMetadata> kafkaSpoutConfig0 = (KafkaSpoutConfig<ConsumerRecord<Integer, DelegationTokenIdentifier>, OffsetAndMetadata>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(string0).when(kafkaSpoutConfig0).getConsumerGroupId();
      doReturn(treeMap0).when(kafkaSpoutConfig0).getKafkaProps();
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<ConsumerRecord<Integer, DelegationTokenIdentifier>, OffsetAndMetadata> kafkaSpout0 = new KafkaSpout<ConsumerRecord<Integer, DelegationTokenIdentifier>, OffsetAndMetadata>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      assertEquals(0, treeMap0.size());
      
      Map<String, Object> map0 = kafkaSpout0.getComponentConfiguration();
      assertNotNull(map0);
      assertEquals(0, treeMap0.size());
      assertFalse(map0.isEmpty());
      assertEquals(2, map0.size());
      
      KafkaSpoutStreams kafkaSpoutStreams1 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<Integer, Object> kafkaSpoutConfig1 = (KafkaSpoutConfig<Integer, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams1).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<Integer, Object> kafkaSpout1 = new KafkaSpout<Integer, Object>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      long long0 = (-2063L);
      long long1 = 0L;
      // Undeclared exception!
      try { 
        kafkaSpout1.deactivate();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test03()  throws Throwable  {
      KafkaSpoutConfig.FirstPollOffsetStrategy[] kafkaSpoutConfig_FirstPollOffsetStrategyArray0 = KafkaSpoutConfig.FirstPollOffsetStrategy.values();
      assertEquals(4, kafkaSpoutConfig_FirstPollOffsetStrategyArray0.length);
      assertNotNull(kafkaSpoutConfig_FirstPollOffsetStrategyArray0);
      
      KafkaSpoutStreams kafkaSpoutStreams0 = null;
      KafkaSpoutConfig<DelegationTokenIdentifier, Integer> kafkaSpoutConfig0 = (KafkaSpoutConfig<DelegationTokenIdentifier, Integer>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<DelegationTokenIdentifier, Integer> kafkaSpout0 = new KafkaSpout<DelegationTokenIdentifier, Integer>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "fA_m";
      TopicPartition topicPartition0 = new TopicPartition(string0, kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS);
      assertNotNull(topicPartition0);
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      
      long long0 = 1L;
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      
      String string1 = "function ";
      int int0 = 5;
      DelegationTokenIdentifier delegationTokenIdentifier0 = new DelegationTokenIdentifier();
      assertNotNull(delegationTokenIdentifier0);
      assertEquals(0, delegationTokenIdentifier0.getMasterKeyId());
      assertEquals(0, delegationTokenIdentifier0.getSequenceNumber());
      assertEquals(0L, delegationTokenIdentifier0.getMaxDate());
      assertEquals(0L, delegationTokenIdentifier0.getIssueDate());
      
      Text text0 = DelegationTokenIdentifier.HIVE_DELEGATION_KIND;
      assertNotNull(text0);
      assertEquals(1048576, Text.DEFAULT_MAX_LEN);
      assertEquals(21, text0.getLength());
      
      ConsumerRecord<Integer, DelegationTokenIdentifier> consumerRecord0 = new ConsumerRecord<Integer, DelegationTokenIdentifier>(string1, int0, long0, (Integer) kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS, delegationTokenIdentifier0);
      assertNotNull(consumerRecord0);
      assertFalse(string1.equals((Object)string0));
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals(0, delegationTokenIdentifier0.getMasterKeyId());
      assertEquals(0, delegationTokenIdentifier0.getSequenceNumber());
      assertEquals(0L, delegationTokenIdentifier0.getMaxDate());
      assertEquals(0L, delegationTokenIdentifier0.getIssueDate());
      assertEquals((-1), consumerRecord0.serializedKeySize());
      assertEquals(5, consumerRecord0.partition());
      assertEquals((-1L), consumerRecord0.timestamp());
      assertEquals(1L, consumerRecord0.offset());
      assertEquals("function ", consumerRecord0.topic());
      assertEquals((-1), consumerRecord0.serializedValueSize());
      assertEquals(TimestampType.NO_TIMESTAMP_TYPE, consumerRecord0.timestampType());
      
      KafkaSpoutMessageId kafkaSpoutMessageId0 = new KafkaSpoutMessageId(consumerRecord0);
      assertNotNull(kafkaSpoutMessageId0);
      assertFalse(string1.equals((Object)string0));
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals(0, delegationTokenIdentifier0.getMasterKeyId());
      assertEquals(0, delegationTokenIdentifier0.getSequenceNumber());
      assertEquals(0L, delegationTokenIdentifier0.getMaxDate());
      assertEquals(0L, delegationTokenIdentifier0.getIssueDate());
      assertEquals((-1), consumerRecord0.serializedKeySize());
      assertEquals(5, consumerRecord0.partition());
      assertEquals((-1L), consumerRecord0.timestamp());
      assertEquals(1L, consumerRecord0.offset());
      assertEquals("function ", consumerRecord0.topic());
      assertEquals((-1), consumerRecord0.serializedValueSize());
      assertEquals(TimestampType.NO_TIMESTAMP_TYPE, consumerRecord0.timestampType());
      assertEquals("function ", kafkaSpoutMessageId0.topic());
      assertEquals(1L, kafkaSpoutMessageId0.offset());
      assertEquals(5, kafkaSpoutMessageId0.partition());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      
      kafkaSpout_OffsetEntry0.add(kafkaSpoutMessageId0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string0));
      assertNotSame(string0, string1);
      assertNotSame(string1, string0);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      assertEquals(0, delegationTokenIdentifier0.getMasterKeyId());
      assertEquals(0, delegationTokenIdentifier0.getSequenceNumber());
      assertEquals(0L, delegationTokenIdentifier0.getMaxDate());
      assertEquals(0L, delegationTokenIdentifier0.getIssueDate());
      assertEquals((-1), consumerRecord0.serializedKeySize());
      assertEquals(5, consumerRecord0.partition());
      assertEquals((-1L), consumerRecord0.timestamp());
      assertEquals(1L, consumerRecord0.offset());
      assertEquals("function ", consumerRecord0.topic());
      assertEquals((-1), consumerRecord0.serializedValueSize());
      assertEquals(TimestampType.NO_TIMESTAMP_TYPE, consumerRecord0.timestampType());
      assertEquals("function ", kafkaSpoutMessageId0.topic());
      assertEquals(1L, kafkaSpoutMessageId0.offset());
      assertEquals(5, kafkaSpoutMessageId0.partition());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      
      String string2 = kafkaSpout_OffsetEntry0.toString();
      assertEquals("OffsetEntry{topic-partition=fA_m-10000000, fetchOffset=1, committedOffset=0, ackedMsgs=[{topic-partition=function -5, offset=1, numFails=0}]}", string2);
      assertNotNull(string2);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertNotSame(string0, string1);
      assertNotSame(string0, string2);
      assertNotSame(string2, string1);
      assertNotSame(string2, string0);
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      
      long long1 = 0L;
      KafkaSpoutMessageId kafkaSpoutMessageId1 = new KafkaSpoutMessageId(topicPartition0, long1);
      assertNotNull(kafkaSpoutMessageId1);
      assertFalse(long1 == long0);
      assertFalse(kafkaSpoutMessageId1.equals((Object)kafkaSpoutMessageId0));
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertEquals(10000000, kafkaSpoutMessageId1.partition());
      assertEquals(0, kafkaSpoutMessageId1.numFails());
      assertEquals("fA_m", kafkaSpoutMessageId1.topic());
      assertEquals(0L, kafkaSpoutMessageId1.offset());
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      
      kafkaSpout_OffsetEntry0.add(kafkaSpoutMessageId1);
      assertFalse(long1 == long0);
      assertFalse(kafkaSpoutMessageId1.equals((Object)kafkaSpoutMessageId0));
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertFalse(long0 == long1);
      assertNotSame(kafkaSpoutMessageId1, kafkaSpoutMessageId0);
      assertNotSame(string0, string1);
      assertNotSame(string0, string2);
      assertEquals(10000000, kafkaSpoutMessageId1.partition());
      assertEquals(0, kafkaSpoutMessageId1.numFails());
      assertEquals("fA_m", kafkaSpoutMessageId1.topic());
      assertEquals(0L, kafkaSpoutMessageId1.offset());
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      
      OffsetAndMetadata offsetAndMetadata0 = kafkaSpout_OffsetEntry0.findNextCommitOffset();
      assertNotNull(offsetAndMetadata0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertFalse(long0 == long1);
      assertNotSame(string0, string1);
      assertNotSame(string0, string2);
      assertEquals("{topic-partition=function -5, offset=1, numFails=0, thread='TEST_EXECUTION_THREAD_1'}", offsetAndMetadata0.metadata());
      assertEquals(1L, offsetAndMetadata0.offset());
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      
      boolean boolean0 = kafkaSpout_OffsetEntry0.isEmpty();
      assertFalse(boolean0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertFalse(long0 == long1);
      assertNotSame(string0, string1);
      assertNotSame(string0, string2);
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      
      KafkaSpoutConfig<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>> kafkaSpoutConfig1 = (KafkaSpoutConfig<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>> kafkaSpout1 = new KafkaSpout<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      OutputFieldsGetter outputFieldsGetter0 = new OutputFieldsGetter();
      assertNotNull(outputFieldsGetter0);
      
      // Undeclared exception!
      try { 
        KafkaSpoutConfig.FirstPollOffsetStrategy.valueOf(string0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // No enum constant org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy.fA_m
         //
         verifyException("java.lang.Enum", e);
      }
  }

  @Test(timeout = 11000)
  public void test04()  throws Throwable  {
      KafkaSpoutConfig.FirstPollOffsetStrategy kafkaSpoutConfig_FirstPollOffsetStrategy0 = KafkaSpoutConfig.FirstPollOffsetStrategy.LATEST;
      String[] stringArray0 = new String[4];
      String string0 = "DbRO_4I']AWcxHaY E";
      stringArray0[0] = string0;
      String string1 = "route-params";
      stringArray0[1] = string1;
      String string2 = "_oKYIs6QV4usyG";
      stringArray0[2] = string2;
      String string3 = "";
      stringArray0[3] = string3;
      Fields fields0 = new Fields(stringArray0);
      assertEquals(4, stringArray0.length);
      assertNotNull(fields0);
      assertEquals(4, fields0.size());
      
      String string4 = "";
      KafkaSpoutConfig<String, Integer> kafkaSpoutConfig0 = (KafkaSpoutConfig<String, Integer>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<String, Integer> kafkaSpout0 = new KafkaSpout<String, Integer>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      Map<Object, MapEntry> map0 = null;
      StormTopology stormTopology0 = new StormTopology();
      assertNotNull(stormTopology0);
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertFalse(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertFalse(stormTopology0.is_set_bolts());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_spouts());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertFalse(stormTopology0.is_set_worker_hooks());
      
      Map<Integer, String> map1 = null;
      GenerationClauseNode generationClauseNode0 = new GenerationClauseNode();
      assertNotNull(generationClauseNode0);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertFalse(generationClauseNode0.updatableByCursor());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertNull(generationClauseNode0.getExpressionText());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.isParameterNode());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertNull(generationClauseNode0.getColumnName());
      assertFalse(generationClauseNode0.isCloneable());
      assertNull(generationClauseNode0.getTableName());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertNull(generationClauseNode0.getSchemaName());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      
      ProviderList providerList0 = generationClauseNode0.getAuxiliaryProviderList();
      assertNull(providerList0);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertFalse(generationClauseNode0.updatableByCursor());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertNull(generationClauseNode0.getExpressionText());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.isParameterNode());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertNull(generationClauseNode0.getColumnName());
      assertFalse(generationClauseNode0.isCloneable());
      assertNull(generationClauseNode0.getTableName());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertNull(generationClauseNode0.getSchemaName());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      
      String string5 = " with assignedTableMap = ";
      String string6 = "e+J,COo~:7hA6~";
      int int0 = (-102);
      Integer integer0 = new Integer(int0);
      assertEquals((-102), (int)integer0);
      assertNotNull(integer0);
      assertTrue(integer0.equals((Object)int0));
      
      int int1 = 944;
      Integer integer1 = new Integer(int1);
      assertEquals(944, (int)integer1);
      assertNotNull(integer1);
      assertFalse(int1 == int0);
      assertFalse(integer1.equals((Object)int0));
      assertFalse(integer1.equals((Object)integer0));
      assertTrue(integer1.equals((Object)int1));
      
      Object[] objectArray0 = new Object[5];
      objectArray0[0] = (Object) providerList0;
      objectArray0[1] = (Object) string6;
  }

  @Test(timeout = 11000)
  public void test05()  throws Throwable  {
      PersistentArrayMap persistentArrayMap0 = PersistentArrayMap.EMPTY;
      assertNotNull(persistentArrayMap0);
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentArrayMap0.capacity());
      
      DataDictionaryImpl dataDictionaryImpl0 = new DataDictionaryImpl();
      assertNotNull(dataDictionaryImpl0);
      assertNull(dataDictionaryImpl0.getAuthorizationDatabaseOwner());
      assertEquals(0, dataDictionaryImpl0.getCollationTypeOfUserSchemas());
      assertEquals(0, dataDictionaryImpl0.getCacheMode());
      assertEquals(0, dataDictionaryImpl0.getCollationTypeOfSystemSchemas());
      assertTrue(dataDictionaryImpl0.doCreateIndexStatsRefresher());
      assertFalse(dataDictionaryImpl0.isReadOnlyUpgrade());
      assertFalse(dataDictionaryImpl0.usesSqlAuthorization());
      assertEquals(0, dataDictionaryImpl0.getEngineType());
      
      KafkaSpoutConfig<JMXPrincipal, Object> kafkaSpoutConfig0 = (KafkaSpoutConfig<JMXPrincipal, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<JMXPrincipal, Object> kafkaSpout0 = new KafkaSpout<JMXPrincipal, Object>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "generate-key-fn-map";
      String[] stringArray0 = new String[0];
      Fields fields0 = new Fields(stringArray0);
      assertEquals(0, stringArray0.length);
      assertNotNull(fields0);
      assertEquals(0, fields0.size());
      
      String string1 = "";
      String string2 = "t9`$iC5es";
      Pattern pattern0 = Pattern.compile(string2, kafkaSpoutConfig0.DEFAULT_MAX_RETRIES);
      assertNotNull(pattern0);
      assertFalse(string2.equals((Object)string0));
      assertFalse(string2.equals((Object)string1));
      assertNotSame(string2, string0);
      assertNotSame(string2, string1);
      assertEquals("t9`$iC5es", pattern0.toString());
      assertEquals("t9`$iC5es", pattern0.pattern());
      assertEquals(Integer.MAX_VALUE, pattern0.flags());
      
      KafkaSpoutStream kafkaSpoutStream0 = new KafkaSpoutStream(fields0, string1, pattern0);
      assertEquals(0, stringArray0.length);
      assertNotNull(kafkaSpoutStream0);
      assertFalse(string1.equals((Object)string2));
      assertFalse(string1.equals((Object)string0));
      assertFalse(string2.equals((Object)string0));
      assertFalse(string2.equals((Object)string1));
      assertEquals(0, fields0.size());
      assertEquals("t9`$iC5es", pattern0.toString());
      assertEquals("t9`$iC5es", pattern0.pattern());
      assertEquals(Integer.MAX_VALUE, pattern0.flags());
      assertNull(kafkaSpoutStream0.getTopic());
      
      KafkaSpoutStreamsWildcardTopics kafkaSpoutStreamsWildcardTopics0 = new KafkaSpoutStreamsWildcardTopics(kafkaSpoutStream0);
      assertEquals(0, stringArray0.length);
      assertNotNull(kafkaSpoutStreamsWildcardTopics0);
      assertFalse(string1.equals((Object)string2));
      assertFalse(string1.equals((Object)string0));
      assertFalse(string2.equals((Object)string0));
      assertFalse(string2.equals((Object)string1));
      assertEquals(0, fields0.size());
      assertEquals("t9`$iC5es", pattern0.toString());
      assertEquals("t9`$iC5es", pattern0.pattern());
      assertEquals(Integer.MAX_VALUE, pattern0.flags());
      assertNull(kafkaSpoutStream0.getTopic());
      
      KafkaSpoutConfig<ExecutorSummary._Fields, OffsetAndMetadata> kafkaSpoutConfig1 = (KafkaSpoutConfig<ExecutorSummary._Fields, OffsetAndMetadata>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((String) null).when(kafkaSpoutConfig1).getConsumerGroupId();
      doReturn((Map) null).when(kafkaSpoutConfig1).getKafkaProps();
      doReturn(kafkaSpoutStreamsWildcardTopics0).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      doReturn(pattern0).when(kafkaSpoutConfig1).getTopicWildcardPattern();
      KafkaSpout<ExecutorSummary._Fields, OffsetAndMetadata> kafkaSpout1 = new KafkaSpout<ExecutorSummary._Fields, OffsetAndMetadata>(kafkaSpoutConfig1);
      assertEquals(0, stringArray0.length);
      assertNotNull(kafkaSpout1);
      assertFalse(string1.equals((Object)string2));
      assertFalse(string1.equals((Object)string0));
      assertFalse(string2.equals((Object)string0));
      assertFalse(string2.equals((Object)string1));
      assertEquals(0, fields0.size());
      assertEquals("t9`$iC5es", pattern0.toString());
      assertEquals("t9`$iC5es", pattern0.pattern());
      assertEquals(Integer.MAX_VALUE, pattern0.flags());
      assertNull(kafkaSpoutStream0.getTopic());
      
      // Undeclared exception!
      try { 
        kafkaSpout1.getComponentConfiguration();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test06()  throws Throwable  {
      KafkaSpoutConfig.FirstPollOffsetStrategy kafkaSpoutConfig_FirstPollOffsetStrategy0 = KafkaSpoutConfig.FirstPollOffsetStrategy.UNCOMMITTED_LATEST;
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      int int0 = (-2028178999);
      long long0 = 2216L;
      KafkaSpoutRetryService kafkaSpoutRetryService0 = mock(KafkaSpoutRetryService.class, new ViolatedAssumptionAnswer());
      KafkaSpoutTuplesBuilder<String, Integer> kafkaSpoutTuplesBuilder0 = (KafkaSpoutTuplesBuilder<String, Integer>) mock(KafkaSpoutTuplesBuilder.class, new ViolatedAssumptionAnswer());
      boolean boolean0 = true;
      KafkaSpoutConfig<String, Integer> kafkaSpoutConfig0 = (KafkaSpoutConfig<String, Integer>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutConfig_FirstPollOffsetStrategy0).when(kafkaSpoutConfig0).getFirstPollOffsetStrategy();
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      doReturn(int0).when(kafkaSpoutConfig0).getMaxTupleRetries();
      doReturn(kafkaSpoutRetryService0).when(kafkaSpoutConfig0).getRetryService();
      doReturn(kafkaSpoutTuplesBuilder0).when(kafkaSpoutConfig0).getTuplesBuilder();
      doReturn(boolean0).when(kafkaSpoutConfig0).isConsumerAutoCommitMode();
      KafkaSpout<String, Integer> kafkaSpout0 = new KafkaSpout<String, Integer>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      Map<Object, MapEntry> map0 = null;
      StormTopology stormTopology0 = new StormTopology();
      assertNotNull(stormTopology0);
      assertFalse(stormTopology0.is_set_bolts());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertFalse(stormTopology0.is_set_spouts());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertFalse(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertEquals(0, stormTopology0.get_spouts_size());
      
      Map<Integer, String> map1 = null;
      GenerationClauseNode generationClauseNode0 = new GenerationClauseNode();
      assertNotNull(generationClauseNode0);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertFalse(generationClauseNode0.isCloneable());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertFalse(generationClauseNode0.isParameterNode());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertNull(generationClauseNode0.getColumnName());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertNull(generationClauseNode0.getTableName());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertNull(generationClauseNode0.getSchemaName());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertNull(generationClauseNode0.getExpressionText());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      
      ProviderList providerList0 = generationClauseNode0.getAuxiliaryProviderList();
      assertNull(providerList0);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertFalse(generationClauseNode0.isCloneable());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertFalse(generationClauseNode0.isParameterNode());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertNull(generationClauseNode0.getColumnName());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertNull(generationClauseNode0.getTableName());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertNull(generationClauseNode0.getSchemaName());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertNull(generationClauseNode0.getExpressionText());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      
      String string0 = " with assignedTableMap = ";
      String string1 = "e+J,COo~:7hA6~";
      int int1 = (-102);
      Integer integer0 = new Integer(int1);
      assertEquals((-102), (int)integer0);
      assertNotNull(integer0);
      assertFalse(int1 == int0);
      assertFalse(integer0.equals((Object)int0));
      assertTrue(integer0.equals((Object)int1));
      
      int int2 = 944;
      Object[] objectArray0 = new Object[5];
      objectArray0[0] = (Object) providerList0;
      objectArray0[1] = (Object) string1;
      objectArray0[2] = (Object) generationClauseNode0;
      objectArray0[3] = (Object) string0;
      objectArray0[4] = (Object) integer0;
      ArraySeq arraySeq0 = ArraySeq.create(objectArray0);
      assertEquals(5, objectArray0.length);
      assertNotNull(arraySeq0);
      assertFalse(arraySeq0.isEmpty());
      assertEquals(0, arraySeq0.index());
      assertEquals(5, arraySeq0.count());
      
      boolean boolean1 = true;
      AtomicBoolean atomicBoolean0 = new AtomicBoolean(boolean1);
      assertNotNull(atomicBoolean0);
      assertTrue(atomicBoolean0.get());
      assertEquals("true", atomicBoolean0.toString());
      
      TopologyContext topologyContext0 = new TopologyContext(stormTopology0, map0, map1, providerList0, providerList0, string0, string0, string1, integer0, (Integer) generationClauseNode0.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX, arraySeq0, providerList0, providerList0, providerList0, providerList0, atomicBoolean0);
      assertEquals(5, objectArray0.length);
      assertNotNull(topologyContext0);
      assertFalse(int1 == int2);
      assertFalse(int1 == int0);
      assertFalse(integer0.equals((Object)int2));
      assertFalse(integer0.equals((Object)int0));
      assertTrue(integer0.equals((Object)int1));
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string0));
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertFalse(arraySeq0.isEmpty());
      assertEquals(0, arraySeq0.index());
      assertEquals(5, arraySeq0.count());
      assertFalse(stormTopology0.is_set_bolts());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertFalse(stormTopology0.is_set_spouts());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertFalse(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertTrue(atomicBoolean0.get());
      assertEquals("true", atomicBoolean0.toString());
      assertEquals((-102), topologyContext0.getThisTaskId());
      assertEquals(2, (int)topologyContext0.getThisWorkerPort());
      assertEquals(" with assignedTableMap = ", topologyContext0.getStormId());
      assertEquals(" with assignedTableMap = ", topologyContext0.getCodeDir());
      assertEquals("/home/CIN/lmps2/semantic-conflict-study/SMAT/output-test-dest/storm/bd1f5c54752f67b484a83c26667331234234d3a3/evosuite_2/e+J,COo~:7hA6~", topologyContext0.getPIDDir());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertFalse(generationClauseNode0.isCloneable());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertFalse(generationClauseNode0.isParameterNode());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertNull(generationClauseNode0.getColumnName());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertNull(generationClauseNode0.getTableName());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertNull(generationClauseNode0.getSchemaName());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertNull(generationClauseNode0.getExpressionText());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      
      KafkaSpoutStreams kafkaSpoutStreams1 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<ExecutorSummary._Fields, OffsetAndMetadata> kafkaSpoutConfig1 = (KafkaSpoutConfig<ExecutorSummary._Fields, OffsetAndMetadata>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams1).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<ExecutorSummary._Fields, OffsetAndMetadata> kafkaSpout1 = new KafkaSpout<ExecutorSummary._Fields, OffsetAndMetadata>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      SpoutOutputCollector spoutOutputCollector0 = kafkaSpout1.collector;
      assertNull(spoutOutputCollector0);
      
      kafkaSpout0.open(map0, topologyContext0, spoutOutputCollector0);
      assertEquals(5, objectArray0.length);
      assertFalse(int0 == int1);
      assertFalse(int0 == int2);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string0));
      assertFalse(int1 == int2);
      assertFalse(int1 == int0);
      assertFalse(integer0.equals((Object)int2));
      assertFalse(integer0.equals((Object)int0));
      assertTrue(integer0.equals((Object)int1));
      assertNotSame(string0, string1);
      assertNotSame(string1, string0);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertFalse(arraySeq0.isEmpty());
      assertEquals(0, arraySeq0.index());
      assertEquals(5, arraySeq0.count());
      assertFalse(stormTopology0.is_set_bolts());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertFalse(stormTopology0.is_set_spouts());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertFalse(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertTrue(atomicBoolean0.get());
      assertEquals("true", atomicBoolean0.toString());
      assertEquals((-102), topologyContext0.getThisTaskId());
      assertEquals(2, (int)topologyContext0.getThisWorkerPort());
      assertEquals(" with assignedTableMap = ", topologyContext0.getStormId());
      assertEquals(" with assignedTableMap = ", topologyContext0.getCodeDir());
      assertEquals("/home/CIN/lmps2/semantic-conflict-study/SMAT/output-test-dest/storm/bd1f5c54752f67b484a83c26667331234234d3a3/evosuite_2/e+J,COo~:7hA6~", topologyContext0.getPIDDir());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertFalse(generationClauseNode0.isCloneable());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertFalse(generationClauseNode0.isParameterNode());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertNull(generationClauseNode0.getColumnName());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertNull(generationClauseNode0.getTableName());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertNull(generationClauseNode0.getSchemaName());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertNull(generationClauseNode0.getExpressionText());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      
      // Undeclared exception!
      try { 
        kafkaSpout0.close();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test07()  throws Throwable  {
      KafkaSpoutConfig<String, Integer> kafkaSpoutConfig0 = (KafkaSpoutConfig<String, Integer>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutConfig.FirstPollOffsetStrategy) null).when(kafkaSpoutConfig0).getFirstPollOffsetStrategy();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      doReturn(0).when(kafkaSpoutConfig0).getMaxTupleRetries();
      doReturn(0L).when(kafkaSpoutConfig0).getOffsetsCommitPeriodMs();
      doReturn((KafkaSpoutRetryService) null).when(kafkaSpoutConfig0).getRetryService();
      doReturn((KafkaSpoutTuplesBuilder) null).when(kafkaSpoutConfig0).getTuplesBuilder();
      doReturn(false).when(kafkaSpoutConfig0).isConsumerAutoCommitMode();
      KafkaSpout<String, Integer> kafkaSpout0 = new KafkaSpout<String, Integer>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      Map<Object, MapEntry> map0 = null;
      StormTopology stormTopology0 = new StormTopology();
      assertNotNull(stormTopology0);
      assertFalse(stormTopology0.is_set_bolts());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertFalse(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_spouts());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      
      Map<Integer, String> map1 = null;
      GenerationClauseNode generationClauseNode0 = new GenerationClauseNode();
      assertNotNull(generationClauseNode0);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertNull(generationClauseNode0.getColumnName());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertFalse(generationClauseNode0.isParameterNode());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertNull(generationClauseNode0.getExpressionText());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertNull(generationClauseNode0.getSchemaName());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertFalse(generationClauseNode0.isCloneable());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertNull(generationClauseNode0.getTableName());
      
      ProviderList providerList0 = generationClauseNode0.getAuxiliaryProviderList();
      assertNull(providerList0);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertNull(generationClauseNode0.getColumnName());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertFalse(generationClauseNode0.isParameterNode());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertNull(generationClauseNode0.getExpressionText());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertNull(generationClauseNode0.getSchemaName());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertFalse(generationClauseNode0.isCloneable());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertNull(generationClauseNode0.getTableName());
      
      String string0 = " with assignedTableMap = ";
      String string1 = "e+J,COo~:7hA6~";
      int int0 = (-102);
      Integer integer0 = new Integer(int0);
      assertEquals((-102), (int)integer0);
      assertNotNull(integer0);
      assertTrue(integer0.equals((Object)int0));
      
      int int1 = 944;
      Integer integer1 = new Integer(int1);
      assertEquals(944, (int)integer1);
      assertNotNull(integer1);
      assertFalse(int1 == int0);
      assertFalse(integer1.equals((Object)int0));
      assertFalse(integer1.equals((Object)integer0));
      assertTrue(integer1.equals((Object)int1));
      
      Object[] objectArray0 = new Object[5];
      objectArray0[0] = (Object) providerList0;
      objectArray0[1] = (Object) string1;
      objectArray0[2] = (Object) generationClauseNode0;
      objectArray0[3] = (Object) string0;
      objectArray0[4] = (Object) integer0;
      ArraySeq arraySeq0 = ArraySeq.create(objectArray0);
      assertEquals(5, objectArray0.length);
      assertNotNull(arraySeq0);
      assertEquals(0, arraySeq0.index());
      assertEquals(5, arraySeq0.count());
      assertFalse(arraySeq0.isEmpty());
      
      boolean boolean0 = true;
      AtomicBoolean atomicBoolean0 = new AtomicBoolean(boolean0);
      assertNotNull(atomicBoolean0);
      assertEquals("true", atomicBoolean0.toString());
      assertTrue(atomicBoolean0.get());
      
      TopologyContext topologyContext0 = new TopologyContext(stormTopology0, map0, map1, providerList0, providerList0, string0, string0, string1, integer0, integer1, arraySeq0, providerList0, providerList0, providerList0, providerList0, atomicBoolean0);
      assertEquals(5, objectArray0.length);
      assertNotNull(topologyContext0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string0));
      assertFalse(int0 == int1);
      assertFalse(integer0.equals((Object)int1));
      assertTrue(integer0.equals((Object)int0));
      assertFalse(integer0.equals((Object)integer1));
      assertFalse(int1 == int0);
      assertFalse(integer1.equals((Object)int0));
      assertFalse(integer1.equals((Object)integer0));
      assertTrue(integer1.equals((Object)int1));
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(0, arraySeq0.index());
      assertEquals(5, arraySeq0.count());
      assertFalse(arraySeq0.isEmpty());
      assertFalse(stormTopology0.is_set_bolts());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertFalse(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_spouts());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals("true", atomicBoolean0.toString());
      assertTrue(atomicBoolean0.get());
      assertNull(generationClauseNode0.getColumnName());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertFalse(generationClauseNode0.isParameterNode());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertNull(generationClauseNode0.getExpressionText());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertNull(generationClauseNode0.getSchemaName());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertFalse(generationClauseNode0.isCloneable());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertNull(generationClauseNode0.getTableName());
      assertEquals(" with assignedTableMap = ", topologyContext0.getStormId());
      assertEquals(944, (int)topologyContext0.getThisWorkerPort());
      assertEquals(" with assignedTableMap = ", topologyContext0.getCodeDir());
      assertEquals("/home/CIN/lmps2/semantic-conflict-study/SMAT/output-test-dest/storm/bd1f5c54752f67b484a83c26667331234234d3a3/evosuite_2/e+J,COo~:7hA6~", topologyContext0.getPIDDir());
      assertEquals((-102), topologyContext0.getThisTaskId());
      
      KafkaSpoutConfig<ExecutorSummary._Fields, OffsetAndMetadata> kafkaSpoutConfig1 = (KafkaSpoutConfig<ExecutorSummary._Fields, OffsetAndMetadata>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<ExecutorSummary._Fields, OffsetAndMetadata> kafkaSpout1 = new KafkaSpout<ExecutorSummary._Fields, OffsetAndMetadata>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      SpoutOutputCollector spoutOutputCollector0 = kafkaSpout1.collector;
      assertNull(spoutOutputCollector0);
      
      kafkaSpout0.open(map0, topologyContext0, spoutOutputCollector0);
      assertEquals(5, objectArray0.length);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string0));
      assertFalse(int0 == int1);
      assertFalse(integer0.equals((Object)int1));
      assertTrue(integer0.equals((Object)int0));
      assertFalse(integer0.equals((Object)integer1));
      assertFalse(int1 == int0);
      assertFalse(integer1.equals((Object)int0));
      assertFalse(integer1.equals((Object)integer0));
      assertTrue(integer1.equals((Object)int1));
      assertNotSame(string0, string1);
      assertNotSame(string1, string0);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(0, arraySeq0.index());
      assertEquals(5, arraySeq0.count());
      assertFalse(arraySeq0.isEmpty());
      assertFalse(stormTopology0.is_set_bolts());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertFalse(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_spouts());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals("true", atomicBoolean0.toString());
      assertTrue(atomicBoolean0.get());
      assertNull(generationClauseNode0.getColumnName());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertFalse(generationClauseNode0.isParameterNode());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertNull(generationClauseNode0.getExpressionText());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertNull(generationClauseNode0.getSchemaName());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertFalse(generationClauseNode0.isCloneable());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertNull(generationClauseNode0.getTableName());
      assertEquals(" with assignedTableMap = ", topologyContext0.getStormId());
      assertEquals(944, (int)topologyContext0.getThisWorkerPort());
      assertEquals(" with assignedTableMap = ", topologyContext0.getCodeDir());
      assertEquals("/home/CIN/lmps2/semantic-conflict-study/SMAT/output-test-dest/storm/bd1f5c54752f67b484a83c26667331234234d3a3/evosuite_2/e+J,COo~:7hA6~", topologyContext0.getPIDDir());
      assertEquals((-102), topologyContext0.getThisTaskId());
      
      // Undeclared exception!
      try { 
        kafkaSpout0.close();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test08()  throws Throwable  {
      StormTopology stormTopology0 = new StormTopology();
      assertNotNull(stormTopology0);
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertFalse(stormTopology0.is_set_spouts());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertFalse(stormTopology0.is_set_bolts());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_state_spouts());
      
      StormTopology stormTopology1 = new StormTopology(stormTopology0);
      assertNotNull(stormTopology1);
      assertTrue(stormTopology1.equals((Object)stormTopology0));
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertFalse(stormTopology0.is_set_spouts());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertFalse(stormTopology0.is_set_bolts());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_state_spouts());
      assertFalse(stormTopology1.is_set_dependency_artifacts());
      assertEquals(0, stormTopology1.get_spouts_size());
      assertEquals(0, stormTopology1.get_dependency_jars_size());
      assertFalse(stormTopology1.is_set_bolts());
      assertFalse(stormTopology1.is_set_worker_hooks());
      assertEquals(0, stormTopology1.get_worker_hooks_size());
      assertEquals(0, stormTopology1.get_dependency_artifacts_size());
      assertFalse(stormTopology1.is_set_dependency_jars());
      assertFalse(stormTopology1.is_set_state_spouts());
      assertEquals(0, stormTopology1.get_bolts_size());
      assertFalse(stormTopology1.is_set_spouts());
      assertEquals(0, stormTopology1.get_state_spouts_size());
      
      Map<DelegationTokenIdentifier, Object> map0 = null;
      Object[] objectArray0 = new Object[6];
      objectArray0[0] = (Object) stormTopology0;
      objectArray0[1] = (Object) stormTopology0;
  }

  @Test(timeout = 11000)
  public void test09()  throws Throwable  {
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<Integer, KafkaSpoutStreamsNamedTopics> kafkaSpoutConfig0 = (KafkaSpoutConfig<Integer, KafkaSpoutStreamsNamedTopics>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<Integer, KafkaSpoutStreamsNamedTopics> kafkaSpout0 = new KafkaSpout<Integer, KafkaSpoutStreamsNamedTopics>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "with-open only allows Symbols in bindings";
      TopicPartition topicPartition0 = new TopicPartition(string0, kafkaSpoutConfig0.DEFAULT_MAX_RETRIES);
      assertNotNull(topicPartition0);
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      
      long long0 = 1689L;
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      
      Integer integer0 = new Integer(kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS);
      assertEquals(10000000, (int)integer0);
      assertNotNull(integer0);
      
      Optional<Integer> optional0 = Optional.ofNullable(integer0);
      assertNotNull(optional0);
      
      Supplier<BatchUpdateException> supplier0 = null;
      Integer integer1 = optional0.orElseThrow((Supplier<? extends BatchUpdateException>) supplier0);
      assertEquals(10000000, (int)integer1);
      assertNotNull(integer1);
      
      String string1 = "clojure.core$generate_class$iname__6022";
      int int0 = 5208;
      long long1 = 1076L;
      TimestampType timestampType0 = TimestampType.CREATE_TIME;
      int int1 = 505;
      KafkaSpoutStreamsNamedTopics kafkaSpoutStreamsNamedTopics0 = mock(KafkaSpoutStreamsNamedTopics.class, new ViolatedAssumptionAnswer());
      String string2 = topicPartition0.toString();
      assertEquals("with-open only allows Symbols in bindings-2147483647", string2);
      assertNotNull(string2);
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertFalse(string0.equals((Object)string1));
      assertNotSame(string2, string1);
      assertNotSame(string2, string0);
      assertNotSame(string0, string1);
      assertNotSame(string0, string2);
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      
      JMXPrincipal jMXPrincipal0 = mock(JMXPrincipal.class, new ViolatedAssumptionAnswer());
      ConsumerRecord<KafkaSpoutStreamsNamedTopics, JMXPrincipal> consumerRecord0 = new ConsumerRecord<KafkaSpoutStreamsNamedTopics, JMXPrincipal>(string1, int0, long0, long1, timestampType0, kafkaSpoutConfig0.DEFAULT_OFFSET_COMMIT_PERIOD_MS, int1, int1, kafkaSpoutStreamsNamedTopics0, jMXPrincipal0);
      assertNotNull(consumerRecord0);
      assertFalse(long0 == long1);
      assertFalse(string1.equals((Object)string2));
      assertFalse(string1.equals((Object)string0));
      assertFalse(int0 == int1);
      assertFalse(long1 == long0);
      assertFalse(int1 == int0);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals(1076L, consumerRecord0.timestamp());
      assertEquals(5208, consumerRecord0.partition());
      assertEquals(505, consumerRecord0.serializedValueSize());
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals(505, consumerRecord0.serializedKeySize());
      assertEquals("clojure.core$generate_class$iname__6022", consumerRecord0.topic());
      assertEquals(1689L, consumerRecord0.offset());
      
      KafkaSpoutMessageId kafkaSpoutMessageId0 = new KafkaSpoutMessageId(consumerRecord0);
      assertNotNull(kafkaSpoutMessageId0);
      assertFalse(long0 == long1);
      assertFalse(string1.equals((Object)string2));
      assertFalse(string1.equals((Object)string0));
      assertFalse(int0 == int1);
      assertFalse(long1 == long0);
      assertFalse(int1 == int0);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals(1076L, consumerRecord0.timestamp());
      assertEquals(5208, consumerRecord0.partition());
      assertEquals(505, consumerRecord0.serializedValueSize());
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals(505, consumerRecord0.serializedKeySize());
      assertEquals("clojure.core$generate_class$iname__6022", consumerRecord0.topic());
      assertEquals(1689L, consumerRecord0.offset());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals(5208, kafkaSpoutMessageId0.partition());
      assertEquals("clojure.core$generate_class$iname__6022", kafkaSpoutMessageId0.topic());
      assertEquals(1689L, kafkaSpoutMessageId0.offset());
      
      kafkaSpoutMessageId0.incrementNumFails();
      assertFalse(long0 == long1);
      assertFalse(string1.equals((Object)string2));
      assertFalse(string1.equals((Object)string0));
      assertFalse(int0 == int1);
      assertFalse(long1 == long0);
      assertFalse(int1 == int0);
      assertNotSame(string1, string2);
      assertNotSame(string1, string0);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals(1076L, consumerRecord0.timestamp());
      assertEquals(5208, consumerRecord0.partition());
      assertEquals(505, consumerRecord0.serializedValueSize());
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals(505, consumerRecord0.serializedKeySize());
      assertEquals("clojure.core$generate_class$iname__6022", consumerRecord0.topic());
      assertEquals(1689L, consumerRecord0.offset());
      assertEquals(5208, kafkaSpoutMessageId0.partition());
      assertEquals("clojure.core$generate_class$iname__6022", kafkaSpoutMessageId0.topic());
      assertEquals(1689L, kafkaSpoutMessageId0.offset());
      assertEquals(1, kafkaSpoutMessageId0.numFails());
      
      kafkaSpout_OffsetEntry0.add(kafkaSpoutMessageId0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertFalse(long0 == long1);
      assertFalse(string1.equals((Object)string2));
      assertFalse(string1.equals((Object)string0));
      assertFalse(int0 == int1);
      assertFalse(long1 == long0);
      assertFalse(int1 == int0);
      assertNotSame(string0, string1);
      assertNotSame(string0, string2);
      assertNotSame(string1, string2);
      assertNotSame(string1, string0);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals(1076L, consumerRecord0.timestamp());
      assertEquals(5208, consumerRecord0.partition());
      assertEquals(505, consumerRecord0.serializedValueSize());
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals(505, consumerRecord0.serializedKeySize());
      assertEquals("clojure.core$generate_class$iname__6022", consumerRecord0.topic());
      assertEquals(1689L, consumerRecord0.offset());
      assertEquals(5208, kafkaSpoutMessageId0.partition());
      assertEquals("clojure.core$generate_class$iname__6022", kafkaSpoutMessageId0.topic());
      assertEquals(1689L, kafkaSpoutMessageId0.offset());
      assertEquals(1, kafkaSpoutMessageId0.numFails());
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      
      OffsetAndMetadata offsetAndMetadata0 = new OffsetAndMetadata(kafkaSpoutConfig0.DEFAULT_POLL_TIMEOUT_MS, optional0, string0);
      assertNotNull(offsetAndMetadata0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertFalse(integer0.equals((Object)int0));
      assertFalse(integer0.equals((Object)int1));
      assertEquals("with-open only allows Symbols in bindings", offsetAndMetadata0.metadata());
      assertEquals(200L, offsetAndMetadata0.offset());
      
      String string3 = offsetAndMetadata0.toString();
      assertEquals("OffsetAndMetadata{offset=200, leaderEpoch=10000000, metadata='with-open only allows Symbols in bindings'}", string3);
      assertNotNull(string3);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertFalse(integer0.equals((Object)int0));
      assertFalse(integer0.equals((Object)int1));
      assertFalse(string3.equals((Object)string0));
      assertFalse(string3.equals((Object)string2));
      assertFalse(string3.equals((Object)string1));
      assertNotSame(string0, string1);
      assertNotSame(string0, string2);
      assertNotSame(string0, string3);
      assertNotSame(string3, string0);
      assertNotSame(string3, string2);
      assertNotSame(string3, string1);
      assertEquals("with-open only allows Symbols in bindings", offsetAndMetadata0.metadata());
      assertEquals(200L, offsetAndMetadata0.offset());
      
      kafkaSpout_OffsetEntry0.commit(offsetAndMetadata0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertFalse(string0.equals((Object)string3));
      assertFalse(long0 == long1);
      assertFalse(integer0.equals((Object)int0));
      assertFalse(integer0.equals((Object)int1));
      assertNotSame(string0, string1);
      assertNotSame(string0, string2);
      assertNotSame(string0, string3);
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("with-open only allows Symbols in bindings", offsetAndMetadata0.metadata());
      assertEquals(200L, offsetAndMetadata0.offset());
      
      KafkaSpoutStreams kafkaSpoutStreams1 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<Object, OffsetAndMetadata> kafkaSpoutConfig1 = (KafkaSpoutConfig<Object, OffsetAndMetadata>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams1).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<Object, OffsetAndMetadata> kafkaSpout1 = new KafkaSpout<Object, OffsetAndMetadata>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      String string4 = kafkaSpout1.toString();
      assertEquals("KafkaSpout{acked=null, emitted=null}", string4);
      assertNotNull(string4);
      assertFalse(string4.equals((Object)string0));
      assertFalse(string4.equals((Object)string3));
      assertFalse(string4.equals((Object)string2));
      assertFalse(string4.equals((Object)string1));
      assertNotSame(string4, string0);
      assertNotSame(string4, string3);
      assertNotSame(string4, string2);
      assertNotSame(string4, string1);
      
      kafkaSpout1.nextTuple();
      long long2 = (-1L);
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry1 = kafkaSpout0.new OffsetEntry(topicPartition0, long2);
      assertNotNull(kafkaSpout_OffsetEntry1);
      assertFalse(string0.equals((Object)string4));
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertFalse(string0.equals((Object)string3));
      assertFalse(long2 == long0);
      assertFalse(long2 == long1);
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      
      boolean boolean0 = kafkaSpout_OffsetEntry1.contains(consumerRecord0);
      assertFalse(boolean0);
      assertFalse(string0.equals((Object)string4));
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertFalse(string0.equals((Object)string3));
      assertFalse(long0 == long2);
      assertFalse(long0 == long1);
      assertFalse(string1.equals((Object)string2));
      assertFalse(string1.equals((Object)string4));
      assertFalse(string1.equals((Object)string3));
      assertFalse(string1.equals((Object)string0));
      assertFalse(int0 == int1);
      assertFalse(long1 == long2);
      assertFalse(long1 == long0);
      assertFalse(int1 == int0);
      assertFalse(long2 == long0);
      assertFalse(long2 == long1);
      assertNotSame(string0, string4);
      assertNotSame(string0, string1);
      assertNotSame(string0, string2);
      assertNotSame(string0, string3);
      assertNotSame(string1, string2);
      assertNotSame(string1, string4);
      assertNotSame(string1, string3);
      assertNotSame(string1, string0);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals(1076L, consumerRecord0.timestamp());
      assertEquals(5208, consumerRecord0.partition());
      assertEquals(505, consumerRecord0.serializedValueSize());
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals(505, consumerRecord0.serializedKeySize());
      assertEquals("clojure.core$generate_class$iname__6022", consumerRecord0.topic());
      assertEquals(1689L, consumerRecord0.offset());
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      
      kafkaSpout_OffsetEntry1.add(kafkaSpoutMessageId0);
      assertFalse(string0.equals((Object)string4));
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertFalse(string0.equals((Object)string3));
      assertFalse(long0 == long2);
      assertFalse(long0 == long1);
      assertFalse(string1.equals((Object)string2));
      assertFalse(string1.equals((Object)string4));
      assertFalse(string1.equals((Object)string3));
      assertFalse(string1.equals((Object)string0));
      assertFalse(int0 == int1);
      assertFalse(long1 == long2);
      assertFalse(long1 == long0);
      assertFalse(int1 == int0);
      assertFalse(long2 == long0);
      assertFalse(long2 == long1);
      assertNotSame(string0, string4);
      assertNotSame(string0, string1);
      assertNotSame(string0, string2);
      assertNotSame(string0, string3);
      assertNotSame(string1, string2);
      assertNotSame(string1, string4);
      assertNotSame(string1, string3);
      assertNotSame(string1, string0);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals(1076L, consumerRecord0.timestamp());
      assertEquals(5208, consumerRecord0.partition());
      assertEquals(505, consumerRecord0.serializedValueSize());
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals(505, consumerRecord0.serializedKeySize());
      assertEquals("clojure.core$generate_class$iname__6022", consumerRecord0.topic());
      assertEquals(1689L, consumerRecord0.offset());
      assertEquals(5208, kafkaSpoutMessageId0.partition());
      assertEquals("clojure.core$generate_class$iname__6022", kafkaSpoutMessageId0.topic());
      assertEquals(1689L, kafkaSpoutMessageId0.offset());
      assertEquals(1, kafkaSpoutMessageId0.numFails());
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      
      OffsetAndMetadata offsetAndMetadata1 = kafkaSpout_OffsetEntry1.findNextCommitOffset();
      assertNull(offsetAndMetadata1);
      assertFalse(string0.equals((Object)string4));
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertFalse(string0.equals((Object)string3));
      assertFalse(long2 == long0);
      assertFalse(long2 == long1);
      assertNotSame(string0, string4);
      assertNotSame(string0, string1);
      assertNotSame(string0, string2);
      assertNotSame(string0, string3);
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
  }

  @Test(timeout = 11000)
  public void test10()  throws Throwable  {
      StormTopology stormTopology0 = null;
      HashMap<KafkaSpoutStreamsWildcardTopics, Integer> hashMap0 = new HashMap<KafkaSpoutStreamsWildcardTopics, Integer>();
      assertNotNull(hashMap0);
      assertEquals(0, hashMap0.size());
      assertTrue(hashMap0.isEmpty());
      
      Map<Integer, String> map0 = null;
      PersistentTreeMap persistentTreeMap0 = null;
      try {
        persistentTreeMap0 = new PersistentTreeMap();
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
      }
  }

  @Test(timeout = 11000)
  public void test11()  throws Throwable  {
      KafkaSpoutStreams kafkaSpoutStreams0 = null;
      KafkaSpoutConfig<String, HftpFileSystem> kafkaSpoutConfig0 = (KafkaSpoutConfig<String, HftpFileSystem>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<String, HftpFileSystem> kafkaSpout0 = new KafkaSpout<String, HftpFileSystem>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "";
      int int0 = (-1534);
      TopicPartition topicPartition0 = new TopicPartition(string0, int0);
      assertNotNull(topicPartition0);
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      
      long long0 = 0L;
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      
      KafkaSpoutMessageId kafkaSpoutMessageId0 = new KafkaSpoutMessageId(topicPartition0, int0);
      assertNotNull(kafkaSpoutMessageId0);
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      assertEquals((-1534), kafkaSpoutMessageId0.partition());
      assertEquals((-1534L), kafkaSpoutMessageId0.offset());
      assertEquals("", kafkaSpoutMessageId0.topic());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      
      kafkaSpout_OffsetEntry0.add(kafkaSpoutMessageId0);
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      assertEquals((-1534), kafkaSpoutMessageId0.partition());
      assertEquals((-1534L), kafkaSpoutMessageId0.offset());
      assertEquals("", kafkaSpoutMessageId0.topic());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      
      long long1 = 3439L;
      OffsetAndMetadata offsetAndMetadata0 = new OffsetAndMetadata(long1);
      assertNotNull(offsetAndMetadata0);
      assertFalse(long1 == long0);
      assertEquals(3439L, offsetAndMetadata0.offset());
      assertEquals("", offsetAndMetadata0.metadata());
      
      int int1 = (-1468);
      TimestampType timestampType0 = TimestampType.CREATE_TIME;
      int int2 = 3571;
      MapEntry mapEntry0 = null;
      ConsumerRecord<MapEntry, Integer> consumerRecord0 = new ConsumerRecord<MapEntry, Integer>(string0, int1, kafkaSpoutConfig0.DEFAULT_POLL_TIMEOUT_MS, kafkaSpoutConfig0.DEFAULT_OFFSET_COMMIT_PERIOD_MS, timestampType0, kafkaSpoutConfig0.DEFAULT_MAX_RETRIES, int1, int2, mapEntry0, (Integer) kafkaSpoutConfig0.DEFAULT_MAX_RETRIES);
      assertNotNull(consumerRecord0);
      assertFalse(int1 == int2);
      assertFalse(int1 == int0);
      assertFalse(int2 == int1);
      assertFalse(int2 == int0);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals(200L, consumerRecord0.offset());
      assertEquals((-1468), consumerRecord0.serializedKeySize());
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals((-1468), consumerRecord0.partition());
      assertEquals("", consumerRecord0.topic());
      assertEquals(3571, consumerRecord0.serializedValueSize());
      assertEquals(30000L, consumerRecord0.timestamp());
      
      boolean boolean0 = kafkaSpout_OffsetEntry0.contains(consumerRecord0);
      assertFalse(boolean0);
      assertFalse(int0 == int2);
      assertFalse(int0 == int1);
      assertFalse(long0 == long1);
      assertFalse(int1 == int2);
      assertFalse(int1 == int0);
      assertFalse(int2 == int1);
      assertFalse(int2 == int0);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals(200L, consumerRecord0.offset());
      assertEquals((-1468), consumerRecord0.serializedKeySize());
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals((-1468), consumerRecord0.partition());
      assertEquals("", consumerRecord0.topic());
      assertEquals(3571, consumerRecord0.serializedValueSize());
      assertEquals(30000L, consumerRecord0.timestamp());
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      
      Header[] headerArray0 = new Header[2];
      byte[] byteArray0 = new byte[9];
      byte byte0 = (byte) (-92);
      byteArray0[1] = byte0;
      byte byte1 = (byte) (-84);
      byte byte2 = (byte)93;
      byteArray0[3] = byte2;
      byte byte3 = (byte)2;
      byteArray0[4] = byte3;
      byte byte4 = (byte) (-42);
      byteArray0[5] = byte4;
      byteArray0[6] = byte0;
      byte byte5 = (byte) (-88);
      byteArray0[7] = byte5;
      byte byte6 = (byte) (-76);
      byteArray0[8] = byte6;
      RecordHeader recordHeader0 = new RecordHeader(string0, byteArray0);
      assertEquals(9, byteArray0.length);
      assertArrayEquals(new byte[] {(byte)0, (byte) (-92), (byte)0, (byte)93, (byte)2, (byte) (-42), (byte) (-92), (byte) (-88), (byte) (-76)}, byteArray0);
      assertNotNull(recordHeader0);
      assertEquals("", recordHeader0.key());
      
      headerArray0[0] = (Header) recordHeader0;
      RecordHeader recordHeader1 = new RecordHeader(string0, byteArray0);
      assertEquals(9, byteArray0.length);
      assertArrayEquals(new byte[] {(byte)0, (byte) (-92), (byte)0, (byte)93, (byte)2, (byte) (-42), (byte) (-92), (byte) (-88), (byte) (-76)}, byteArray0);
      assertNotNull(recordHeader1);
      assertTrue(recordHeader1.equals((Object)recordHeader0));
      assertEquals("", recordHeader1.key());
      
      headerArray0[1] = (Header) recordHeader1;
      Object object0 = null;
      kafkaSpout_OffsetEntry0.commit(offsetAndMetadata0);
      assertFalse(int0 == int2);
      assertFalse(int0 == int1);
      assertFalse(long0 == long1);
      assertFalse(long1 == long0);
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      assertEquals(3439L, offsetAndMetadata0.offset());
      assertEquals("", offsetAndMetadata0.metadata());
      
      KafkaSpoutConfig<Object, KafkaSpoutStreamsNamedTopics> kafkaSpoutConfig1 = (KafkaSpoutConfig<Object, KafkaSpoutStreamsNamedTopics>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<Object, KafkaSpoutStreamsNamedTopics> kafkaSpout1 = new KafkaSpout<Object, KafkaSpoutStreamsNamedTopics>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      Object object1 = null;
      // Undeclared exception!
      try { 
        kafkaSpout1.fail(object1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test12()  throws Throwable  {
      KafkaSpoutConfig<MapEntry, Header> kafkaSpoutConfig0 = (KafkaSpoutConfig<MapEntry, Header>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<MapEntry, Header> kafkaSpout0 = new KafkaSpout<MapEntry, Header>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      Object[] objectArray0 = new Object[7];
      objectArray0[0] = (Object) kafkaSpout0;
      objectArray0[1] = (Object) kafkaSpout0;
      EvoSuiteFile evoSuiteFile0 = null;
      boolean boolean0 = FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      assertFalse(boolean0);
      
      objectArray0[2] = (Object) kafkaSpout0;
      objectArray0[3] = (Object) kafkaSpoutConfig0;
      objectArray0[4] = (Object) kafkaSpoutConfig0;
      Object object0 = new Object();
      assertNotNull(object0);
      
      objectArray0[5] = object0;
      objectArray0[6] = (Object) kafkaSpout0;
      PersistentArrayMap persistentArrayMap0 = new PersistentArrayMap(objectArray0);
      assertEquals(7, objectArray0.length);
      assertNotNull(persistentArrayMap0);
      assertEquals(3, persistentArrayMap0.count());
      assertEquals(3, persistentArrayMap0.capacity());
      
      kafkaSpout0.acked = (Map<TopicPartition, KafkaSpout.OffsetEntry>) persistentArrayMap0;
      assertEquals(3, persistentArrayMap0.count());
      assertEquals(3, persistentArrayMap0.capacity());
      assertFalse(kafkaSpout0.acked.isEmpty());
      assertEquals(3, kafkaSpout0.acked.size());
      
      kafkaSpout0.nextTuple();
      OutputFieldsGetter outputFieldsGetter0 = new OutputFieldsGetter();
      assertNotNull(outputFieldsGetter0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.deactivate();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test13()  throws Throwable  {
      KafkaSpoutConfig<ExecutorSummary._Fields, String> kafkaSpoutConfig0 = (KafkaSpoutConfig<ExecutorSummary._Fields, String>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<ExecutorSummary._Fields, String> kafkaSpout0 = new KafkaSpout<ExecutorSummary._Fields, String>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = null;
      int int0 = (-247);
      TopicPartition topicPartition0 = new TopicPartition(string0, int0);
      assertNotNull(topicPartition0);
      assertNull(topicPartition0.topic());
      assertEquals((-247), topicPartition0.partition());
      
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertNull(topicPartition0.topic());
      assertEquals((-247), topicPartition0.partition());
  }

  @Test(timeout = 11000)
  public void test14()  throws Throwable  {
      KafkaSpoutConfig<String, Object> kafkaSpoutConfig0 = (KafkaSpoutConfig<String, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<String, Object> kafkaSpout0 = new KafkaSpout<String, Object>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "bootstrap.servers";
      TopicPartition topicPartition0 = new TopicPartition(string0, kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS);
      assertNotNull(topicPartition0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("bootstrap.servers", topicPartition0.topic());
      
      String string1 = topicPartition0.toString();
      assertEquals("bootstrap.servers-10000000", string1);
      assertNotNull(string1);
      assertFalse(string1.equals((Object)string0));
      assertNotSame(string0, string1);
      assertNotSame(string1, string0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("bootstrap.servers", topicPartition0.topic());
      
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, kafkaSpoutConfig0.DEFAULT_MAX_RETRIES);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertFalse(string0.equals((Object)string1));
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("bootstrap.servers", topicPartition0.topic());
      
      long long0 = kafkaSpout_OffsetEntry0.getCommittedOffset();
      assertEquals(2147483646L, long0);
      assertFalse(string0.equals((Object)string1));
      assertNotSame(string0, string1);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("bootstrap.servers", topicPartition0.topic());
      
      KafkaSpoutConfig<ExecutorSummary._Fields, KafkaSpoutStreamsNamedTopics> kafkaSpoutConfig1 = null;
      KafkaSpout<ExecutorSummary._Fields, KafkaSpoutStreamsNamedTopics> kafkaSpout1 = null;
      try {
        kafkaSpout1 = new KafkaSpout<ExecutorSummary._Fields, KafkaSpoutStreamsNamedTopics>(kafkaSpoutConfig1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test15()  throws Throwable  {
      KafkaSpoutConfig<TopicPartition, DelegationTokenIdentifier> kafkaSpoutConfig0 = (KafkaSpoutConfig<TopicPartition, DelegationTokenIdentifier>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<TopicPartition, DelegationTokenIdentifier> kafkaSpout0 = new KafkaSpout<TopicPartition, DelegationTokenIdentifier>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "49l!w5-Y.cp+";
      TopicPartition topicPartition0 = new TopicPartition(string0, kafkaSpoutConfig0.DEFAULT_MAX_RETRIES);
      assertNotNull(topicPartition0);
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("49l!w5-Y.cp+", topicPartition0.topic());
      
      long long0 = (-4878L);
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("49l!w5-Y.cp+", topicPartition0.topic());
      
      boolean boolean0 = kafkaSpout_OffsetEntry0.isEmpty();
      assertTrue(boolean0);
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("49l!w5-Y.cp+", topicPartition0.topic());
  }

  @Test(timeout = 11000)
  public void test16()  throws Throwable  {
      KafkaSpoutConfig<KafkaSpoutStreamsNamedTopics, Object> kafkaSpoutConfig0 = (KafkaSpoutConfig<KafkaSpoutStreamsNamedTopics, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutStreamsNamedTopics, Object> kafkaSpout0 = new KafkaSpout<KafkaSpoutStreamsNamedTopics, Object>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "";
      TopicPartition topicPartition0 = new TopicPartition(string0, kafkaSpoutConfig0.DEFAULT_MAX_RETRIES);
      assertNotNull(topicPartition0);
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("", topicPartition0.topic());
      
      long long0 = 0L;
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("", topicPartition0.topic());
      
      OffsetAndMetadata offsetAndMetadata0 = kafkaSpout_OffsetEntry0.findNextCommitOffset();
      assertNull(offsetAndMetadata0);
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("", topicPartition0.topic());
  }

  @Test(timeout = 11000)
  public void test17()  throws Throwable  {
      KafkaSpoutConfig<KafkaSpoutStreamsWildcardTopics, JMXPrincipal> kafkaSpoutConfig0 = (KafkaSpoutConfig<KafkaSpoutStreamsWildcardTopics, JMXPrincipal>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutStreamsWildcardTopics, JMXPrincipal> kafkaSpout0 = new KafkaSpout<KafkaSpoutStreamsWildcardTopics, JMXPrincipal>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "FIELDS";
      TopicPartition topicPartition0 = new TopicPartition(string0, kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS);
      assertNotNull(topicPartition0);
      assertEquals("FIELDS", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, kafkaSpoutConfig0.DEFAULT_OFFSET_COMMIT_PERIOD_MS);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals("FIELDS", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      
      int int0 = 3;
      KafkaSpoutStreamsNamedTopics kafkaSpoutStreamsNamedTopics0 = mock(KafkaSpoutStreamsNamedTopics.class, new ViolatedAssumptionAnswer());
      ConsumerRecord<String, KafkaSpoutStreamsNamedTopics> consumerRecord0 = new ConsumerRecord<String, KafkaSpoutStreamsNamedTopics>(string0, int0, int0, string0, kafkaSpoutStreamsNamedTopics0);
      assertNotNull(consumerRecord0);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals(TimestampType.NO_TIMESTAMP_TYPE, consumerRecord0.timestampType());
      assertEquals((-1), consumerRecord0.serializedKeySize());
      assertEquals("FIELDS", consumerRecord0.topic());
      assertEquals(3L, consumerRecord0.offset());
      assertEquals((-1), consumerRecord0.serializedValueSize());
      assertEquals(3, consumerRecord0.partition());
      assertEquals((-1L), consumerRecord0.timestamp());
      
      boolean boolean0 = kafkaSpout_OffsetEntry0.contains(consumerRecord0);
      assertFalse(boolean0);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals("FIELDS", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      assertEquals(TimestampType.NO_TIMESTAMP_TYPE, consumerRecord0.timestampType());
      assertEquals((-1), consumerRecord0.serializedKeySize());
      assertEquals("FIELDS", consumerRecord0.topic());
      assertEquals(3L, consumerRecord0.offset());
      assertEquals((-1), consumerRecord0.serializedValueSize());
      assertEquals(3, consumerRecord0.partition());
      assertEquals((-1L), consumerRecord0.timestamp());
      
      KafkaSpoutConfig<KafkaSpout<Integer, ExecutorSummary._Fields>, String> kafkaSpoutConfig1 = (KafkaSpoutConfig<KafkaSpout<Integer, ExecutorSummary._Fields>, String>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpout<Integer, ExecutorSummary._Fields>, String> kafkaSpout1 = new KafkaSpout<KafkaSpout<Integer, ExecutorSummary._Fields>, String>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      // Undeclared exception!
      try { 
        kafkaSpout1.deactivate();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test18()  throws Throwable  {
      KafkaSpoutConfig<OffsetAndMetadata, Object> kafkaSpoutConfig0 = (KafkaSpoutConfig<OffsetAndMetadata, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<OffsetAndMetadata, Object> kafkaSpout0 = new KafkaSpout<OffsetAndMetadata, Object>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "YJTp3";
      // Undeclared exception!
      try { 
        kafkaSpout0.fail(string0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // java.lang.String cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test19()  throws Throwable  {
      KafkaSpoutConfig<JMXPrincipal, KafkaSpoutStreamsNamedTopics> kafkaSpoutConfig0 = (KafkaSpoutConfig<JMXPrincipal, KafkaSpoutStreamsNamedTopics>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<JMXPrincipal, KafkaSpoutStreamsNamedTopics> kafkaSpout0 = new KafkaSpout<JMXPrincipal, KafkaSpoutStreamsNamedTopics>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      kafkaSpout0.nextTuple();
  }

  @Test(timeout = 11000)
  public void test20()  throws Throwable  {
      KafkaSpoutConfig<Integer, Object> kafkaSpoutConfig0 = (KafkaSpoutConfig<Integer, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<Integer, Object> kafkaSpout0 = new KafkaSpout<Integer, Object>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "SS";
      TopicPartition topicPartition0 = new TopicPartition(string0, kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS);
      assertNotNull(topicPartition0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("SS", topicPartition0.topic());
      
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, kafkaSpoutConfig0.DEFAULT_POLL_TIMEOUT_MS);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("SS", topicPartition0.topic());
      
      String string1 = kafkaSpout_OffsetEntry0.toString();
      assertEquals("OffsetEntry{topic-partition=SS-10000000, fetchOffset=200, committedOffset=199, ackedMsgs=[]}", string1);
      assertNotNull(string1);
      assertFalse(string1.equals((Object)string0));
      assertNotSame(string0, string1);
      assertNotSame(string1, string0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("SS", topicPartition0.topic());
  }

  @Test(timeout = 11000)
  public void test21()  throws Throwable  {
      KafkaSpoutConfig<OffsetAndMetadata, KafkaSpout.OffsetEntry> kafkaSpoutConfig0 = (KafkaSpoutConfig<OffsetAndMetadata, KafkaSpout.OffsetEntry>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<OffsetAndMetadata, KafkaSpout.OffsetEntry> kafkaSpout0 = new KafkaSpout<OffsetAndMetadata, KafkaSpout.OffsetEntry>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      KafkaSpoutConfig<ExecutorSummary._Fields, KafkaSpoutStreamsWildcardTopics> kafkaSpoutConfig1 = null;
      KafkaSpout<ExecutorSummary._Fields, KafkaSpoutStreamsWildcardTopics> kafkaSpout1 = null;
      try {
        kafkaSpout1 = new KafkaSpout<ExecutorSummary._Fields, KafkaSpoutStreamsWildcardTopics>(kafkaSpoutConfig1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test22()  throws Throwable  {
      KafkaSpoutConfig<KafkaSpoutStreamsWildcardTopics, TopicPartition> kafkaSpoutConfig0 = (KafkaSpoutConfig<KafkaSpoutStreamsWildcardTopics, TopicPartition>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutStreamsWildcardTopics, TopicPartition> kafkaSpout0 = new KafkaSpout<KafkaSpoutStreamsWildcardTopics, TopicPartition>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      kafkaSpout0.nextTuple();
      String string0 = "@\\uPOmzVp#{R/9Y";
      int int0 = (-2047);
      TopicPartition topicPartition0 = new TopicPartition(string0, int0);
      assertNotNull(topicPartition0);
      assertEquals((-2047), topicPartition0.partition());
      assertEquals("@\\uPOmzVp#{R/9Y", topicPartition0.topic());
      
      long long0 = (-714L);
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals((-2047), topicPartition0.partition());
      assertEquals("@\\uPOmzVp#{R/9Y", topicPartition0.topic());
      
      long long1 = 1168L;
      KafkaSpoutMessageId kafkaSpoutMessageId0 = new KafkaSpoutMessageId(topicPartition0, long1);
      assertNotNull(kafkaSpoutMessageId0);
      assertFalse(long1 == long0);
      assertEquals((-2047), topicPartition0.partition());
      assertEquals("@\\uPOmzVp#{R/9Y", topicPartition0.topic());
      assertEquals("@\\uPOmzVp#{R/9Y", kafkaSpoutMessageId0.topic());
      assertEquals(1168L, kafkaSpoutMessageId0.offset());
      assertEquals((-2047), kafkaSpoutMessageId0.partition());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      
      boolean boolean0 = kafkaSpout_OffsetEntry0.contains(kafkaSpoutMessageId0);
      assertFalse(boolean0);
      assertFalse(long0 == long1);
      assertFalse(long1 == long0);
      assertEquals((-2047), topicPartition0.partition());
      assertEquals("@\\uPOmzVp#{R/9Y", topicPartition0.topic());
      assertEquals("@\\uPOmzVp#{R/9Y", kafkaSpoutMessageId0.topic());
      assertEquals(1168L, kafkaSpoutMessageId0.offset());
      assertEquals((-2047), kafkaSpoutMessageId0.partition());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
  }

  @Test(timeout = 11000)
  public void test23()  throws Throwable  {
      KafkaSpoutConfig<KafkaSpoutStreamsNamedTopics, KafkaSpoutStreamsWildcardTopics> kafkaSpoutConfig0 = (KafkaSpoutConfig<KafkaSpoutStreamsNamedTopics, KafkaSpoutStreamsWildcardTopics>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutStreamsNamedTopics, KafkaSpoutStreamsWildcardTopics> kafkaSpout0 = new KafkaSpout<KafkaSpoutStreamsNamedTopics, KafkaSpoutStreamsWildcardTopics>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = null;
      int int0 = 0;
      TopicPartition topicPartition0 = new TopicPartition(string0, int0);
      assertNotNull(topicPartition0);
      assertEquals(0, topicPartition0.partition());
      assertNull(topicPartition0.topic());
      
      long long0 = 0L;
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals(0, topicPartition0.partition());
      assertNull(topicPartition0.topic());
      
      KafkaSpoutMessageId kafkaSpoutMessageId0 = null;
      // Undeclared exception!
      try { 
        kafkaSpout_OffsetEntry0.add(kafkaSpoutMessageId0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout$OffsetComparator", e);
      }
  }

  @Test(timeout = 11000)
  public void test24()  throws Throwable  {
      KafkaSpoutConfig<KafkaSpoutMessageId, KafkaSpoutStreamsNamedTopics> kafkaSpoutConfig0 = (KafkaSpoutConfig<KafkaSpoutMessageId, KafkaSpoutStreamsNamedTopics>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutMessageId, KafkaSpoutStreamsNamedTopics> kafkaSpout0 = new KafkaSpout<KafkaSpoutMessageId, KafkaSpoutStreamsNamedTopics>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "i2vN37H#";
      TopicPartition topicPartition0 = new TopicPartition(string0, kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS);
      assertNotNull(topicPartition0);
      assertEquals("i2vN37H#", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals("i2vN37H#", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      
      long long0 = 0L;
      KafkaSpoutMessageId kafkaSpoutMessageId0 = new KafkaSpoutMessageId(topicPartition0, long0);
      assertNotNull(kafkaSpoutMessageId0);
      assertEquals("i2vN37H#", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals(0L, kafkaSpoutMessageId0.offset());
      assertEquals(10000000, kafkaSpoutMessageId0.partition());
      assertEquals("i2vN37H#", kafkaSpoutMessageId0.topic());
      
      kafkaSpout_OffsetEntry0.add(kafkaSpoutMessageId0);
      assertEquals("i2vN37H#", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals(0L, kafkaSpoutMessageId0.offset());
      assertEquals(10000000, kafkaSpoutMessageId0.partition());
      assertEquals("i2vN37H#", kafkaSpoutMessageId0.topic());
      
      KafkaSpoutConfig<ExecutorSummary._Fields, Object> kafkaSpoutConfig1 = (KafkaSpoutConfig<ExecutorSummary._Fields, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<ExecutorSummary._Fields, Object> kafkaSpout1 = new KafkaSpout<ExecutorSummary._Fields, Object>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      // Undeclared exception!
      try { 
        kafkaSpout1.close();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test25()  throws Throwable  {
      KafkaSpoutConfig<KafkaSpoutStreamsNamedTopics, MapEntry> kafkaSpoutConfig0 = (KafkaSpoutConfig<KafkaSpoutStreamsNamedTopics, MapEntry>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutStreamsNamedTopics, MapEntry> kafkaSpout0 = new KafkaSpout<KafkaSpoutStreamsNamedTopics, MapEntry>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "Tv~(Ukw5%";
      int int0 = 2;
      TopicPartition topicPartition0 = new TopicPartition(string0, int0);
      assertNotNull(topicPartition0);
      assertEquals("Tv~(Ukw5%", topicPartition0.topic());
      assertEquals(2, topicPartition0.partition());
      
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, kafkaSpoutConfig0.DEFAULT_MAX_RETRIES);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals("Tv~(Ukw5%", topicPartition0.topic());
      assertEquals(2, topicPartition0.partition());
      
      OffsetAndMetadata offsetAndMetadata0 = null;
      kafkaSpout_OffsetEntry0.commit(offsetAndMetadata0);
      assertEquals("Tv~(Ukw5%", topicPartition0.topic());
      assertEquals(2, topicPartition0.partition());
  }

  @Test(timeout = 11000)
  public void test26()  throws Throwable  {
      KafkaSpoutConfig<KafkaSpout.OffsetEntry, HftpFileSystem> kafkaSpoutConfig0 = (KafkaSpoutConfig<KafkaSpout.OffsetEntry, HftpFileSystem>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpout.OffsetEntry, HftpFileSystem> kafkaSpout0 = new KafkaSpout<KafkaSpout.OffsetEntry, HftpFileSystem>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "sqlAuthorization";
      int int0 = 1418;
      TopicPartition topicPartition0 = new TopicPartition(string0, int0);
      assertNotNull(topicPartition0);
      assertEquals(1418, topicPartition0.partition());
      assertEquals("sqlAuthorization", topicPartition0.topic());
      
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, kafkaSpoutConfig0.DEFAULT_POLL_TIMEOUT_MS);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals(1418, topicPartition0.partition());
      assertEquals("sqlAuthorization", topicPartition0.topic());
      
      long long0 = 0L;
      OffsetAndMetadata offsetAndMetadata0 = new OffsetAndMetadata(long0);
      assertNotNull(offsetAndMetadata0);
      assertEquals("", offsetAndMetadata0.metadata());
      assertEquals(0L, offsetAndMetadata0.offset());
      
      kafkaSpout_OffsetEntry0.commit(offsetAndMetadata0);
      assertEquals(1418, topicPartition0.partition());
      assertEquals("sqlAuthorization", topicPartition0.topic());
      assertEquals("", offsetAndMetadata0.metadata());
      assertEquals(0L, offsetAndMetadata0.offset());
  }

  @Test(timeout = 11000)
  public void test27()  throws Throwable  {
      KafkaSpoutConfig<Integer, Integer> kafkaSpoutConfig0 = (KafkaSpoutConfig<Integer, Integer>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<Integer, Integer> kafkaSpout0 = new KafkaSpout<Integer, Integer>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "";
      TopicPartition topicPartition0 = new TopicPartition(string0, kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS);
      assertNotNull(topicPartition0);
      assertEquals("", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      
      long long0 = 9L;
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals("", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      
      OffsetAndMetadata offsetAndMetadata0 = kafkaSpout_OffsetEntry0.findNextCommitOffset();
      assertNull(offsetAndMetadata0);
      assertEquals("", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      
      OffsetAndMetadata offsetAndMetadata1 = null;
      kafkaSpout_OffsetEntry0.commit(offsetAndMetadata1);
      assertEquals("", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      
      KafkaSpoutConfig<KafkaSpout<OffsetAndMetadata, String>, String> kafkaSpoutConfig1 = (KafkaSpoutConfig<KafkaSpout<OffsetAndMetadata, String>, String>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((Map) null).when(kafkaSpoutConfig1).getKafkaProps();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      doReturn((Deserializer) null).when(kafkaSpoutConfig1).getKeyDeserializer();
      doReturn((Deserializer) null).when(kafkaSpoutConfig1).getValueDeserializer();
      KafkaSpout<KafkaSpout<OffsetAndMetadata, String>, String> kafkaSpout1 = new KafkaSpout<KafkaSpout<OffsetAndMetadata, String>, String>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      kafkaSpout1.nextTuple();
      // Undeclared exception!
      try { 
        kafkaSpout1.activate();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.util.HashMap", e);
      }
  }

  @Test(timeout = 11000)
  public void test28()  throws Throwable  {
      KafkaSpoutConfig<MapEntry, Integer> kafkaSpoutConfig0 = (KafkaSpoutConfig<MapEntry, Integer>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<MapEntry, Integer> kafkaSpout0 = new KafkaSpout<MapEntry, Integer>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = kafkaSpout0.toString();
      assertEquals("KafkaSpout{acked=null, emitted=null}", string0);
      assertNotNull(string0);
  }

  @Test(timeout = 11000)
  public void test29()  throws Throwable  {
      KafkaSpoutConfig<DelegationTokenIdentifier, ConsumerRecord<KafkaSpoutMessageId, OffsetAndMetadata>> kafkaSpoutConfig0 = (KafkaSpoutConfig<DelegationTokenIdentifier, ConsumerRecord<KafkaSpoutMessageId, OffsetAndMetadata>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<DelegationTokenIdentifier, ConsumerRecord<KafkaSpoutMessageId, OffsetAndMetadata>> kafkaSpout0 = new KafkaSpout<DelegationTokenIdentifier, ConsumerRecord<KafkaSpoutMessageId, OffsetAndMetadata>>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      OutputFieldsGetter outputFieldsGetter0 = new OutputFieldsGetter();
      assertNotNull(outputFieldsGetter0);
      
      ConsumerRecords<DelegationTokenIdentifier, ConsumerRecord<KafkaSpoutMessageId, OffsetAndMetadata>> consumerRecords0 = null;
      // Undeclared exception!
      try { 
        kafkaSpout0.setWaitingToEmit(consumerRecords0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test30()  throws Throwable  {
      KafkaSpoutConfig<DelegationTokenIdentifier, ForkJoinTask<KafkaSpoutStreamsWildcardTopics>> kafkaSpoutConfig0 = (KafkaSpoutConfig<DelegationTokenIdentifier, ForkJoinTask<KafkaSpoutStreamsWildcardTopics>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<DelegationTokenIdentifier, ForkJoinTask<KafkaSpoutStreamsWildcardTopics>> kafkaSpout0 = new KafkaSpout<DelegationTokenIdentifier, ForkJoinTask<KafkaSpoutStreamsWildcardTopics>>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "a@;";
      // Undeclared exception!
      try { 
        kafkaSpout0.ack(string0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // java.lang.String cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test31()  throws Throwable  {
      KafkaSpoutConfig<KafkaSpoutMessageId, AbstractMap.SimpleImmutableEntry<TopicPartition, KafkaSpoutMessageId>> kafkaSpoutConfig0 = (KafkaSpoutConfig<KafkaSpoutMessageId, AbstractMap.SimpleImmutableEntry<TopicPartition, KafkaSpoutMessageId>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutMessageId, AbstractMap.SimpleImmutableEntry<TopicPartition, KafkaSpoutMessageId>> kafkaSpout0 = new KafkaSpout<KafkaSpoutMessageId, AbstractMap.SimpleImmutableEntry<TopicPartition, KafkaSpoutMessageId>>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      OutputFieldsGetter outputFieldsGetter0 = new OutputFieldsGetter();
      assertNotNull(outputFieldsGetter0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.declareOutputFields(outputFieldsGetter0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test32()  throws Throwable  {
      KafkaSpoutConfig<Integer, ExecutorSummary._Fields> kafkaSpoutConfig0 = (KafkaSpoutConfig<Integer, ExecutorSummary._Fields>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<Integer, ExecutorSummary._Fields> kafkaSpout0 = new KafkaSpout<Integer, ExecutorSummary._Fields>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = null;
      long long0 = 0L;
      long long1 = 1379L;
      long long2 = 0L;
      long long3 = (-382L);
      DelegationTokenSecretManager delegationTokenSecretManager0 = new DelegationTokenSecretManager(long0, long1, long2, long3);
      assertNotNull(delegationTokenSecretManager0);
      assertFalse(long0 == long1);
      assertFalse(long0 == long3);
      assertFalse(long1 == long0);
      assertFalse(long1 == long3);
      assertFalse(long1 == long2);
      assertFalse(long2 == long1);
      assertFalse(long2 == long3);
      assertFalse(long3 == long2);
      assertFalse(long3 == long0);
      assertFalse(long3 == long1);
      assertFalse(delegationTokenSecretManager0.isRunning());
      
      DelegationTokenIdentifier delegationTokenIdentifier0 = delegationTokenSecretManager0.createIdentifier();
      assertNotNull(delegationTokenIdentifier0);
      assertFalse(long0 == long1);
      assertFalse(long0 == long3);
      assertFalse(long1 == long0);
      assertFalse(long1 == long3);
      assertFalse(long1 == long2);
      assertFalse(long2 == long1);
      assertFalse(long2 == long3);
      assertFalse(long3 == long2);
      assertFalse(long3 == long0);
      assertFalse(long3 == long1);
      assertFalse(delegationTokenSecretManager0.isRunning());
      assertEquals(0, delegationTokenIdentifier0.getMasterKeyId());
      assertEquals(0L, delegationTokenIdentifier0.getIssueDate());
      assertEquals(0L, delegationTokenIdentifier0.getMaxDate());
      assertEquals(0, delegationTokenIdentifier0.getSequenceNumber());
      
      // Undeclared exception!
      try { 
        kafkaSpout0.ack(delegationTokenIdentifier0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // org.apache.hadoop.hive.thrift.DelegationTokenIdentifier cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test33()  throws Throwable  {
      KafkaSpoutConfig<OffsetAndMetadata, KafkaSpoutMessageId> kafkaSpoutConfig0 = (KafkaSpoutConfig<OffsetAndMetadata, KafkaSpoutMessageId>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<OffsetAndMetadata, KafkaSpoutMessageId> kafkaSpout0 = new KafkaSpout<OffsetAndMetadata, KafkaSpoutMessageId>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      kafkaSpout0.nextTuple();
      KafkaSpoutConfig<KafkaSpoutStreamsWildcardTopics, Object> kafkaSpoutConfig1 = (KafkaSpoutConfig<KafkaSpoutStreamsWildcardTopics, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutStreamsWildcardTopics, Object> kafkaSpout1 = new KafkaSpout<KafkaSpoutStreamsWildcardTopics, Object>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      kafkaSpout1.nextTuple();
      KafkaSpoutConfig<Integer, ExecutorSummary._Fields> kafkaSpoutConfig2 = (KafkaSpoutConfig<Integer, ExecutorSummary._Fields>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig2).getKafkaSpoutStreams();
      KafkaSpout<Integer, ExecutorSummary._Fields> kafkaSpout2 = new KafkaSpout<Integer, ExecutorSummary._Fields>(kafkaSpoutConfig2);
      assertNotNull(kafkaSpout2);
      
      // Undeclared exception!
      try { 
        kafkaSpout2.close();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test34()  throws Throwable  {
      KafkaSpoutConfig<String, OffsetAndMetadata> kafkaSpoutConfig0 = (KafkaSpoutConfig<String, OffsetAndMetadata>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<String, OffsetAndMetadata> kafkaSpout0 = new KafkaSpout<String, OffsetAndMetadata>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = kafkaSpout0.toString();
      assertEquals("KafkaSpout{acked=null, emitted=null}", string0);
      assertNotNull(string0);
      
      String string1 = kafkaSpout0.toString();
      assertEquals("KafkaSpout{acked=null, emitted=null}", string1);
      assertNotNull(string1);
      assertTrue(string1.equals((Object)string0));
      assertNotSame(string1, string0);
      
      OutputFieldsGetter outputFieldsGetter0 = new OutputFieldsGetter();
      assertNotNull(outputFieldsGetter0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.declareOutputFields(outputFieldsGetter0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test35()  throws Throwable  {
      KafkaSpoutConfig<AbstractMap.SimpleEntry<String, KafkaSpoutStreamsNamedTopics>, ForkJoinTask<KafkaSpoutMessageId>> kafkaSpoutConfig0 = (KafkaSpoutConfig<AbstractMap.SimpleEntry<String, KafkaSpoutStreamsNamedTopics>, ForkJoinTask<KafkaSpoutMessageId>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((String) null).when(kafkaSpoutConfig0).getConsumerGroupId();
      doReturn((Map) null).when(kafkaSpoutConfig0).getKafkaProps();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<AbstractMap.SimpleEntry<String, KafkaSpoutStreamsNamedTopics>, ForkJoinTask<KafkaSpoutMessageId>> kafkaSpout0 = new KafkaSpout<AbstractMap.SimpleEntry<String, KafkaSpoutStreamsNamedTopics>, ForkJoinTask<KafkaSpoutMessageId>>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.getComponentConfiguration();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test36()  throws Throwable  {
      KafkaSpoutConfig<String, ConsumerRecord<Object, KafkaSpoutStreamsWildcardTopics>> kafkaSpoutConfig0 = (KafkaSpoutConfig<String, ConsumerRecord<Object, KafkaSpoutStreamsWildcardTopics>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<String, ConsumerRecord<Object, KafkaSpoutStreamsWildcardTopics>> kafkaSpout0 = new KafkaSpout<String, ConsumerRecord<Object, KafkaSpoutStreamsWildcardTopics>>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      TreeMap<TopicPartition, List<ConsumerRecord<String, ConsumerRecord<Object, KafkaSpoutStreamsWildcardTopics>>>> treeMap0 = new TreeMap<TopicPartition, List<ConsumerRecord<String, ConsumerRecord<Object, KafkaSpoutStreamsWildcardTopics>>>>();
      assertNotNull(treeMap0);
      assertEquals(0, treeMap0.size());
      
      ConsumerRecords<String, ConsumerRecord<Object, KafkaSpoutStreamsWildcardTopics>> consumerRecords0 = new ConsumerRecords<String, ConsumerRecord<Object, KafkaSpoutStreamsWildcardTopics>>(treeMap0);
      assertNotNull(consumerRecords0);
      assertEquals(0, treeMap0.size());
      assertTrue(consumerRecords0.isEmpty());
      
      String string0 = "@3-9";
      Iterable<ConsumerRecord<String, ConsumerRecord<Object, KafkaSpoutStreamsWildcardTopics>>> iterable0 = consumerRecords0.records(string0);
      assertNotNull(iterable0);
      assertEquals(0, treeMap0.size());
      assertTrue(consumerRecords0.isEmpty());
      
      Set<TopicPartition> set0 = consumerRecords0.partitions();
      assertNotNull(set0);
      assertEquals(0, treeMap0.size());
      assertTrue(consumerRecords0.isEmpty());
      assertEquals(0, set0.size());
      assertTrue(set0.isEmpty());
      
      kafkaSpout0.setWaitingToEmit(consumerRecords0);
      assertEquals(0, treeMap0.size());
      assertTrue(consumerRecords0.isEmpty());
      
      KafkaSpoutConfig<KafkaSpoutMessageId, KafkaSpout.OffsetEntry> kafkaSpoutConfig1 = (KafkaSpoutConfig<KafkaSpoutMessageId, KafkaSpout.OffsetEntry>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutMessageId, KafkaSpout.OffsetEntry> kafkaSpout1 = new KafkaSpout<KafkaSpoutMessageId, KafkaSpout.OffsetEntry>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      // Undeclared exception!
      try { 
        kafkaSpout1.deactivate();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test37()  throws Throwable  {
      KafkaSpoutConfig.FirstPollOffsetStrategy[] kafkaSpoutConfig_FirstPollOffsetStrategyArray0 = KafkaSpoutConfig.FirstPollOffsetStrategy.values();
      assertEquals(4, kafkaSpoutConfig_FirstPollOffsetStrategyArray0.length);
      assertNotNull(kafkaSpoutConfig_FirstPollOffsetStrategyArray0);
      
      KafkaSpoutConfig.FirstPollOffsetStrategy[] kafkaSpoutConfig_FirstPollOffsetStrategyArray1 = KafkaSpoutConfig.FirstPollOffsetStrategy.values();
      assertEquals(4, kafkaSpoutConfig_FirstPollOffsetStrategyArray1.length);
      assertNotNull(kafkaSpoutConfig_FirstPollOffsetStrategyArray1);
      assertFalse(kafkaSpoutConfig_FirstPollOffsetStrategyArray1.equals((Object)kafkaSpoutConfig_FirstPollOffsetStrategyArray0));
      assertNotSame(kafkaSpoutConfig_FirstPollOffsetStrategyArray1, kafkaSpoutConfig_FirstPollOffsetStrategyArray0);
      
      KafkaSpoutConfig<DelegationTokenIdentifier, Integer> kafkaSpoutConfig0 = (KafkaSpoutConfig<DelegationTokenIdentifier, Integer>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<DelegationTokenIdentifier, Integer> kafkaSpout0 = new KafkaSpout<DelegationTokenIdentifier, Integer>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "fA_m";
      TopicPartition topicPartition0 = new TopicPartition(string0, kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS);
      assertNotNull(topicPartition0);
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      
      long long0 = 1L;
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      
      long long1 = 0L;
      KafkaSpoutMessageId kafkaSpoutMessageId0 = new KafkaSpoutMessageId(topicPartition0, long1);
      assertNotNull(kafkaSpoutMessageId0);
      assertFalse(long1 == long0);
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals(0L, kafkaSpoutMessageId0.offset());
      assertEquals("fA_m", kafkaSpoutMessageId0.topic());
      assertEquals(10000000, kafkaSpoutMessageId0.partition());
      
      kafkaSpout_OffsetEntry0.add(kafkaSpoutMessageId0);
      assertFalse(long0 == long1);
      assertFalse(long1 == long0);
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals(0L, kafkaSpoutMessageId0.offset());
      assertEquals("fA_m", kafkaSpoutMessageId0.topic());
      assertEquals(10000000, kafkaSpoutMessageId0.partition());
      
      OffsetAndMetadata offsetAndMetadata0 = kafkaSpout_OffsetEntry0.findNextCommitOffset();
      assertNull(offsetAndMetadata0);
      assertFalse(long0 == long1);
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      
      boolean boolean0 = kafkaSpout_OffsetEntry0.isEmpty();
      assertFalse(boolean0);
      assertFalse(long0 == long1);
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals(10000000, topicPartition0.partition());
      
      KafkaSpoutConfig<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>> kafkaSpoutConfig1 = (KafkaSpoutConfig<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>> kafkaSpout1 = new KafkaSpout<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      OutputFieldsGetter outputFieldsGetter0 = new OutputFieldsGetter();
      assertNotNull(outputFieldsGetter0);
      
      // Undeclared exception!
      try { 
        kafkaSpout1.declareOutputFields(outputFieldsGetter0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test38()  throws Throwable  {
      KafkaSpoutConfig<KafkaSpoutStreamsNamedTopics, Integer> kafkaSpoutConfig0 = (KafkaSpoutConfig<KafkaSpoutStreamsNamedTopics, Integer>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutStreamsNamedTopics, Integer> kafkaSpout0 = new KafkaSpout<KafkaSpoutStreamsNamedTopics, Integer>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      Object object0 = null;
      // Undeclared exception!
      try { 
        kafkaSpout0.ack(object0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test39()  throws Throwable  {
      KafkaSpoutConfig<DelegationTokenIdentifier, Object> kafkaSpoutConfig0 = (KafkaSpoutConfig<DelegationTokenIdentifier, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((String) null).when(kafkaSpoutConfig0).getConsumerGroupId();
      doReturn((Map) null).when(kafkaSpoutConfig0).getKafkaProps();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<DelegationTokenIdentifier, Object> kafkaSpout0 = new KafkaSpout<DelegationTokenIdentifier, Object>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.getComponentConfiguration();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test40()  throws Throwable  {
      KafkaSpoutConfig<Integer, KafkaSpoutMessageId> kafkaSpoutConfig0 = (KafkaSpoutConfig<Integer, KafkaSpoutMessageId>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<Integer, KafkaSpoutMessageId> kafkaSpout0 = new KafkaSpout<Integer, KafkaSpoutMessageId>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "0ryl~&a^8iDj*ifty>K";
      int int0 = 1;
      TopicPartition topicPartition0 = new TopicPartition(string0, int0);
      assertNotNull(topicPartition0);
      assertEquals(1, topicPartition0.partition());
      assertEquals("0ryl~&a^8iDj*ifty>K", topicPartition0.topic());
      
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, kafkaSpoutConfig0.DEFAULT_POLL_TIMEOUT_MS);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals(1, topicPartition0.partition());
      assertEquals("0ryl~&a^8iDj*ifty>K", topicPartition0.topic());
      
      String string1 = null;
      Object[] objectArray0 = new Object[5];
      objectArray0[0] = (Object) topicPartition0;
      objectArray0[1] = (Object) string1;
      objectArray0[2] = (Object) topicPartition0;
      objectArray0[3] = (Object) string1;
      objectArray0[4] = (Object) kafkaSpout_OffsetEntry0;
      PersistentArrayMap persistentArrayMap0 = PersistentArrayMap.createAsIfByAssoc(objectArray0);
      assertEquals(5, objectArray0.length);
      assertNotNull(persistentArrayMap0);
      assertEquals(2, persistentArrayMap0.count());
      assertEquals(2, persistentArrayMap0.capacity());
      
      ConsumerRecords<Integer, KafkaSpoutMessageId> consumerRecords0 = new ConsumerRecords<Integer, KafkaSpoutMessageId>(persistentArrayMap0);
      assertEquals(5, objectArray0.length);
      assertNotNull(consumerRecords0);
      assertEquals(2, persistentArrayMap0.count());
      assertEquals(2, persistentArrayMap0.capacity());
      assertFalse(consumerRecords0.isEmpty());
      
      // Undeclared exception!
      try { 
        kafkaSpout0.setWaitingToEmit(consumerRecords0);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // org.apache.kafka.common.TopicPartition cannot be cast to java.util.List
         //
         verifyException("org.apache.kafka.clients.consumer.ConsumerRecords", e);
      }
  }

  @Test(timeout = 11000)
  public void test41()  throws Throwable  {
      KafkaSpoutConfig<TopicPartition, MapEntry> kafkaSpoutConfig0 = (KafkaSpoutConfig<TopicPartition, MapEntry>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<TopicPartition, MapEntry> kafkaSpout0 = new KafkaSpout<TopicPartition, MapEntry>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "}eaS";
      TopicPartition topicPartition0 = new TopicPartition(string0, kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS);
      assertNotNull(topicPartition0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("}eaS", topicPartition0.topic());
      
      long long0 = 0L;
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("}eaS", topicPartition0.topic());
      
      OffsetAndMetadata offsetAndMetadata0 = kafkaSpout_OffsetEntry0.findNextCommitOffset();
      assertNull(offsetAndMetadata0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("}eaS", topicPartition0.topic());
      
      KafkaSpoutMessageId kafkaSpoutMessageId0 = new KafkaSpoutMessageId(topicPartition0, kafkaSpoutConfig0.DEFAULT_OFFSET_COMMIT_PERIOD_MS);
      assertNotNull(kafkaSpoutMessageId0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("}eaS", topicPartition0.topic());
      assertEquals(10000000, kafkaSpoutMessageId0.partition());
      assertEquals(30000L, kafkaSpoutMessageId0.offset());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals("}eaS", kafkaSpoutMessageId0.topic());
      
      kafkaSpout_OffsetEntry0.add(kafkaSpoutMessageId0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("}eaS", topicPartition0.topic());
      assertEquals(10000000, kafkaSpoutMessageId0.partition());
      assertEquals(30000L, kafkaSpoutMessageId0.offset());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals("}eaS", kafkaSpoutMessageId0.topic());
      
      KafkaSpoutMessageId kafkaSpoutMessageId1 = null;
      // Undeclared exception!
      try { 
        kafkaSpout_OffsetEntry0.add(kafkaSpoutMessageId1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout$OffsetComparator", e);
      }
  }

  @Test(timeout = 11000)
  public void test42()  throws Throwable  {
      KafkaSpoutConfig<KafkaSpout<Object, Integer>, TopicPartition> kafkaSpoutConfig0 = (KafkaSpoutConfig<KafkaSpout<Object, Integer>, TopicPartition>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpout<Object, Integer>, TopicPartition> kafkaSpout0 = new KafkaSpout<KafkaSpout<Object, Integer>, TopicPartition>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      TreeMap<TopicPartition, KafkaSpout.OffsetEntry> treeMap0 = new TreeMap<TopicPartition, KafkaSpout.OffsetEntry>();
      assertNotNull(treeMap0);
      assertEquals(0, treeMap0.size());
      
      kafkaSpout0.acked = (Map<TopicPartition, KafkaSpout.OffsetEntry>) treeMap0;
      assertEquals(0, treeMap0.size());
      assertEquals(0, kafkaSpout0.acked.size());
      assertTrue(kafkaSpout0.acked.isEmpty());
      
      // Undeclared exception!
      try { 
        kafkaSpout0.close();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test43()  throws Throwable  {
      KafkaSpoutConfig<TopicPartition, Object> kafkaSpoutConfig0 = (KafkaSpoutConfig<TopicPartition, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<TopicPartition, Object> kafkaSpout0 = new KafkaSpout<TopicPartition, Object>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "oPf9l*#8`[sou8wlj";
      int int0 = 1636;
      TopicPartition topicPartition0 = new TopicPartition(string0, int0);
      assertNotNull(topicPartition0);
      assertEquals(1636, topicPartition0.partition());
      assertEquals("oPf9l*#8`[sou8wlj", topicPartition0.topic());
      
      Object object0 = null;
      // Undeclared exception!
      try { 
        kafkaSpout0.fail(object0);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test44()  throws Throwable  {
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<String, OffsetAndMetadata> kafkaSpoutConfig0 = (KafkaSpoutConfig<String, OffsetAndMetadata>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<String, OffsetAndMetadata> kafkaSpout0 = new KafkaSpout<String, OffsetAndMetadata>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = kafkaSpout0.toString();
      assertEquals("KafkaSpout{acked=null, emitted=null}", string0);
      assertNotNull(string0);
      
      String string1 = kafkaSpout0.toString();
      assertEquals("KafkaSpout{acked=null, emitted=null}", string1);
      assertNotNull(string1);
      assertTrue(string1.equals((Object)string0));
      assertNotSame(string1, string0);
      
      OutputFieldsGetter outputFieldsGetter0 = new OutputFieldsGetter();
      assertNotNull(outputFieldsGetter0);
      
      kafkaSpout0.declareOutputFields(outputFieldsGetter0);
      KafkaSpoutConfig<DelegationTokenIdentifier, JMXPrincipal> kafkaSpoutConfig1 = (KafkaSpoutConfig<DelegationTokenIdentifier, JMXPrincipal>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((String) null).when(kafkaSpoutConfig1).getConsumerGroupId();
      doReturn((Map) null).when(kafkaSpoutConfig1).getKafkaProps();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<DelegationTokenIdentifier, JMXPrincipal> kafkaSpout1 = new KafkaSpout<DelegationTokenIdentifier, JMXPrincipal>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      // Undeclared exception!
      try { 
        kafkaSpout1.getComponentConfiguration();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test45()  throws Throwable  {
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<BatchUpdateException, Integer> kafkaSpoutConfig0 = (KafkaSpoutConfig<BatchUpdateException, Integer>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<BatchUpdateException, Integer> kafkaSpout0 = new KafkaSpout<BatchUpdateException, Integer>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "R{zi*xN";
      int int0 = 1523;
      TopicPartition topicPartition0 = new TopicPartition(string0, int0);
      assertNotNull(topicPartition0);
      assertEquals("R{zi*xN", topicPartition0.topic());
      assertEquals(1523, topicPartition0.partition());
      
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals("R{zi*xN", topicPartition0.topic());
      assertEquals(1523, topicPartition0.partition());
      
      OffsetAndMetadata offsetAndMetadata0 = kafkaSpout_OffsetEntry0.findNextCommitOffset();
      assertNull(offsetAndMetadata0);
      assertEquals("R{zi*xN", topicPartition0.topic());
      assertEquals(1523, topicPartition0.partition());
      
      String string1 = "Qgg%I7Du/bxX ";
      Map<String, Object> map0 = null;
      KafkaSpoutStreams kafkaSpoutStreams1 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<String, KafkaSpout<ExecutorSummary._Fields, String>> kafkaSpoutConfig1 = (KafkaSpoutConfig<String, KafkaSpout<ExecutorSummary._Fields, String>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(string1).when(kafkaSpoutConfig1).getConsumerGroupId();
      doReturn(map0).when(kafkaSpoutConfig1).getKafkaProps();
      doReturn(kafkaSpoutStreams1).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<String, KafkaSpout<ExecutorSummary._Fields, String>> kafkaSpout1 = new KafkaSpout<String, KafkaSpout<ExecutorSummary._Fields, String>>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      assertFalse(string1.equals((Object)string0));
      
      // Undeclared exception!
      try { 
        kafkaSpout1.getComponentConfiguration();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test46()  throws Throwable  {
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<TopicPartition, BatchUpdateException> kafkaSpoutConfig0 = (KafkaSpoutConfig<TopicPartition, BatchUpdateException>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<TopicPartition, BatchUpdateException> kafkaSpout0 = new KafkaSpout<TopicPartition, BatchUpdateException>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      PersistentArrayMap persistentArrayMap0 = PersistentArrayMap.EMPTY;
      assertNotNull(persistentArrayMap0);
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      
      ConsumerRecords<TopicPartition, BatchUpdateException> consumerRecords0 = new ConsumerRecords<TopicPartition, BatchUpdateException>(persistentArrayMap0);
      assertNotNull(consumerRecords0);
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertTrue(consumerRecords0.isEmpty());
      
      kafkaSpout0.setWaitingToEmit(consumerRecords0);
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertTrue(consumerRecords0.isEmpty());
      
      KafkaSpoutStreams kafkaSpoutStreams1 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      Deserializer<ForkJoinTask<String>> deserializer0 = (Deserializer<ForkJoinTask<String>>) mock(Deserializer.class, new ViolatedAssumptionAnswer());
      Deserializer<ExecutorSummary._Fields> deserializer1 = (Deserializer<ExecutorSummary._Fields>) mock(Deserializer.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<ForkJoinTask<String>, ExecutorSummary._Fields> kafkaSpoutConfig1 = (KafkaSpoutConfig<ForkJoinTask<String>, ExecutorSummary._Fields>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(persistentArrayMap0).when(kafkaSpoutConfig1).getKafkaProps();
      doReturn(kafkaSpoutStreams1).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      doReturn(deserializer0).when(kafkaSpoutConfig1).getKeyDeserializer();
      doReturn(deserializer1).when(kafkaSpoutConfig1).getValueDeserializer();
      KafkaSpout<ForkJoinTask<String>, ExecutorSummary._Fields> kafkaSpout1 = new KafkaSpout<ForkJoinTask<String>, ExecutorSummary._Fields>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      
      // Undeclared exception!
      try { 
        kafkaSpout1.activate();
        fail("Expecting exception: RuntimeException");
      
      } catch(RuntimeException e) {
         //
         // Failed to construct kafka consumer
         //
         verifyException("org.apache.kafka.clients.consumer.KafkaConsumer", e);
      }
  }

  @Test(timeout = 11000)
  public void test47()  throws Throwable  {
      Map<String, Object> map0 = null;
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      Deserializer<JMXPrincipal> deserializer0 = (Deserializer<JMXPrincipal>) mock(Deserializer.class, new ViolatedAssumptionAnswer());
      Deserializer<Object> deserializer1 = null;
      KafkaSpoutConfig<JMXPrincipal, Object> kafkaSpoutConfig0 = (KafkaSpoutConfig<JMXPrincipal, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(map0).when(kafkaSpoutConfig0).getKafkaProps();
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      doReturn(deserializer0).when(kafkaSpoutConfig0).getKeyDeserializer();
      doReturn(deserializer1).when(kafkaSpoutConfig0).getValueDeserializer();
      KafkaSpout<JMXPrincipal, Object> kafkaSpout0 = new KafkaSpout<JMXPrincipal, Object>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.activate();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.util.HashMap", e);
      }
  }

  @Test(timeout = 11000)
  public void test48()  throws Throwable  {
      Comparator<MapEntry> comparator0 = null;
      KafkaSpoutConfig<KafkaSpout.OffsetEntry, KafkaSpoutMessageId> kafkaSpoutConfig0 = (KafkaSpoutConfig<KafkaSpout.OffsetEntry, KafkaSpoutMessageId>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((Map) null).when(kafkaSpoutConfig0).getKafkaProps();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      doReturn((Deserializer) null).when(kafkaSpoutConfig0).getKeyDeserializer();
      doReturn((Deserializer) null).when(kafkaSpoutConfig0).getValueDeserializer();
      KafkaSpout<KafkaSpout.OffsetEntry, KafkaSpoutMessageId> kafkaSpout0 = new KafkaSpout<KafkaSpout.OffsetEntry, KafkaSpoutMessageId>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.activate();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("java.util.HashMap", e);
      }
  }

  @Test(timeout = 11000)
  public void test49()  throws Throwable  {
      KafkaSpoutConfig.FirstPollOffsetStrategy[] kafkaSpoutConfig_FirstPollOffsetStrategyArray0 = KafkaSpoutConfig.FirstPollOffsetStrategy.values();
      assertEquals(4, kafkaSpoutConfig_FirstPollOffsetStrategyArray0.length);
      assertNotNull(kafkaSpoutConfig_FirstPollOffsetStrategyArray0);
      
      KafkaSpoutConfig.FirstPollOffsetStrategy[] kafkaSpoutConfig_FirstPollOffsetStrategyArray1 = KafkaSpoutConfig.FirstPollOffsetStrategy.values();
      assertEquals(4, kafkaSpoutConfig_FirstPollOffsetStrategyArray1.length);
      assertNotNull(kafkaSpoutConfig_FirstPollOffsetStrategyArray1);
      assertFalse(kafkaSpoutConfig_FirstPollOffsetStrategyArray1.equals((Object)kafkaSpoutConfig_FirstPollOffsetStrategyArray0));
      assertNotSame(kafkaSpoutConfig_FirstPollOffsetStrategyArray1, kafkaSpoutConfig_FirstPollOffsetStrategyArray0);
      
      KafkaSpoutStreams kafkaSpoutStreams0 = null;
      KafkaSpoutConfig<DelegationTokenIdentifier, Integer> kafkaSpoutConfig0 = (KafkaSpoutConfig<DelegationTokenIdentifier, Integer>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<DelegationTokenIdentifier, Integer> kafkaSpout0 = new KafkaSpout<DelegationTokenIdentifier, Integer>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "fA_m";
      TopicPartition topicPartition0 = new TopicPartition(string0, kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS);
      assertNotNull(topicPartition0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      
      long long0 = 17L;
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      
      long long1 = 0L;
      KafkaSpoutMessageId kafkaSpoutMessageId0 = new KafkaSpoutMessageId(topicPartition0, long1);
      assertNotNull(kafkaSpoutMessageId0);
      assertFalse(long1 == long0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals(0L, kafkaSpoutMessageId0.offset());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals(10000000, kafkaSpoutMessageId0.partition());
      assertEquals("fA_m", kafkaSpoutMessageId0.topic());
      
      kafkaSpout_OffsetEntry0.add(kafkaSpoutMessageId0);
      assertFalse(long0 == long1);
      assertFalse(long1 == long0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals(0L, kafkaSpoutMessageId0.offset());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals(10000000, kafkaSpoutMessageId0.partition());
      assertEquals("fA_m", kafkaSpoutMessageId0.topic());
      
      OffsetAndMetadata offsetAndMetadata0 = kafkaSpout_OffsetEntry0.findNextCommitOffset();
      assertNull(offsetAndMetadata0);
      assertFalse(long0 == long1);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      
      boolean boolean0 = kafkaSpout_OffsetEntry0.isEmpty();
      assertFalse(boolean0);
      assertFalse(long0 == long1);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      
      KafkaSpoutConfig<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>> kafkaSpoutConfig1 = (KafkaSpoutConfig<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>> kafkaSpout1 = new KafkaSpout<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      OutputFieldsGetter outputFieldsGetter0 = new OutputFieldsGetter();
      assertNotNull(outputFieldsGetter0);
  }

  @Test(timeout = 11000)
  public void test50()  throws Throwable  {
      KafkaSpoutConfig.FirstPollOffsetStrategy kafkaSpoutConfig_FirstPollOffsetStrategy0 = KafkaSpoutConfig.FirstPollOffsetStrategy.UNCOMMITTED_LATEST;
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      int int0 = (-2028178999);
      long long0 = 2196L;
      KafkaSpoutRetryService kafkaSpoutRetryService0 = mock(KafkaSpoutRetryService.class, new ViolatedAssumptionAnswer());
      KafkaSpoutTuplesBuilder<String, Integer> kafkaSpoutTuplesBuilder0 = (KafkaSpoutTuplesBuilder<String, Integer>) mock(KafkaSpoutTuplesBuilder.class, new ViolatedAssumptionAnswer());
      boolean boolean0 = true;
      KafkaSpoutConfig<String, Integer> kafkaSpoutConfig0 = (KafkaSpoutConfig<String, Integer>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutConfig_FirstPollOffsetStrategy0).when(kafkaSpoutConfig0).getFirstPollOffsetStrategy();
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      doReturn(int0).when(kafkaSpoutConfig0).getMaxTupleRetries();
      doReturn(kafkaSpoutRetryService0).when(kafkaSpoutConfig0).getRetryService();
      doReturn(kafkaSpoutTuplesBuilder0).when(kafkaSpoutConfig0).getTuplesBuilder();
      doReturn(boolean0).when(kafkaSpoutConfig0).isConsumerAutoCommitMode();
      KafkaSpout<String, Integer> kafkaSpout0 = new KafkaSpout<String, Integer>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      Map<Object, MapEntry> map0 = null;
      StormTopology stormTopology0 = new StormTopology();
      assertNotNull(stormTopology0);
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_spouts());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertFalse(stormTopology0.is_set_bolts());
      assertFalse(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      
      Map<Integer, String> map1 = null;
      GenerationClauseNode generationClauseNode0 = new GenerationClauseNode();
      assertNotNull(generationClauseNode0);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertNull(generationClauseNode0.getColumnName());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertFalse(generationClauseNode0.isParameterNode());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertFalse(generationClauseNode0.isCloneable());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertNull(generationClauseNode0.getExpressionText());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertNull(generationClauseNode0.getTableName());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertNull(generationClauseNode0.getSchemaName());
      
      ProviderList providerList0 = generationClauseNode0.getAuxiliaryProviderList();
      assertNull(providerList0);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertNull(generationClauseNode0.getColumnName());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertFalse(generationClauseNode0.isParameterNode());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertFalse(generationClauseNode0.isCloneable());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertNull(generationClauseNode0.getExpressionText());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertNull(generationClauseNode0.getTableName());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertNull(generationClauseNode0.getSchemaName());
      
      String string0 = " with assignedTableMap = ";
      String string1 = "e+J,COo~:7hA6~";
      int int1 = (-102);
      Integer integer0 = new Integer(int1);
      assertEquals((-102), (int)integer0);
      assertNotNull(integer0);
      assertFalse(int1 == int0);
      assertFalse(integer0.equals((Object)int0));
      assertTrue(integer0.equals((Object)int1));
      
      int int2 = 944;
      Integer integer1 = new Integer(int2);
      assertEquals(944, (int)integer1);
      assertNotNull(integer1);
      assertFalse(int2 == int0);
      assertFalse(int2 == int1);
      assertFalse(integer1.equals((Object)int1));
      assertFalse(integer1.equals((Object)integer0));
      assertFalse(integer1.equals((Object)int0));
      assertTrue(integer1.equals((Object)int2));
      
      Object[] objectArray0 = new Object[5];
      objectArray0[0] = (Object) providerList0;
      objectArray0[1] = (Object) string1;
      objectArray0[2] = (Object) generationClauseNode0;
      objectArray0[3] = (Object) string0;
      objectArray0[4] = (Object) integer0;
      ArraySeq arraySeq0 = ArraySeq.create(objectArray0);
      assertEquals(5, objectArray0.length);
      assertNotNull(arraySeq0);
      assertEquals(0, arraySeq0.index());
      assertEquals(5, arraySeq0.count());
      assertFalse(arraySeq0.isEmpty());
      
      boolean boolean1 = true;
      AtomicBoolean atomicBoolean0 = new AtomicBoolean(boolean1);
      assertNotNull(atomicBoolean0);
      assertTrue(atomicBoolean0.get());
      assertEquals("true", atomicBoolean0.toString());
      
      TopologyContext topologyContext0 = new TopologyContext(stormTopology0, map0, map1, providerList0, providerList0, string0, string0, string1, integer0, integer1, arraySeq0, providerList0, providerList0, providerList0, providerList0, atomicBoolean0);
      assertEquals(5, objectArray0.length);
      assertNotNull(topologyContext0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string0));
      assertFalse(int1 == int0);
      assertFalse(int1 == int2);
      assertFalse(integer0.equals((Object)int2));
      assertFalse(integer0.equals((Object)integer1));
      assertFalse(integer0.equals((Object)int0));
      assertTrue(integer0.equals((Object)int1));
      assertFalse(int2 == int0);
      assertFalse(int2 == int1);
      assertFalse(integer1.equals((Object)int1));
      assertFalse(integer1.equals((Object)integer0));
      assertFalse(integer1.equals((Object)int0));
      assertTrue(integer1.equals((Object)int2));
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(0, arraySeq0.index());
      assertEquals(5, arraySeq0.count());
      assertFalse(arraySeq0.isEmpty());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_spouts());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertFalse(stormTopology0.is_set_bolts());
      assertFalse(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertTrue(atomicBoolean0.get());
      assertEquals("true", atomicBoolean0.toString());
      assertNull(generationClauseNode0.getColumnName());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertFalse(generationClauseNode0.isParameterNode());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertFalse(generationClauseNode0.isCloneable());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertNull(generationClauseNode0.getExpressionText());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertNull(generationClauseNode0.getTableName());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertNull(generationClauseNode0.getSchemaName());
      assertEquals(" with assignedTableMap = ", topologyContext0.getStormId());
      assertEquals(944, (int)topologyContext0.getThisWorkerPort());
      assertEquals("/home/CIN/lmps2/semantic-conflict-study/SMAT/output-test-dest/storm/bd1f5c54752f67b484a83c26667331234234d3a3/evosuite_2/e+J,COo~:7hA6~", topologyContext0.getPIDDir());
      assertEquals(" with assignedTableMap = ", topologyContext0.getCodeDir());
      assertEquals((-102), topologyContext0.getThisTaskId());
      
      KafkaSpoutStreams kafkaSpoutStreams1 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<ExecutorSummary._Fields, OffsetAndMetadata> kafkaSpoutConfig1 = (KafkaSpoutConfig<ExecutorSummary._Fields, OffsetAndMetadata>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams1).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<ExecutorSummary._Fields, OffsetAndMetadata> kafkaSpout1 = new KafkaSpout<ExecutorSummary._Fields, OffsetAndMetadata>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      SpoutOutputCollector spoutOutputCollector0 = kafkaSpout1.collector;
      assertNull(spoutOutputCollector0);
      
      kafkaSpout0.open(map0, topologyContext0, spoutOutputCollector0);
      assertEquals(5, objectArray0.length);
      assertFalse(int0 == int1);
      assertFalse(int0 == int2);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string0));
      assertFalse(int1 == int0);
      assertFalse(int1 == int2);
      assertFalse(integer0.equals((Object)int2));
      assertFalse(integer0.equals((Object)integer1));
      assertFalse(integer0.equals((Object)int0));
      assertTrue(integer0.equals((Object)int1));
      assertFalse(int2 == int0);
      assertFalse(int2 == int1);
      assertFalse(integer1.equals((Object)int1));
      assertFalse(integer1.equals((Object)integer0));
      assertFalse(integer1.equals((Object)int0));
      assertTrue(integer1.equals((Object)int2));
      assertNotSame(string0, string1);
      assertNotSame(string1, string0);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(0, arraySeq0.index());
      assertEquals(5, arraySeq0.count());
      assertFalse(arraySeq0.isEmpty());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_spouts());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertFalse(stormTopology0.is_set_bolts());
      assertFalse(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertTrue(atomicBoolean0.get());
      assertEquals("true", atomicBoolean0.toString());
      assertNull(generationClauseNode0.getColumnName());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertFalse(generationClauseNode0.isParameterNode());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertFalse(generationClauseNode0.isCloneable());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertNull(generationClauseNode0.getExpressionText());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertNull(generationClauseNode0.getTableName());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertNull(generationClauseNode0.getSchemaName());
      assertEquals(" with assignedTableMap = ", topologyContext0.getStormId());
      assertEquals(944, (int)topologyContext0.getThisWorkerPort());
      assertEquals("/home/CIN/lmps2/semantic-conflict-study/SMAT/output-test-dest/storm/bd1f5c54752f67b484a83c26667331234234d3a3/evosuite_2/e+J,COo~:7hA6~", topologyContext0.getPIDDir());
      assertEquals(" with assignedTableMap = ", topologyContext0.getCodeDir());
      assertEquals((-102), topologyContext0.getThisTaskId());
      
      // Undeclared exception!
      try { 
        kafkaSpout0.close();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test51()  throws Throwable  {
      KafkaSpoutConfig.FirstPollOffsetStrategy[] kafkaSpoutConfig_FirstPollOffsetStrategyArray0 = KafkaSpoutConfig.FirstPollOffsetStrategy.values();
      assertEquals(4, kafkaSpoutConfig_FirstPollOffsetStrategyArray0.length);
      assertNotNull(kafkaSpoutConfig_FirstPollOffsetStrategyArray0);
      
      KafkaSpoutConfig.FirstPollOffsetStrategy[] kafkaSpoutConfig_FirstPollOffsetStrategyArray1 = KafkaSpoutConfig.FirstPollOffsetStrategy.values();
      assertEquals(4, kafkaSpoutConfig_FirstPollOffsetStrategyArray1.length);
      assertNotNull(kafkaSpoutConfig_FirstPollOffsetStrategyArray1);
      assertFalse(kafkaSpoutConfig_FirstPollOffsetStrategyArray1.equals((Object)kafkaSpoutConfig_FirstPollOffsetStrategyArray0));
      assertNotSame(kafkaSpoutConfig_FirstPollOffsetStrategyArray1, kafkaSpoutConfig_FirstPollOffsetStrategyArray0);
      
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<DelegationTokenIdentifier, Integer> kafkaSpoutConfig0 = (KafkaSpoutConfig<DelegationTokenIdentifier, Integer>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<DelegationTokenIdentifier, Integer> kafkaSpout0 = new KafkaSpout<DelegationTokenIdentifier, Integer>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "fA_m";
      TopicPartition topicPartition0 = new TopicPartition(string0, kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS);
      assertNotNull(topicPartition0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      
      long long0 = 1L;
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      
      long long1 = 47L;
      KafkaSpoutMessageId kafkaSpoutMessageId0 = new KafkaSpoutMessageId(topicPartition0, long1);
      assertNotNull(kafkaSpoutMessageId0);
      assertFalse(long1 == long0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals("fA_m", kafkaSpoutMessageId0.topic());
      assertEquals(47L, kafkaSpoutMessageId0.offset());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals(10000000, kafkaSpoutMessageId0.partition());
      
      kafkaSpout_OffsetEntry0.add(kafkaSpoutMessageId0);
      assertFalse(long0 == long1);
      assertFalse(long1 == long0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals("fA_m", kafkaSpoutMessageId0.topic());
      assertEquals(47L, kafkaSpoutMessageId0.offset());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals(10000000, kafkaSpoutMessageId0.partition());
      
      OffsetAndMetadata offsetAndMetadata0 = kafkaSpout_OffsetEntry0.findNextCommitOffset();
      assertNull(offsetAndMetadata0);
      assertFalse(long0 == long1);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      
      boolean boolean0 = kafkaSpout_OffsetEntry0.isEmpty();
      assertFalse(boolean0);
      assertFalse(long0 == long1);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      
      KafkaSpoutStreams kafkaSpoutStreams1 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>> kafkaSpoutConfig1 = (KafkaSpoutConfig<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams1).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>> kafkaSpout1 = new KafkaSpout<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
  }

  @Test(timeout = 11000)
  public void test52()  throws Throwable  {
      KafkaSpoutConfig.FirstPollOffsetStrategy kafkaSpoutConfig_FirstPollOffsetStrategy0 = KafkaSpoutConfig.FirstPollOffsetStrategy.UNCOMMITTED_EARLIEST;
      KafkaSpoutConfig<String, Integer> kafkaSpoutConfig0 = (KafkaSpoutConfig<String, Integer>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutConfig.FirstPollOffsetStrategy) null).when(kafkaSpoutConfig0).getFirstPollOffsetStrategy();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      doReturn(0).when(kafkaSpoutConfig0).getMaxTupleRetries();
      doReturn(0L).when(kafkaSpoutConfig0).getOffsetsCommitPeriodMs();
      doReturn((KafkaSpoutRetryService) null).when(kafkaSpoutConfig0).getRetryService();
      doReturn((KafkaSpoutTuplesBuilder) null).when(kafkaSpoutConfig0).getTuplesBuilder();
      doReturn(false).when(kafkaSpoutConfig0).isConsumerAutoCommitMode();
      KafkaSpout<String, Integer> kafkaSpout0 = new KafkaSpout<String, Integer>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      Map<Object, MapEntry> map0 = null;
      StormTopology stormTopology0 = new StormTopology();
      assertNotNull(stormTopology0);
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_spouts());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertFalse(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertFalse(stormTopology0.is_set_bolts());
      
      Map<Integer, String> map1 = null;
      GenerationClauseNode generationClauseNode0 = new GenerationClauseNode();
      assertNotNull(generationClauseNode0);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertFalse(generationClauseNode0.updatableByCursor());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertFalse(generationClauseNode0.isParameterNode());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertNull(generationClauseNode0.getColumnName());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertFalse(generationClauseNode0.isCloneable());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertNull(generationClauseNode0.getTableName());
      assertNull(generationClauseNode0.getExpressionText());
      assertNull(generationClauseNode0.getSchemaName());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      
      ProviderList providerList0 = generationClauseNode0.getAuxiliaryProviderList();
      assertNull(providerList0);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertFalse(generationClauseNode0.updatableByCursor());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertFalse(generationClauseNode0.isParameterNode());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertNull(generationClauseNode0.getColumnName());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertFalse(generationClauseNode0.isCloneable());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertNull(generationClauseNode0.getTableName());
      assertNull(generationClauseNode0.getExpressionText());
      assertNull(generationClauseNode0.getSchemaName());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      
      String string0 = " with assignedTableMap = ";
      String string1 = "e+J,COo~:7hA6~";
      int int0 = (-102);
      Integer integer0 = new Integer(int0);
      assertEquals((-102), (int)integer0);
      assertNotNull(integer0);
      assertTrue(integer0.equals((Object)int0));
      
      int int1 = 944;
      Integer integer1 = new Integer(int1);
      assertEquals(944, (int)integer1);
      assertNotNull(integer1);
      assertFalse(int1 == int0);
      assertTrue(integer1.equals((Object)int1));
      assertFalse(integer1.equals((Object)int0));
      assertFalse(integer1.equals((Object)integer0));
      
      Object[] objectArray0 = new Object[5];
      objectArray0[0] = (Object) providerList0;
      objectArray0[1] = (Object) string1;
      objectArray0[2] = (Object) generationClauseNode0;
      objectArray0[3] = (Object) string0;
      objectArray0[4] = (Object) integer0;
      ArraySeq arraySeq0 = ArraySeq.create(objectArray0);
      assertEquals(5, objectArray0.length);
      assertNotNull(arraySeq0);
      assertFalse(arraySeq0.isEmpty());
      assertEquals(5, arraySeq0.count());
      assertEquals(0, arraySeq0.index());
      
      boolean boolean0 = true;
      AtomicBoolean atomicBoolean0 = new AtomicBoolean(boolean0);
      assertNotNull(atomicBoolean0);
      assertEquals("true", atomicBoolean0.toString());
      assertTrue(atomicBoolean0.get());
      
      TopologyContext topologyContext0 = new TopologyContext(stormTopology0, map0, map1, providerList0, providerList0, string0, string0, string1, integer0, integer1, arraySeq0, providerList0, providerList0, providerList0, providerList0, atomicBoolean0);
      assertEquals(5, objectArray0.length);
      assertNotNull(topologyContext0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string0));
      assertFalse(int0 == int1);
      assertFalse(integer0.equals((Object)integer1));
      assertFalse(integer0.equals((Object)int1));
      assertTrue(integer0.equals((Object)int0));
      assertFalse(int1 == int0);
      assertTrue(integer1.equals((Object)int1));
      assertFalse(integer1.equals((Object)int0));
      assertFalse(integer1.equals((Object)integer0));
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertFalse(arraySeq0.isEmpty());
      assertEquals(5, arraySeq0.count());
      assertEquals(0, arraySeq0.index());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_spouts());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertFalse(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertFalse(stormTopology0.is_set_bolts());
      assertEquals("true", atomicBoolean0.toString());
      assertTrue(atomicBoolean0.get());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertFalse(generationClauseNode0.isParameterNode());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertNull(generationClauseNode0.getColumnName());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertFalse(generationClauseNode0.isCloneable());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertNull(generationClauseNode0.getTableName());
      assertNull(generationClauseNode0.getExpressionText());
      assertNull(generationClauseNode0.getSchemaName());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      assertEquals("/home/CIN/lmps2/semantic-conflict-study/SMAT/output-test-dest/storm/bd1f5c54752f67b484a83c26667331234234d3a3/evosuite_2/e+J,COo~:7hA6~", topologyContext0.getPIDDir());
      assertEquals((-102), topologyContext0.getThisTaskId());
      assertEquals(944, (int)topologyContext0.getThisWorkerPort());
      assertEquals(" with assignedTableMap = ", topologyContext0.getCodeDir());
      assertEquals(" with assignedTableMap = ", topologyContext0.getStormId());
      
      KafkaSpoutConfig<ExecutorSummary._Fields, OffsetAndMetadata> kafkaSpoutConfig1 = (KafkaSpoutConfig<ExecutorSummary._Fields, OffsetAndMetadata>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<ExecutorSummary._Fields, OffsetAndMetadata> kafkaSpout1 = new KafkaSpout<ExecutorSummary._Fields, OffsetAndMetadata>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      SpoutOutputCollector spoutOutputCollector0 = kafkaSpout1.collector;
      assertNull(spoutOutputCollector0);
      
      kafkaSpout0.open(map0, topologyContext0, spoutOutputCollector0);
      assertEquals(5, objectArray0.length);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string0));
      assertFalse(int0 == int1);
      assertFalse(integer0.equals((Object)integer1));
      assertFalse(integer0.equals((Object)int1));
      assertTrue(integer0.equals((Object)int0));
      assertFalse(int1 == int0);
      assertTrue(integer1.equals((Object)int1));
      assertFalse(integer1.equals((Object)int0));
      assertFalse(integer1.equals((Object)integer0));
      assertNotSame(string0, string1);
      assertNotSame(string1, string0);
      assertEquals(0, QueryTreeNode.AUTOINCREMENT_START_INDEX);
      assertEquals(2, QueryTreeNode.AUTOINCREMENT_IS_AUTOINCREMENT_INDEX);
      assertEquals(1, QueryTreeNode.AUTOINCREMENT_INC_INDEX);
      assertEquals(3, QueryTreeNode.AUTOINCREMENT_CREATE_MODIFY);
      assertFalse(arraySeq0.isEmpty());
      assertEquals(5, arraySeq0.count());
      assertEquals(0, arraySeq0.index());
      assertEquals(0, stormTopology0.get_bolts_size());
      assertFalse(stormTopology0.is_set_spouts());
      assertFalse(stormTopology0.is_set_worker_hooks());
      assertFalse(stormTopology0.is_set_state_spouts());
      assertEquals(0, stormTopology0.get_dependency_jars_size());
      assertFalse(stormTopology0.is_set_dependency_artifacts());
      assertEquals(0, stormTopology0.get_spouts_size());
      assertEquals(0, stormTopology0.get_worker_hooks_size());
      assertFalse(stormTopology0.is_set_dependency_jars());
      assertEquals(0, stormTopology0.get_state_spouts_size());
      assertEquals(0, stormTopology0.get_dependency_artifacts_size());
      assertFalse(stormTopology0.is_set_bolts());
      assertEquals("true", atomicBoolean0.toString());
      assertTrue(atomicBoolean0.get());
      assertFalse(generationClauseNode0.updatableByCursor());
      assertTrue(generationClauseNode0.isPrivilegeCollectionRequired());
      assertFalse(generationClauseNode0.requiresTypeFromContext());
      assertFalse(generationClauseNode0.isConstantExpression());
      assertEquals((-1), generationClauseNode0.getEndOffset());
      assertFalse(generationClauseNode0.isParameterNode());
      assertFalse(generationClauseNode0.isInListProbeNode());
      assertNull(generationClauseNode0.getColumnName());
      assertFalse(generationClauseNode0.isBinaryEqualsOperatorNode());
      assertFalse(generationClauseNode0.isCloneable());
      assertTrue(generationClauseNode0.verifyChangeToCNF());
      assertNull(generationClauseNode0.getTableName());
      assertNull(generationClauseNode0.getExpressionText());
      assertNull(generationClauseNode0.getSchemaName());
      assertEquals((-1), generationClauseNode0.getBeginOffset());
      assertFalse(generationClauseNode0.isRelationalOperator());
      assertTrue(generationClauseNode0.verifyPutAndsOnTop());
      assertEquals("/home/CIN/lmps2/semantic-conflict-study/SMAT/output-test-dest/storm/bd1f5c54752f67b484a83c26667331234234d3a3/evosuite_2/e+J,COo~:7hA6~", topologyContext0.getPIDDir());
      assertEquals((-102), topologyContext0.getThisTaskId());
      assertEquals(944, (int)topologyContext0.getThisWorkerPort());
      assertEquals(" with assignedTableMap = ", topologyContext0.getCodeDir());
      assertEquals(" with assignedTableMap = ", topologyContext0.getStormId());
      
      // Undeclared exception!
      try { 
        kafkaSpout0.close();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test53()  throws Throwable  {
      KafkaSpoutConfig<AbstractMap.SimpleImmutableEntry<TopicPartition, Object>, HftpFileSystem> kafkaSpoutConfig0 = (KafkaSpoutConfig<AbstractMap.SimpleImmutableEntry<TopicPartition, Object>, HftpFileSystem>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutConfig.FirstPollOffsetStrategy) null).when(kafkaSpoutConfig0).getFirstPollOffsetStrategy();
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      doReturn(0).when(kafkaSpoutConfig0).getMaxTupleRetries();
      doReturn(0L).when(kafkaSpoutConfig0).getOffsetsCommitPeriodMs();
      doReturn((KafkaSpoutRetryService) null).when(kafkaSpoutConfig0).getRetryService();
      doReturn((KafkaSpoutTuplesBuilder) null).when(kafkaSpoutConfig0).getTuplesBuilder();
      doReturn(false).when(kafkaSpoutConfig0).isConsumerAutoCommitMode();
      KafkaSpout<AbstractMap.SimpleImmutableEntry<TopicPartition, Object>, HftpFileSystem> kafkaSpout0 = new KafkaSpout<AbstractMap.SimpleImmutableEntry<TopicPartition, Object>, HftpFileSystem>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      Object[] objectArray0 = new Object[0];
      PersistentHashMap persistentHashMap0 = PersistentHashMap.createWithCheck(objectArray0);
      assertEquals(0, objectArray0.length);
      assertNotNull(persistentHashMap0);
      assertEquals(0, persistentHashMap0.count());
      
      String string0 = kafkaSpout0.toString();
      assertEquals("KafkaSpout{acked=null, emitted=null}", string0);
      assertNotNull(string0);
      
      PersistentArrayMap persistentArrayMap0 = (PersistentArrayMap)PersistentArrayMap.create(persistentHashMap0);
      assertEquals(0, objectArray0.length);
      assertNotNull(persistentArrayMap0);
      assertEquals(0, persistentHashMap0.count());
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      
      PersistentArrayMap persistentArrayMap1 = new PersistentArrayMap(persistentArrayMap0, objectArray0);
      assertEquals(0, objectArray0.length);
      assertNotNull(persistentArrayMap1);
      assertTrue(persistentArrayMap1.equals((Object)persistentArrayMap0));
      assertEquals(0, persistentHashMap0.count());
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentArrayMap1.count());
      assertEquals(0, persistentArrayMap1.capacity());
      
      PersistentArrayMap persistentArrayMap2 = persistentArrayMap1.withMeta(persistentArrayMap0);
      assertEquals(0, objectArray0.length);
      assertNotNull(persistentArrayMap2);
      assertTrue(persistentArrayMap0.equals((Object)persistentArrayMap1));
      assertTrue(persistentArrayMap1.equals((Object)persistentArrayMap0));
      assertTrue(persistentArrayMap2.equals((Object)persistentArrayMap1));
      assertTrue(persistentArrayMap2.equals((Object)persistentArrayMap0));
      assertNotSame(persistentArrayMap0, persistentArrayMap2);
      assertNotSame(persistentArrayMap0, persistentArrayMap1);
      assertNotSame(persistentArrayMap1, persistentArrayMap2);
      assertNotSame(persistentArrayMap1, persistentArrayMap0);
      assertNotSame(persistentArrayMap2, persistentArrayMap1);
      assertNotSame(persistentArrayMap2, persistentArrayMap0);
      assertEquals(0, persistentHashMap0.count());
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentArrayMap1.count());
      assertEquals(0, persistentArrayMap1.capacity());
      assertEquals(0, persistentArrayMap2.capacity());
      assertEquals(0, persistentArrayMap2.count());
      
      TopologyContext topologyContext0 = null;
      ISpoutOutputCollector iSpoutOutputCollector0 = null;
      SpoutOutputCollector spoutOutputCollector0 = new SpoutOutputCollector(iSpoutOutputCollector0);
      assertNotNull(spoutOutputCollector0);
      
      kafkaSpout0.open(persistentArrayMap2, topologyContext0, spoutOutputCollector0);
      assertEquals(0, objectArray0.length);
      assertTrue(persistentArrayMap0.equals((Object)persistentArrayMap1));
      assertTrue(persistentArrayMap0.equals((Object)persistentArrayMap2));
      assertTrue(persistentArrayMap1.equals((Object)persistentArrayMap0));
      assertTrue(persistentArrayMap1.equals((Object)persistentArrayMap2));
      assertTrue(persistentArrayMap2.equals((Object)persistentArrayMap1));
      assertTrue(persistentArrayMap2.equals((Object)persistentArrayMap0));
      assertNotSame(persistentArrayMap0, persistentArrayMap2);
      assertNotSame(persistentArrayMap0, persistentArrayMap1);
      assertNotSame(persistentArrayMap1, persistentArrayMap2);
      assertNotSame(persistentArrayMap1, persistentArrayMap0);
      assertNotSame(persistentArrayMap2, persistentArrayMap1);
      assertNotSame(persistentArrayMap2, persistentArrayMap0);
      assertEquals(0, persistentHashMap0.count());
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentArrayMap1.count());
      assertEquals(0, persistentArrayMap1.capacity());
      assertEquals(0, persistentArrayMap2.capacity());
      assertEquals(0, persistentArrayMap2.count());
      
      kafkaSpout0.nextTuple();
      KafkaSpoutConfig<JMXPrincipal, ForkJoinTask<OffsetAndMetadata>> kafkaSpoutConfig1 = (KafkaSpoutConfig<JMXPrincipal, ForkJoinTask<OffsetAndMetadata>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<JMXPrincipal, ForkJoinTask<OffsetAndMetadata>> kafkaSpout1 = new KafkaSpout<JMXPrincipal, ForkJoinTask<OffsetAndMetadata>>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      // Undeclared exception!
      try { 
        kafkaSpout1.close();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test54()  throws Throwable  {
      Fields fields0 = null;
      String string0 = "";
      KafkaSpoutConfig<HftpFileSystem, AbstractMap.SimpleEntry<OffsetAndMetadata, ExecutorSummary._Fields>> kafkaSpoutConfig0 = (KafkaSpoutConfig<HftpFileSystem, AbstractMap.SimpleEntry<OffsetAndMetadata, ExecutorSummary._Fields>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<HftpFileSystem, AbstractMap.SimpleEntry<OffsetAndMetadata, ExecutorSummary._Fields>> kafkaSpout0 = new KafkaSpout<HftpFileSystem, AbstractMap.SimpleEntry<OffsetAndMetadata, ExecutorSummary._Fields>>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      kafkaSpout0.nextTuple();
      KafkaSpoutConfig<MapEntry, Integer> kafkaSpoutConfig1 = (KafkaSpoutConfig<MapEntry, Integer>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<MapEntry, Integer> kafkaSpout1 = new KafkaSpout<MapEntry, Integer>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      String string1 = ">lG-[h|FX@_=M";
      // Undeclared exception!
      try { 
        kafkaSpout1.ack(string1);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // java.lang.String cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test55()  throws Throwable  {
      PersistentArrayMap persistentArrayMap0 = PersistentArrayMap.EMPTY;
      assertNotNull(persistentArrayMap0);
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      
      DataDictionaryImpl dataDictionaryImpl0 = new DataDictionaryImpl();
      assertNotNull(dataDictionaryImpl0);
      assertEquals(0, dataDictionaryImpl0.getEngineType());
      assertNull(dataDictionaryImpl0.getAuthorizationDatabaseOwner());
      assertEquals(0, dataDictionaryImpl0.getCollationTypeOfUserSchemas());
      assertFalse(dataDictionaryImpl0.usesSqlAuthorization());
      assertFalse(dataDictionaryImpl0.isReadOnlyUpgrade());
      assertEquals(0, dataDictionaryImpl0.getCollationTypeOfSystemSchemas());
      assertTrue(dataDictionaryImpl0.doCreateIndexStatsRefresher());
      assertEquals(0, dataDictionaryImpl0.getCacheMode());
      
      KafkaSpoutConfig<JMXPrincipal, Object> kafkaSpoutConfig0 = (KafkaSpoutConfig<JMXPrincipal, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<JMXPrincipal, Object> kafkaSpout0 = new KafkaSpout<JMXPrincipal, Object>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "Q!";
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<ExecutorSummary._Fields, OffsetAndMetadata> kafkaSpoutConfig1 = (KafkaSpoutConfig<ExecutorSummary._Fields, OffsetAndMetadata>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(string0).when(kafkaSpoutConfig1).getConsumerGroupId();
      doReturn(persistentArrayMap0).when(kafkaSpoutConfig1).getKafkaProps();
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<ExecutorSummary._Fields, OffsetAndMetadata> kafkaSpout1 = new KafkaSpout<ExecutorSummary._Fields, OffsetAndMetadata>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      
      kafkaSpout1.acked = (Map<TopicPartition, KafkaSpout.OffsetEntry>) persistentArrayMap0;
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertTrue(kafkaSpout1.acked.isEmpty());
      assertEquals(0, kafkaSpout1.acked.size());
      
      Map<String, Object> map0 = kafkaSpout1.getComponentConfiguration();
      assertNotNull(map0);
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertFalse(map0.isEmpty());
      assertEquals(2, map0.size());
      
      // Undeclared exception!
      try { 
        kafkaSpout1.toString();
        fail("Expecting exception: NoClassDefFoundError");
      
      } catch(NoClassDefFoundError e) {
         //
         // Could not initialize class clojure.lang.RT
         //
         verifyException("clojure.lang.APersistentMap", e);
      }
  }

  @Test(timeout = 11000)
  public void test56()  throws Throwable  {
      KafkaSpoutConfig.FirstPollOffsetStrategy[] kafkaSpoutConfig_FirstPollOffsetStrategyArray0 = KafkaSpoutConfig.FirstPollOffsetStrategy.values();
      assertEquals(4, kafkaSpoutConfig_FirstPollOffsetStrategyArray0.length);
      assertNotNull(kafkaSpoutConfig_FirstPollOffsetStrategyArray0);
      
      KafkaSpoutConfig.FirstPollOffsetStrategy[] kafkaSpoutConfig_FirstPollOffsetStrategyArray1 = KafkaSpoutConfig.FirstPollOffsetStrategy.values();
      assertEquals(4, kafkaSpoutConfig_FirstPollOffsetStrategyArray1.length);
      assertNotNull(kafkaSpoutConfig_FirstPollOffsetStrategyArray1);
      assertFalse(kafkaSpoutConfig_FirstPollOffsetStrategyArray1.equals((Object)kafkaSpoutConfig_FirstPollOffsetStrategyArray0));
      assertNotSame(kafkaSpoutConfig_FirstPollOffsetStrategyArray1, kafkaSpoutConfig_FirstPollOffsetStrategyArray0);
      
      KafkaSpoutStreams kafkaSpoutStreams0 = null;
      KafkaSpoutConfig<DelegationTokenIdentifier, Integer> kafkaSpoutConfig0 = (KafkaSpoutConfig<DelegationTokenIdentifier, Integer>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<DelegationTokenIdentifier, Integer> kafkaSpout0 = new KafkaSpout<DelegationTokenIdentifier, Integer>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "fA_m";
      TopicPartition topicPartition0 = new TopicPartition(string0, kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS);
      assertNotNull(topicPartition0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      
      long long0 = 1L;
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      
      KafkaSpoutMessageId kafkaSpoutMessageId0 = new KafkaSpoutMessageId(topicPartition0, long0);
      assertNotNull(kafkaSpoutMessageId0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals("fA_m", kafkaSpoutMessageId0.topic());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals(10000000, kafkaSpoutMessageId0.partition());
      assertEquals(1L, kafkaSpoutMessageId0.offset());
      
      kafkaSpout_OffsetEntry0.add(kafkaSpoutMessageId0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals("fA_m", kafkaSpoutMessageId0.topic());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals(10000000, kafkaSpoutMessageId0.partition());
      assertEquals(1L, kafkaSpoutMessageId0.offset());
      
      OffsetAndMetadata offsetAndMetadata0 = kafkaSpout_OffsetEntry0.findNextCommitOffset();
      assertNotNull(offsetAndMetadata0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals("{topic-partition=fA_m-10000000, offset=1, numFails=0, thread='TEST_EXECUTION_THREAD_1'}", offsetAndMetadata0.metadata());
      assertEquals(1L, offsetAndMetadata0.offset());
      
      boolean boolean0 = kafkaSpout_OffsetEntry0.isEmpty();
      assertFalse(boolean0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      
      KafkaSpoutConfig<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>> kafkaSpoutConfig1 = (KafkaSpoutConfig<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>> kafkaSpout1 = new KafkaSpout<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      OutputFieldsGetter outputFieldsGetter0 = new OutputFieldsGetter();
      assertNotNull(outputFieldsGetter0);
  }

  @Test(timeout = 11000)
  public void test57()  throws Throwable  {
      KafkaSpoutConfig<Integer, KafkaSpoutStreamsNamedTopics> kafkaSpoutConfig0 = (KafkaSpoutConfig<Integer, KafkaSpoutStreamsNamedTopics>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<Integer, KafkaSpoutStreamsNamedTopics> kafkaSpout0 = new KafkaSpout<Integer, KafkaSpoutStreamsNamedTopics>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "with-open only allows Symbols in bindings";
      TopicPartition topicPartition0 = new TopicPartition(string0, kafkaSpoutConfig0.DEFAULT_MAX_RETRIES);
      assertNotNull(topicPartition0);
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      
      long long0 = 1689L;
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      
      Integer integer0 = new Integer(kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS);
      assertEquals(10000000, (int)integer0);
      assertNotNull(integer0);
      
      Optional<Integer> optional0 = Optional.ofNullable(integer0);
      assertNotNull(optional0);
      
      Supplier<BatchUpdateException> supplier0 = null;
      Integer integer1 = optional0.orElseThrow((Supplier<? extends BatchUpdateException>) supplier0);
      assertEquals(10000000, (int)integer1);
      assertNotNull(integer1);
      
      String string1 = "(h";
      int int0 = 5208;
      long long1 = 3856L;
      long long2 = 1076L;
      TimestampType timestampType0 = TimestampType.CREATE_TIME;
      int int1 = 505;
      KafkaSpoutStreamsNamedTopics kafkaSpoutStreamsNamedTopics0 = mock(KafkaSpoutStreamsNamedTopics.class, new ViolatedAssumptionAnswer());
      String string2 = topicPartition0.toString();
      assertEquals("with-open only allows Symbols in bindings-2147483647", string2);
      assertNotNull(string2);
      assertFalse(string2.equals((Object)string0));
      assertFalse(string2.equals((Object)string1));
      assertFalse(string0.equals((Object)string1));
      assertNotSame(string2, string0);
      assertNotSame(string2, string1);
      assertNotSame(string0, string2);
      assertNotSame(string0, string1);
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      
      JMXPrincipal jMXPrincipal0 = mock(JMXPrincipal.class, new ViolatedAssumptionAnswer());
      ConsumerRecord<KafkaSpoutStreamsNamedTopics, JMXPrincipal> consumerRecord0 = new ConsumerRecord<KafkaSpoutStreamsNamedTopics, JMXPrincipal>(string1, int0, long1, long2, timestampType0, kafkaSpoutConfig0.DEFAULT_OFFSET_COMMIT_PERIOD_MS, int1, int1, kafkaSpoutStreamsNamedTopics0, jMXPrincipal0);
      assertNotNull(consumerRecord0);
      assertFalse(string1.equals((Object)string0));
      assertFalse(string1.equals((Object)string2));
      assertFalse(int0 == int1);
      assertFalse(long1 == long2);
      assertFalse(long1 == long0);
      assertFalse(long2 == long0);
      assertFalse(long2 == long1);
      assertFalse(int1 == int0);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals(3856L, consumerRecord0.offset());
      assertEquals(5208, consumerRecord0.partition());
      assertEquals(505, consumerRecord0.serializedValueSize());
      assertEquals(1076L, consumerRecord0.timestamp());
      assertEquals(505, consumerRecord0.serializedKeySize());
      assertEquals("(h", consumerRecord0.topic());
      
      KafkaSpoutMessageId kafkaSpoutMessageId0 = new KafkaSpoutMessageId(consumerRecord0);
      assertNotNull(kafkaSpoutMessageId0);
      assertFalse(string1.equals((Object)string0));
      assertFalse(string1.equals((Object)string2));
      assertFalse(int0 == int1);
      assertFalse(long1 == long2);
      assertFalse(long1 == long0);
      assertFalse(long2 == long0);
      assertFalse(long2 == long1);
      assertFalse(int1 == int0);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals(3856L, consumerRecord0.offset());
      assertEquals(5208, consumerRecord0.partition());
      assertEquals(505, consumerRecord0.serializedValueSize());
      assertEquals(1076L, consumerRecord0.timestamp());
      assertEquals(505, consumerRecord0.serializedKeySize());
      assertEquals("(h", consumerRecord0.topic());
      assertEquals(5208, kafkaSpoutMessageId0.partition());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals(3856L, kafkaSpoutMessageId0.offset());
      assertEquals("(h", kafkaSpoutMessageId0.topic());
      
      kafkaSpoutMessageId0.incrementNumFails();
      assertFalse(string1.equals((Object)string0));
      assertFalse(string1.equals((Object)string2));
      assertFalse(int0 == int1);
      assertFalse(long1 == long2);
      assertFalse(long1 == long0);
      assertFalse(long2 == long0);
      assertFalse(long2 == long1);
      assertFalse(int1 == int0);
      assertNotSame(string1, string0);
      assertNotSame(string1, string2);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals(3856L, consumerRecord0.offset());
      assertEquals(5208, consumerRecord0.partition());
      assertEquals(505, consumerRecord0.serializedValueSize());
      assertEquals(1076L, consumerRecord0.timestamp());
      assertEquals(505, consumerRecord0.serializedKeySize());
      assertEquals("(h", consumerRecord0.topic());
      assertEquals(5208, kafkaSpoutMessageId0.partition());
      assertEquals(3856L, kafkaSpoutMessageId0.offset());
      assertEquals("(h", kafkaSpoutMessageId0.topic());
      assertEquals(1, kafkaSpoutMessageId0.numFails());
      
      kafkaSpout_OffsetEntry0.add(kafkaSpoutMessageId0);
      assertFalse(string0.equals((Object)string2));
      assertFalse(string0.equals((Object)string1));
      assertFalse(long0 == long2);
      assertFalse(long0 == long1);
      assertFalse(string1.equals((Object)string0));
      assertFalse(string1.equals((Object)string2));
      assertFalse(int0 == int1);
      assertFalse(long1 == long2);
      assertFalse(long1 == long0);
      assertFalse(long2 == long0);
      assertFalse(long2 == long1);
      assertFalse(int1 == int0);
      assertNotSame(string0, string2);
      assertNotSame(string0, string1);
      assertNotSame(string1, string0);
      assertNotSame(string1, string2);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals(3856L, consumerRecord0.offset());
      assertEquals(5208, consumerRecord0.partition());
      assertEquals(505, consumerRecord0.serializedValueSize());
      assertEquals(1076L, consumerRecord0.timestamp());
      assertEquals(505, consumerRecord0.serializedKeySize());
      assertEquals("(h", consumerRecord0.topic());
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals(5208, kafkaSpoutMessageId0.partition());
      assertEquals(3856L, kafkaSpoutMessageId0.offset());
      assertEquals("(h", kafkaSpoutMessageId0.topic());
      assertEquals(1, kafkaSpoutMessageId0.numFails());
      
      OffsetAndMetadata offsetAndMetadata0 = new OffsetAndMetadata(kafkaSpoutConfig0.DEFAULT_POLL_TIMEOUT_MS, optional0, string0);
      assertNotNull(offsetAndMetadata0);
      assertFalse(string0.equals((Object)string2));
      assertFalse(string0.equals((Object)string1));
      assertFalse(integer0.equals((Object)int0));
      assertFalse(integer0.equals((Object)int1));
      assertEquals("with-open only allows Symbols in bindings", offsetAndMetadata0.metadata());
      assertEquals(200L, offsetAndMetadata0.offset());
      
      String string3 = offsetAndMetadata0.toString();
      assertEquals("OffsetAndMetadata{offset=200, leaderEpoch=10000000, metadata='with-open only allows Symbols in bindings'}", string3);
      assertNotNull(string3);
      assertFalse(string0.equals((Object)string2));
      assertFalse(string0.equals((Object)string1));
      assertFalse(integer0.equals((Object)int0));
      assertFalse(integer0.equals((Object)int1));
      assertFalse(string3.equals((Object)string0));
      assertFalse(string3.equals((Object)string2));
      assertFalse(string3.equals((Object)string1));
      assertNotSame(string0, string2);
      assertNotSame(string0, string3);
      assertNotSame(string0, string1);
      assertNotSame(string3, string0);
      assertNotSame(string3, string2);
      assertNotSame(string3, string1);
      assertEquals("with-open only allows Symbols in bindings", offsetAndMetadata0.metadata());
      assertEquals(200L, offsetAndMetadata0.offset());
      
      kafkaSpout_OffsetEntry0.commit(offsetAndMetadata0);
      assertFalse(string0.equals((Object)string2));
      assertFalse(string0.equals((Object)string3));
      assertFalse(string0.equals((Object)string1));
      assertFalse(long0 == long2);
      assertFalse(long0 == long1);
      assertFalse(integer0.equals((Object)int0));
      assertFalse(integer0.equals((Object)int1));
      assertNotSame(string0, string2);
      assertNotSame(string0, string3);
      assertNotSame(string0, string1);
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("with-open only allows Symbols in bindings", offsetAndMetadata0.metadata());
      assertEquals(200L, offsetAndMetadata0.offset());
      
      KafkaSpoutConfig<Object, OffsetAndMetadata> kafkaSpoutConfig1 = (KafkaSpoutConfig<Object, OffsetAndMetadata>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<Object, OffsetAndMetadata> kafkaSpout1 = new KafkaSpout<Object, OffsetAndMetadata>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      String string4 = kafkaSpout1.toString();
      assertEquals("KafkaSpout{acked=null, emitted=null}", string4);
      assertNotNull(string4);
      assertFalse(string4.equals((Object)string1));
      assertFalse(string4.equals((Object)string2));
      assertFalse(string4.equals((Object)string3));
      assertFalse(string4.equals((Object)string0));
      assertNotSame(string4, string1);
      assertNotSame(string4, string2);
      assertNotSame(string4, string3);
      assertNotSame(string4, string0);
      
      kafkaSpout1.nextTuple();
      long long3 = (-1L);
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry1 = kafkaSpout0.new OffsetEntry(topicPartition0, long3);
      assertNotNull(kafkaSpout_OffsetEntry1);
      assertFalse(string0.equals((Object)string2));
      assertFalse(string0.equals((Object)string4));
      assertFalse(string0.equals((Object)string3));
      assertFalse(string0.equals((Object)string1));
      assertFalse(long3 == long0);
      assertFalse(long3 == long2);
      assertFalse(long3 == long1);
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      
      OffsetAndMetadata offsetAndMetadata1 = kafkaSpout_OffsetEntry1.findNextCommitOffset();
      assertNull(offsetAndMetadata1);
      assertFalse(string0.equals((Object)string2));
      assertFalse(string0.equals((Object)string4));
      assertFalse(string0.equals((Object)string3));
      assertFalse(string0.equals((Object)string1));
      assertFalse(long3 == long0);
      assertFalse(long3 == long2);
      assertFalse(long3 == long1);
      assertNotSame(string0, string2);
      assertNotSame(string0, string4);
      assertNotSame(string0, string3);
      assertNotSame(string0, string1);
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      
      KafkaSpoutConfig<DelegationTokenRenewer.RenewAction<HftpFileSystem>, BatchUpdateException> kafkaSpoutConfig2 = (KafkaSpoutConfig<DelegationTokenRenewer.RenewAction<HftpFileSystem>, BatchUpdateException>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig2).getKafkaSpoutStreams();
      KafkaSpout<DelegationTokenRenewer.RenewAction<HftpFileSystem>, BatchUpdateException> kafkaSpout2 = new KafkaSpout<DelegationTokenRenewer.RenewAction<HftpFileSystem>, BatchUpdateException>(kafkaSpoutConfig2);
      assertNotNull(kafkaSpout2);
      
      // Undeclared exception!
      try { 
        kafkaSpout2.deactivate();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test58()  throws Throwable  {
      KafkaSpoutConfig<String, HftpFileSystem> kafkaSpoutConfig0 = (KafkaSpoutConfig<String, HftpFileSystem>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<String, HftpFileSystem> kafkaSpout0 = new KafkaSpout<String, HftpFileSystem>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "";
      int int0 = (-1534);
      TopicPartition topicPartition0 = new TopicPartition(string0, int0);
      assertNotNull(topicPartition0);
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      
      long long0 = 0L;
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      
      KafkaSpoutMessageId kafkaSpoutMessageId0 = new KafkaSpoutMessageId(topicPartition0, int0);
      assertNotNull(kafkaSpoutMessageId0);
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      assertEquals((-1534), kafkaSpoutMessageId0.partition());
      assertEquals("", kafkaSpoutMessageId0.topic());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals((-1534L), kafkaSpoutMessageId0.offset());
      
      kafkaSpout_OffsetEntry0.add(kafkaSpoutMessageId0);
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      assertEquals((-1534), kafkaSpoutMessageId0.partition());
      assertEquals("", kafkaSpoutMessageId0.topic());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals((-1534L), kafkaSpoutMessageId0.offset());
      
      long long1 = 3439L;
      OffsetAndMetadata offsetAndMetadata0 = new OffsetAndMetadata(long1);
      assertNotNull(offsetAndMetadata0);
      assertFalse(long1 == long0);
      assertEquals(3439L, offsetAndMetadata0.offset());
      assertEquals("", offsetAndMetadata0.metadata());
      
      Object object0 = null;
      boolean boolean0 = offsetAndMetadata0.equals(object0);
      assertFalse(boolean0);
      assertFalse(long1 == long0);
      assertEquals(3439L, offsetAndMetadata0.offset());
      assertEquals("", offsetAndMetadata0.metadata());
      
      kafkaSpout_OffsetEntry0.commit(offsetAndMetadata0);
      assertFalse(long0 == long1);
      assertFalse(long1 == long0);
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      assertEquals(3439L, offsetAndMetadata0.offset());
      assertEquals("", offsetAndMetadata0.metadata());
      
      KafkaSpoutConfig<Object, KafkaSpoutStreamsNamedTopics> kafkaSpoutConfig1 = (KafkaSpoutConfig<Object, KafkaSpoutStreamsNamedTopics>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<Object, KafkaSpoutStreamsNamedTopics> kafkaSpout1 = new KafkaSpout<Object, KafkaSpoutStreamsNamedTopics>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      Object object1 = null;
      // Undeclared exception!
      try { 
        kafkaSpout1.fail(object1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test59()  throws Throwable  {
      PersistentArrayMap persistentArrayMap0 = PersistentArrayMap.EMPTY;
      assertNotNull(persistentArrayMap0);
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentArrayMap0.capacity());
      
      DataDictionaryImpl dataDictionaryImpl0 = new DataDictionaryImpl();
      assertNotNull(dataDictionaryImpl0);
      assertTrue(dataDictionaryImpl0.doCreateIndexStatsRefresher());
      assertEquals(0, dataDictionaryImpl0.getCacheMode());
      assertEquals(0, dataDictionaryImpl0.getEngineType());
      assertNull(dataDictionaryImpl0.getAuthorizationDatabaseOwner());
      assertEquals(0, dataDictionaryImpl0.getCollationTypeOfSystemSchemas());
      assertFalse(dataDictionaryImpl0.usesSqlAuthorization());
      assertFalse(dataDictionaryImpl0.isReadOnlyUpgrade());
      assertEquals(0, dataDictionaryImpl0.getCollationTypeOfUserSchemas());
      
      KafkaSpoutConfig<JMXPrincipal, Object> kafkaSpoutConfig0 = (KafkaSpoutConfig<JMXPrincipal, Object>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<JMXPrincipal, Object> kafkaSpout0 = new KafkaSpout<JMXPrincipal, Object>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "generate-key-fn-map";
      String[] stringArray0 = new String[0];
      Fields fields0 = new Fields(stringArray0);
      assertEquals(0, stringArray0.length);
      assertNotNull(fields0);
      assertEquals(0, fields0.size());
      
      String string1 = "";
      String string2 = "t9`$iC5es";
      Pattern pattern0 = Pattern.compile(string2, kafkaSpoutConfig0.DEFAULT_MAX_RETRIES);
      assertNotNull(pattern0);
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertNotSame(string2, string1);
      assertNotSame(string2, string0);
      assertEquals("t9`$iC5es", pattern0.toString());
      assertEquals("t9`$iC5es", pattern0.pattern());
      assertEquals(Integer.MAX_VALUE, pattern0.flags());
      
      KafkaSpoutStream kafkaSpoutStream0 = new KafkaSpoutStream(fields0, string1, pattern0);
      assertEquals(0, stringArray0.length);
      assertNotNull(kafkaSpoutStream0);
      assertFalse(string1.equals((Object)string2));
      assertFalse(string1.equals((Object)string0));
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertEquals(0, fields0.size());
      assertEquals("t9`$iC5es", pattern0.toString());
      assertEquals("t9`$iC5es", pattern0.pattern());
      assertEquals(Integer.MAX_VALUE, pattern0.flags());
      assertNull(kafkaSpoutStream0.getTopic());
      
      KafkaSpoutStreamsWildcardTopics kafkaSpoutStreamsWildcardTopics0 = new KafkaSpoutStreamsWildcardTopics(kafkaSpoutStream0);
      assertEquals(0, stringArray0.length);
      assertNotNull(kafkaSpoutStreamsWildcardTopics0);
      assertFalse(string1.equals((Object)string2));
      assertFalse(string1.equals((Object)string0));
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertEquals(0, fields0.size());
      assertEquals("t9`$iC5es", pattern0.toString());
      assertEquals("t9`$iC5es", pattern0.pattern());
      assertEquals(Integer.MAX_VALUE, pattern0.flags());
      assertNull(kafkaSpoutStream0.getTopic());
      
      KafkaSpoutConfig<ExecutorSummary._Fields, OffsetAndMetadata> kafkaSpoutConfig1 = (KafkaSpoutConfig<ExecutorSummary._Fields, OffsetAndMetadata>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreamsWildcardTopics0).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      doReturn((Pattern) null).when(kafkaSpoutConfig1).getTopicWildcardPattern();
      KafkaSpout<ExecutorSummary._Fields, OffsetAndMetadata> kafkaSpout1 = new KafkaSpout<ExecutorSummary._Fields, OffsetAndMetadata>(kafkaSpoutConfig1);
      assertEquals(0, stringArray0.length);
      assertNotNull(kafkaSpout1);
      assertFalse(string0.equals((Object)string2));
      assertFalse(string0.equals((Object)string1));
      assertFalse(string1.equals((Object)string2));
      assertFalse(string1.equals((Object)string0));
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertEquals(0, persistentArrayMap0.count());
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, fields0.size());
      assertEquals("t9`$iC5es", pattern0.toString());
      assertEquals("t9`$iC5es", pattern0.pattern());
      assertEquals(Integer.MAX_VALUE, pattern0.flags());
      assertNull(kafkaSpoutStream0.getTopic());
      
      // Undeclared exception!
      try { 
        kafkaSpout1.getComponentConfiguration();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test60()  throws Throwable  {
      String[] stringArray0 = new String[2];
      String string0 = "clj_time.format$with_pivot_year";
      String string1 = "] %%@m!bt9hl";
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<DelegationTokenIdentifier, TopicPartition> kafkaSpoutConfig0 = (KafkaSpoutConfig<DelegationTokenIdentifier, TopicPartition>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<DelegationTokenIdentifier, TopicPartition> kafkaSpout0 = new KafkaSpout<DelegationTokenIdentifier, TopicPartition>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      KafkaSpoutConfig<KafkaSpoutStreamsNamedTopics, JMXPrincipal> kafkaSpoutConfig1 = (KafkaSpoutConfig<KafkaSpoutStreamsNamedTopics, JMXPrincipal>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutStreamsNamedTopics, JMXPrincipal> kafkaSpout1 = new KafkaSpout<KafkaSpoutStreamsNamedTopics, JMXPrincipal>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      PersistentArrayMap persistentArrayMap0 = PersistentArrayMap.createAsIfByAssoc(stringArray0);
      assertEquals(2, stringArray0.length);
      assertNotNull(persistentArrayMap0);
      assertEquals(1, persistentArrayMap0.capacity());
      assertEquals(1, persistentArrayMap0.count());
      
      ConsumerRecords<KafkaSpoutStreamsNamedTopics, JMXPrincipal> consumerRecords0 = new ConsumerRecords<KafkaSpoutStreamsNamedTopics, JMXPrincipal>(persistentArrayMap0);
      assertEquals(2, stringArray0.length);
      assertNotNull(consumerRecords0);
      assertEquals(1, persistentArrayMap0.capacity());
      assertEquals(1, persistentArrayMap0.count());
      assertFalse(consumerRecords0.isEmpty());
      
      kafkaSpout1.setWaitingToEmit(consumerRecords0);
      assertEquals(2, stringArray0.length);
      assertEquals(1, persistentArrayMap0.capacity());
      assertEquals(1, persistentArrayMap0.count());
      assertFalse(consumerRecords0.isEmpty());
      
      // Undeclared exception!
      try { 
        kafkaSpout0.fail(string1);
        fail("Expecting exception: ClassCastException");
      
      } catch(ClassCastException e) {
         //
         // java.lang.String cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test61()  throws Throwable  {
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<TopicPartition, BatchUpdateException> kafkaSpoutConfig0 = (KafkaSpoutConfig<TopicPartition, BatchUpdateException>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<TopicPartition, BatchUpdateException> kafkaSpout0 = new KafkaSpout<TopicPartition, BatchUpdateException>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      PersistentArrayMap persistentArrayMap0 = PersistentArrayMap.EMPTY;
      assertNotNull(persistentArrayMap0);
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      
      ConsumerRecords<TopicPartition, BatchUpdateException> consumerRecords0 = new ConsumerRecords<TopicPartition, BatchUpdateException>(persistentArrayMap0);
      assertNotNull(consumerRecords0);
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertTrue(consumerRecords0.isEmpty());
      
      kafkaSpout0.setWaitingToEmit(consumerRecords0);
      assertEquals(0, persistentArrayMap0.capacity());
      assertEquals(0, persistentArrayMap0.count());
      assertTrue(consumerRecords0.isEmpty());
      
      Object[] objectArray0 = new Object[5];
      objectArray0[0] = (Object) consumerRecords0;
      objectArray0[1] = (Object) consumerRecords0;
      objectArray0[2] = (Object) persistentArrayMap0;
      objectArray0[3] = (Object) consumerRecords0;
      objectArray0[4] = (Object) kafkaSpout0;
      PersistentArrayMap persistentArrayMap1 = PersistentArrayMap.createAsIfByAssoc(objectArray0);
      assertEquals(5, objectArray0.length);
      assertNotNull(persistentArrayMap1);
      assertFalse(persistentArrayMap1.equals((Object)persistentArrayMap0));
      assertNotSame(persistentArrayMap1, persistentArrayMap0);
      assertEquals(2, persistentArrayMap1.count());
      assertEquals(2, persistentArrayMap1.capacity());
      
      KafkaSpoutStreams kafkaSpoutStreams1 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      Deserializer<ForkJoinTask<String>> deserializer0 = null;
      Deserializer<ExecutorSummary._Fields> deserializer1 = (Deserializer<ExecutorSummary._Fields>) mock(Deserializer.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<ForkJoinTask<String>, ExecutorSummary._Fields> kafkaSpoutConfig1 = (KafkaSpoutConfig<ForkJoinTask<String>, ExecutorSummary._Fields>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(persistentArrayMap1).when(kafkaSpoutConfig1).getKafkaProps();
      doReturn(kafkaSpoutStreams1).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      doReturn(deserializer0).when(kafkaSpoutConfig1).getKeyDeserializer();
      doReturn(deserializer1).when(kafkaSpoutConfig1).getValueDeserializer();
      KafkaSpout<ForkJoinTask<String>, ExecutorSummary._Fields> kafkaSpout1 = new KafkaSpout<ForkJoinTask<String>, ExecutorSummary._Fields>(kafkaSpoutConfig1);
      assertEquals(5, objectArray0.length);
      assertNotNull(kafkaSpout1);
      assertFalse(persistentArrayMap1.equals((Object)persistentArrayMap0));
      assertEquals(2, persistentArrayMap1.count());
      assertEquals(2, persistentArrayMap1.capacity());
      
      // Undeclared exception!
      try { 
        kafkaSpout1.activate();
        fail("Expecting exception: ArrayIndexOutOfBoundsException");
      
      } catch(ArrayIndexOutOfBoundsException e) {
         //
         // 5
         //
         verifyException("clojure.lang.PersistentArrayMap$Iter", e);
      }
  }

  @Test(timeout = 11000)
  public void test62()  throws Throwable  {
      KafkaSpoutStreams kafkaSpoutStreams0 = null;
      KafkaSpoutConfig<String, HftpFileSystem> kafkaSpoutConfig0 = (KafkaSpoutConfig<String, HftpFileSystem>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<String, HftpFileSystem> kafkaSpout0 = new KafkaSpout<String, HftpFileSystem>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "";
      int int0 = (-1534);
      TopicPartition topicPartition0 = new TopicPartition(string0, int0);
      assertNotNull(topicPartition0);
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      
      long long0 = 0L;
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      
      KafkaSpoutMessageId kafkaSpoutMessageId0 = new KafkaSpoutMessageId(topicPartition0, int0);
      assertNotNull(kafkaSpoutMessageId0);
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals((-1534L), kafkaSpoutMessageId0.offset());
      assertEquals("", kafkaSpoutMessageId0.topic());
      assertEquals((-1534), kafkaSpoutMessageId0.partition());
      
      kafkaSpout_OffsetEntry0.add(kafkaSpoutMessageId0);
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals((-1534L), kafkaSpoutMessageId0.offset());
      assertEquals("", kafkaSpoutMessageId0.topic());
      assertEquals((-1534), kafkaSpoutMessageId0.partition());
      
      long long1 = 3439L;
      OffsetAndMetadata offsetAndMetadata0 = new OffsetAndMetadata(long1);
      assertNotNull(offsetAndMetadata0);
      assertFalse(long1 == long0);
      assertEquals(3439L, offsetAndMetadata0.offset());
      assertEquals("", offsetAndMetadata0.metadata());
      
      String string1 = "trampoline can be used to convert algorithms requiring mutual\n  recursion without stack consumption. Calls f with supplied args, if\n  any. If f returns a fn, calls that fn with no arguments, and\n  continues to repeat, until the return value is not a fn, then\n  returns that non-fn value. Note that if you want to return a fn as a\n  final value, you must wrap it in some data structure and unpack it\n  after trampoline returns.";
      int int1 = (-1468);
      TimestampType timestampType0 = TimestampType.CREATE_TIME;
      int int2 = 3571;
      MapEntry mapEntry0 = null;
      ConsumerRecord<MapEntry, Integer> consumerRecord0 = new ConsumerRecord<MapEntry, Integer>(string1, int1, kafkaSpoutConfig0.DEFAULT_POLL_TIMEOUT_MS, kafkaSpoutConfig0.DEFAULT_OFFSET_COMMIT_PERIOD_MS, timestampType0, kafkaSpoutConfig0.DEFAULT_MAX_RETRIES, int1, int2, mapEntry0, (Integer) kafkaSpoutConfig0.DEFAULT_MAX_RETRIES);
      assertNotNull(consumerRecord0);
      assertFalse(string1.equals((Object)string0));
      assertFalse(int1 == int0);
      assertFalse(int1 == int2);
      assertFalse(int2 == int0);
      assertFalse(int2 == int1);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals(30000L, consumerRecord0.timestamp());
      assertEquals((-1468), consumerRecord0.partition());
      assertEquals(200L, consumerRecord0.offset());
      assertEquals(3571, consumerRecord0.serializedValueSize());
      assertEquals("trampoline can be used to convert algorithms requiring mutual\n  recursion without stack consumption. Calls f with supplied args, if\n  any. If f returns a fn, calls that fn with no arguments, and\n  continues to repeat, until the return value is not a fn, then\n  returns that non-fn value. Note that if you want to return a fn as a\n  final value, you must wrap it in some data structure and unpack it\n  after trampoline returns.", consumerRecord0.topic());
      assertEquals((-1468), consumerRecord0.serializedKeySize());
      
      boolean boolean0 = kafkaSpout_OffsetEntry0.contains(consumerRecord0);
      assertFalse(boolean0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(int0 == int1);
      assertFalse(int0 == int2);
      assertFalse(long0 == long1);
      assertFalse(string1.equals((Object)string0));
      assertFalse(int1 == int0);
      assertFalse(int1 == int2);
      assertFalse(int2 == int0);
      assertFalse(int2 == int1);
      assertNotSame(string0, string1);
      assertNotSame(string1, string0);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals(30000L, consumerRecord0.timestamp());
      assertEquals((-1468), consumerRecord0.partition());
      assertEquals(200L, consumerRecord0.offset());
      assertEquals(3571, consumerRecord0.serializedValueSize());
      assertEquals("trampoline can be used to convert algorithms requiring mutual\n  recursion without stack consumption. Calls f with supplied args, if\n  any. If f returns a fn, calls that fn with no arguments, and\n  continues to repeat, until the return value is not a fn, then\n  returns that non-fn value. Note that if you want to return a fn as a\n  final value, you must wrap it in some data structure and unpack it\n  after trampoline returns.", consumerRecord0.topic());
      assertEquals((-1468), consumerRecord0.serializedKeySize());
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry1 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry1);
      assertFalse(string0.equals((Object)string1));
      assertFalse(int0 == int1);
      assertFalse(int0 == int2);
      assertFalse(long0 == long1);
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      
      OffsetAndMetadata offsetAndMetadata1 = kafkaSpout_OffsetEntry1.findNextCommitOffset();
      assertNull(offsetAndMetadata1);
      assertFalse(string0.equals((Object)string1));
      assertFalse(int0 == int1);
      assertFalse(int0 == int2);
      assertFalse(long0 == long1);
      assertNotSame(string0, string1);
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      
      Header[] headerArray0 = new Header[2];
      byte[] byteArray0 = new byte[9];
      byte byte0 = (byte)80;
      byteArray0[0] = byte0;
      byte byte1 = (byte) (-92);
      byteArray0[1] = byte1;
      byte byte2 = (byte) (-84);
      byteArray0[2] = byte2;
      byte byte3 = (byte)93;
      byteArray0[3] = byte3;
      byte byte4 = (byte)2;
      byteArray0[4] = byte4;
      byte byte5 = (byte) (-42);
      byteArray0[5] = byte5;
      byte byte6 = (byte) (-103);
      byteArray0[6] = byte6;
      byte byte7 = (byte) (-88);
      byteArray0[7] = byte7;
      byte byte8 = (byte) (-76);
      byteArray0[8] = byte8;
      RecordHeader recordHeader0 = new RecordHeader(string0, byteArray0);
      assertEquals(9, byteArray0.length);
      assertArrayEquals(new byte[] {(byte)80, (byte) (-92), (byte) (-84), (byte)93, (byte)2, (byte) (-42), (byte) (-103), (byte) (-88), (byte) (-76)}, byteArray0);
      assertNotNull(recordHeader0);
      assertFalse(string0.equals((Object)string1));
      assertEquals("", recordHeader0.key());
      
      headerArray0[0] = (Header) recordHeader0;
      RecordHeader recordHeader1 = new RecordHeader(string0, byteArray0);
      assertEquals(9, byteArray0.length);
      assertArrayEquals(new byte[] {(byte)80, (byte) (-92), (byte) (-84), (byte)93, (byte)2, (byte) (-42), (byte) (-103), (byte) (-88), (byte) (-76)}, byteArray0);
      assertNotNull(recordHeader1);
      assertFalse(string0.equals((Object)string1));
      assertTrue(recordHeader1.equals((Object)recordHeader0));
      assertEquals("", recordHeader1.key());
      
      headerArray0[1] = (Header) recordHeader1;
      RecordHeaders recordHeaders0 = new RecordHeaders(headerArray0);
      assertEquals(2, headerArray0.length);
      assertNotNull(recordHeaders0);
      
      Header header0 = recordHeaders0.lastHeader(string1);
      assertEquals(2, headerArray0.length);
      assertNull(header0);
      assertFalse(string1.equals((Object)string0));
      assertNotSame(string1, string0);
      
      boolean boolean1 = topicPartition0.equals(header0);
      assertFalse(boolean1);
      assertEquals(2, headerArray0.length);
      assertFalse(string0.equals((Object)string1));
      assertFalse(int0 == int1);
      assertFalse(int0 == int2);
      assertFalse(string1.equals((Object)string0));
      assertTrue(boolean1 == boolean0);
      assertNotSame(string0, string1);
      assertNotSame(string1, string0);
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      
      Object object0 = null;
      boolean boolean2 = offsetAndMetadata0.equals(object0);
      assertFalse(boolean2);
      assertTrue(boolean2 == boolean1);
      assertTrue(boolean2 == boolean0);
      assertFalse(long1 == long0);
      assertEquals(3439L, offsetAndMetadata0.offset());
      assertEquals("", offsetAndMetadata0.metadata());
      
      kafkaSpout_OffsetEntry0.commit(offsetAndMetadata0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(int0 == int1);
      assertFalse(int0 == int2);
      assertFalse(long0 == long1);
      assertFalse(long1 == long0);
      assertNotSame(string0, string1);
      assertEquals("", topicPartition0.topic());
      assertEquals((-1534), topicPartition0.partition());
      assertEquals(3439L, offsetAndMetadata0.offset());
      assertEquals("", offsetAndMetadata0.metadata());
      
      KafkaSpoutConfig<Object, KafkaSpoutStreamsNamedTopics> kafkaSpoutConfig1 = (KafkaSpoutConfig<Object, KafkaSpoutStreamsNamedTopics>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<Object, KafkaSpoutStreamsNamedTopics> kafkaSpout1 = new KafkaSpout<Object, KafkaSpoutStreamsNamedTopics>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      Object object1 = null;
      // Undeclared exception!
      try { 
        kafkaSpout1.fail(object1);
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }

  @Test(timeout = 11000)
  public void test63()  throws Throwable  {
      KafkaSpoutStreams kafkaSpoutStreams0 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<Integer, KafkaSpoutStreamsNamedTopics> kafkaSpoutConfig0 = (KafkaSpoutConfig<Integer, KafkaSpoutStreamsNamedTopics>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<Integer, KafkaSpoutStreamsNamedTopics> kafkaSpout0 = new KafkaSpout<Integer, KafkaSpoutStreamsNamedTopics>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "with-open only allows Symbols in bindings";
      TopicPartition topicPartition0 = new TopicPartition(string0, kafkaSpoutConfig0.DEFAULT_MAX_RETRIES);
      assertNotNull(topicPartition0);
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      
      long long0 = 1689L;
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      
      Integer integer0 = new Integer(kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS);
      assertEquals(10000000, (int)integer0);
      assertNotNull(integer0);
      
      Optional<Integer> optional0 = Optional.ofNullable(integer0);
      assertNotNull(optional0);
      
      Supplier<BatchUpdateException> supplier0 = null;
      Integer integer1 = optional0.orElseThrow((Supplier<? extends BatchUpdateException>) supplier0);
      assertEquals(10000000, (int)integer1);
      assertNotNull(integer1);
      
      KafkaSpoutMessageId kafkaSpoutMessageId0 = new KafkaSpoutMessageId(topicPartition0, kafkaSpoutConfig0.DEFAULT_POLL_TIMEOUT_MS);
      assertNotNull(kafkaSpoutMessageId0);
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, kafkaSpoutMessageId0.partition());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals("with-open only allows Symbols in bindings", kafkaSpoutMessageId0.topic());
      assertEquals(200L, kafkaSpoutMessageId0.offset());
      
      kafkaSpout_OffsetEntry0.add(kafkaSpoutMessageId0);
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(Integer.MAX_VALUE, kafkaSpoutMessageId0.partition());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      assertEquals("with-open only allows Symbols in bindings", kafkaSpoutMessageId0.topic());
      assertEquals(200L, kafkaSpoutMessageId0.offset());
      
      String string1 = "clojure.core$generate_class$iname__6022";
      boolean boolean0 = topicPartition0.equals(integer1);
      assertFalse(boolean0);
      assertFalse(string0.equals((Object)string1));
      assertNotSame(string0, string1);
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      
      int int0 = 5208;
      long long1 = 1076L;
      TimestampType timestampType0 = TimestampType.CREATE_TIME;
      int int1 = 505;
      KafkaSpoutStreamsNamedTopics kafkaSpoutStreamsNamedTopics0 = mock(KafkaSpoutStreamsNamedTopics.class, new ViolatedAssumptionAnswer());
      String string2 = topicPartition0.toString();
      assertEquals("with-open only allows Symbols in bindings-2147483647", string2);
      assertNotNull(string2);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertFalse(string2.equals((Object)string1));
      assertNotSame(string0, string1);
      assertNotSame(string0, string2);
      assertNotSame(string2, string0);
      assertNotSame(string2, string1);
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      
      JMXPrincipal jMXPrincipal0 = mock(JMXPrincipal.class, new ViolatedAssumptionAnswer());
      ConsumerRecord<KafkaSpoutStreamsNamedTopics, JMXPrincipal> consumerRecord0 = new ConsumerRecord<KafkaSpoutStreamsNamedTopics, JMXPrincipal>(string1, int0, long0, long1, timestampType0, kafkaSpoutConfig0.DEFAULT_OFFSET_COMMIT_PERIOD_MS, int1, int1, kafkaSpoutStreamsNamedTopics0, jMXPrincipal0);
      assertNotNull(consumerRecord0);
      assertFalse(long1 == long0);
      assertFalse(int1 == int0);
      assertFalse(long0 == long1);
      assertFalse(string1.equals((Object)string0));
      assertFalse(string1.equals((Object)string2));
      assertFalse(int0 == int1);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals(1076L, consumerRecord0.timestamp());
      assertEquals(1689L, consumerRecord0.offset());
      assertEquals(505, consumerRecord0.serializedValueSize());
      assertEquals("clojure.core$generate_class$iname__6022", consumerRecord0.topic());
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals(5208, consumerRecord0.partition());
      assertEquals(505, consumerRecord0.serializedKeySize());
      
      KafkaSpoutMessageId kafkaSpoutMessageId1 = new KafkaSpoutMessageId(consumerRecord0);
      assertNotNull(kafkaSpoutMessageId1);
      assertFalse(long1 == long0);
      assertFalse(int1 == int0);
      assertFalse(long0 == long1);
      assertFalse(kafkaSpoutMessageId1.equals((Object)kafkaSpoutMessageId0));
      assertFalse(string1.equals((Object)string0));
      assertFalse(string1.equals((Object)string2));
      assertFalse(int0 == int1);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals(1076L, consumerRecord0.timestamp());
      assertEquals(1689L, consumerRecord0.offset());
      assertEquals(505, consumerRecord0.serializedValueSize());
      assertEquals("clojure.core$generate_class$iname__6022", consumerRecord0.topic());
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals(5208, consumerRecord0.partition());
      assertEquals(505, consumerRecord0.serializedKeySize());
      assertEquals("clojure.core$generate_class$iname__6022", kafkaSpoutMessageId1.topic());
      assertEquals(1689L, kafkaSpoutMessageId1.offset());
      assertEquals(5208, kafkaSpoutMessageId1.partition());
      assertEquals(0, kafkaSpoutMessageId1.numFails());
      
      kafkaSpoutMessageId1.incrementNumFails();
      assertFalse(long1 == long0);
      assertFalse(int1 == int0);
      assertFalse(long0 == long1);
      assertFalse(kafkaSpoutMessageId1.equals((Object)kafkaSpoutMessageId0));
      assertFalse(string1.equals((Object)string0));
      assertFalse(string1.equals((Object)string2));
      assertFalse(int0 == int1);
      assertNotSame(kafkaSpoutMessageId1, kafkaSpoutMessageId0);
      assertNotSame(string1, string0);
      assertNotSame(string1, string2);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals(1076L, consumerRecord0.timestamp());
      assertEquals(1689L, consumerRecord0.offset());
      assertEquals(505, consumerRecord0.serializedValueSize());
      assertEquals("clojure.core$generate_class$iname__6022", consumerRecord0.topic());
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals(5208, consumerRecord0.partition());
      assertEquals(505, consumerRecord0.serializedKeySize());
      assertEquals("clojure.core$generate_class$iname__6022", kafkaSpoutMessageId1.topic());
      assertEquals(1689L, kafkaSpoutMessageId1.offset());
      assertEquals(5208, kafkaSpoutMessageId1.partition());
      assertEquals(1, kafkaSpoutMessageId1.numFails());
      
      kafkaSpout_OffsetEntry0.add(kafkaSpoutMessageId1);
      assertFalse(long1 == long0);
      assertFalse(int1 == int0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertFalse(long0 == long1);
      assertFalse(kafkaSpoutMessageId1.equals((Object)kafkaSpoutMessageId0));
      assertFalse(string1.equals((Object)string0));
      assertFalse(string1.equals((Object)string2));
      assertFalse(int0 == int1);
      assertNotSame(string0, string1);
      assertNotSame(string0, string2);
      assertNotSame(kafkaSpoutMessageId1, kafkaSpoutMessageId0);
      assertNotSame(string1, string0);
      assertNotSame(string1, string2);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(1076L, consumerRecord0.timestamp());
      assertEquals(1689L, consumerRecord0.offset());
      assertEquals(505, consumerRecord0.serializedValueSize());
      assertEquals("clojure.core$generate_class$iname__6022", consumerRecord0.topic());
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals(5208, consumerRecord0.partition());
      assertEquals(505, consumerRecord0.serializedKeySize());
      assertEquals("clojure.core$generate_class$iname__6022", kafkaSpoutMessageId1.topic());
      assertEquals(1689L, kafkaSpoutMessageId1.offset());
      assertEquals(5208, kafkaSpoutMessageId1.partition());
      assertEquals(1, kafkaSpoutMessageId1.numFails());
      
      OffsetAndMetadata offsetAndMetadata0 = new OffsetAndMetadata(kafkaSpoutConfig0.DEFAULT_POLL_TIMEOUT_MS, optional0, string0);
      assertNotNull(offsetAndMetadata0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertFalse(integer0.equals((Object)int1));
      assertFalse(integer0.equals((Object)int0));
      assertEquals(200L, offsetAndMetadata0.offset());
      assertEquals("with-open only allows Symbols in bindings", offsetAndMetadata0.metadata());
      
      String string3 = offsetAndMetadata0.toString();
      assertEquals("OffsetAndMetadata{offset=200, leaderEpoch=10000000, metadata='with-open only allows Symbols in bindings'}", string3);
      assertNotNull(string3);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string2));
      assertFalse(integer0.equals((Object)int1));
      assertFalse(integer0.equals((Object)int0));
      assertFalse(string3.equals((Object)string2));
      assertFalse(string3.equals((Object)string0));
      assertFalse(string3.equals((Object)string1));
      assertNotSame(string0, string1);
      assertNotSame(string0, string3);
      assertNotSame(string0, string2);
      assertNotSame(string3, string2);
      assertNotSame(string3, string0);
      assertNotSame(string3, string1);
      assertEquals(200L, offsetAndMetadata0.offset());
      assertEquals("with-open only allows Symbols in bindings", offsetAndMetadata0.metadata());
      
      kafkaSpout_OffsetEntry0.commit(offsetAndMetadata0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string3));
      assertFalse(string0.equals((Object)string2));
      assertFalse(long0 == long1);
      assertFalse(integer0.equals((Object)int1));
      assertFalse(integer0.equals((Object)int0));
      assertNotSame(string0, string1);
      assertNotSame(string0, string3);
      assertNotSame(string0, string2);
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(200L, offsetAndMetadata0.offset());
      assertEquals("with-open only allows Symbols in bindings", offsetAndMetadata0.metadata());
      
      KafkaSpoutStreams kafkaSpoutStreams1 = mock(KafkaSpoutStreams.class, new ViolatedAssumptionAnswer());
      KafkaSpoutConfig<Object, OffsetAndMetadata> kafkaSpoutConfig1 = (KafkaSpoutConfig<Object, OffsetAndMetadata>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams1).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<Object, OffsetAndMetadata> kafkaSpout1 = new KafkaSpout<Object, OffsetAndMetadata>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      String string4 = kafkaSpout1.toString();
      assertEquals("KafkaSpout{acked=null, emitted=null}", string4);
      assertNotNull(string4);
      assertFalse(string4.equals((Object)string3));
      assertFalse(string4.equals((Object)string0));
      assertFalse(string4.equals((Object)string1));
      assertFalse(string4.equals((Object)string2));
      assertNotSame(string4, string3);
      assertNotSame(string4, string0);
      assertNotSame(string4, string1);
      assertNotSame(string4, string2);
      
      kafkaSpout1.nextTuple();
      long long2 = (-1L);
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry1 = kafkaSpout0.new OffsetEntry(topicPartition0, long2);
      assertNotNull(kafkaSpout_OffsetEntry1);
      assertFalse(long2 == long0);
      assertFalse(long2 == long1);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string4));
      assertFalse(string0.equals((Object)string3));
      assertFalse(string0.equals((Object)string2));
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      
      boolean boolean1 = kafkaSpout_OffsetEntry1.contains(consumerRecord0);
      assertFalse(boolean1);
      assertFalse(long2 == long0);
      assertFalse(long2 == long1);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string4));
      assertFalse(string0.equals((Object)string3));
      assertFalse(string0.equals((Object)string2));
      assertTrue(boolean1 == boolean0);
      assertFalse(long0 == long2);
      assertFalse(long0 == long1);
      assertFalse(string1.equals((Object)string3));
      assertFalse(string1.equals((Object)string0));
      assertFalse(string1.equals((Object)string2));
      assertFalse(string1.equals((Object)string4));
      assertFalse(int0 == int1);
      assertFalse(long1 == long2);
      assertFalse(long1 == long0);
      assertFalse(int1 == int0);
      assertNotSame(string0, string1);
      assertNotSame(string0, string4);
      assertNotSame(string0, string3);
      assertNotSame(string0, string2);
      assertNotSame(string1, string3);
      assertNotSame(string1, string0);
      assertNotSame(string1, string2);
      assertNotSame(string1, string4);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(1076L, consumerRecord0.timestamp());
      assertEquals(1689L, consumerRecord0.offset());
      assertEquals(505, consumerRecord0.serializedValueSize());
      assertEquals("clojure.core$generate_class$iname__6022", consumerRecord0.topic());
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals(5208, consumerRecord0.partition());
      assertEquals(505, consumerRecord0.serializedKeySize());
      
      kafkaSpout_OffsetEntry1.add(kafkaSpoutMessageId1);
      assertFalse(long2 == long0);
      assertFalse(long2 == long1);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string4));
      assertFalse(string0.equals((Object)string3));
      assertFalse(string0.equals((Object)string2));
      assertFalse(long0 == long2);
      assertFalse(long0 == long1);
      assertFalse(string1.equals((Object)string3));
      assertFalse(string1.equals((Object)string0));
      assertFalse(string1.equals((Object)string2));
      assertFalse(string1.equals((Object)string4));
      assertFalse(int0 == int1);
      assertFalse(long1 == long2);
      assertFalse(long1 == long0);
      assertFalse(int1 == int0);
      assertFalse(kafkaSpoutMessageId1.equals((Object)kafkaSpoutMessageId0));
      assertNotSame(string0, string1);
      assertNotSame(string0, string4);
      assertNotSame(string0, string3);
      assertNotSame(string0, string2);
      assertNotSame(kafkaSpoutMessageId1, kafkaSpoutMessageId0);
      assertNotSame(string1, string3);
      assertNotSame(string1, string0);
      assertNotSame(string1, string2);
      assertNotSame(string1, string4);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
      assertEquals(1076L, consumerRecord0.timestamp());
      assertEquals(1689L, consumerRecord0.offset());
      assertEquals(505, consumerRecord0.serializedValueSize());
      assertEquals("clojure.core$generate_class$iname__6022", consumerRecord0.topic());
      assertEquals(TimestampType.CREATE_TIME, consumerRecord0.timestampType());
      assertEquals(5208, consumerRecord0.partition());
      assertEquals(505, consumerRecord0.serializedKeySize());
      assertEquals("clojure.core$generate_class$iname__6022", kafkaSpoutMessageId1.topic());
      assertEquals(1689L, kafkaSpoutMessageId1.offset());
      assertEquals(5208, kafkaSpoutMessageId1.partition());
      assertEquals(1, kafkaSpoutMessageId1.numFails());
      
      OffsetAndMetadata offsetAndMetadata1 = kafkaSpout_OffsetEntry1.findNextCommitOffset();
      assertNull(offsetAndMetadata1);
      assertFalse(long2 == long0);
      assertFalse(long2 == long1);
      assertFalse(string0.equals((Object)string1));
      assertFalse(string0.equals((Object)string4));
      assertFalse(string0.equals((Object)string3));
      assertFalse(string0.equals((Object)string2));
      assertNotSame(string0, string1);
      assertNotSame(string0, string4);
      assertNotSame(string0, string3);
      assertNotSame(string0, string2);
      assertEquals(Integer.MAX_VALUE, topicPartition0.partition());
      assertEquals("with-open only allows Symbols in bindings", topicPartition0.topic());
  }

  @Test(timeout = 11000)
  public void test64()  throws Throwable  {
      KafkaSpoutConfig.FirstPollOffsetStrategy[] kafkaSpoutConfig_FirstPollOffsetStrategyArray0 = KafkaSpoutConfig.FirstPollOffsetStrategy.values();
      assertEquals(4, kafkaSpoutConfig_FirstPollOffsetStrategyArray0.length);
      assertNotNull(kafkaSpoutConfig_FirstPollOffsetStrategyArray0);
      
      KafkaSpoutStreams kafkaSpoutStreams0 = null;
      KafkaSpoutConfig<DelegationTokenIdentifier, Integer> kafkaSpoutConfig0 = (KafkaSpoutConfig<DelegationTokenIdentifier, Integer>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<DelegationTokenIdentifier, Integer> kafkaSpout0 = new KafkaSpout<DelegationTokenIdentifier, Integer>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      String string0 = "fA_m";
      TopicPartition topicPartition0 = new TopicPartition(string0, kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS);
      assertNotNull(topicPartition0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      
      long long0 = 1L;
      KafkaSpout.OffsetEntry kafkaSpout_OffsetEntry0 = kafkaSpout0.new OffsetEntry(topicPartition0, long0);
      assertNotNull(kafkaSpout_OffsetEntry0);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      
      String string1 = "function ";
      int int0 = 5;
      long long1 = 1580L;
      DelegationTokenIdentifier delegationTokenIdentifier0 = new DelegationTokenIdentifier();
      assertNotNull(delegationTokenIdentifier0);
      assertEquals(0, delegationTokenIdentifier0.getSequenceNumber());
      assertEquals(0, delegationTokenIdentifier0.getMasterKeyId());
      assertEquals(0L, delegationTokenIdentifier0.getIssueDate());
      assertEquals(0L, delegationTokenIdentifier0.getMaxDate());
      
      Text text0 = DelegationTokenIdentifier.HIVE_DELEGATION_KIND;
      assertNotNull(text0);
      assertEquals(1048576, Text.DEFAULT_MAX_LEN);
      assertEquals(21, text0.getLength());
      
      delegationTokenIdentifier0.setRealUser(text0);
      assertEquals(1048576, Text.DEFAULT_MAX_LEN);
      assertEquals(0, delegationTokenIdentifier0.getSequenceNumber());
      assertEquals(0, delegationTokenIdentifier0.getMasterKeyId());
      assertEquals(0L, delegationTokenIdentifier0.getIssueDate());
      assertEquals(0L, delegationTokenIdentifier0.getMaxDate());
      assertEquals(21, text0.getLength());
      
      ConsumerRecord<Integer, DelegationTokenIdentifier> consumerRecord0 = new ConsumerRecord<Integer, DelegationTokenIdentifier>(string1, int0, long1, (Integer) kafkaSpoutConfig0.DEFAULT_MAX_UNCOMMITTED_OFFSETS, delegationTokenIdentifier0);
      assertNotNull(consumerRecord0);
      assertFalse(string1.equals((Object)string0));
      assertFalse(long1 == long0);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals(0, delegationTokenIdentifier0.getSequenceNumber());
      assertEquals(0, delegationTokenIdentifier0.getMasterKeyId());
      assertEquals(0L, delegationTokenIdentifier0.getIssueDate());
      assertEquals(0L, delegationTokenIdentifier0.getMaxDate());
      assertEquals((-1), consumerRecord0.serializedKeySize());
      assertEquals(5, consumerRecord0.partition());
      assertEquals((-1L), consumerRecord0.timestamp());
      assertEquals("function ", consumerRecord0.topic());
      assertEquals(1580L, consumerRecord0.offset());
      assertEquals((-1), consumerRecord0.serializedValueSize());
      assertEquals(TimestampType.NO_TIMESTAMP_TYPE, consumerRecord0.timestampType());
      
      KafkaSpoutMessageId kafkaSpoutMessageId0 = new KafkaSpoutMessageId(consumerRecord0);
      assertNotNull(kafkaSpoutMessageId0);
      assertFalse(string1.equals((Object)string0));
      assertFalse(long1 == long0);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals(0, delegationTokenIdentifier0.getSequenceNumber());
      assertEquals(0, delegationTokenIdentifier0.getMasterKeyId());
      assertEquals(0L, delegationTokenIdentifier0.getIssueDate());
      assertEquals(0L, delegationTokenIdentifier0.getMaxDate());
      assertEquals((-1), consumerRecord0.serializedKeySize());
      assertEquals(5, consumerRecord0.partition());
      assertEquals((-1L), consumerRecord0.timestamp());
      assertEquals("function ", consumerRecord0.topic());
      assertEquals(1580L, consumerRecord0.offset());
      assertEquals((-1), consumerRecord0.serializedValueSize());
      assertEquals(TimestampType.NO_TIMESTAMP_TYPE, consumerRecord0.timestampType());
      assertEquals("function ", kafkaSpoutMessageId0.topic());
      assertEquals(5, kafkaSpoutMessageId0.partition());
      assertEquals(1580L, kafkaSpoutMessageId0.offset());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      
      kafkaSpout_OffsetEntry0.add(kafkaSpoutMessageId0);
      assertFalse(string0.equals((Object)string1));
      assertFalse(long0 == long1);
      assertFalse(string1.equals((Object)string0));
      assertFalse(long1 == long0);
      assertNotSame(string0, string1);
      assertNotSame(string1, string0);
      assertEquals((-1L), ConsumerRecord.NO_TIMESTAMP);
      assertEquals((-1), ConsumerRecord.NULL_CHECKSUM);
      assertEquals((-1), ConsumerRecord.NULL_SIZE);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      assertEquals(0, delegationTokenIdentifier0.getSequenceNumber());
      assertEquals(0, delegationTokenIdentifier0.getMasterKeyId());
      assertEquals(0L, delegationTokenIdentifier0.getIssueDate());
      assertEquals(0L, delegationTokenIdentifier0.getMaxDate());
      assertEquals((-1), consumerRecord0.serializedKeySize());
      assertEquals(5, consumerRecord0.partition());
      assertEquals((-1L), consumerRecord0.timestamp());
      assertEquals("function ", consumerRecord0.topic());
      assertEquals(1580L, consumerRecord0.offset());
      assertEquals((-1), consumerRecord0.serializedValueSize());
      assertEquals(TimestampType.NO_TIMESTAMP_TYPE, consumerRecord0.timestampType());
      assertEquals("function ", kafkaSpoutMessageId0.topic());
      assertEquals(5, kafkaSpoutMessageId0.partition());
      assertEquals(1580L, kafkaSpoutMessageId0.offset());
      assertEquals(0, kafkaSpoutMessageId0.numFails());
      
      String string2 = kafkaSpout_OffsetEntry0.toString();
      assertEquals("OffsetEntry{topic-partition=fA_m-10000000, fetchOffset=1, committedOffset=0, ackedMsgs=[{topic-partition=function -5, offset=1580, numFails=0}]}", string2);
      assertNotNull(string2);
      assertFalse(string2.equals((Object)string1));
      assertFalse(string2.equals((Object)string0));
      assertFalse(string0.equals((Object)string1));
      assertFalse(long0 == long1);
      assertNotSame(string2, string1);
      assertNotSame(string2, string0);
      assertNotSame(string0, string2);
      assertNotSame(string0, string1);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      
      long long2 = 0L;
      KafkaSpoutMessageId kafkaSpoutMessageId1 = new KafkaSpoutMessageId(topicPartition0, long2);
      assertNotNull(kafkaSpoutMessageId1);
      assertFalse(long2 == long1);
      assertFalse(long2 == long0);
      assertFalse(kafkaSpoutMessageId1.equals((Object)kafkaSpoutMessageId0));
      assertFalse(string0.equals((Object)string2));
      assertFalse(string0.equals((Object)string1));
      assertEquals("fA_m", kafkaSpoutMessageId1.topic());
      assertEquals(0, kafkaSpoutMessageId1.numFails());
      assertEquals(10000000, kafkaSpoutMessageId1.partition());
      assertEquals(0L, kafkaSpoutMessageId1.offset());
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      
      kafkaSpout_OffsetEntry0.add(kafkaSpoutMessageId1);
      assertFalse(long2 == long1);
      assertFalse(long2 == long0);
      assertFalse(kafkaSpoutMessageId1.equals((Object)kafkaSpoutMessageId0));
      assertFalse(string0.equals((Object)string2));
      assertFalse(string0.equals((Object)string1));
      assertFalse(long0 == long2);
      assertFalse(long0 == long1);
      assertNotSame(kafkaSpoutMessageId1, kafkaSpoutMessageId0);
      assertNotSame(string0, string2);
      assertNotSame(string0, string1);
      assertEquals("fA_m", kafkaSpoutMessageId1.topic());
      assertEquals(0, kafkaSpoutMessageId1.numFails());
      assertEquals(10000000, kafkaSpoutMessageId1.partition());
      assertEquals(0L, kafkaSpoutMessageId1.offset());
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      
      OffsetAndMetadata offsetAndMetadata0 = kafkaSpout_OffsetEntry0.findNextCommitOffset();
      assertNull(offsetAndMetadata0);
      assertFalse(string0.equals((Object)string2));
      assertFalse(string0.equals((Object)string1));
      assertFalse(long0 == long2);
      assertFalse(long0 == long1);
      assertNotSame(string0, string2);
      assertNotSame(string0, string1);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      
      boolean boolean0 = kafkaSpout_OffsetEntry0.isEmpty();
      assertFalse(boolean0);
      assertFalse(string0.equals((Object)string2));
      assertFalse(string0.equals((Object)string1));
      assertFalse(long0 == long2);
      assertFalse(long0 == long1);
      assertNotSame(string0, string2);
      assertNotSame(string0, string1);
      assertEquals(10000000, topicPartition0.partition());
      assertEquals("fA_m", topicPartition0.topic());
      
      KafkaSpoutConfig<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>> kafkaSpoutConfig1 = (KafkaSpoutConfig<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn(kafkaSpoutStreams0).when(kafkaSpoutConfig1).getKafkaSpoutStreams();
      KafkaSpout<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>> kafkaSpout1 = new KafkaSpout<KafkaSpoutMessageId, KafkaSpout<TopicPartition, TopicPartition>>(kafkaSpoutConfig1);
      assertNotNull(kafkaSpout1);
      
      OutputFieldsGetter outputFieldsGetter0 = new OutputFieldsGetter();
      assertNotNull(outputFieldsGetter0);
      
      // Undeclared exception!
      try { 
        KafkaSpoutConfig.FirstPollOffsetStrategy.valueOf(string0);
        fail("Expecting exception: IllegalArgumentException");
      
      } catch(IllegalArgumentException e) {
         //
         // No enum constant org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy.fA_m
         //
         verifyException("java.lang.Enum", e);
      }
  }

  @Test(timeout = 11000)
  public void test65()  throws Throwable  {
      KafkaSpoutConfig<MapEntry, Header> kafkaSpoutConfig0 = (KafkaSpoutConfig<MapEntry, Header>) mock(KafkaSpoutConfig.class, new ViolatedAssumptionAnswer());
      doReturn((KafkaSpoutStreams) null).when(kafkaSpoutConfig0).getKafkaSpoutStreams();
      KafkaSpout<MapEntry, Header> kafkaSpout0 = new KafkaSpout<MapEntry, Header>(kafkaSpoutConfig0);
      assertNotNull(kafkaSpout0);
      
      Object[] objectArray0 = new Object[7];
      objectArray0[0] = (Object) kafkaSpout0;
      objectArray0[1] = (Object) kafkaSpout0;
      EvoSuiteFile evoSuiteFile0 = null;
      boolean boolean0 = FileSystemHandling.shouldThrowIOException(evoSuiteFile0);
      assertFalse(boolean0);
      
      objectArray0[2] = (Object) kafkaSpout0;
      objectArray0[3] = (Object) kafkaSpoutConfig0;
      objectArray0[4] = (Object) kafkaSpoutConfig0;
      Object object0 = new Object();
      assertNotNull(object0);
      
      objectArray0[5] = object0;
      objectArray0[6] = (Object) kafkaSpout0;
      PersistentArrayMap persistentArrayMap0 = new PersistentArrayMap(objectArray0);
      assertEquals(7, objectArray0.length);
      assertNotNull(persistentArrayMap0);
      assertEquals(3, persistentArrayMap0.capacity());
      assertEquals(3, persistentArrayMap0.count());
      
      kafkaSpout0.acked = (Map<TopicPartition, KafkaSpout.OffsetEntry>) persistentArrayMap0;
      assertEquals(3, persistentArrayMap0.capacity());
      assertEquals(3, persistentArrayMap0.count());
      assertEquals(3, kafkaSpout0.acked.size());
      assertFalse(kafkaSpout0.acked.isEmpty());
      
      OutputFieldsGetter outputFieldsGetter0 = new OutputFieldsGetter();
      assertNotNull(outputFieldsGetter0);
      
      // Undeclared exception!
      try { 
        kafkaSpout0.deactivate();
        fail("Expecting exception: NullPointerException");
      
      } catch(NullPointerException e) {
         //
         // no message in exception (getMessage() returned null)
         //
         verifyException("org.apache.storm.kafka.spout.KafkaSpout", e);
      }
  }
}
