import org.junit.FixMethodOrder;
import org.junit.Test;
import org.junit.runners.MethodSorters;

@FixMethodOrder(MethodSorters.NAME_ASCENDING)
public class RegressionTest0 {

    public static boolean debug = false;

    @Test
    public void test00001() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00001");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, java.lang.String> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.String> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.String>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00002() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00002");
        java.io.Serializable serializable4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.io.Serializable> strComparableConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.io.Serializable>("", 100, (long) 'a', (java.lang.Comparable<java.lang.String>) "hi!", serializable4);
    }

    @Test
    public void test00003() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00003");
        int int0 = org.apache.kafka.clients.consumer.ConsumerRecord.NULL_CHECKSUM;
        org.junit.Assert.assertTrue("'" + int0 + "' != '" + (-1) + "'", int0 == (-1));
    }

    @Test
    public void test00004() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00004");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        java.lang.String str19 = objConsumerRecord18.toString();
        java.lang.String str20 = objConsumerRecord18.toString();
        org.apache.kafka.common.header.Headers headers22 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) (short) 100, (long) 1, timestampType4, (java.lang.Long) 10L, (int) (byte) 1, (int) 'a', (java.lang.Object) objConsumerRecord18, (java.io.Serializable) 0, headers22);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
    }

    @Test
    public void test00005() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00005");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        java.lang.String str19 = objConsumerRecord18.toString();
        java.lang.String str20 = objConsumerRecord18.toString();
        java.lang.Class<?> wildcardClass21 = objConsumerRecord18.getClass();
        org.apache.kafka.common.header.Headers headers23 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.lang.String> annotatedElementConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.lang.String>("", 100, (long) (byte) -1, (long) (short) 100, timestampType4, (java.lang.Long) 0L, (int) (short) 1, (int) (byte) -1, (java.lang.reflect.AnnotatedElement) wildcardClass21, "", headers23);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass21);
    }

    @Test
    public void test00006() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00006");
        long long0 = org.apache.kafka.clients.consumer.ConsumerRecord.NO_TIMESTAMP;
        org.junit.Assert.assertTrue("'" + long0 + "' != '" + (-1L) + "'", long0 == (-1L));
    }

    @Test
    public void test00007() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00007");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, java.lang.reflect.AnnotatedElement> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.reflect.AnnotatedElement> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.reflect.AnnotatedElement>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00008() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00008");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        java.lang.String str19 = objConsumerRecord18.toString();
        java.lang.String str20 = objConsumerRecord18.toString();
        java.lang.Class<?> wildcardClass21 = objConsumerRecord18.getClass();
        java.io.Serializable serializable22 = null;
        org.apache.kafka.common.header.Headers headers23 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) 100, 100L, 1L, timestampType4, (java.lang.Long) 0L, (int) (short) 1, (int) '4', (java.lang.Object) objConsumerRecord18, serializable22, headers23);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass21);
    }

    @Test
    public void test00009() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00009");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, java.lang.reflect.Type> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.reflect.Type> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.reflect.Type>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00010() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00010");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        long long19 = objConsumerRecord18.timestamp();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord18.leaderEpoch();
        org.apache.kafka.common.header.Headers headers22 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (byte) 0, (long) (byte) 100, (long) (short) -1, timestampType4, (java.lang.Long) 10L, (int) 'a', (int) '4', (java.lang.Object) intOptional20, (java.io.Serializable) (byte) 1, headers22);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertNotNull(intOptional20);
    }

    @Test
    public void test00011() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00011");
        int int0 = org.apache.kafka.clients.consumer.ConsumerRecord.NULL_SIZE;
        org.junit.Assert.assertTrue("'" + int0 + "' != '" + (-1) + "'", int0 == (-1));
    }

    @Test
    public void test00012() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00012");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        java.lang.String str19 = objConsumerRecord18.toString();
        java.lang.String str20 = objConsumerRecord18.toString();
        java.lang.Class<?> wildcardClass21 = objConsumerRecord18.getClass();
        org.apache.kafka.common.record.TimestampType timestampType26 = null;
        java.lang.Object obj30 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType26, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj30, (java.io.Serializable) 1);
        long long33 = objConsumerRecord32.timestamp();
        java.util.Optional<java.lang.Integer> intOptional34 = objConsumerRecord32.leaderEpoch();
        org.apache.kafka.common.header.Headers headers35 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.util.Optional<java.lang.Integer>> typeConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.util.Optional<java.lang.Integer>>("", (-1), (long) 1, (-1L), timestampType4, (java.lang.Long) 10L, 10, (int) (short) 0, (java.lang.reflect.Type) wildcardClass21, intOptional34, headers35);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass21);
        org.junit.Assert.assertTrue("'" + long33 + "' != '" + 52L + "'", long33 == 52L);
        org.junit.Assert.assertNotNull(intOptional34);
    }

    @Test
    public void test00013() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00013");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.reflect.Type> objConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.reflect.Type> objConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.reflect.Type>(objConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00014() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00014");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00015() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00015");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, java.lang.String> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.String> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.String>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00016() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00016");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, java.lang.reflect.AnnotatedElement> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.reflect.AnnotatedElement> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.reflect.AnnotatedElement>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00017() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00017");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, java.io.Serializable> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.io.Serializable> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.io.Serializable>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00018() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00018");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType13 = null;
        java.lang.Object obj17 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType13, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj17, (java.io.Serializable) 1);
        java.lang.String str20 = objConsumerRecord19.toString();
        long long21 = objConsumerRecord19.offset();
        org.apache.kafka.common.header.Headers headers22 = objConsumerRecord19.headers();
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.common.record.TimestampType timestampType38 = null;
        java.lang.Object obj42 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType38, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj42, (java.io.Serializable) 1);
        java.lang.String str45 = objConsumerRecord44.toString();
        long long46 = objConsumerRecord44.offset();
        org.apache.kafka.common.header.Headers headers47 = objConsumerRecord44.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable> headersConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable>("", (int) (short) 100, (long) 10, headers47, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType54 = null;
        java.lang.Object obj58 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType54, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj58, (java.io.Serializable) 1);
        java.lang.String str61 = objConsumerRecord60.toString();
        java.lang.String str62 = objConsumerRecord60.toString();
        java.lang.Class<?> wildcardClass63 = objConsumerRecord60.getClass();
        org.apache.kafka.common.record.TimestampType timestampType71 = null;
        java.lang.Object obj75 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType71, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj75, (java.io.Serializable) 1);
        java.lang.String str78 = objConsumerRecord77.toString();
        long long79 = objConsumerRecord77.offset();
        org.apache.kafka.common.header.Headers headers80 = objConsumerRecord77.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable> headersConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable>("", (int) (short) 100, (long) 10, headers80, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType87 = null;
        java.lang.Object obj91 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord93 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType87, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj91, (java.io.Serializable) 1);
        java.lang.String str94 = objConsumerRecord93.toString();
        java.util.Optional<java.lang.Integer> intOptional95 = objConsumerRecord93.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.lang.reflect.GenericDeclaration> headersConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (-1), (long) '#', (long) (short) 1, timestampType27, (java.lang.Long) 0L, (int) (short) -1, (int) '#', headers47, (java.lang.reflect.GenericDeclaration) wildcardClass63, headers80, intOptional95);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.Iterable<org.apache.kafka.common.header.Header>> strConsumerRecord97 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.Iterable<org.apache.kafka.common.header.Header>>("", (int) (byte) 0, (long) (short) 10, (long) (short) 10, timestampType4, (java.lang.Long) 52L, (int) (byte) 0, 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers22, headers80);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertNotNull(headers22);
        org.junit.Assert.assertEquals("'" + str45 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str45, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long46 + "' != '" + (-1L) + "'", long46 == (-1L));
        org.junit.Assert.assertNotNull(headers47);
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str61, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str62 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str62, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass63);
        org.junit.Assert.assertEquals("'" + str78 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str78, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long79 + "' != '" + (-1L) + "'", long79 == (-1L));
        org.junit.Assert.assertNotNull(headers80);
        org.junit.Assert.assertEquals("'" + str94 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str94, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional95);
    }

    @Test
    public void test00019() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00019");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, java.lang.String> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.String> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.String>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00020() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00020");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00021() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00021");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.String> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.String> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.String>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00022() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00022");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.util.Optional<java.lang.Integer>> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.util.Optional<java.lang.Integer>> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.util.Optional<java.lang.Integer>>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00023() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00023");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.lang.reflect.AnnotatedElement> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.reflect.AnnotatedElement> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.reflect.AnnotatedElement>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00024() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00024");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.CharSequence> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.CharSequence> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.CharSequence>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00025() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00025");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, java.lang.Object> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.Object> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.Object>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00026() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00026");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, java.lang.Iterable<org.apache.kafka.common.header.Header>> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.Iterable<org.apache.kafka.common.header.Header>> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.Iterable<org.apache.kafka.common.header.Header>>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00027() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00027");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, java.util.Optional<java.lang.Integer>> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.util.Optional<java.lang.Integer>> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.util.Optional<java.lang.Integer>>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00028() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00028");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, java.lang.CharSequence> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.CharSequence> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.CharSequence>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00029() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00029");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00030() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00030");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.String> objConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.String> objConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.String>(objConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00031() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00031");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, java.util.Optional<java.lang.Integer>> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.util.Optional<java.lang.Integer>> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.util.Optional<java.lang.Integer>>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00032() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00032");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.AnnotatedElement> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.AnnotatedElement> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.AnnotatedElement>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00033() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00033");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        int int14 = objConsumerRecord10.partition();
        long long15 = objConsumerRecord10.offset();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
    }

    @Test
    public void test00034() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00034");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, java.lang.Iterable<org.apache.kafka.common.header.Header>> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.Iterable<org.apache.kafka.common.header.Header>> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.Iterable<org.apache.kafka.common.header.Header>>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00035() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00035");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, org.apache.kafka.common.header.Headers> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, org.apache.kafka.common.header.Headers> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, org.apache.kafka.common.header.Headers>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00036() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00036");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, java.lang.String> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.String> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.String>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00037() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00037");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, java.lang.reflect.GenericDeclaration> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.reflect.GenericDeclaration> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.reflect.GenericDeclaration>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00038() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00038");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.io.Serializable> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.io.Serializable> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.io.Serializable>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00039() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00039");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00040() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00040");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, java.lang.CharSequence> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.CharSequence> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.CharSequence>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00041() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00041");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        org.apache.kafka.common.record.TimestampType timestampType20 = null;
        java.io.Serializable serializable24 = null;
        org.apache.kafka.common.record.TimestampType timestampType29 = null;
        java.lang.Object obj33 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType29, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj33, (java.io.Serializable) 1);
        java.lang.String str36 = objConsumerRecord35.toString();
        java.lang.String str37 = objConsumerRecord35.toString();
        java.lang.Class<?> wildcardClass38 = objConsumerRecord35.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.reflect.Type> serializableConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.reflect.Type>("", (int) (short) 1, (long) 1, (long) 'a', timestampType20, (long) 10, 0, (int) (byte) 0, serializable24, (java.lang.reflect.Type) wildcardClass38);
        org.apache.kafka.common.record.TimestampType timestampType44 = null;
        java.lang.Object obj48 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType44, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj48, (java.io.Serializable) 1);
        long long51 = objConsumerRecord50.timestamp();
        java.util.Optional<java.lang.Integer> intOptional52 = objConsumerRecord50.leaderEpoch();
        java.lang.Class<?> wildcardClass53 = objConsumerRecord50.getClass();
        org.apache.kafka.common.record.TimestampType timestampType61 = null;
        java.lang.Object obj65 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType61, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj65, (java.io.Serializable) 1);
        java.lang.String str68 = objConsumerRecord67.toString();
        long long69 = objConsumerRecord67.offset();
        org.apache.kafka.common.header.Headers headers70 = objConsumerRecord67.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable> headersConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable>("", (int) (short) 100, (long) 10, headers70, (java.io.Serializable) false);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (byte) -1, (long) (-1), 1L, timestampType12, (java.lang.Long) 1L, (int) '#', 0, (java.lang.Object) serializable24, (java.io.Serializable) wildcardClass53, headers70);
        org.apache.kafka.common.record.TimestampType timestampType78 = null;
        org.apache.kafka.common.record.TimestampType timestampType87 = null;
        java.lang.Object obj91 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord93 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType87, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj91, (java.io.Serializable) 1);
        long long94 = objConsumerRecord93.timestamp();
        java.util.Optional<java.lang.Integer> intOptional95 = objConsumerRecord93.leaderEpoch();
        java.lang.Class<?> wildcardClass96 = objConsumerRecord93.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.GenericDeclaration> charSequenceConsumerRecord97 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '4', (long) 1, (long) 0, timestampType78, 100L, 1, (int) (short) 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (java.lang.reflect.GenericDeclaration) wildcardClass96);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.lang.reflect.GenericDeclaration> annotatedElementConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) 0, (long) 35, (long) (byte) 0, timestampType4, 100L, (int) '4', (-1), (java.lang.reflect.AnnotatedElement) wildcardClass53, (java.lang.reflect.GenericDeclaration) wildcardClass96);
        org.junit.Assert.assertEquals("'" + str36 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str36, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str37 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str37, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass38);
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + 52L + "'", long51 == 52L);
        org.junit.Assert.assertNotNull(intOptional52);
        org.junit.Assert.assertNotNull(wildcardClass53);
        org.junit.Assert.assertEquals("'" + str68 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str68, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long69 + "' != '" + (-1L) + "'", long69 == (-1L));
        org.junit.Assert.assertNotNull(headers70);
        org.junit.Assert.assertTrue("'" + long94 + "' != '" + 52L + "'", long94 == 52L);
        org.junit.Assert.assertNotNull(intOptional95);
        org.junit.Assert.assertNotNull(wildcardClass96);
    }

    @Test
    public void test00042() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00042");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, org.apache.kafka.common.header.Headers> objConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, org.apache.kafka.common.header.Headers> objConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, org.apache.kafka.common.header.Headers>(objConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00043() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00043");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, java.lang.reflect.AnnotatedElement> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.reflect.AnnotatedElement> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.reflect.AnnotatedElement>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00044() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00044");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, java.lang.CharSequence> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.CharSequence> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.CharSequence>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00045() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00045");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.lang.Object obj12 = objConsumerRecord10.key();
        // The following exception was thrown during execution in test generation
        try {
            java.lang.Class<?> wildcardClass13 = obj12.getClass();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNull(obj12);
    }

    @Test
    public void test00046() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00046");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, java.lang.reflect.GenericDeclaration> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.reflect.GenericDeclaration> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.reflect.GenericDeclaration>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00047() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00047");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, java.lang.reflect.AnnotatedElement> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.reflect.AnnotatedElement> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.reflect.AnnotatedElement>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00048() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00048");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, java.lang.Comparable<java.lang.String>> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.Comparable<java.lang.String>> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.Comparable<java.lang.String>>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00049() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00049");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, java.lang.Iterable<org.apache.kafka.common.header.Header>> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.Iterable<org.apache.kafka.common.header.Header>> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.Iterable<org.apache.kafka.common.header.Header>>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00050() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00050");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00051() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00051");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.lang.String> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.String> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.String>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00052() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00052");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00053() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00053");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, java.lang.Object> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.Object> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.Object>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00054() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00054");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, org.apache.kafka.common.header.Headers> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, org.apache.kafka.common.header.Headers> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, org.apache.kafka.common.header.Headers>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00055() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00055");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.reflect.Type> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.reflect.Type> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.reflect.Type>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00056() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00056");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, java.lang.Object> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.Object> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.Object>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00057() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00057");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.String> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.String> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.String>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00058() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00058");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Optional<java.lang.Integer>> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Optional<java.lang.Integer>> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Optional<java.lang.Integer>>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00059() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00059");
        org.apache.kafka.common.record.TimestampType timestampType11 = null;
        java.lang.Object obj15 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType11, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj15, (java.io.Serializable) 1);
        java.lang.String str18 = objConsumerRecord17.toString();
        java.lang.String str19 = objConsumerRecord17.toString();
        java.lang.Class<?> wildcardClass20 = objConsumerRecord17.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '#', (long) (short) -1, (java.lang.CharSequence) "", (java.lang.reflect.Type) wildcardClass20);
        org.apache.kafka.common.record.TimestampType timestampType26 = null;
        org.apache.kafka.common.record.TimestampType timestampType34 = null;
        java.io.Serializable serializable38 = null;
        org.apache.kafka.common.record.TimestampType timestampType43 = null;
        java.lang.Object obj47 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType43, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj47, (java.io.Serializable) 1);
        java.lang.String str50 = objConsumerRecord49.toString();
        java.lang.String str51 = objConsumerRecord49.toString();
        java.lang.Class<?> wildcardClass52 = objConsumerRecord49.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.reflect.Type> serializableConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.reflect.Type>("", (int) (short) 1, (long) 1, (long) 'a', timestampType34, (long) 10, 0, (int) (byte) 0, serializable38, (java.lang.reflect.Type) wildcardClass52);
        org.apache.kafka.common.record.TimestampType timestampType58 = null;
        java.lang.Object obj62 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType58, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj62, (java.io.Serializable) 1);
        long long65 = objConsumerRecord64.timestamp();
        java.util.Optional<java.lang.Integer> intOptional66 = objConsumerRecord64.leaderEpoch();
        java.lang.Class<?> wildcardClass67 = objConsumerRecord64.getClass();
        org.apache.kafka.common.record.TimestampType timestampType75 = null;
        java.lang.Object obj79 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType75, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj79, (java.io.Serializable) 1);
        java.lang.String str82 = objConsumerRecord81.toString();
        long long83 = objConsumerRecord81.offset();
        org.apache.kafka.common.header.Headers headers84 = objConsumerRecord81.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable> headersConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable>("", (int) (short) 100, (long) 10, headers84, (java.io.Serializable) false);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (byte) -1, (long) (-1), 1L, timestampType26, (java.lang.Long) 1L, (int) '#', 0, (java.lang.Object) serializable38, (java.io.Serializable) wildcardClass67, headers84);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration> typeConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", (int) ' ', (long) (byte) 100, (java.lang.reflect.Type) wildcardClass20, (java.lang.reflect.GenericDeclaration) wildcardClass67);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str18, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass20);
        org.junit.Assert.assertEquals("'" + str50 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str50, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str51 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str51, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass52);
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + 52L + "'", long65 == 52L);
        org.junit.Assert.assertNotNull(intOptional66);
        org.junit.Assert.assertNotNull(wildcardClass67);
        org.junit.Assert.assertEquals("'" + str82 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str82, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + (-1L) + "'", long83 == (-1L));
        org.junit.Assert.assertNotNull(headers84);
    }

    @Test
    public void test00060() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00060");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, java.lang.reflect.Type> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.reflect.Type> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.reflect.Type>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00061() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00061");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00062() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00062");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, java.lang.CharSequence> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.CharSequence> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.CharSequence>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00063() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00063");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00064() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00064");
        org.apache.kafka.common.record.TimestampType timestampType15 = null;
        java.lang.Object obj19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType15, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj19, (java.io.Serializable) 1);
        long long22 = objConsumerRecord21.timestamp();
        int int23 = objConsumerRecord21.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional24 = objConsumerRecord21.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord21, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType27 = objConsumerRecord26.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType38 = null;
        java.lang.Object obj42 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType38, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj42, (java.io.Serializable) 1);
        long long45 = objConsumerRecord44.timestamp();
        int int46 = objConsumerRecord44.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional47 = objConsumerRecord44.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord44, (java.io.Serializable) false);
        java.lang.String str50 = objConsumerRecord49.toString();
        java.lang.Class<?> wildcardClass51 = objConsumerRecord49.getClass();
        org.apache.kafka.common.record.TimestampType timestampType59 = null;
        java.lang.Object obj63 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType59, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj63, (java.io.Serializable) 1);
        long long66 = objConsumerRecord65.timestamp();
        int int67 = objConsumerRecord65.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional68 = objConsumerRecord65.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord65, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType71 = objConsumerRecord70.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> serializableConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", 35, 0L, (long) (byte) -1, timestampType27, (long) '4', (int) (short) 100, 35, (java.io.Serializable) wildcardClass51, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType71);
        org.apache.kafka.common.record.TimestampType timestampType80 = null;
        java.lang.Object obj84 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType80, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj84, (java.io.Serializable) 1);
        long long87 = objConsumerRecord86.timestamp();
        java.util.Optional<java.lang.Integer> intOptional88 = objConsumerRecord86.leaderEpoch();
        long long89 = objConsumerRecord86.timestamp();
        java.lang.Class<?> wildcardClass90 = objConsumerRecord86.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.io.Serializable> annotatedElementConsumerRecord92 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.io.Serializable>("hi!", 0, (long) '#', (long) (byte) 100, timestampType27, (long) (short) 1, 32, (int) (short) -1, (java.lang.reflect.AnnotatedElement) wildcardClass90, (java.io.Serializable) false);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 52L + "'", long22 == 52L);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 100 + "'", int23 == 100);
        org.junit.Assert.assertNotNull(intOptional24);
        org.junit.Assert.assertTrue("'" + timestampType27 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType27.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long45 + "' != '" + 52L + "'", long45 == 52L);
        org.junit.Assert.assertTrue("'" + int46 + "' != '" + 100 + "'", int46 == 100);
        org.junit.Assert.assertNotNull(intOptional47);
        org.junit.Assert.assertEquals("'" + str50 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)" + "'", str50, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)");
        org.junit.Assert.assertNotNull(wildcardClass51);
        org.junit.Assert.assertTrue("'" + long66 + "' != '" + 52L + "'", long66 == 52L);
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + 100 + "'", int67 == 100);
        org.junit.Assert.assertNotNull(intOptional68);
        org.junit.Assert.assertTrue("'" + timestampType71 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType71.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long87 + "' != '" + 52L + "'", long87 == 52L);
        org.junit.Assert.assertNotNull(intOptional88);
        org.junit.Assert.assertTrue("'" + long89 + "' != '" + 52L + "'", long89 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass90);
    }

    @Test
    public void test00065() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00065");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, java.lang.Iterable<org.apache.kafka.common.header.Header>> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.Iterable<org.apache.kafka.common.header.Header>> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.Iterable<org.apache.kafka.common.header.Header>>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00066() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00066");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType13 = null;
        org.apache.kafka.common.record.TimestampType timestampType22 = null;
        java.lang.Object obj26 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType22, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj26, (java.io.Serializable) 1);
        long long29 = objConsumerRecord28.timestamp();
        java.util.Optional<java.lang.Integer> intOptional30 = objConsumerRecord28.leaderEpoch();
        long long31 = objConsumerRecord28.offset();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> charSequenceConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>("", (int) '4', (long) 'a', 0L, timestampType13, 10L, (-1), (int) (short) 0, (java.lang.CharSequence) "hi!", objConsumerRecord28);
        java.lang.Class<?> wildcardClass33 = charSequenceConsumerRecord32.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.Object> strConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.Object>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)", 1, (long) (short) 1, (long) (byte) 1, timestampType4, 1L, (int) (byte) 10, (int) (byte) 10, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (java.lang.Object) charSequenceConsumerRecord32);
        org.junit.Assert.assertTrue("'" + long29 + "' != '" + 52L + "'", long29 == 52L);
        org.junit.Assert.assertNotNull(intOptional30);
        org.junit.Assert.assertTrue("'" + long31 + "' != '" + (-1L) + "'", long31 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass33);
    }

    @Test
    public void test00067() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00067");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        java.lang.String str13 = objConsumerRecord10.toString();
        java.lang.String str14 = objConsumerRecord10.toString();
        java.io.Serializable serializable15 = objConsumerRecord10.value();
        long long16 = objConsumerRecord10.offset();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + serializable15 + "' != '" + 1 + "'", serializable15, 1);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
    }

    @Test
    public void test00068() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00068");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, java.lang.Object> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.Object> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.Object>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00069() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00069");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.reflect.GenericDeclaration> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.reflect.GenericDeclaration> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.reflect.GenericDeclaration>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00070() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00070");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00071() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00071");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.reflect.GenericDeclaration>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00072() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00072");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, java.lang.String> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.String> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.String>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00073() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00073");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.common.record.TimestampType> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.common.record.TimestampType> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.common.record.TimestampType>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00074() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00074");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, java.lang.Comparable<java.lang.String>> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.Comparable<java.lang.String>> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.Comparable<java.lang.String>>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00075() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00075");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00076() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00076");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.reflect.AnnotatedElement> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.reflect.AnnotatedElement> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.reflect.AnnotatedElement>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00077() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00077");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType18 = null;
        java.lang.Object obj22 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType18, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj22, (java.io.Serializable) 1);
        long long25 = objConsumerRecord24.timestamp();
        int int26 = objConsumerRecord24.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional27 = objConsumerRecord24.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord24, (java.io.Serializable) false);
        java.lang.String str30 = objConsumerRecord29.toString();
        int int31 = objConsumerRecord29.partition();
        org.apache.kafka.common.record.TimestampType timestampType36 = null;
        org.apache.kafka.common.record.TimestampType timestampType44 = null;
        org.apache.kafka.common.record.TimestampType timestampType52 = null;
        java.lang.Object obj56 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType52, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj56, (java.io.Serializable) 1);
        long long59 = objConsumerRecord58.timestamp();
        java.util.Optional<java.lang.Integer> intOptional60 = objConsumerRecord58.leaderEpoch();
        long long61 = objConsumerRecord58.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType44, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord58, (java.io.Serializable) '#');
        java.lang.Class<?> wildcardClass64 = objConsumerRecord63.getClass();
        org.apache.kafka.common.record.TimestampType timestampType69 = null;
        java.lang.Object obj73 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType69, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj73, (java.io.Serializable) 1);
        java.lang.String str76 = objConsumerRecord75.toString();
        java.lang.String str77 = objConsumerRecord75.toString();
        long long78 = objConsumerRecord75.offset();
        java.lang.String str79 = objConsumerRecord75.topic();
        java.lang.Class<?> wildcardClass80 = objConsumerRecord75.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.AnnotatedElement> typeConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) '4', (long) '4', (long) '#', timestampType36, 0L, (int) (byte) 100, (int) ' ', (java.lang.reflect.Type) wildcardClass64, (java.lang.reflect.AnnotatedElement) wildcardClass80);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.reflect.AnnotatedElement> objConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.reflect.AnnotatedElement>("", (int) (short) 100, 100L, (java.lang.Object) objConsumerRecord29, (java.lang.reflect.AnnotatedElement) wildcardClass64);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.String> typeConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)", (int) '#', (long) '4', (long) '4', timestampType4, (long) 35, 35, (int) (short) 10, (java.lang.reflect.Type) wildcardClass64, "");
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + 52L + "'", long25 == 52L);
        org.junit.Assert.assertTrue("'" + int26 + "' != '" + 100 + "'", int26 == 100);
        org.junit.Assert.assertNotNull(intOptional27);
        org.junit.Assert.assertEquals("'" + str30 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)" + "'", str30, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)");
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 100 + "'", int31 == 100);
        org.junit.Assert.assertTrue("'" + long59 + "' != '" + 52L + "'", long59 == 52L);
        org.junit.Assert.assertNotNull(intOptional60);
        org.junit.Assert.assertTrue("'" + long61 + "' != '" + 52L + "'", long61 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass64);
        org.junit.Assert.assertEquals("'" + str76 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str76, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str77 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str77, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long78 + "' != '" + (-1L) + "'", long78 == (-1L));
        org.junit.Assert.assertEquals("'" + str79 + "' != '" + "" + "'", str79, "");
        org.junit.Assert.assertNotNull(wildcardClass80);
    }

    @Test
    public void test00078() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00078");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, java.lang.CharSequence> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.CharSequence> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.CharSequence>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00079() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00079");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00080() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00080");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        java.lang.String str14 = objConsumerRecord13.toString();
        long long15 = objConsumerRecord13.offset();
        java.lang.String str16 = objConsumerRecord13.toString();
        java.lang.String str17 = objConsumerRecord13.toString();
        org.apache.kafka.common.header.Headers headers18 = objConsumerRecord13.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.CharSequence> objConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.CharSequence>("ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", 0, (long) (short) -1, (java.lang.Object) headers18, (java.lang.CharSequence) "hi!");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str17, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(headers18);
    }

    @Test
    public void test00081() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00081");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        java.lang.String str14 = objConsumerRecord13.toString();
        java.util.Optional<java.lang.Integer> intOptional15 = objConsumerRecord13.leaderEpoch();
        int int16 = objConsumerRecord13.serializedKeySize();
        long long17 = objConsumerRecord13.timestamp();
        org.apache.kafka.common.header.Headers headers18 = objConsumerRecord13.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.lang.CharSequence> headersConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.lang.CharSequence>("", (int) (short) 1, 0L, headers18, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertNotNull(headers18);
    }

    @Test
    public void test00082() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00082");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        java.lang.String str19 = objConsumerRecord18.toString();
        java.lang.String str20 = objConsumerRecord18.toString();
        org.apache.kafka.common.record.TimestampType timestampType26 = null;
        java.lang.Object obj30 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType26, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj30, (java.io.Serializable) 1);
        java.lang.String str33 = objConsumerRecord32.toString();
        long long34 = objConsumerRecord32.offset();
        org.apache.kafka.common.header.Headers headers35 = objConsumerRecord32.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) (byte) 100, (long) (byte) 1, (long) (short) 1, timestampType4, (java.lang.Long) 10L, (int) (short) 0, (int) (short) 1, (java.lang.Object) str20, (java.io.Serializable) 10, headers35);
        long long37 = objConsumerRecord36.checksum();
        java.lang.String str38 = objConsumerRecord36.topic();
        org.apache.kafka.common.record.TimestampType timestampType39 = objConsumerRecord36.timestampType();
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str33, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertNotNull(headers35);
        org.junit.Assert.assertTrue("'" + long37 + "' != '" + 10L + "'", long37 == 10L);
        org.junit.Assert.assertEquals("'" + str38 + "' != '" + "hi!" + "'", str38, "hi!");
        org.junit.Assert.assertNull(timestampType39);
    }

    @Test
    public void test00083() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00083");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        int int14 = objConsumerRecord10.partition();
        int int15 = objConsumerRecord10.serializedValueSize();
        int int16 = objConsumerRecord10.serializedKeySize();
        int int17 = objConsumerRecord10.partition();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
    }

    @Test
    public void test00084() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00084");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, java.lang.reflect.Type> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.reflect.Type> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.reflect.Type>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00085() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00085");
        java.lang.Object obj14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj14, (java.io.Serializable) (byte) 100);
        java.lang.Object obj17 = objConsumerRecord16.key();
        java.lang.String str18 = objConsumerRecord16.toString();
        org.apache.kafka.common.record.TimestampType timestampType19 = objConsumerRecord16.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        java.lang.Object obj36 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType32, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj36, (java.io.Serializable) 1);
        java.lang.String str39 = objConsumerRecord38.toString();
        java.lang.String str40 = objConsumerRecord38.toString();
        java.lang.Class<?> wildcardClass41 = objConsumerRecord38.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type> charSequenceConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '#', (long) (short) -1, (java.lang.CharSequence) "", (java.lang.reflect.Type) wildcardClass41);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement> charSequenceConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) '#', 100L, (long) 'a', timestampType19, (long) (byte) 100, (int) (byte) -1, 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (java.lang.reflect.AnnotatedElement) wildcardClass41);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.CharSequence> timestampTypeEnumConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.CharSequence>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) '#', (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType19, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)");
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        java.lang.Object obj57 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType53, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj57, (java.io.Serializable) 1);
        java.lang.String str60 = objConsumerRecord59.toString();
        java.util.Optional<java.lang.Integer> intOptional61 = objConsumerRecord59.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional62 = objConsumerRecord59.leaderEpoch();
        int int63 = objConsumerRecord59.partition();
        java.lang.Class<?> wildcardClass64 = objConsumerRecord59.getClass();
        org.apache.kafka.common.record.TimestampType timestampType69 = null;
        java.lang.Object obj73 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType69, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj73, (java.io.Serializable) 1);
        java.lang.String str76 = objConsumerRecord75.toString();
        java.util.Optional<java.lang.Integer> intOptional77 = objConsumerRecord75.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional78 = objConsumerRecord75.leaderEpoch();
        int int79 = objConsumerRecord75.partition();
        int int80 = objConsumerRecord75.serializedValueSize();
        java.io.Serializable serializable81 = objConsumerRecord75.value();
        org.apache.kafka.common.record.TimestampType timestampType86 = null;
        java.lang.Object obj90 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord92 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType86, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj90, (java.io.Serializable) 1);
        long long93 = objConsumerRecord92.offset();
        long long94 = objConsumerRecord92.checksum();
        org.apache.kafka.common.header.Headers headers95 = objConsumerRecord92.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.Object> typeConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.Object>("hi!", (int) (short) 1, (long) (short) 0, (long) (byte) -1, timestampType19, (java.lang.Long) (-1L), (int) 'a', (int) (short) -1, (java.lang.reflect.Type) wildcardClass64, (java.lang.Object) serializable81, headers95);
        org.junit.Assert.assertNull(obj17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str18, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str39 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str39, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str40 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str40, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass41);
        org.junit.Assert.assertEquals("'" + str60 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str60, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional61);
        org.junit.Assert.assertNotNull(intOptional62);
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 10 + "'", int63 == 10);
        org.junit.Assert.assertNotNull(wildcardClass64);
        org.junit.Assert.assertEquals("'" + str76 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str76, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertNotNull(intOptional78);
        org.junit.Assert.assertTrue("'" + int79 + "' != '" + 10 + "'", int79 == 10);
        org.junit.Assert.assertTrue("'" + int80 + "' != '" + 100 + "'", int80 == 100);
        org.junit.Assert.assertEquals("'" + serializable81 + "' != '" + 1 + "'", serializable81, 1);
        org.junit.Assert.assertTrue("'" + long93 + "' != '" + (-1L) + "'", long93 == (-1L));
        org.junit.Assert.assertTrue("'" + long94 + "' != '" + 0L + "'", long94 == 0L);
        org.junit.Assert.assertNotNull(headers95);
    }

    @Test
    public void test00086() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00086");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, java.lang.Comparable<java.lang.String>> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.Comparable<java.lang.String>> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.Comparable<java.lang.String>>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00087() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00087");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.lang.Object> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.Object> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.Object>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00088() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00088");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00089() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00089");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00090() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00090");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, java.lang.String> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.String> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.String>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00091() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00091");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, java.io.Serializable> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.io.Serializable> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.io.Serializable>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00092() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00092");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.lang.Comparable<java.lang.String>> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.Comparable<java.lang.String>> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.Comparable<java.lang.String>>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00093() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00093");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, java.lang.reflect.AnnotatedElement> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.reflect.AnnotatedElement> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.reflect.AnnotatedElement>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00094() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00094");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, java.lang.reflect.AnnotatedElement> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.reflect.AnnotatedElement> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.reflect.AnnotatedElement>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00095() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00095");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, org.apache.kafka.common.header.Headers> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, org.apache.kafka.common.header.Headers> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, org.apache.kafka.common.header.Headers>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00096() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00096");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00097() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00097");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, org.apache.kafka.common.header.Headers> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, org.apache.kafka.common.header.Headers> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, org.apache.kafka.common.header.Headers>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00098() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00098");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.io.Serializable> objConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.io.Serializable> objConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.io.Serializable>(objConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00099() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00099");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Comparable<java.lang.String>> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Comparable<java.lang.String>> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Comparable<java.lang.String>>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00100() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00100");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, java.lang.Comparable<java.lang.String>> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.Comparable<java.lang.String>> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.Comparable<java.lang.String>>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00101() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00101");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, java.util.Optional<java.lang.Integer>> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.util.Optional<java.lang.Integer>> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.util.Optional<java.lang.Integer>>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00102() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00102");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.lang.reflect.GenericDeclaration> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.reflect.GenericDeclaration> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.reflect.GenericDeclaration>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00103() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00103");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.Iterable<org.apache.kafka.common.header.Header>> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.Iterable<org.apache.kafka.common.header.Header>> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.Iterable<org.apache.kafka.common.header.Header>>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00104() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00104");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        int int12 = objConsumerRecord10.serializedValueSize();
        java.lang.Object obj13 = objConsumerRecord10.key();
        int int14 = objConsumerRecord10.serializedValueSize();
        int int15 = objConsumerRecord10.serializedKeySize();
        java.lang.Object obj16 = objConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
        org.junit.Assert.assertNull(obj13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 100 + "'", int14 == 100);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertNull(obj16);
    }

    @Test
    public void test00105() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00105");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, java.util.Optional<java.lang.Integer>> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.util.Optional<java.lang.Integer>> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.util.Optional<java.lang.Integer>>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00106() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00106");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, java.lang.Iterable<org.apache.kafka.common.header.Header>> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.Iterable<org.apache.kafka.common.header.Header>> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.Iterable<org.apache.kafka.common.header.Header>>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00107() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00107");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        int int14 = objConsumerRecord10.partition();
        long long15 = objConsumerRecord10.offset();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord10.timestampType();
        java.io.Serializable serializable17 = objConsumerRecord10.value();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertEquals("'" + serializable17 + "' != '" + 1 + "'", serializable17, 1);
    }

    @Test
    public void test00108() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00108");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, java.lang.CharSequence> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.CharSequence> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.CharSequence>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00109() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00109");
        java.lang.Object obj19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj19, (java.io.Serializable) (byte) 100);
        java.lang.Object obj22 = objConsumerRecord21.key();
        java.lang.String str23 = objConsumerRecord21.toString();
        org.apache.kafka.common.record.TimestampType timestampType24 = objConsumerRecord21.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType37 = null;
        java.lang.Object obj41 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType37, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj41, (java.io.Serializable) 1);
        java.lang.String str44 = objConsumerRecord43.toString();
        java.lang.String str45 = objConsumerRecord43.toString();
        java.lang.Class<?> wildcardClass46 = objConsumerRecord43.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type> charSequenceConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '#', (long) (short) -1, (java.lang.CharSequence) "", (java.lang.reflect.Type) wildcardClass46);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement> charSequenceConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) '#', 100L, (long) 'a', timestampType24, (long) (byte) 100, (int) (byte) -1, 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (java.lang.reflect.AnnotatedElement) wildcardClass46);
        org.apache.kafka.common.record.TimestampType timestampType56 = null;
        java.lang.Object obj60 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord62 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType56, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj60, (java.io.Serializable) 1);
        long long63 = objConsumerRecord62.timestamp();
        java.lang.Object obj64 = objConsumerRecord62.key();
        long long65 = objConsumerRecord62.checksum();
        long long66 = objConsumerRecord62.checksum();
        org.apache.kafka.common.record.TimestampType timestampType67 = objConsumerRecord62.timestampType();
        org.apache.kafka.common.header.Headers headers68 = objConsumerRecord62.headers();
        org.apache.kafka.common.record.TimestampType timestampType76 = null;
        java.lang.Object obj80 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType76, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj80, (java.io.Serializable) 1);
        long long83 = objConsumerRecord82.timestamp();
        int int84 = objConsumerRecord82.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional85 = objConsumerRecord82.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord82, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType88 = objConsumerRecord87.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord89 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), 1L, (long) (short) 1, timestampType24, (long) 10, (int) (byte) 0, (int) '#', (java.lang.Object) headers68, (java.io.Serializable) timestampType88);
        java.lang.Object obj93 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord95 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)", (int) (byte) 0, 52L, (long) (byte) -1, timestampType24, (long) 1, (int) (short) 0, (int) (byte) -1, obj93, (java.io.Serializable) false);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.io.Serializable> strComparableConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", 100, (long) (byte) 100, (java.lang.Comparable<java.lang.String>) "", (java.io.Serializable) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)");
        java.lang.Class<?> wildcardClass97 = strComparableConsumerRecord96.getClass();
        org.junit.Assert.assertNull(obj22);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str23, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType24 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType24.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str44 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str44, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str45 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str45, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass46);
        org.junit.Assert.assertTrue("'" + long63 + "' != '" + 52L + "'", long63 == 52L);
        org.junit.Assert.assertNull(obj64);
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + 0L + "'", long65 == 0L);
        org.junit.Assert.assertTrue("'" + long66 + "' != '" + 0L + "'", long66 == 0L);
        org.junit.Assert.assertNull(timestampType67);
        org.junit.Assert.assertNotNull(headers68);
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + 52L + "'", long83 == 52L);
        org.junit.Assert.assertTrue("'" + int84 + "' != '" + 100 + "'", int84 == 100);
        org.junit.Assert.assertNotNull(intOptional85);
        org.junit.Assert.assertTrue("'" + timestampType88 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType88.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass97);
    }

    @Test
    public void test00110() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00110");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, java.lang.CharSequence> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.CharSequence> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.CharSequence>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00111() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00111");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, java.lang.Comparable<java.lang.String>> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.Comparable<java.lang.String>> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.Comparable<java.lang.String>>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00112() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00112");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, java.io.Serializable> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.io.Serializable> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.io.Serializable>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00113() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00113");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.String> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.String> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.String>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00114() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00114");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, org.apache.kafka.common.record.TimestampType> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, org.apache.kafka.common.record.TimestampType> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, org.apache.kafka.common.record.TimestampType>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00115() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00115");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        long long19 = objConsumerRecord18.timestamp();
        java.lang.Object obj20 = objConsumerRecord18.key();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.io.Serializable> objConsumerRecordConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.io.Serializable>("", 100, (long) '#', (long) (byte) 0, timestampType4, (long) (-1), (int) (byte) 0, (int) (short) 100, objConsumerRecord18, (java.io.Serializable) (-1.0d));
        java.lang.Class<?> wildcardClass23 = objConsumerRecordConsumerRecord22.getClass();
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertNull(obj20);
        org.junit.Assert.assertNotNull(wildcardClass23);
    }

    @Test
    public void test00116() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00116");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, java.io.Serializable> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.io.Serializable> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.io.Serializable>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00117() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00117");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.reflect.AnnotatedElement> objConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.reflect.AnnotatedElement> objConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.reflect.AnnotatedElement>(objConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00118() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00118");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, org.apache.kafka.common.record.TimestampType> objConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, org.apache.kafka.common.record.TimestampType> objConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, org.apache.kafka.common.record.TimestampType>(objConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00119() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00119");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, java.lang.Iterable<org.apache.kafka.common.header.Header>> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.Iterable<org.apache.kafka.common.header.Header>> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.Iterable<org.apache.kafka.common.header.Header>>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00120() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00120");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, java.lang.Comparable<java.lang.String>> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.Comparable<java.lang.String>> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.Comparable<java.lang.String>>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00121() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00121");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, java.util.Optional<java.lang.Integer>> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.util.Optional<java.lang.Integer>> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.util.Optional<java.lang.Integer>>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00122() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00122");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.CharSequence> objConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.CharSequence> objConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.CharSequence>(objConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00123() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00123");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.reflect.AnnotatedElement> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.reflect.AnnotatedElement> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.reflect.AnnotatedElement>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00124() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00124");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers13 = objConsumerRecord10.headers();
        java.lang.String str14 = objConsumerRecord10.toString();
        long long15 = objConsumerRecord10.offset();
        long long16 = objConsumerRecord10.checksum();
        java.lang.Object obj17 = objConsumerRecord10.key();
        java.io.Serializable serializable18 = objConsumerRecord10.value();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertNull(obj17);
        org.junit.Assert.assertEquals("'" + serializable18 + "' != '" + 1 + "'", serializable18, 1);
    }

    @Test
    public void test00125() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00125");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00126() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00126");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, org.apache.kafka.common.record.TimestampType> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, org.apache.kafka.common.record.TimestampType> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, org.apache.kafka.common.record.TimestampType>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00127() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00127");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, java.lang.reflect.AnnotatedElement> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.reflect.AnnotatedElement> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.reflect.AnnotatedElement>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00128() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00128");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.lang.String str12 = objConsumerRecord10.toString();
        long long13 = objConsumerRecord10.offset();
        java.lang.String str14 = objConsumerRecord10.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = objConsumerRecord10.timestampType();
        java.util.Optional<java.lang.Integer> intOptional16 = objConsumerRecord10.leaderEpoch();
        java.lang.Class<?> wildcardClass17 = objConsumerRecord10.getClass();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str12, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertNull(timestampType15);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertNotNull(wildcardClass17);
    }

    @Test
    public void test00129() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00129");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.header.Headers> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.header.Headers> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.header.Headers>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00130() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00130");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.io.Serializable> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.io.Serializable> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.io.Serializable>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00131() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00131");
        org.apache.kafka.common.record.TimestampType timestampType11 = null;
        java.lang.Object obj15 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType11, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj15, (java.io.Serializable) 1);
        long long18 = objConsumerRecord17.timestamp();
        int int19 = objConsumerRecord17.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord17.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord17, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType23 = objConsumerRecord22.timestampType();
        java.lang.Object obj35 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj35, (java.io.Serializable) (byte) 100);
        java.lang.Object obj38 = objConsumerRecord37.key();
        java.lang.String str39 = objConsumerRecord37.toString();
        org.apache.kafka.common.record.TimestampType timestampType40 = objConsumerRecord37.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        java.lang.Object obj57 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType53, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj57, (java.io.Serializable) 1);
        java.lang.String str60 = objConsumerRecord59.toString();
        java.lang.String str61 = objConsumerRecord59.toString();
        java.lang.Class<?> wildcardClass62 = objConsumerRecord59.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type> charSequenceConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '#', (long) (short) -1, (java.lang.CharSequence) "", (java.lang.reflect.Type) wildcardClass62);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement> charSequenceConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) '#', 100L, (long) 'a', timestampType40, (long) (byte) 100, (int) (byte) -1, 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (java.lang.reflect.AnnotatedElement) wildcardClass62);
        org.apache.kafka.common.header.Headers headers65 = null;
        java.lang.Object obj69 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj69, (java.io.Serializable) (byte) 100);
        long long72 = objConsumerRecord71.timestamp();
        java.util.Optional<java.lang.Integer> intOptional73 = objConsumerRecord71.leaderEpoch();
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.reflect.GenericDeclaration> strConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.reflect.GenericDeclaration>("", (int) (byte) -1, (long) (-1), 0L, timestampType23, (java.lang.Long) 0L, 100, 0, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (java.lang.reflect.GenericDeclaration) wildcardClass62, headers65, intOptional73);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 52L + "'", long18 == 52L);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 100 + "'", int19 == 100);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNull(obj38);
        org.junit.Assert.assertEquals("'" + str39 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str39, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType40 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType40.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str60 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str60, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str61, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass62);
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + (-1L) + "'", long72 == (-1L));
        org.junit.Assert.assertNotNull(intOptional73);
    }

    @Test
    public void test00132() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00132");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.reflect.GenericDeclaration> objConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.reflect.GenericDeclaration> objConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.reflect.GenericDeclaration>(objConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00133() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00133");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.reflect.Type> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.reflect.Type> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.reflect.Type>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00134() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00134");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> objConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> objConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>(objConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00135() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00135");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        long long13 = objConsumerRecord10.checksum();
        java.lang.String str14 = objConsumerRecord10.topic();
        java.io.Serializable serializable15 = objConsumerRecord10.value();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord10.timestampType();
        int int17 = objConsumerRecord10.serializedValueSize();
        java.lang.Class<?> wildcardClass18 = objConsumerRecord10.getClass();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertEquals("'" + serializable15 + "' != '" + 1 + "'", serializable15, 1);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 100 + "'", int17 == 100);
        org.junit.Assert.assertNotNull(wildcardClass18);
    }

    @Test
    public void test00136() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00136");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Object> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Object> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Object>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00137() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00137");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, org.apache.kafka.common.record.TimestampType> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, org.apache.kafka.common.record.TimestampType> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, org.apache.kafka.common.record.TimestampType>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00138() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00138");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00139() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00139");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.offset();
        long long12 = objConsumerRecord10.checksum();
        long long13 = objConsumerRecord10.offset();
        int int14 = objConsumerRecord10.serializedKeySize();
        long long15 = objConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional16 = objConsumerRecord10.leaderEpoch();
        java.lang.Class<?> wildcardClass17 = objConsumerRecord10.getClass();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 0L + "'", long12 == 0L);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertNotNull(wildcardClass17);
    }

    @Test
    public void test00140() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00140");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType15 = null;
        java.lang.Object obj19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType15, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj19, (java.io.Serializable) 1);
        java.lang.String str22 = objConsumerRecord21.toString();
        long long23 = objConsumerRecord21.offset();
        org.apache.kafka.common.header.Headers headers24 = objConsumerRecord21.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable> headersConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable>("", (int) (short) 100, (long) 10, headers24, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType31 = null;
        java.lang.Object obj35 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType31, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj35, (java.io.Serializable) 1);
        java.lang.String str38 = objConsumerRecord37.toString();
        java.lang.String str39 = objConsumerRecord37.toString();
        java.lang.Class<?> wildcardClass40 = objConsumerRecord37.getClass();
        org.apache.kafka.common.record.TimestampType timestampType48 = null;
        java.lang.Object obj52 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType48, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj52, (java.io.Serializable) 1);
        java.lang.String str55 = objConsumerRecord54.toString();
        long long56 = objConsumerRecord54.offset();
        org.apache.kafka.common.header.Headers headers57 = objConsumerRecord54.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable> headersConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable>("", (int) (short) 100, (long) 10, headers57, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType64 = null;
        java.lang.Object obj68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType64, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj68, (java.io.Serializable) 1);
        java.lang.String str71 = objConsumerRecord70.toString();
        java.util.Optional<java.lang.Integer> intOptional72 = objConsumerRecord70.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.lang.reflect.GenericDeclaration> headersConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (-1), (long) '#', (long) (short) 1, timestampType4, (java.lang.Long) 0L, (int) (short) -1, (int) '#', headers24, (java.lang.reflect.GenericDeclaration) wildcardClass40, headers57, intOptional72);
        java.lang.Class<?> wildcardClass74 = headersConsumerRecord73.getClass();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str22, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long23 + "' != '" + (-1L) + "'", long23 == (-1L));
        org.junit.Assert.assertNotNull(headers24);
        org.junit.Assert.assertEquals("'" + str38 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str38, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str39 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str39, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass40);
        org.junit.Assert.assertEquals("'" + str55 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str55, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + (-1L) + "'", long56 == (-1L));
        org.junit.Assert.assertNotNull(headers57);
        org.junit.Assert.assertEquals("'" + str71 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str71, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional72);
        org.junit.Assert.assertNotNull(wildcardClass74);
    }

    @Test
    public void test00141() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00141");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Comparable<java.lang.String>> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Comparable<java.lang.String>> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Comparable<java.lang.String>>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00142() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00142");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, java.lang.reflect.GenericDeclaration> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.reflect.GenericDeclaration> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.reflect.GenericDeclaration>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00143() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00143");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(objConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00144() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00144");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, java.util.Optional<java.lang.Integer>> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.util.Optional<java.lang.Integer>> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.util.Optional<java.lang.Integer>>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00145() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00145");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, java.lang.reflect.GenericDeclaration> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.reflect.GenericDeclaration> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.reflect.GenericDeclaration>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00146() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00146");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, java.lang.Object> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.Object> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.Object>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00147() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00147");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.Object> objConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.Object> objConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.Object>(objConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00148() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00148");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.lang.String> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.String> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.String>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00149() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00149");
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj11, (java.io.Serializable) (byte) 100);
        java.lang.Object obj14 = objConsumerRecord13.key();
        java.lang.String str15 = objConsumerRecord13.toString();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType24 = null;
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        java.lang.Object obj36 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType32, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj36, (java.io.Serializable) 1);
        long long39 = objConsumerRecord38.timestamp();
        java.util.Optional<java.lang.Integer> intOptional40 = objConsumerRecord38.leaderEpoch();
        long long41 = objConsumerRecord38.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType24, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord38, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional44 = objConsumerRecord38.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.String> intOptionalConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.String>("hi!", (int) (short) -1, (long) (short) 0, (long) (short) 0, timestampType16, (long) (byte) 0, (int) (byte) 0, 0, intOptional44, "");
        org.apache.kafka.common.record.TimestampType timestampType54 = null;
        org.apache.kafka.common.record.TimestampType timestampType63 = null;
        java.lang.Object obj67 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType63, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj67, (java.io.Serializable) 1);
        long long70 = objConsumerRecord69.timestamp();
        java.util.Optional<java.lang.Integer> intOptional71 = objConsumerRecord69.leaderEpoch();
        long long72 = objConsumerRecord69.offset();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> charSequenceConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>("", (int) '4', (long) 'a', 0L, timestampType54, 10L, (-1), (int) (short) 0, (java.lang.CharSequence) "hi!", objConsumerRecord69);
        org.apache.kafka.common.record.TimestampType timestampType78 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType78, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        org.apache.kafka.common.header.Headers headers85 = objConsumerRecord84.headers();
        org.apache.kafka.common.header.Headers headers86 = objConsumerRecord84.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord92 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '4', (long) (short) 100, (java.lang.Object) (-1.0d), (java.io.Serializable) (-1.0d));
        java.lang.String str93 = objConsumerRecord92.topic();
        org.apache.kafka.common.header.Headers headers94 = objConsumerRecord92.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Iterable<org.apache.kafka.common.header.Header>> objConsumerRecord95 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Iterable<org.apache.kafka.common.header.Header>>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)", 100, (long) '4', (long) (short) 1, timestampType16, (java.lang.Long) 100L, 35, (int) (byte) 1, (java.lang.Object) "hi!", (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers86, headers94);
        org.junit.Assert.assertNull(obj14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str15, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + 52L + "'", long39 == 52L);
        org.junit.Assert.assertNotNull(intOptional40);
        org.junit.Assert.assertTrue("'" + long41 + "' != '" + 52L + "'", long41 == 52L);
        org.junit.Assert.assertNotNull(intOptional44);
        org.junit.Assert.assertTrue("'" + long70 + "' != '" + 52L + "'", long70 == 52L);
        org.junit.Assert.assertNotNull(intOptional71);
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + (-1L) + "'", long72 == (-1L));
        org.junit.Assert.assertNotNull(headers85);
        org.junit.Assert.assertNotNull(headers86);
        org.junit.Assert.assertEquals("'" + str93 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str93, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(headers94);
    }

    @Test
    public void test00150() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00150");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00151() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00151");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, java.util.Optional<java.lang.Integer>> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.util.Optional<java.lang.Integer>> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.util.Optional<java.lang.Integer>>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00152() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00152");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.lang.reflect.Type> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.reflect.Type> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.reflect.Type>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00153() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00153");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.lang.reflect.GenericDeclaration> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.reflect.GenericDeclaration> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.reflect.GenericDeclaration>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00154() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00154");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, org.apache.kafka.common.record.TimestampType> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, org.apache.kafka.common.record.TimestampType> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, org.apache.kafka.common.record.TimestampType>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00155() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00155");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, java.util.Optional<java.lang.Integer>> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.util.Optional<java.lang.Integer>> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.util.Optional<java.lang.Integer>>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00156() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00156");
        org.apache.kafka.common.record.TimestampType timestampType15 = null;
        java.lang.Object obj19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType15, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj19, (java.io.Serializable) 1);
        long long22 = objConsumerRecord21.timestamp();
        int int23 = objConsumerRecord21.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional24 = objConsumerRecord21.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord21, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType27 = objConsumerRecord26.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType38 = null;
        java.lang.Object obj42 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType38, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj42, (java.io.Serializable) 1);
        long long45 = objConsumerRecord44.timestamp();
        int int46 = objConsumerRecord44.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional47 = objConsumerRecord44.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord44, (java.io.Serializable) false);
        java.lang.String str50 = objConsumerRecord49.toString();
        java.lang.Class<?> wildcardClass51 = objConsumerRecord49.getClass();
        org.apache.kafka.common.record.TimestampType timestampType59 = null;
        java.lang.Object obj63 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType59, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj63, (java.io.Serializable) 1);
        long long66 = objConsumerRecord65.timestamp();
        int int67 = objConsumerRecord65.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional68 = objConsumerRecord65.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord65, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType71 = objConsumerRecord70.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> serializableConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", 35, 0L, (long) (byte) -1, timestampType27, (long) '4', (int) (short) 100, 35, (java.io.Serializable) wildcardClass51, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType71);
        org.apache.kafka.common.record.TimestampType timestampType80 = null;
        java.lang.Object obj84 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType80, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj84, (java.io.Serializable) 1);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) '#', (long) (byte) -1, (-1L), timestampType27, (long) (byte) 100, (-1), 100, (java.lang.Object) timestampType80, (java.io.Serializable) (short) -1);
        java.lang.Class<?> wildcardClass89 = timestampType27.getClass();
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 52L + "'", long22 == 52L);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 100 + "'", int23 == 100);
        org.junit.Assert.assertNotNull(intOptional24);
        org.junit.Assert.assertTrue("'" + timestampType27 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType27.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long45 + "' != '" + 52L + "'", long45 == 52L);
        org.junit.Assert.assertTrue("'" + int46 + "' != '" + 100 + "'", int46 == 100);
        org.junit.Assert.assertNotNull(intOptional47);
        org.junit.Assert.assertEquals("'" + str50 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)" + "'", str50, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)");
        org.junit.Assert.assertNotNull(wildcardClass51);
        org.junit.Assert.assertTrue("'" + long66 + "' != '" + 52L + "'", long66 == 52L);
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + 100 + "'", int67 == 100);
        org.junit.Assert.assertNotNull(intOptional68);
        org.junit.Assert.assertTrue("'" + timestampType71 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType71.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass89);
    }

    @Test
    public void test00157() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00157");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.lang.CharSequence> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.CharSequence> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.CharSequence>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00158() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00158");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.GenericDeclaration> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.GenericDeclaration> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.GenericDeclaration>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00159() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00159");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        long long13 = objConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType14 = objConsumerRecord10.timestampType();
        long long15 = objConsumerRecord10.timestamp();
        long long16 = objConsumerRecord10.timestamp();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 52L + "'", long16 == 52L);
    }

    @Test
    public void test00160() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00160");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers13 = objConsumerRecord10.headers();
        java.lang.String str14 = objConsumerRecord10.toString();
        long long15 = objConsumerRecord10.offset();
        long long16 = objConsumerRecord10.checksum();
        java.lang.String str17 = objConsumerRecord10.toString();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str17, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
    }

    @Test
    public void test00161() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00161");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00162() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00162");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.lang.Object> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.Object> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.Object>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00163() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00163");
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj11, (java.io.Serializable) (byte) 100);
        java.lang.Object obj14 = objConsumerRecord13.key();
        java.lang.String str15 = objConsumerRecord13.toString();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) -1, 10L, (long) (short) 100, timestampType16, (long) 0, 0, 35, (java.lang.Object) (-1), (java.io.Serializable) 1L);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.CharSequence> strComparableConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.CharSequence>("ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", (int) (byte) -1, (long) 1, (long) 100, timestampType16, (long) '4', 32, (int) (byte) 100, (java.lang.Comparable<java.lang.String>) "", (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        java.lang.Class<?> wildcardClass29 = strComparableConsumerRecord28.getClass();
        org.junit.Assert.assertNull(obj14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str15, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass29);
    }

    @Test
    public void test00164() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00164");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        int int12 = objConsumerRecord10.serializedValueSize();
        java.lang.Object obj13 = objConsumerRecord10.key();
        long long14 = objConsumerRecord10.offset();
        java.lang.Class<?> wildcardClass15 = objConsumerRecord10.getClass();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
        org.junit.Assert.assertNull(obj13);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass15);
    }

    @Test
    public void test00165() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00165");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.topic();
        java.io.Serializable serializable12 = objConsumerRecord10.value();
        int int13 = objConsumerRecord10.partition();
        java.lang.Object obj14 = objConsumerRecord10.key();
        java.lang.String str15 = objConsumerRecord10.topic();
        int int16 = objConsumerRecord10.partition();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertEquals("'" + serializable12 + "' != '" + 1 + "'", serializable12, 1);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
        org.junit.Assert.assertNull(obj14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "" + "'", str15, "");
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
    }

    @Test
    public void test00166() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00166");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, org.apache.kafka.common.record.TimestampType> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, org.apache.kafka.common.record.TimestampType> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, org.apache.kafka.common.record.TimestampType>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00167() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00167");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.util.Optional<java.lang.Integer>> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.util.Optional<java.lang.Integer>> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.util.Optional<java.lang.Integer>>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00168() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00168");
        org.apache.kafka.common.record.TimestampType timestampType10 = null;
        java.lang.Object obj14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType10, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj14, (java.io.Serializable) 1);
        long long17 = objConsumerRecord16.timestamp();
        java.util.Optional<java.lang.Integer> intOptional18 = objConsumerRecord16.leaderEpoch();
        long long19 = objConsumerRecord16.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType24 = null;
        java.lang.Object obj28 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType24, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj28, (java.io.Serializable) 1);
        java.lang.String str31 = objConsumerRecord30.toString();
        java.lang.String str32 = objConsumerRecord30.toString();
        java.lang.Class<?> wildcardClass33 = objConsumerRecord30.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (short) 10, (java.lang.Object) objConsumerRecord16, (java.io.Serializable) wildcardClass33);
        long long35 = objConsumerRecord16.timestamp();
        int int36 = objConsumerRecord16.serializedValueSize();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)", 35, (long) (short) 10, (java.lang.Object) int36, (java.io.Serializable) 1);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertNotNull(intOptional18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertEquals("'" + str31 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str31, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str32, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass33);
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + 52L + "'", long35 == 52L);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + 100 + "'", int36 == 100);
    }

    @Test
    public void test00169() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00169");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.common.header.Headers> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.common.header.Headers> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.common.header.Headers>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00170() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00170");
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj11, (java.io.Serializable) (byte) 100);
        java.lang.Object obj14 = objConsumerRecord13.key();
        java.lang.String str15 = objConsumerRecord13.toString();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType24 = null;
        java.lang.Object obj28 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType24, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj28, (java.io.Serializable) 1);
        long long31 = objConsumerRecord30.offset();
        long long32 = objConsumerRecord30.checksum();
        org.apache.kafka.common.header.Headers headers33 = objConsumerRecord30.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), (long) (short) 1, (long) 0, timestampType16, 10L, 97, (int) '4', (java.lang.Object) headers33, (java.io.Serializable) 0.0d);
        org.apache.kafka.common.record.TimestampType timestampType43 = null;
        java.lang.Object obj47 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType43, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj47, (java.io.Serializable) 1);
        java.lang.String str50 = objConsumerRecord49.toString();
        long long51 = objConsumerRecord49.offset();
        org.apache.kafka.common.header.Headers headers52 = objConsumerRecord49.headers();
        java.lang.String str53 = objConsumerRecord49.toString();
        long long54 = objConsumerRecord49.offset();
        long long55 = objConsumerRecord49.checksum();
        int int56 = objConsumerRecord49.partition();
        long long57 = objConsumerRecord49.offset();
        java.lang.Object obj58 = objConsumerRecord49.key();
        org.apache.kafka.common.record.TimestampType timestampType63 = null;
        java.lang.Object obj67 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType63, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj67, (java.io.Serializable) 1);
        long long70 = objConsumerRecord69.timestamp();
        long long71 = objConsumerRecord69.timestamp();
        java.lang.Class<?> wildcardClass72 = objConsumerRecord69.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (int) ' ', 52L, (long) (byte) 0, timestampType16, 0L, 32, 0, obj58, (java.io.Serializable) wildcardClass72);
        // The following exception was thrown during execution in test generation
        try {
            java.lang.Class<?> wildcardClass74 = obj58.getClass();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(obj14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str15, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long31 + "' != '" + (-1L) + "'", long31 == (-1L));
        org.junit.Assert.assertTrue("'" + long32 + "' != '" + 0L + "'", long32 == 0L);
        org.junit.Assert.assertNotNull(headers33);
        org.junit.Assert.assertEquals("'" + str50 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str50, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + (-1L) + "'", long51 == (-1L));
        org.junit.Assert.assertNotNull(headers52);
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str53, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + (-1L) + "'", long54 == (-1L));
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + 0L + "'", long55 == 0L);
        org.junit.Assert.assertTrue("'" + int56 + "' != '" + 10 + "'", int56 == 10);
        org.junit.Assert.assertTrue("'" + long57 + "' != '" + (-1L) + "'", long57 == (-1L));
        org.junit.Assert.assertNull(obj58);
        org.junit.Assert.assertTrue("'" + long70 + "' != '" + 52L + "'", long70 == 52L);
        org.junit.Assert.assertTrue("'" + long71 + "' != '" + 52L + "'", long71 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass72);
    }

    @Test
    public void test00171() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00171");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        long long15 = objConsumerRecord13.timestamp();
        int int16 = objConsumerRecord13.serializedKeySize();
        long long17 = objConsumerRecord13.timestamp();
        long long18 = objConsumerRecord13.offset();
        long long19 = objConsumerRecord13.offset();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord13.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType25 = null;
        org.apache.kafka.common.record.TimestampType timestampType33 = null;
        org.apache.kafka.common.record.TimestampType timestampType41 = null;
        java.lang.Object obj45 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType41, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj45, (java.io.Serializable) 1);
        long long48 = objConsumerRecord47.timestamp();
        java.util.Optional<java.lang.Integer> intOptional49 = objConsumerRecord47.leaderEpoch();
        long long50 = objConsumerRecord47.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType33, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord47, (java.io.Serializable) '#');
        java.lang.Class<?> wildcardClass53 = objConsumerRecord52.getClass();
        org.apache.kafka.common.record.TimestampType timestampType58 = null;
        java.lang.Object obj62 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType58, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj62, (java.io.Serializable) 1);
        java.lang.String str65 = objConsumerRecord64.toString();
        java.lang.String str66 = objConsumerRecord64.toString();
        long long67 = objConsumerRecord64.offset();
        java.lang.String str68 = objConsumerRecord64.topic();
        java.lang.Class<?> wildcardClass69 = objConsumerRecord64.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.AnnotatedElement> typeConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) '4', (long) '4', (long) '#', timestampType25, 0L, (int) (byte) 100, (int) ' ', (java.lang.reflect.Type) wildcardClass53, (java.lang.reflect.AnnotatedElement) wildcardClass69);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.reflect.GenericDeclaration> intOptionalConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 100, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = class org.apache.kafka.clients.consumer.ConsumerRecord, value = null)", (int) 'a', (long) 35, intOptional20, (java.lang.reflect.GenericDeclaration) wildcardClass53);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + 52L + "'", long48 == 52L);
        org.junit.Assert.assertNotNull(intOptional49);
        org.junit.Assert.assertTrue("'" + long50 + "' != '" + 52L + "'", long50 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass53);
        org.junit.Assert.assertEquals("'" + str65 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str65, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str66 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str66, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long67 + "' != '" + (-1L) + "'", long67 == (-1L));
        org.junit.Assert.assertEquals("'" + str68 + "' != '" + "" + "'", str68, "");
        org.junit.Assert.assertNotNull(wildcardClass69);
    }

    @Test
    public void test00172() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00172");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers13 = objConsumerRecord10.headers();
        java.lang.String str14 = objConsumerRecord10.toString();
        long long15 = objConsumerRecord10.offset();
        long long16 = objConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional17 = objConsumerRecord10.leaderEpoch();
        java.lang.Object obj18 = objConsumerRecord10.key();
        long long19 = objConsumerRecord10.offset();
        int int20 = objConsumerRecord10.serializedKeySize();
        long long21 = objConsumerRecord10.timestamp();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertNotNull(intOptional17);
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 10 + "'", int20 == 10);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
    }

    @Test
    public void test00173() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00173");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.Type> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.Type> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.Type>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00174() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00174");
        java.lang.Object obj7 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj7, (java.io.Serializable) (byte) 100);
        long long10 = objConsumerRecord9.timestamp();
        java.lang.String str11 = objConsumerRecord9.toString();
        int int12 = objConsumerRecord9.serializedValueSize();
        org.apache.kafka.common.header.Headers headers13 = objConsumerRecord9.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.Iterable<org.apache.kafka.common.header.Header>> strConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.Iterable<org.apache.kafka.common.header.Header>>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 100, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = class org.apache.kafka.clients.consumer.ConsumerRecord, value = null)", (int) (short) -1, 35L, "", (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers13);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str11, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNotNull(headers13);
    }

    @Test
    public void test00175() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00175");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        int int15 = objConsumerRecord13.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional16 = objConsumerRecord13.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord13, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType19 = objConsumerRecord18.timestampType();
        int int20 = objConsumerRecord18.serializedKeySize();
        long long21 = objConsumerRecord18.checksum();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + (-1) + "'", int20 == (-1));
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
    }

    @Test
    public void test00176() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00176");
        org.apache.kafka.common.record.TimestampType timestampType10 = null;
        java.lang.Object obj14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType10, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj14, (java.io.Serializable) 1);
        long long17 = objConsumerRecord16.timestamp();
        int int18 = objConsumerRecord16.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional19 = objConsumerRecord16.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord16, (java.io.Serializable) false);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) 0, (long) 97, (java.lang.Object) false, (java.io.Serializable) (short) 100);
        int int24 = objConsumerRecord23.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 100 + "'", int18 == 100);
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
    }

    @Test
    public void test00177() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00177");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, java.io.Serializable> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.io.Serializable> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.io.Serializable>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00178() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00178");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, java.lang.reflect.Type> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.reflect.Type> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.reflect.Type>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00179() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00179");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, java.lang.reflect.GenericDeclaration> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.reflect.GenericDeclaration> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.reflect.GenericDeclaration>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00180() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00180");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, org.apache.kafka.common.record.TimestampType> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, org.apache.kafka.common.record.TimestampType> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, org.apache.kafka.common.record.TimestampType>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00181() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00181");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        long long19 = objConsumerRecord18.timestamp();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord18.leaderEpoch();
        long long21 = objConsumerRecord18.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType4, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord18, (java.io.Serializable) '#');
        java.io.Serializable serializable24 = objConsumerRecord23.value();
        org.apache.kafka.common.record.TimestampType timestampType25 = objConsumerRecord23.timestampType();
        java.lang.String str26 = objConsumerRecord23.toString();
        long long27 = objConsumerRecord23.offset();
        java.lang.Class<?> wildcardClass28 = objConsumerRecord23.getClass();
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertEquals("'" + serializable24 + "' != '" + '#' + "'", serializable24, '#');
        org.junit.Assert.assertNull(timestampType25);
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)" + "'", str26, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)");
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + (-1L) + "'", long27 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass28);
    }

    @Test
    public void test00182() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00182");
        org.apache.kafka.common.record.TimestampType timestampType10 = null;
        java.lang.Object obj14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType10, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj14, (java.io.Serializable) 1);
        long long17 = objConsumerRecord16.timestamp();
        java.lang.Object obj18 = objConsumerRecord16.key();
        long long19 = objConsumerRecord16.checksum();
        org.apache.kafka.common.record.TimestampType timestampType24 = null;
        java.lang.Object obj28 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType24, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj28, (java.io.Serializable) 1);
        long long31 = objConsumerRecord30.timestamp();
        java.util.Optional<java.lang.Integer> intOptional32 = objConsumerRecord30.leaderEpoch();
        long long33 = objConsumerRecord30.timestamp();
        java.lang.Class<?> wildcardClass34 = objConsumerRecord30.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (byte) -1, (long) 0, (java.lang.Object) objConsumerRecord16, (java.io.Serializable) wildcardClass34);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)", (int) (byte) -1, (long) 10, (java.lang.Object) objConsumerRecord16, (java.io.Serializable) (-1.0f));
        long long38 = objConsumerRecord16.timestamp();
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertTrue("'" + long31 + "' != '" + 52L + "'", long31 == 52L);
        org.junit.Assert.assertNotNull(intOptional32);
        org.junit.Assert.assertTrue("'" + long33 + "' != '" + 52L + "'", long33 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass34);
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + 52L + "'", long38 == 52L);
    }

    @Test
    public void test00183() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00183");
        java.lang.Object obj10 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj10, (java.io.Serializable) (byte) 100);
        org.apache.kafka.common.record.TimestampType timestampType17 = null;
        java.lang.Object obj21 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType17, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj21, (java.io.Serializable) 1);
        long long24 = objConsumerRecord23.timestamp();
        java.lang.Object obj25 = objConsumerRecord23.key();
        long long26 = objConsumerRecord23.checksum();
        java.lang.Class<?> wildcardClass27 = objConsumerRecord23.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) 1, (long) '#', obj10, (java.io.Serializable) wildcardClass27);
        java.lang.Object obj29 = objConsumerRecord28.key();
        long long30 = objConsumerRecord28.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType31 = objConsumerRecord28.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType39 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType39, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        org.apache.kafka.common.record.TimestampType timestampType46 = objConsumerRecord45.timestampType();
        long long47 = objConsumerRecord45.timestamp();
        org.apache.kafka.common.header.Headers headers48 = objConsumerRecord45.headers();
        int int49 = objConsumerRecord45.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType57 = null;
        org.apache.kafka.common.record.TimestampType timestampType65 = null;
        java.lang.Object obj69 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType65, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj69, (java.io.Serializable) 1);
        long long72 = objConsumerRecord71.timestamp();
        java.util.Optional<java.lang.Integer> intOptional73 = objConsumerRecord71.leaderEpoch();
        long long74 = objConsumerRecord71.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType57, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord71, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional77 = objConsumerRecord71.leaderEpoch();
        java.lang.Object obj85 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj85, (java.io.Serializable) (byte) 100);
        java.lang.Object obj88 = objConsumerRecord87.key();
        java.lang.String str89 = objConsumerRecord87.toString();
        org.apache.kafka.common.record.TimestampType timestampType90 = objConsumerRecord87.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) -1, 10L, (long) (short) 100, timestampType90, (long) 0, 0, 35, (java.lang.Object) (-1), (java.io.Serializable) 1L);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType> intOptionalConsumerRecord97 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType>("", (-1), (long) (byte) -1, intOptional77, timestampType90);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)", (int) 'a', (long) '#', (long) 32, timestampType31, 97L, 100, (int) (short) 100, (java.lang.Object) objConsumerRecord45, (java.io.Serializable) (-1));
        java.lang.String str99 = objConsumerRecord45.topic();
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 52L + "'", long24 == 52L);
        org.junit.Assert.assertNull(obj25);
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + 0L + "'", long26 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass27);
        org.junit.Assert.assertNull(obj29);
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNull(timestampType46);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 10L + "'", long47 == 10L);
        org.junit.Assert.assertNotNull(headers48);
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + (-1) + "'", int49 == (-1));
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + 52L + "'", long72 == 52L);
        org.junit.Assert.assertNotNull(intOptional73);
        org.junit.Assert.assertTrue("'" + long74 + "' != '" + 52L + "'", long74 == 52L);
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertNull(obj88);
        org.junit.Assert.assertEquals("'" + str89 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str89, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType90 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType90.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str99 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str99, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
    }

    @Test
    public void test00184() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00184");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00185() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00185");
        java.lang.reflect.GenericDeclaration genericDeclaration3 = null;
        java.lang.Object obj19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj19, (java.io.Serializable) (byte) 100);
        java.lang.Object obj22 = objConsumerRecord21.key();
        java.lang.String str23 = objConsumerRecord21.toString();
        org.apache.kafka.common.record.TimestampType timestampType24 = objConsumerRecord21.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) -1, 10L, (long) (short) 100, timestampType24, (long) 0, 0, 35, (java.lang.Object) (-1), (java.io.Serializable) 1L);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.CharSequence> strComparableConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.CharSequence>("ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", (int) (byte) -1, (long) 1, (long) 100, timestampType24, (long) '4', 32, (int) (byte) 100, (java.lang.Comparable<java.lang.String>) "", (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.apache.kafka.common.record.TimestampType timestampType44 = null;
        java.lang.Object obj48 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType44, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj48, (java.io.Serializable) 1);
        java.lang.String str51 = objConsumerRecord50.toString();
        int int52 = objConsumerRecord50.serializedValueSize();
        java.lang.String str53 = objConsumerRecord50.toString();
        java.io.Serializable serializable54 = objConsumerRecord50.value();
        long long55 = objConsumerRecord50.offset();
        java.lang.String str56 = objConsumerRecord50.topic();
        java.lang.Object obj61 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj61, (java.io.Serializable) (byte) 100);
        long long64 = objConsumerRecord63.timestamp();
        org.apache.kafka.common.header.Headers headers65 = objConsumerRecord63.headers();
        org.apache.kafka.common.record.TimestampType timestampType70 = null;
        org.apache.kafka.common.record.TimestampType timestampType78 = null;
        java.lang.Object obj82 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType78, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj82, (java.io.Serializable) 1);
        long long85 = objConsumerRecord84.timestamp();
        java.util.Optional<java.lang.Integer> intOptional86 = objConsumerRecord84.leaderEpoch();
        long long87 = objConsumerRecord84.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord89 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType70, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord84, (java.io.Serializable) '#');
        int int90 = objConsumerRecord89.partition();
        java.util.Optional<java.lang.Integer> intOptional91 = objConsumerRecord89.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord92 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)", (int) (short) 1, (long) 'a', (-1L), timestampType24, (java.lang.Long) 0L, (int) (short) 1, 35, (java.lang.Object) str56, (java.io.Serializable) 0.0f, headers65, intOptional91);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.util.Optional<java.lang.Integer>> genericDeclarationConsumerRecord93 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.util.Optional<java.lang.Integer>>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)", 32, 97L, genericDeclaration3, intOptional91);
        org.junit.Assert.assertNull(obj22);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str23, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType24 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType24.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str51 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str51, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + int52 + "' != '" + 100 + "'", int52 == 100);
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str53, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + serializable54 + "' != '" + 1 + "'", serializable54, 1);
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + (-1L) + "'", long55 == (-1L));
        org.junit.Assert.assertEquals("'" + str56 + "' != '" + "" + "'", str56, "");
        org.junit.Assert.assertTrue("'" + long64 + "' != '" + (-1L) + "'", long64 == (-1L));
        org.junit.Assert.assertNotNull(headers65);
        org.junit.Assert.assertTrue("'" + long85 + "' != '" + 52L + "'", long85 == 52L);
        org.junit.Assert.assertNotNull(intOptional86);
        org.junit.Assert.assertTrue("'" + long87 + "' != '" + 52L + "'", long87 == 52L);
        org.junit.Assert.assertTrue("'" + int90 + "' != '" + (-1) + "'", int90 == (-1));
        org.junit.Assert.assertNotNull(intOptional91);
    }

    @Test
    public void test00186() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00186");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, org.apache.kafka.common.header.Headers> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, org.apache.kafka.common.header.Headers> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, org.apache.kafka.common.header.Headers>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00187() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00187");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        java.lang.String str14 = objConsumerRecord13.toString();
        long long15 = objConsumerRecord13.offset();
        org.apache.kafka.common.header.Headers headers16 = objConsumerRecord13.headers();
        java.lang.String str17 = objConsumerRecord13.toString();
        long long18 = objConsumerRecord13.offset();
        long long19 = objConsumerRecord13.checksum();
        java.lang.Object obj20 = objConsumerRecord13.key();
        java.util.Optional<java.lang.Integer> intOptional21 = objConsumerRecord13.leaderEpoch();
        org.apache.kafka.common.header.Headers headers22 = objConsumerRecord13.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.String> objConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.String>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) (short) -1, (long) (short) 1, (java.lang.Object) headers22, "");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str17, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertNull(obj20);
        org.junit.Assert.assertNotNull(intOptional21);
        org.junit.Assert.assertNotNull(headers22);
    }

    @Test
    public void test00188() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00188");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.kafka.common.record.TimestampType timestampType15 = null;
        java.lang.Object obj19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType15, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj19, (java.io.Serializable) 1);
        long long22 = objConsumerRecord21.timestamp();
        java.util.Optional<java.lang.Integer> intOptional23 = objConsumerRecord21.leaderEpoch();
        long long24 = objConsumerRecord21.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType7, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord21, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional27 = objConsumerRecord21.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        org.apache.kafka.common.record.TimestampType timestampType49 = null;
        java.lang.Object obj53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType49, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj53, (java.io.Serializable) 1);
        long long56 = objConsumerRecord55.timestamp();
        java.util.Optional<java.lang.Integer> intOptional57 = objConsumerRecord55.leaderEpoch();
        long long58 = objConsumerRecord55.offset();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>("", (int) '4', (long) 'a', 0L, timestampType40, 10L, (-1), (int) (short) 0, (java.lang.CharSequence) "hi!", objConsumerRecord55);
        java.lang.Class<?> wildcardClass60 = charSequenceConsumerRecord59.getClass();
        org.apache.kafka.common.record.TimestampType timestampType65 = null;
        java.lang.Object obj69 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType65, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj69, (java.io.Serializable) 1);
        long long72 = objConsumerRecord71.timestamp();
        java.lang.Object obj73 = objConsumerRecord71.key();
        long long74 = objConsumerRecord71.checksum();
        java.lang.Class<?> wildcardClass75 = objConsumerRecord71.getClass();
        org.apache.kafka.common.record.TimestampType timestampType80 = null;
        java.lang.Object obj87 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord89 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj87, (java.io.Serializable) (byte) 100);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord91 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (byte) 100, (long) (byte) 10, (long) 0, timestampType80, (-1L), 1, (int) (short) 1, (java.lang.Object) 'a', (java.io.Serializable) (short) 1);
        org.apache.kafka.common.header.Headers headers92 = objConsumerRecord91.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.reflect.AnnotatedElement> genericDeclarationConsumerRecord93 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.reflect.AnnotatedElement>("hi!", 10, (long) (-1), 1L, timestampType32, (java.lang.Long) 52L, (int) (byte) 1, 10, (java.lang.reflect.GenericDeclaration) wildcardClass60, (java.lang.reflect.AnnotatedElement) wildcardClass75, headers92);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord94 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (int) (byte) 1, (long) '4', (java.lang.Object) intOptional27, (java.io.Serializable) 10);
        java.lang.Class<?> wildcardClass95 = objConsumerRecord94.getClass();
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 52L + "'", long22 == 52L);
        org.junit.Assert.assertNotNull(intOptional23);
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 52L + "'", long24 == 52L);
        org.junit.Assert.assertNotNull(intOptional27);
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + 52L + "'", long56 == 52L);
        org.junit.Assert.assertNotNull(intOptional57);
        org.junit.Assert.assertTrue("'" + long58 + "' != '" + (-1L) + "'", long58 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass60);
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + 52L + "'", long72 == 52L);
        org.junit.Assert.assertNull(obj73);
        org.junit.Assert.assertTrue("'" + long74 + "' != '" + 0L + "'", long74 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass75);
        org.junit.Assert.assertNotNull(headers92);
        org.junit.Assert.assertNotNull(wildcardClass95);
    }

    @Test
    public void test00189() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00189");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.lang.String str12 = objConsumerRecord10.toString();
        long long13 = objConsumerRecord10.offset();
        java.util.Optional<java.lang.Integer> intOptional14 = objConsumerRecord10.leaderEpoch();
        java.lang.Class<?> wildcardClass15 = intOptional14.getClass();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str12, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertNotNull(intOptional14);
        org.junit.Assert.assertNotNull(wildcardClass15);
    }

    @Test
    public void test00190() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00190");
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj11, (java.io.Serializable) (byte) 100);
        java.lang.Object obj14 = objConsumerRecord13.key();
        java.lang.String str15 = objConsumerRecord13.toString();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType24 = null;
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        java.lang.Object obj36 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType32, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj36, (java.io.Serializable) 1);
        long long39 = objConsumerRecord38.timestamp();
        java.util.Optional<java.lang.Integer> intOptional40 = objConsumerRecord38.leaderEpoch();
        long long41 = objConsumerRecord38.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType24, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord38, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional44 = objConsumerRecord38.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.String> intOptionalConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.String>("hi!", (int) (short) -1, (long) (short) 0, (long) (short) 0, timestampType16, (long) (byte) 0, (int) (byte) 0, 0, intOptional44, "");
        org.apache.kafka.common.record.TimestampType timestampType54 = null;
        java.lang.Object obj58 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType54, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj58, (java.io.Serializable) 1);
        java.lang.String str61 = objConsumerRecord60.toString();
        long long62 = objConsumerRecord60.offset();
        org.apache.kafka.common.header.Headers headers63 = objConsumerRecord60.headers();
        java.lang.String str64 = objConsumerRecord60.topic();
        org.apache.kafka.common.header.Headers headers65 = objConsumerRecord60.headers();
        org.apache.kafka.common.record.TimestampType timestampType70 = null;
        java.lang.Object obj74 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType70, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj74, (java.io.Serializable) 1);
        org.apache.kafka.common.record.TimestampType timestampType77 = objConsumerRecord76.timestampType();
        java.util.Optional<java.lang.Integer> intOptional78 = objConsumerRecord76.leaderEpoch();
        java.lang.Class<?> wildcardClass79 = intOptional78.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 0, leaderEpoch = null, offset = 1, NoTimestampType = 97, serialized key size = 35, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)", (int) (byte) 0, (long) (byte) 10, 52L, timestampType16, (long) (byte) 100, (int) 'a', 0, (java.lang.Object) headers65, (java.io.Serializable) wildcardClass79);
        java.lang.Class<?> wildcardClass81 = headers65.getClass();
        org.junit.Assert.assertNull(obj14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str15, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + 52L + "'", long39 == 52L);
        org.junit.Assert.assertNotNull(intOptional40);
        org.junit.Assert.assertTrue("'" + long41 + "' != '" + 52L + "'", long41 == 52L);
        org.junit.Assert.assertNotNull(intOptional44);
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str61, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + (-1L) + "'", long62 == (-1L));
        org.junit.Assert.assertNotNull(headers63);
        org.junit.Assert.assertEquals("'" + str64 + "' != '" + "" + "'", str64, "");
        org.junit.Assert.assertNotNull(headers65);
        org.junit.Assert.assertNull(timestampType77);
        org.junit.Assert.assertNotNull(intOptional78);
        org.junit.Assert.assertNotNull(wildcardClass79);
        org.junit.Assert.assertNotNull(wildcardClass81);
    }

    @Test
    public void test00191() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00191");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00192() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00192");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 100, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = class org.apache.kafka.clients.consumer.ConsumerRecord, value = null)", (int) (byte) 100, (long) 1, (long) 100, timestampType4, (long) 97, (int) (byte) 1, (int) (byte) 10, "ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 100, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = class org.apache.kafka.clients.consumer.ConsumerRecord, value = null)", (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 1, NoTimestampType = 1, serialized key size = 0, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = NoTimestampType)");
    }

    @Test
    public void test00193() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00193");
        org.apache.kafka.common.record.TimestampType timestampType13 = null;
        java.lang.Object obj17 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType13, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj17, (java.io.Serializable) 1);
        long long20 = objConsumerRecord19.timestamp();
        int int21 = objConsumerRecord19.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional22 = objConsumerRecord19.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord19, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType25 = objConsumerRecord19.timestampType();
        java.lang.String str26 = objConsumerRecord19.topic();
        long long27 = objConsumerRecord19.timestamp();
        java.lang.Object obj28 = objConsumerRecord19.key();
        org.apache.kafka.common.header.Headers headers29 = objConsumerRecord19.headers();
        org.apache.kafka.common.record.TimestampType timestampType34 = null;
        java.lang.Object obj38 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord40 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType34, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj38, (java.io.Serializable) 1);
        org.apache.kafka.common.record.TimestampType timestampType41 = objConsumerRecord40.timestampType();
        java.util.Optional<java.lang.Integer> intOptional42 = objConsumerRecord40.leaderEpoch();
        long long43 = objConsumerRecord40.offset();
        int int44 = objConsumerRecord40.partition();
        java.lang.Class<?> wildcardClass45 = objConsumerRecord40.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.GenericDeclaration> headerIterableConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)", (int) (byte) 1, (long) (byte) 0, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers29, (java.lang.reflect.GenericDeclaration) wildcardClass45);
        org.apache.kafka.common.record.TimestampType timestampType54 = null;
        java.lang.Object obj58 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType54, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj58, (java.io.Serializable) 1);
        long long61 = objConsumerRecord60.timestamp();
        java.util.Optional<java.lang.Integer> intOptional62 = objConsumerRecord60.leaderEpoch();
        int int63 = objConsumerRecord60.serializedValueSize();
        java.lang.String str64 = objConsumerRecord60.topic();
        java.lang.String str65 = objConsumerRecord60.topic();
        java.lang.String str66 = objConsumerRecord60.topic();
        java.lang.Class<?> wildcardClass67 = objConsumerRecord60.getClass();
        org.apache.kafka.common.record.TimestampType timestampType72 = null;
        java.lang.Object obj76 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType72, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj76, (java.io.Serializable) 1);
        long long79 = objConsumerRecord78.timestamp();
        int int80 = objConsumerRecord78.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional81 = objConsumerRecord78.leaderEpoch();
        java.io.Serializable serializable82 = objConsumerRecord78.value();
        int int83 = objConsumerRecord78.serializedValueSize();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.lang.Object> annotatedElementConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.lang.Object>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 0, leaderEpoch = null, offset = 1, NoTimestampType = 97, serialized key size = 35, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)", (int) (short) -1, 10L, (java.lang.reflect.AnnotatedElement) wildcardClass67, (java.lang.Object) objConsumerRecord78);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.reflect.AnnotatedElement> genericDeclarationConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", (int) '#', (long) '#', (java.lang.reflect.GenericDeclaration) wildcardClass45, (java.lang.reflect.AnnotatedElement) wildcardClass67);
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 52L + "'", long20 == 52L);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 100 + "'", int21 == 100);
        org.junit.Assert.assertNotNull(intOptional22);
        org.junit.Assert.assertNull(timestampType25);
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "" + "'", str26, "");
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + 52L + "'", long27 == 52L);
        org.junit.Assert.assertNull(obj28);
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertNull(timestampType41);
        org.junit.Assert.assertNotNull(intOptional42);
        org.junit.Assert.assertTrue("'" + long43 + "' != '" + (-1L) + "'", long43 == (-1L));
        org.junit.Assert.assertTrue("'" + int44 + "' != '" + 10 + "'", int44 == 10);
        org.junit.Assert.assertNotNull(wildcardClass45);
        org.junit.Assert.assertTrue("'" + long61 + "' != '" + 52L + "'", long61 == 52L);
        org.junit.Assert.assertNotNull(intOptional62);
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 100 + "'", int63 == 100);
        org.junit.Assert.assertEquals("'" + str64 + "' != '" + "" + "'", str64, "");
        org.junit.Assert.assertEquals("'" + str65 + "' != '" + "" + "'", str65, "");
        org.junit.Assert.assertEquals("'" + str66 + "' != '" + "" + "'", str66, "");
        org.junit.Assert.assertNotNull(wildcardClass67);
        org.junit.Assert.assertTrue("'" + long79 + "' != '" + 52L + "'", long79 == 52L);
        org.junit.Assert.assertTrue("'" + int80 + "' != '" + 100 + "'", int80 == 100);
        org.junit.Assert.assertNotNull(intOptional81);
        org.junit.Assert.assertEquals("'" + serializable82 + "' != '" + 1 + "'", serializable82, 1);
        org.junit.Assert.assertTrue("'" + int83 + "' != '" + 100 + "'", int83 == 100);
    }

    @Test
    public void test00194() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00194");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, java.io.Serializable> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.io.Serializable> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.io.Serializable>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00195() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00195");
        java.lang.Object obj6 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj6, (java.io.Serializable) (byte) 100);
        java.lang.Object obj9 = objConsumerRecord8.key();
        int int10 = objConsumerRecord8.partition();
        org.apache.kafka.common.header.Headers headers11 = objConsumerRecord8.headers();
        org.apache.kafka.common.record.TimestampType timestampType16 = null;
        org.apache.kafka.common.record.TimestampType timestampType24 = null;
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        java.lang.Object obj36 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType32, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj36, (java.io.Serializable) 1);
        long long39 = objConsumerRecord38.timestamp();
        java.lang.Object obj40 = objConsumerRecord38.key();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.io.Serializable> objConsumerRecordConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.io.Serializable>("", 100, (long) '#', (long) (byte) 0, timestampType24, (long) (-1), (int) (byte) 0, (int) (short) 100, objConsumerRecord38, (java.io.Serializable) (-1.0d));
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) (byte) -1, (long) 1, (long) (byte) 0, timestampType16, (long) '4', (int) (byte) 0, (int) 'a', (java.lang.Object) objConsumerRecordConsumerRecord42, (java.io.Serializable) 10.0f);
        java.lang.Class<?> wildcardClass45 = objConsumerRecord44.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 0, (long) ' ', (java.lang.Object) headers11, (java.io.Serializable) wildcardClass45);
        java.lang.String str47 = objConsumerRecord46.toString();
        org.junit.Assert.assertNull(obj9);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 97 + "'", int10 == 97);
        org.junit.Assert.assertNotNull(headers11);
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + 52L + "'", long39 == 52L);
        org.junit.Assert.assertNull(obj40);
        org.junit.Assert.assertNotNull(wildcardClass45);
        org.junit.Assert.assertEquals("'" + str47 + "' != '" + "ConsumerRecord(topic = hi!, partition = 0, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = class org.apache.kafka.clients.consumer.ConsumerRecord)" + "'", str47, "ConsumerRecord(topic = hi!, partition = 0, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = class org.apache.kafka.clients.consumer.ConsumerRecord)");
    }

    @Test
    public void test00196() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00196");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.reflect.GenericDeclaration> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.reflect.GenericDeclaration> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.reflect.GenericDeclaration>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00197() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00197");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.io.Serializable> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.io.Serializable> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.io.Serializable>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00198() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00198");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.util.Optional<java.lang.Integer>> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.util.Optional<java.lang.Integer>> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.util.Optional<java.lang.Integer>>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00199() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00199");
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj11, (java.io.Serializable) (byte) 100);
        java.lang.Object obj14 = objConsumerRecord13.key();
        java.lang.String str15 = objConsumerRecord13.toString();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType24 = null;
        java.lang.Object obj28 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType24, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj28, (java.io.Serializable) 1);
        long long31 = objConsumerRecord30.offset();
        long long32 = objConsumerRecord30.checksum();
        org.apache.kafka.common.header.Headers headers33 = objConsumerRecord30.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), (long) (short) 1, (long) 0, timestampType16, 10L, 97, (int) '4', (java.lang.Object) headers33, (java.io.Serializable) 0.0d);
        java.lang.Object obj39 = null;
        java.io.Serializable serializable40 = null;
        org.apache.kafka.common.record.TimestampType timestampType48 = null;
        java.lang.Object obj52 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType48, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj52, (java.io.Serializable) 1);
        java.lang.String str55 = objConsumerRecord54.toString();
        long long56 = objConsumerRecord54.offset();
        org.apache.kafka.common.header.Headers headers57 = objConsumerRecord54.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable> headersConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable>("", (int) (short) 100, (long) 10, headers57, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType64 = null;
        java.lang.Object obj68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType64, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj68, (java.io.Serializable) 1);
        java.lang.String str71 = objConsumerRecord70.toString();
        long long72 = objConsumerRecord70.offset();
        java.util.Optional<java.lang.Integer> intOptional73 = objConsumerRecord70.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) (byte) 10, (long) 100, 10L, timestampType16, (java.lang.Long) 100L, 0, (int) (short) -1, obj39, serializable40, headers57, intOptional73);
        java.lang.Object obj75 = objConsumerRecord74.key();
        org.junit.Assert.assertNull(obj14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str15, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long31 + "' != '" + (-1L) + "'", long31 == (-1L));
        org.junit.Assert.assertTrue("'" + long32 + "' != '" + 0L + "'", long32 == 0L);
        org.junit.Assert.assertNotNull(headers33);
        org.junit.Assert.assertEquals("'" + str55 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str55, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + (-1L) + "'", long56 == (-1L));
        org.junit.Assert.assertNotNull(headers57);
        org.junit.Assert.assertEquals("'" + str71 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str71, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + (-1L) + "'", long72 == (-1L));
        org.junit.Assert.assertNotNull(intOptional73);
        org.junit.Assert.assertNull(obj75);
    }

    @Test
    public void test00200() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00200");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        int int13 = objConsumerRecord10.serializedValueSize();
        java.io.Serializable serializable14 = objConsumerRecord10.value();
        int int15 = objConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 100 + "'", int13 == 100);
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + 1 + "'", serializable14, 1);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
    }

    @Test
    public void test00201() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00201");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00202() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00202");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        int int13 = objConsumerRecord10.serializedKeySize();
        long long14 = objConsumerRecord10.timestamp();
        int int15 = objConsumerRecord10.serializedValueSize();
        java.lang.Class<?> wildcardClass16 = objConsumerRecord10.getClass();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertNotNull(wildcardClass16);
    }

    @Test
    public void test00203() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00203");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, java.lang.reflect.Type> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.reflect.Type> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.reflect.Type>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00204() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00204");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.offset();
        long long12 = objConsumerRecord10.timestamp();
        java.lang.Object obj13 = objConsumerRecord10.key();
        java.lang.Object obj14 = objConsumerRecord10.key();
        long long15 = objConsumerRecord10.timestamp();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
        org.junit.Assert.assertNull(obj13);
        org.junit.Assert.assertNull(obj14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
    }

    @Test
    public void test00205() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00205");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType12, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        org.apache.kafka.common.header.Headers headers19 = objConsumerRecord18.headers();
        org.apache.kafka.common.record.TimestampType timestampType24 = null;
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        java.lang.Object obj36 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType32, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj36, (java.io.Serializable) 1);
        java.lang.String str39 = objConsumerRecord38.toString();
        java.lang.String str40 = objConsumerRecord38.toString();
        org.apache.kafka.common.record.TimestampType timestampType46 = null;
        java.lang.Object obj50 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType46, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj50, (java.io.Serializable) 1);
        java.lang.String str53 = objConsumerRecord52.toString();
        long long54 = objConsumerRecord52.offset();
        org.apache.kafka.common.header.Headers headers55 = objConsumerRecord52.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) (byte) 100, (long) (byte) 1, (long) (short) 1, timestampType24, (java.lang.Long) 10L, (int) (short) 0, (int) (short) 1, (java.lang.Object) str40, (java.io.Serializable) 10, headers55);
        org.apache.kafka.common.record.TimestampType timestampType61 = null;
        org.apache.kafka.common.record.TimestampType timestampType69 = null;
        java.lang.Object obj73 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType69, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj73, (java.io.Serializable) 1);
        long long76 = objConsumerRecord75.timestamp();
        java.util.Optional<java.lang.Integer> intOptional77 = objConsumerRecord75.leaderEpoch();
        long long78 = objConsumerRecord75.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType61, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord75, (java.io.Serializable) '#');
        java.lang.Object obj81 = objConsumerRecord80.key();
        org.apache.kafka.common.header.Headers headers82 = objConsumerRecord80.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, org.apache.kafka.common.header.Headers> headersConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, org.apache.kafka.common.header.Headers>("", 35, 1L, (long) (byte) 10, timestampType4, (java.lang.Long) (-1L), 0, 10, headers19, headers55, headers82);
        java.lang.Class<?> wildcardClass84 = headers19.getClass();
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertEquals("'" + str39 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str39, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str40 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str40, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str53, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + (-1L) + "'", long54 == (-1L));
        org.junit.Assert.assertNotNull(headers55);
        org.junit.Assert.assertTrue("'" + long76 + "' != '" + 52L + "'", long76 == 52L);
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertTrue("'" + long78 + "' != '" + 52L + "'", long78 == 52L);
        org.junit.Assert.assertNotNull(obj81);
        org.junit.Assert.assertEquals(obj81.toString(), "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals(java.lang.String.valueOf(obj81), "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals(java.util.Objects.toString(obj81), "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(headers82);
        org.junit.Assert.assertNotNull(wildcardClass84);
    }

    @Test
    public void test00206() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00206");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        int int12 = objConsumerRecord10.serializedValueSize();
        java.lang.String str13 = objConsumerRecord10.toString();
        java.io.Serializable serializable14 = objConsumerRecord10.value();
        long long15 = objConsumerRecord10.offset();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord10.timestampType();
        int int17 = objConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + 1 + "'", serializable14, 1);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 100 + "'", int17 == 100);
    }

    @Test
    public void test00207() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00207");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        org.apache.kafka.common.record.TimestampType timestampType20 = null;
        java.lang.Object obj24 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType20, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj24, (java.io.Serializable) 1);
        long long27 = objConsumerRecord26.timestamp();
        java.lang.Object obj28 = objConsumerRecord26.key();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.io.Serializable> objConsumerRecordConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.io.Serializable>("", 100, (long) '#', (long) (byte) 0, timestampType12, (long) (-1), (int) (byte) 0, (int) (short) 100, objConsumerRecord26, (java.io.Serializable) (-1.0d));
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) (byte) -1, (long) 1, (long) (byte) 0, timestampType4, (long) '4', (int) (byte) 0, (int) 'a', (java.lang.Object) objConsumerRecordConsumerRecord30, (java.io.Serializable) 10.0f);
        java.lang.String str33 = objConsumerRecord32.topic();
        org.apache.kafka.common.record.TimestampType timestampType34 = objConsumerRecord32.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType35 = objConsumerRecord32.timestampType();
        java.lang.Object obj36 = objConsumerRecord32.key();
        org.apache.kafka.common.record.TimestampType timestampType37 = objConsumerRecord32.timestampType();
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + 52L + "'", long27 == 52L);
        org.junit.Assert.assertNull(obj28);
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)" + "'", str33, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)");
        org.junit.Assert.assertNull(timestampType34);
        org.junit.Assert.assertNull(timestampType35);
        org.junit.Assert.assertNotNull(obj36);
        org.junit.Assert.assertEquals(obj36.toString(), "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 35, null = 0, serialized key size = 0, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = -1.0)");
        org.junit.Assert.assertEquals(java.lang.String.valueOf(obj36), "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 35, null = 0, serialized key size = 0, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = -1.0)");
        org.junit.Assert.assertEquals(java.util.Objects.toString(obj36), "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 35, null = 0, serialized key size = 0, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = -1.0)");
        org.junit.Assert.assertNull(timestampType37);
    }

    @Test
    public void test00208() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00208");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 1, NoTimestampType = 1, serialized key size = 0, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = NoTimestampType)", (int) ' ', (long) (short) 0, (java.lang.Object) "", (java.io.Serializable) 1.0f);
        long long6 = objConsumerRecord5.checksum();
        org.apache.kafka.common.header.Headers headers7 = objConsumerRecord5.headers();
        java.lang.Class<?> wildcardClass8 = headers7.getClass();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertNotNull(headers7);
        org.junit.Assert.assertNotNull(wildcardClass8);
    }

    @Test
    public void test00209() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00209");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.io.Serializable> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.io.Serializable> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.io.Serializable>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00210() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00210");
        org.apache.kafka.common.record.TimestampType timestampType10 = null;
        org.apache.kafka.common.record.TimestampType timestampType18 = null;
        java.lang.Object obj22 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType18, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj22, (java.io.Serializable) 1);
        long long25 = objConsumerRecord24.timestamp();
        java.util.Optional<java.lang.Integer> intOptional26 = objConsumerRecord24.leaderEpoch();
        long long27 = objConsumerRecord24.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType10, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord24, (java.io.Serializable) '#');
        java.io.Serializable serializable30 = objConsumerRecord29.value();
        org.apache.kafka.common.record.TimestampType timestampType31 = objConsumerRecord29.timestampType();
        java.lang.String str32 = objConsumerRecord29.toString();
        org.apache.kafka.common.record.TimestampType timestampType37 = null;
        org.apache.kafka.common.record.TimestampType timestampType45 = null;
        java.lang.Object obj49 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType45, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj49, (java.io.Serializable) 1);
        long long52 = objConsumerRecord51.timestamp();
        java.util.Optional<java.lang.Integer> intOptional53 = objConsumerRecord51.leaderEpoch();
        long long54 = objConsumerRecord51.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType37, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord51, (java.io.Serializable) '#');
        java.lang.Class<?> wildcardClass57 = objConsumerRecord56.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 32, (long) '#', (java.lang.Object) objConsumerRecord29, (java.io.Serializable) wildcardClass57);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.String> genericDeclarationConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.String>("hi!", (int) (byte) 10, 100L, (java.lang.reflect.GenericDeclaration) wildcardClass57, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 0, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = class org.apache.kafka.clients.consumer.ConsumerRecord)");
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + 52L + "'", long25 == 52L);
        org.junit.Assert.assertNotNull(intOptional26);
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + 52L + "'", long27 == 52L);
        org.junit.Assert.assertEquals("'" + serializable30 + "' != '" + '#' + "'", serializable30, '#');
        org.junit.Assert.assertNull(timestampType31);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)" + "'", str32, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)");
        org.junit.Assert.assertTrue("'" + long52 + "' != '" + 52L + "'", long52 == 52L);
        org.junit.Assert.assertNotNull(intOptional53);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + 52L + "'", long54 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass57);
    }

    @Test
    public void test00211() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00211");
        java.lang.Object obj3 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj3, (java.io.Serializable) (byte) 100);
        long long6 = objConsumerRecord5.timestamp();
        org.apache.kafka.common.header.Headers headers7 = objConsumerRecord5.headers();
        org.apache.kafka.common.header.Headers headers8 = objConsumerRecord5.headers();
        long long9 = objConsumerRecord5.timestamp();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertNotNull(headers7);
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
    }

    @Test
    public void test00212() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00212");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        java.lang.String str19 = objConsumerRecord18.toString();
        java.lang.String str20 = objConsumerRecord18.toString();
        org.apache.kafka.common.record.TimestampType timestampType26 = null;
        java.lang.Object obj30 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType26, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj30, (java.io.Serializable) 1);
        java.lang.String str33 = objConsumerRecord32.toString();
        long long34 = objConsumerRecord32.offset();
        org.apache.kafka.common.header.Headers headers35 = objConsumerRecord32.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) (byte) 100, (long) (byte) 1, (long) (short) 1, timestampType4, (java.lang.Long) 10L, (int) (short) 0, (int) (short) 1, (java.lang.Object) str20, (java.io.Serializable) 10, headers35);
        java.io.Serializable serializable37 = objConsumerRecord36.value();
        java.lang.Object obj38 = objConsumerRecord36.key();
        int int39 = objConsumerRecord36.serializedKeySize();
        java.lang.String str40 = objConsumerRecord36.topic();
        long long41 = objConsumerRecord36.offset();
        org.apache.kafka.common.record.TimestampType timestampType42 = objConsumerRecord36.timestampType();
        // The following exception was thrown during execution in test generation
        try {
            java.lang.Class<?> wildcardClass43 = timestampType42.getClass();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str33, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertNotNull(headers35);
        org.junit.Assert.assertEquals("'" + serializable37 + "' != '" + 10 + "'", serializable37, 10);
        org.junit.Assert.assertEquals("'" + obj38 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", obj38, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + 0 + "'", int39 == 0);
        org.junit.Assert.assertEquals("'" + str40 + "' != '" + "hi!" + "'", str40, "hi!");
        org.junit.Assert.assertTrue("'" + long41 + "' != '" + 1L + "'", long41 == 1L);
        org.junit.Assert.assertNull(timestampType42);
    }

    @Test
    public void test00213() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00213");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00214() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00214");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        java.lang.Object obj15 = objConsumerRecord13.key();
        long long16 = objConsumerRecord13.checksum();
        long long17 = objConsumerRecord13.checksum();
        long long18 = objConsumerRecord13.timestamp();
        java.lang.Object obj19 = objConsumerRecord13.key();
        org.apache.kafka.common.header.Headers headers20 = objConsumerRecord13.headers();
        java.util.Optional<java.lang.Integer> intOptional21 = objConsumerRecord13.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.String> intOptionalConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.String>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) (byte) 10, (long) 100, intOptional21, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 0, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = class org.apache.kafka.clients.consumer.ConsumerRecord)");
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertNull(obj15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 52L + "'", long18 == 52L);
        org.junit.Assert.assertNull(obj19);
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertNotNull(intOptional21);
    }

    @Test
    public void test00215() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00215");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        java.lang.String str13 = objConsumerRecord10.toString();
        org.apache.kafka.common.header.Headers headers14 = objConsumerRecord10.headers();
        java.lang.String str15 = objConsumerRecord10.toString();
        int int16 = objConsumerRecord10.serializedValueSize();
        int int17 = objConsumerRecord10.serializedValueSize();
        java.lang.String str18 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional19 = objConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType20 = objConsumerRecord10.timestampType();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(headers14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str15, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 100 + "'", int16 == 100);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 100 + "'", int17 == 100);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str18, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertNull(timestampType20);
    }

    @Test
    public void test00216() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00216");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, java.lang.reflect.GenericDeclaration> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.reflect.GenericDeclaration> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.reflect.GenericDeclaration>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00217() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00217");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.lang.reflect.AnnotatedElement> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.reflect.AnnotatedElement> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.reflect.AnnotatedElement>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00218() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00218");
        java.lang.Object obj15 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj15, (java.io.Serializable) (byte) 100);
        java.lang.Object obj18 = objConsumerRecord17.key();
        java.lang.String str19 = objConsumerRecord17.toString();
        org.apache.kafka.common.record.TimestampType timestampType20 = objConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType33 = null;
        java.lang.Object obj37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType33, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj37, (java.io.Serializable) 1);
        java.lang.String str40 = objConsumerRecord39.toString();
        java.lang.String str41 = objConsumerRecord39.toString();
        java.lang.Class<?> wildcardClass42 = objConsumerRecord39.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type> charSequenceConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '#', (long) (short) -1, (java.lang.CharSequence) "", (java.lang.reflect.Type) wildcardClass42);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement> charSequenceConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) '#', 100L, (long) 'a', timestampType20, (long) (byte) 100, (int) (byte) -1, 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (java.lang.reflect.AnnotatedElement) wildcardClass42);
        org.apache.kafka.common.record.TimestampType timestampType52 = null;
        java.lang.Object obj56 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType52, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj56, (java.io.Serializable) 1);
        long long59 = objConsumerRecord58.timestamp();
        java.lang.Object obj60 = objConsumerRecord58.key();
        long long61 = objConsumerRecord58.checksum();
        long long62 = objConsumerRecord58.checksum();
        org.apache.kafka.common.record.TimestampType timestampType63 = objConsumerRecord58.timestampType();
        org.apache.kafka.common.header.Headers headers64 = objConsumerRecord58.headers();
        org.apache.kafka.common.record.TimestampType timestampType72 = null;
        java.lang.Object obj76 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType72, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj76, (java.io.Serializable) 1);
        long long79 = objConsumerRecord78.timestamp();
        int int80 = objConsumerRecord78.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional81 = objConsumerRecord78.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord78, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType84 = objConsumerRecord83.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), 1L, (long) (short) 1, timestampType20, (long) 10, (int) (byte) 0, (int) '#', (java.lang.Object) headers64, (java.io.Serializable) timestampType84);
        java.lang.Object obj89 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord91 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)", (int) (byte) 0, 52L, (long) (byte) -1, timestampType20, (long) 1, (int) (short) 0, (int) (byte) -1, obj89, (java.io.Serializable) false);
        org.apache.kafka.common.header.Headers headers92 = objConsumerRecord91.headers();
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str19, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str40 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str40, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str41 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str41, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass42);
        org.junit.Assert.assertTrue("'" + long59 + "' != '" + 52L + "'", long59 == 52L);
        org.junit.Assert.assertNull(obj60);
        org.junit.Assert.assertTrue("'" + long61 + "' != '" + 0L + "'", long61 == 0L);
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + 0L + "'", long62 == 0L);
        org.junit.Assert.assertNull(timestampType63);
        org.junit.Assert.assertNotNull(headers64);
        org.junit.Assert.assertTrue("'" + long79 + "' != '" + 52L + "'", long79 == 52L);
        org.junit.Assert.assertTrue("'" + int80 + "' != '" + 100 + "'", int80 == 100);
        org.junit.Assert.assertNotNull(intOptional81);
        org.junit.Assert.assertTrue("'" + timestampType84 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType84.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers92);
    }

    @Test
    public void test00219() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00219");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        long long19 = objConsumerRecord18.timestamp();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord18.leaderEpoch();
        long long21 = objConsumerRecord18.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType4, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord18, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional24 = objConsumerRecord18.leaderEpoch();
        java.lang.String str25 = objConsumerRecord18.topic();
        org.apache.kafka.common.record.TimestampType timestampType26 = objConsumerRecord18.timestampType();
        int int27 = objConsumerRecord18.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertNotNull(intOptional24);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "" + "'", str25, "");
        org.junit.Assert.assertNull(timestampType26);
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + 10 + "'", int27 == 10);
    }

    @Test
    public void test00220() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00220");
        java.lang.Object obj7 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj7, (java.io.Serializable) (byte) 100);
        java.lang.Object obj10 = objConsumerRecord9.key();
        org.apache.kafka.common.record.TimestampType timestampType11 = objConsumerRecord9.timestampType();
        java.lang.Object obj15 = null;
        java.lang.Object obj27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj27, (java.io.Serializable) (byte) 100);
        java.lang.Object obj30 = objConsumerRecord29.key();
        java.lang.String str31 = objConsumerRecord29.toString();
        org.apache.kafka.common.record.TimestampType timestampType32 = objConsumerRecord29.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType45 = null;
        java.lang.Object obj49 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType45, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj49, (java.io.Serializable) 1);
        java.lang.String str52 = objConsumerRecord51.toString();
        java.lang.String str53 = objConsumerRecord51.toString();
        java.lang.Class<?> wildcardClass54 = objConsumerRecord51.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type> charSequenceConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '#', (long) (short) -1, (java.lang.CharSequence) "", (java.lang.reflect.Type) wildcardClass54);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement> charSequenceConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) '#', 100L, (long) 'a', timestampType32, (long) (byte) 100, (int) (byte) -1, 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (java.lang.reflect.AnnotatedElement) wildcardClass54);
        org.apache.kafka.common.record.TimestampType timestampType67 = null;
        java.lang.Object obj71 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType67, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj71, (java.io.Serializable) 1);
        long long74 = objConsumerRecord73.timestamp();
        int int75 = objConsumerRecord73.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional76 = objConsumerRecord73.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord73, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType79 = objConsumerRecord78.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType84 = null;
        java.lang.Object obj88 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord90 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType84, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj88, (java.io.Serializable) 1);
        long long91 = objConsumerRecord90.timestamp();
        long long92 = objConsumerRecord90.timestamp();
        java.util.Optional<java.lang.Integer> intOptional93 = objConsumerRecord90.leaderEpoch();
        java.lang.String str94 = objConsumerRecord90.topic();
        java.lang.Class<?> wildcardClass95 = objConsumerRecord90.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.reflect.AnnotatedElement> timestampTypeEnumConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.reflect.AnnotatedElement>("hi!", 0, (long) (short) -1, (long) ' ', timestampType32, (long) (byte) 100, 35, (int) (short) -1, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType79, (java.lang.reflect.AnnotatedElement) wildcardClass95);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.reflect.AnnotatedElement> objConsumerRecord97 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)", (int) (byte) -1, (long) 32, (long) (-1), timestampType11, (long) ' ', (int) (byte) 10, (int) (byte) 1, obj15, (java.lang.reflect.AnnotatedElement) wildcardClass95);
        org.junit.Assert.assertNull(obj10);
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNull(obj30);
        org.junit.Assert.assertEquals("'" + str31 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str31, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType32 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType32.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str52 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str52, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str53, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass54);
        org.junit.Assert.assertTrue("'" + long74 + "' != '" + 52L + "'", long74 == 52L);
        org.junit.Assert.assertTrue("'" + int75 + "' != '" + 100 + "'", int75 == 100);
        org.junit.Assert.assertNotNull(intOptional76);
        org.junit.Assert.assertTrue("'" + timestampType79 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType79.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long91 + "' != '" + 52L + "'", long91 == 52L);
        org.junit.Assert.assertTrue("'" + long92 + "' != '" + 52L + "'", long92 == 52L);
        org.junit.Assert.assertNotNull(intOptional93);
        org.junit.Assert.assertEquals("'" + str94 + "' != '" + "" + "'", str94, "");
        org.junit.Assert.assertNotNull(wildcardClass95);
    }

    @Test
    public void test00221() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00221");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        java.lang.String str13 = objConsumerRecord10.toString();
        org.apache.kafka.common.header.Headers headers14 = objConsumerRecord10.headers();
        java.lang.String str15 = objConsumerRecord10.toString();
        java.lang.Object obj16 = objConsumerRecord10.key();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(headers14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str15, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNull(obj16);
    }

    @Test
    public void test00222() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00222");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.Comparable<java.lang.String>> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 1, NoTimestampType = 1, serialized key size = 0, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = NoTimestampType)", (int) (short) 0, (long) '4', "ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = -1, null = 1, serialized key size = 35, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100), partition = 0, leaderEpoch = null, offset = 100, null = 52, serialized key size = 10, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = true)");
    }

    @Test
    public void test00223() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00223");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, java.lang.Object> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.Object> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.Object>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00224() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00224");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType4, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        org.apache.kafka.common.record.TimestampType timestampType11 = objConsumerRecord10.timestampType();
        java.lang.String str12 = objConsumerRecord10.toString();
        long long13 = objConsumerRecord10.offset();
        java.io.Serializable serializable14 = objConsumerRecord10.value();
        int int15 = objConsumerRecord10.partition();
        long long16 = objConsumerRecord10.offset();
        java.lang.String str17 = objConsumerRecord10.toString();
        java.lang.String str18 = objConsumerRecord10.toString();
        org.junit.Assert.assertNull(timestampType11);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)" + "'", str12, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 100L + "'", long13 == 100L);
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + 10 + "'", serializable14, 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 100L + "'", long16 == 100L);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)" + "'", str17, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)");
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)" + "'", str18, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)");
    }

    @Test
    public void test00225() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00225");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        org.apache.kafka.common.record.TimestampType timestampType20 = null;
        java.lang.Object obj24 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType20, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj24, (java.io.Serializable) 1);
        long long27 = objConsumerRecord26.timestamp();
        java.lang.Object obj28 = objConsumerRecord26.key();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.io.Serializable> objConsumerRecordConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.io.Serializable>("", 100, (long) '#', (long) (byte) 0, timestampType12, (long) (-1), (int) (byte) 0, (int) (short) 100, objConsumerRecord26, (java.io.Serializable) (-1.0d));
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) (byte) -1, (long) 1, (long) (byte) 0, timestampType4, (long) '4', (int) (byte) 0, (int) 'a', (java.lang.Object) objConsumerRecordConsumerRecord30, (java.io.Serializable) 10.0f);
        int int33 = objConsumerRecord32.partition();
        int int34 = objConsumerRecord32.serializedKeySize();
        java.lang.String str35 = objConsumerRecord32.topic();
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + 52L + "'", long27 == 52L);
        org.junit.Assert.assertNull(obj28);
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + (-1) + "'", int33 == (-1));
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + 0 + "'", int34 == 0);
        org.junit.Assert.assertEquals("'" + str35 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)" + "'", str35, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)");
    }

    @Test
    public void test00226() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00226");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.kafka.common.record.TimestampType timestampType15 = null;
        java.lang.Object obj19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType15, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj19, (java.io.Serializable) 1);
        long long22 = objConsumerRecord21.timestamp();
        java.util.Optional<java.lang.Integer> intOptional23 = objConsumerRecord21.leaderEpoch();
        long long24 = objConsumerRecord21.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType7, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord21, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional27 = objConsumerRecord21.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        org.apache.kafka.common.record.TimestampType timestampType49 = null;
        java.lang.Object obj53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType49, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj53, (java.io.Serializable) 1);
        long long56 = objConsumerRecord55.timestamp();
        java.util.Optional<java.lang.Integer> intOptional57 = objConsumerRecord55.leaderEpoch();
        long long58 = objConsumerRecord55.offset();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>("", (int) '4', (long) 'a', 0L, timestampType40, 10L, (-1), (int) (short) 0, (java.lang.CharSequence) "hi!", objConsumerRecord55);
        java.lang.Class<?> wildcardClass60 = charSequenceConsumerRecord59.getClass();
        org.apache.kafka.common.record.TimestampType timestampType65 = null;
        java.lang.Object obj69 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType65, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj69, (java.io.Serializable) 1);
        long long72 = objConsumerRecord71.timestamp();
        java.lang.Object obj73 = objConsumerRecord71.key();
        long long74 = objConsumerRecord71.checksum();
        java.lang.Class<?> wildcardClass75 = objConsumerRecord71.getClass();
        org.apache.kafka.common.record.TimestampType timestampType80 = null;
        java.lang.Object obj87 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord89 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj87, (java.io.Serializable) (byte) 100);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord91 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (byte) 100, (long) (byte) 10, (long) 0, timestampType80, (-1L), 1, (int) (short) 1, (java.lang.Object) 'a', (java.io.Serializable) (short) 1);
        org.apache.kafka.common.header.Headers headers92 = objConsumerRecord91.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.reflect.AnnotatedElement> genericDeclarationConsumerRecord93 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.reflect.AnnotatedElement>("hi!", 10, (long) (-1), 1L, timestampType32, (java.lang.Long) 52L, (int) (byte) 1, 10, (java.lang.reflect.GenericDeclaration) wildcardClass60, (java.lang.reflect.AnnotatedElement) wildcardClass75, headers92);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord94 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (int) (byte) 1, (long) '4', (java.lang.Object) intOptional27, (java.io.Serializable) 10);
        long long95 = objConsumerRecord94.checksum();
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 52L + "'", long22 == 52L);
        org.junit.Assert.assertNotNull(intOptional23);
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 52L + "'", long24 == 52L);
        org.junit.Assert.assertNotNull(intOptional27);
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + 52L + "'", long56 == 52L);
        org.junit.Assert.assertNotNull(intOptional57);
        org.junit.Assert.assertTrue("'" + long58 + "' != '" + (-1L) + "'", long58 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass60);
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + 52L + "'", long72 == 52L);
        org.junit.Assert.assertNull(obj73);
        org.junit.Assert.assertTrue("'" + long74 + "' != '" + 0L + "'", long74 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass75);
        org.junit.Assert.assertNotNull(headers92);
        org.junit.Assert.assertTrue("'" + long95 + "' != '" + (-1L) + "'", long95 == (-1L));
    }

    @Test
    public void test00227() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00227");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.lang.Object obj12 = objConsumerRecord10.key();
        long long13 = objConsumerRecord10.checksum();
        long long14 = objConsumerRecord10.checksum();
        java.io.Serializable serializable15 = objConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNull(obj12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + serializable15 + "' != '" + 1 + "'", serializable15, 1);
    }

    @Test
    public void test00228() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00228");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.CharSequence> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.CharSequence> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.CharSequence>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00229() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00229");
        java.lang.Object obj7 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj7, (java.io.Serializable) (byte) 100);
        java.lang.Object obj10 = objConsumerRecord9.key();
        org.apache.kafka.common.record.TimestampType timestampType11 = objConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType19 = null;
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        java.lang.Object obj31 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType27, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj31, (java.io.Serializable) 1);
        java.lang.String str34 = objConsumerRecord33.toString();
        java.lang.String str35 = objConsumerRecord33.toString();
        org.apache.kafka.common.record.TimestampType timestampType41 = null;
        java.lang.Object obj45 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType41, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj45, (java.io.Serializable) 1);
        java.lang.String str48 = objConsumerRecord47.toString();
        long long49 = objConsumerRecord47.offset();
        org.apache.kafka.common.header.Headers headers50 = objConsumerRecord47.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) (byte) 100, (long) (byte) 1, (long) (short) 1, timestampType19, (java.lang.Long) 10L, (int) (short) 0, (int) (short) 1, (java.lang.Object) str35, (java.io.Serializable) 10, headers50);
        java.io.Serializable serializable52 = objConsumerRecord51.value();
        java.lang.Object obj53 = objConsumerRecord51.key();
        java.util.Optional<java.lang.Integer> intOptional54 = objConsumerRecord51.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType62 = null;
        java.lang.Object obj66 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType62, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj66, (java.io.Serializable) 1);
        long long69 = objConsumerRecord68.timestamp();
        int int70 = objConsumerRecord68.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional71 = objConsumerRecord68.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord68, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType74 = objConsumerRecord73.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType79 = null;
        java.lang.Object obj83 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType79, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj83, (java.io.Serializable) 1);
        java.lang.String str86 = objConsumerRecord85.toString();
        java.util.Optional<java.lang.Integer> intOptional87 = objConsumerRecord85.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional88 = objConsumerRecord85.leaderEpoch();
        long long89 = objConsumerRecord85.offset();
        org.apache.kafka.common.header.Headers headers90 = objConsumerRecord85.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType> intOptionalConsumerRecord91 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType>("ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", (int) (short) 100, (long) 0, 35L, timestampType11, (java.lang.Long) (-1L), (int) ' ', (int) (byte) 100, intOptional54, timestampType74, headers90);
        org.junit.Assert.assertNull(obj10);
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str34 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str34, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str35 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str35, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str48 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str48, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long49 + "' != '" + (-1L) + "'", long49 == (-1L));
        org.junit.Assert.assertNotNull(headers50);
        org.junit.Assert.assertEquals("'" + serializable52 + "' != '" + 10 + "'", serializable52, 10);
        org.junit.Assert.assertEquals("'" + obj53 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", obj53, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional54);
        org.junit.Assert.assertTrue("'" + long69 + "' != '" + 52L + "'", long69 == 52L);
        org.junit.Assert.assertTrue("'" + int70 + "' != '" + 100 + "'", int70 == 100);
        org.junit.Assert.assertNotNull(intOptional71);
        org.junit.Assert.assertTrue("'" + timestampType74 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType74.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str86 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str86, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional87);
        org.junit.Assert.assertNotNull(intOptional88);
        org.junit.Assert.assertTrue("'" + long89 + "' != '" + (-1L) + "'", long89 == (-1L));
        org.junit.Assert.assertNotNull(headers90);
    }

    @Test
    public void test00230() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00230");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.Object> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.Object> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.Object>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00231() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00231");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType4, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        org.apache.kafka.common.record.TimestampType timestampType11 = objConsumerRecord10.timestampType();
        java.lang.String str12 = objConsumerRecord10.toString();
        long long13 = objConsumerRecord10.offset();
        java.io.Serializable serializable14 = objConsumerRecord10.value();
        int int15 = objConsumerRecord10.partition();
        long long16 = objConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers17 = objConsumerRecord10.headers();
        org.junit.Assert.assertNull(timestampType11);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)" + "'", str12, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 100L + "'", long13 == 100L);
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + 10 + "'", serializable14, 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 100L + "'", long16 == 100L);
        org.junit.Assert.assertNotNull(headers17);
    }

    @Test
    public void test00232() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00232");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType14 = objConsumerRecord10.timestampType();
        int int15 = objConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord10.timestampType();
        // The following exception was thrown during execution in test generation
        try {
            java.lang.Class<?> wildcardClass17 = timestampType16.getClass();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertNull(timestampType16);
    }

    @Test
    public void test00233() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00233");
        java.lang.Object obj3 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj3, (java.io.Serializable) (byte) 100);
        java.lang.Object obj6 = objConsumerRecord5.key();
        java.lang.String str7 = objConsumerRecord5.toString();
        org.apache.kafka.common.record.TimestampType timestampType8 = objConsumerRecord5.timestampType();
        org.apache.kafka.common.header.Headers headers9 = objConsumerRecord5.headers();
        org.junit.Assert.assertNull(obj6);
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str7, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers9);
    }

    @Test
    public void test00234() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00234");
        org.apache.kafka.common.record.TimestampType timestampType10 = null;
        java.lang.Object obj14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType10, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj14, (java.io.Serializable) 1);
        org.apache.kafka.common.record.TimestampType timestampType17 = objConsumerRecord16.timestampType();
        java.util.Optional<java.lang.Integer> intOptional18 = objConsumerRecord16.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        org.apache.kafka.common.record.TimestampType timestampType31 = null;
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        java.lang.Object obj44 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType40, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj44, (java.io.Serializable) 1);
        long long47 = objConsumerRecord46.timestamp();
        java.util.Optional<java.lang.Integer> intOptional48 = objConsumerRecord46.leaderEpoch();
        long long49 = objConsumerRecord46.offset();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> charSequenceConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>("", (int) '4', (long) 'a', 0L, timestampType31, 10L, (-1), (int) (short) 0, (java.lang.CharSequence) "hi!", objConsumerRecord46);
        java.lang.Class<?> wildcardClass51 = charSequenceConsumerRecord50.getClass();
        org.apache.kafka.common.record.TimestampType timestampType56 = null;
        java.lang.Object obj60 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord62 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType56, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj60, (java.io.Serializable) 1);
        long long63 = objConsumerRecord62.timestamp();
        java.lang.Object obj64 = objConsumerRecord62.key();
        long long65 = objConsumerRecord62.checksum();
        java.lang.Class<?> wildcardClass66 = objConsumerRecord62.getClass();
        org.apache.kafka.common.record.TimestampType timestampType71 = null;
        java.lang.Object obj78 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj78, (java.io.Serializable) (byte) 100);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (byte) 100, (long) (byte) 10, (long) 0, timestampType71, (-1L), 1, (int) (short) 1, (java.lang.Object) 'a', (java.io.Serializable) (short) 1);
        org.apache.kafka.common.header.Headers headers83 = objConsumerRecord82.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.reflect.AnnotatedElement> genericDeclarationConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.reflect.AnnotatedElement>("hi!", 10, (long) (-1), 1L, timestampType23, (java.lang.Long) 52L, (int) (byte) 1, 10, (java.lang.reflect.GenericDeclaration) wildcardClass51, (java.lang.reflect.AnnotatedElement) wildcardClass66, headers83);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (-1), 0L, (java.lang.Object) objConsumerRecord16, (java.io.Serializable) wildcardClass51);
        java.io.Serializable serializable86 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (int) '4', (long) (-1), (java.lang.Object) 0L, serializable86);
        java.lang.Class<?> wildcardClass88 = objConsumerRecord87.getClass();
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertNotNull(intOptional18);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 52L + "'", long47 == 52L);
        org.junit.Assert.assertNotNull(intOptional48);
        org.junit.Assert.assertTrue("'" + long49 + "' != '" + (-1L) + "'", long49 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass51);
        org.junit.Assert.assertTrue("'" + long63 + "' != '" + 52L + "'", long63 == 52L);
        org.junit.Assert.assertNull(obj64);
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + 0L + "'", long65 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass66);
        org.junit.Assert.assertNotNull(headers83);
        org.junit.Assert.assertNotNull(wildcardClass88);
    }

    @Test
    public void test00235() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00235");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, java.io.Serializable> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.io.Serializable> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.io.Serializable>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00236() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00236");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00237() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00237");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, java.lang.reflect.Type> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.reflect.Type> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.reflect.Type>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00238() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00238");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.Comparable<java.lang.String>> objConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.Comparable<java.lang.String>> objConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.Comparable<java.lang.String>>(objConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00239() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00239");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        java.lang.String str19 = objConsumerRecord18.toString();
        java.lang.String str20 = objConsumerRecord18.toString();
        org.apache.kafka.common.record.TimestampType timestampType26 = null;
        java.lang.Object obj30 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType26, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj30, (java.io.Serializable) 1);
        java.lang.String str33 = objConsumerRecord32.toString();
        long long34 = objConsumerRecord32.offset();
        org.apache.kafka.common.header.Headers headers35 = objConsumerRecord32.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) (byte) 100, (long) (byte) 1, (long) (short) 1, timestampType4, (java.lang.Long) 10L, (int) (short) 0, (int) (short) 1, (java.lang.Object) str20, (java.io.Serializable) 10, headers35);
        long long37 = objConsumerRecord36.checksum();
        long long38 = objConsumerRecord36.checksum();
        java.lang.String str39 = objConsumerRecord36.toString();
        long long40 = objConsumerRecord36.offset();
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str33, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertNotNull(headers35);
        org.junit.Assert.assertTrue("'" + long37 + "' != '" + 10L + "'", long37 == 10L);
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + 10L + "'", long38 == 10L);
        org.junit.Assert.assertEquals("'" + str39 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 1, null = 1, serialized key size = 0, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = 10)" + "'", str39, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 1, null = 1, serialized key size = 0, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = 10)");
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + 1L + "'", long40 == 1L);
    }

    @Test
    public void test00240() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00240");
        java.lang.Object obj15 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj15, (java.io.Serializable) (byte) 100);
        java.lang.Object obj18 = objConsumerRecord17.key();
        java.lang.String str19 = objConsumerRecord17.toString();
        org.apache.kafka.common.record.TimestampType timestampType20 = objConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType28 = null;
        org.apache.kafka.common.record.TimestampType timestampType36 = null;
        java.lang.Object obj40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType36, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj40, (java.io.Serializable) 1);
        long long43 = objConsumerRecord42.timestamp();
        java.util.Optional<java.lang.Integer> intOptional44 = objConsumerRecord42.leaderEpoch();
        long long45 = objConsumerRecord42.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType28, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord42, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional48 = objConsumerRecord42.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.String> intOptionalConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.String>("hi!", (int) (short) -1, (long) (short) 0, (long) (short) 0, timestampType20, (long) (byte) 0, (int) (byte) 0, 0, intOptional48, "");
        org.apache.kafka.common.record.TimestampType timestampType58 = null;
        java.lang.Object obj62 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType58, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj62, (java.io.Serializable) 1);
        java.lang.String str65 = objConsumerRecord64.toString();
        long long66 = objConsumerRecord64.offset();
        org.apache.kafka.common.header.Headers headers67 = objConsumerRecord64.headers();
        java.lang.String str68 = objConsumerRecord64.topic();
        org.apache.kafka.common.header.Headers headers69 = objConsumerRecord64.headers();
        org.apache.kafka.common.record.TimestampType timestampType74 = null;
        java.lang.Object obj78 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType74, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj78, (java.io.Serializable) 1);
        org.apache.kafka.common.record.TimestampType timestampType81 = objConsumerRecord80.timestampType();
        java.util.Optional<java.lang.Integer> intOptional82 = objConsumerRecord80.leaderEpoch();
        java.lang.Class<?> wildcardClass83 = intOptional82.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 0, leaderEpoch = null, offset = 1, NoTimestampType = 97, serialized key size = 35, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)", (int) (byte) 0, (long) (byte) 10, 52L, timestampType20, (long) (byte) 100, (int) 'a', 0, (java.lang.Object) headers69, (java.io.Serializable) wildcardClass83);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, org.apache.kafka.common.record.TimestampType> serializableConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, org.apache.kafka.common.record.TimestampType>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 1, NoTimestampType = 1, serialized key size = 0, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = NoTimestampType)", (int) (byte) 10, 97L, (java.io.Serializable) (byte) 0, timestampType20);
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str19, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long43 + "' != '" + 52L + "'", long43 == 52L);
        org.junit.Assert.assertNotNull(intOptional44);
        org.junit.Assert.assertTrue("'" + long45 + "' != '" + 52L + "'", long45 == 52L);
        org.junit.Assert.assertNotNull(intOptional48);
        org.junit.Assert.assertEquals("'" + str65 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str65, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long66 + "' != '" + (-1L) + "'", long66 == (-1L));
        org.junit.Assert.assertNotNull(headers67);
        org.junit.Assert.assertEquals("'" + str68 + "' != '" + "" + "'", str68, "");
        org.junit.Assert.assertNotNull(headers69);
        org.junit.Assert.assertNull(timestampType81);
        org.junit.Assert.assertNotNull(intOptional82);
        org.junit.Assert.assertNotNull(wildcardClass83);
    }

    @Test
    public void test00241() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00241");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        java.lang.String str14 = objConsumerRecord13.toString();
        java.util.Optional<java.lang.Integer> intOptional15 = objConsumerRecord13.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional16 = objConsumerRecord13.leaderEpoch();
        int int17 = objConsumerRecord13.partition();
        long long18 = objConsumerRecord13.offset();
        org.apache.kafka.common.record.TimestampType timestampType19 = objConsumerRecord13.timestampType();
        java.lang.Object obj27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj27, (java.io.Serializable) (byte) 100);
        java.lang.Object obj30 = objConsumerRecord29.key();
        org.apache.kafka.common.record.TimestampType timestampType31 = objConsumerRecord29.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType45 = null;
        java.lang.Object obj49 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType45, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj49, (java.io.Serializable) 1);
        long long52 = objConsumerRecord51.timestamp();
        int int53 = objConsumerRecord51.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional54 = objConsumerRecord51.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord51, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType57 = objConsumerRecord51.timestampType();
        java.lang.String str58 = objConsumerRecord51.topic();
        long long59 = objConsumerRecord51.timestamp();
        java.lang.Object obj60 = objConsumerRecord51.key();
        org.apache.kafka.common.header.Headers headers61 = objConsumerRecord51.headers();
        org.apache.kafka.common.record.TimestampType timestampType66 = null;
        java.lang.Object obj70 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType66, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj70, (java.io.Serializable) 1);
        org.apache.kafka.common.record.TimestampType timestampType73 = objConsumerRecord72.timestampType();
        java.util.Optional<java.lang.Integer> intOptional74 = objConsumerRecord72.leaderEpoch();
        long long75 = objConsumerRecord72.offset();
        int int76 = objConsumerRecord72.partition();
        java.lang.Class<?> wildcardClass77 = objConsumerRecord72.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.GenericDeclaration> headerIterableConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)", (int) (byte) 1, (long) (byte) 0, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers61, (java.lang.reflect.GenericDeclaration) wildcardClass77);
        java.io.Serializable serializable79 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 1, null = 1, serialized key size = 0, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = 10)", (int) (byte) -1, (long) 'a', (long) 35, timestampType31, (long) '4', 100, (int) (byte) 100, (java.lang.Object) headers61, serializable79);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", 1, (long) 10, (java.lang.Object) timestampType19, (java.io.Serializable) timestampType31);
        // The following exception was thrown during execution in test generation
        try {
            java.lang.Class<?> wildcardClass82 = timestampType19.getClass();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNull(timestampType19);
        org.junit.Assert.assertNull(obj30);
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long52 + "' != '" + 52L + "'", long52 == 52L);
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + 100 + "'", int53 == 100);
        org.junit.Assert.assertNotNull(intOptional54);
        org.junit.Assert.assertNull(timestampType57);
        org.junit.Assert.assertEquals("'" + str58 + "' != '" + "" + "'", str58, "");
        org.junit.Assert.assertTrue("'" + long59 + "' != '" + 52L + "'", long59 == 52L);
        org.junit.Assert.assertNull(obj60);
        org.junit.Assert.assertNotNull(headers61);
        org.junit.Assert.assertNull(timestampType73);
        org.junit.Assert.assertNotNull(intOptional74);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + (-1L) + "'", long75 == (-1L));
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + 10 + "'", int76 == 10);
        org.junit.Assert.assertNotNull(wildcardClass77);
    }

    @Test
    public void test00242() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00242");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        int int12 = objConsumerRecord10.serializedValueSize();
        java.lang.Object obj13 = objConsumerRecord10.key();
        int int14 = objConsumerRecord10.serializedKeySize();
        int int15 = objConsumerRecord10.serializedValueSize();
        org.apache.kafka.common.header.Headers headers16 = objConsumerRecord10.headers();
        int int17 = objConsumerRecord10.serializedKeySize();
        int int18 = objConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
        org.junit.Assert.assertNull(obj13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 10 + "'", int18 == 10);
    }

    @Test
    public void test00243() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00243");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        long long13 = objConsumerRecord10.timestamp();
        java.io.Serializable serializable14 = objConsumerRecord10.value();
        long long15 = objConsumerRecord10.timestamp();
        java.lang.String str16 = objConsumerRecord10.toString();
        int int17 = objConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + 1 + "'", serializable14, 1);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
    }

    @Test
    public void test00244() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00244");
        java.lang.Object obj15 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj15, (java.io.Serializable) (byte) 100);
        java.lang.Object obj18 = objConsumerRecord17.key();
        java.lang.String str19 = objConsumerRecord17.toString();
        org.apache.kafka.common.record.TimestampType timestampType20 = objConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType28 = null;
        java.lang.Object obj32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType28, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj32, (java.io.Serializable) 1);
        long long35 = objConsumerRecord34.offset();
        long long36 = objConsumerRecord34.checksum();
        org.apache.kafka.common.header.Headers headers37 = objConsumerRecord34.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), (long) (short) 1, (long) 0, timestampType20, 10L, 97, (int) '4', (java.lang.Object) headers37, (java.io.Serializable) 0.0d);
        org.apache.kafka.common.record.TimestampType timestampType47 = null;
        java.lang.Object obj51 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType47, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj51, (java.io.Serializable) 1);
        java.lang.String str54 = objConsumerRecord53.toString();
        long long55 = objConsumerRecord53.offset();
        org.apache.kafka.common.header.Headers headers56 = objConsumerRecord53.headers();
        java.lang.String str57 = objConsumerRecord53.toString();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (int) 'a', 35L, (long) 0, timestampType20, 52L, (int) '#', 10, (java.lang.Object) objConsumerRecord53, (java.io.Serializable) true);
        java.lang.Object obj67 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj67, (java.io.Serializable) (byte) 100);
        java.lang.Class<?> wildcardClass70 = objConsumerRecord69.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) 1, (long) (short) 0, (-1L), timestampType20, 52L, 100, (int) (short) 1, (java.lang.Object) (short) 100, (java.io.Serializable) wildcardClass70);
        long long72 = objConsumerRecord71.timestamp();
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str19, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + (-1L) + "'", long35 == (-1L));
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + 0L + "'", long36 == 0L);
        org.junit.Assert.assertNotNull(headers37);
        org.junit.Assert.assertEquals("'" + str54 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str54, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + (-1L) + "'", long55 == (-1L));
        org.junit.Assert.assertNotNull(headers56);
        org.junit.Assert.assertEquals("'" + str57 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str57, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass70);
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + (-1L) + "'", long72 == (-1L));
    }

    @Test
    public void test00245() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00245");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.util.Optional<java.lang.Integer>> objConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.util.Optional<java.lang.Integer>> objConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.util.Optional<java.lang.Integer>>(objConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00246() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00246");
        org.apache.kafka.common.record.TimestampType timestampType11 = null;
        java.lang.Object obj15 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType11, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj15, (java.io.Serializable) 1);
        java.lang.String str18 = objConsumerRecord17.toString();
        java.lang.String str19 = objConsumerRecord17.toString();
        java.lang.Class<?> wildcardClass20 = objConsumerRecord17.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '#', (long) (short) -1, (java.lang.CharSequence) "", (java.lang.reflect.Type) wildcardClass20);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 10, (long) (byte) 100, (java.lang.Object) "", (java.io.Serializable) (short) 10);
        long long24 = objConsumerRecord23.offset();
        org.apache.kafka.common.record.TimestampType timestampType25 = objConsumerRecord23.timestampType();
        long long26 = objConsumerRecord23.timestamp();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str18, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass20);
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 100L + "'", long24 == 100L);
        org.junit.Assert.assertTrue("'" + timestampType25 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType25.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + (-1L) + "'", long26 == (-1L));
    }

    @Test
    public void test00247() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00247");
        java.lang.Object obj10 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj10, (java.io.Serializable) (byte) 100);
        org.apache.kafka.common.record.TimestampType timestampType17 = null;
        java.lang.Object obj21 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType17, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj21, (java.io.Serializable) 1);
        long long24 = objConsumerRecord23.timestamp();
        java.lang.Object obj25 = objConsumerRecord23.key();
        long long26 = objConsumerRecord23.checksum();
        java.lang.Class<?> wildcardClass27 = objConsumerRecord23.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) 1, (long) '#', obj10, (java.io.Serializable) wildcardClass27);
        java.lang.Object obj29 = objConsumerRecord28.key();
        long long30 = objConsumerRecord28.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType31 = objConsumerRecord28.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType39 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType39, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        org.apache.kafka.common.record.TimestampType timestampType46 = objConsumerRecord45.timestampType();
        long long47 = objConsumerRecord45.timestamp();
        org.apache.kafka.common.header.Headers headers48 = objConsumerRecord45.headers();
        int int49 = objConsumerRecord45.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType57 = null;
        org.apache.kafka.common.record.TimestampType timestampType65 = null;
        java.lang.Object obj69 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType65, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj69, (java.io.Serializable) 1);
        long long72 = objConsumerRecord71.timestamp();
        java.util.Optional<java.lang.Integer> intOptional73 = objConsumerRecord71.leaderEpoch();
        long long74 = objConsumerRecord71.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType57, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord71, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional77 = objConsumerRecord71.leaderEpoch();
        java.lang.Object obj85 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj85, (java.io.Serializable) (byte) 100);
        java.lang.Object obj88 = objConsumerRecord87.key();
        java.lang.String str89 = objConsumerRecord87.toString();
        org.apache.kafka.common.record.TimestampType timestampType90 = objConsumerRecord87.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) -1, 10L, (long) (short) 100, timestampType90, (long) 0, 0, 35, (java.lang.Object) (-1), (java.io.Serializable) 1L);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType> intOptionalConsumerRecord97 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType>("", (-1), (long) (byte) -1, intOptional77, timestampType90);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)", (int) 'a', (long) '#', (long) 32, timestampType31, 97L, 100, (int) (short) 100, (java.lang.Object) objConsumerRecord45, (java.io.Serializable) (-1));
        long long99 = objConsumerRecord45.checksum();
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 52L + "'", long24 == 52L);
        org.junit.Assert.assertNull(obj25);
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + 0L + "'", long26 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass27);
        org.junit.Assert.assertNull(obj29);
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNull(timestampType46);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 10L + "'", long47 == 10L);
        org.junit.Assert.assertNotNull(headers48);
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + (-1) + "'", int49 == (-1));
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + 52L + "'", long72 == 52L);
        org.junit.Assert.assertNotNull(intOptional73);
        org.junit.Assert.assertTrue("'" + long74 + "' != '" + 52L + "'", long74 == 52L);
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertNull(obj88);
        org.junit.Assert.assertEquals("'" + str89 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str89, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType90 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType90.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long99 + "' != '" + 10L + "'", long99 == 10L);
    }

    @Test
    public void test00248() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00248");
        java.lang.reflect.AnnotatedElement annotatedElement3 = null;
        java.lang.Comparable<java.lang.String> strComparable4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.lang.Comparable<java.lang.String>> annotatedElementConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 100, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = class org.apache.kafka.clients.consumer.ConsumerRecord, value = null)", 35, 35L, annotatedElement3, strComparable4);
    }

    @Test
    public void test00249() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00249");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        java.lang.Object obj15 = objConsumerRecord13.key();
        long long16 = objConsumerRecord13.checksum();
        long long17 = objConsumerRecord13.checksum();
        org.apache.kafka.common.record.TimestampType timestampType18 = objConsumerRecord13.timestampType();
        long long19 = objConsumerRecord13.offset();
        org.apache.kafka.common.record.TimestampType timestampType20 = objConsumerRecord13.timestampType();
        java.io.Serializable serializable21 = objConsumerRecord13.value();
        java.lang.Object obj29 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj29, (java.io.Serializable) (byte) 100);
        java.lang.Object obj32 = objConsumerRecord31.key();
        java.lang.String str33 = objConsumerRecord31.toString();
        org.apache.kafka.common.record.TimestampType timestampType34 = objConsumerRecord31.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType47 = null;
        java.lang.Object obj51 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType47, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj51, (java.io.Serializable) 1);
        java.lang.String str54 = objConsumerRecord53.toString();
        java.lang.String str55 = objConsumerRecord53.toString();
        java.lang.Class<?> wildcardClass56 = objConsumerRecord53.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type> charSequenceConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '#', (long) (short) -1, (java.lang.CharSequence) "", (java.lang.reflect.Type) wildcardClass56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement> charSequenceConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) '#', 100L, (long) 'a', timestampType34, (long) (byte) 100, (int) (byte) -1, 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (java.lang.reflect.AnnotatedElement) wildcardClass56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 0, (long) '4', (java.lang.Object) serializable21, (java.io.Serializable) wildcardClass56);
        java.lang.Class<?> wildcardClass60 = serializable21.getClass();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertNull(obj15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertNull(timestampType20);
        org.junit.Assert.assertEquals("'" + serializable21 + "' != '" + 1 + "'", serializable21, 1);
        org.junit.Assert.assertNull(obj32);
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str33, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType34 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType34.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str54 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str54, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str55 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str55, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass56);
        org.junit.Assert.assertNotNull(wildcardClass60);
    }

    @Test
    public void test00250() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00250");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.topic();
        java.io.Serializable serializable12 = objConsumerRecord10.value();
        org.apache.kafka.common.record.TimestampType timestampType13 = objConsumerRecord10.timestampType();
        java.lang.Class<?> wildcardClass14 = objConsumerRecord10.getClass();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertEquals("'" + serializable12 + "' != '" + 1 + "'", serializable12, 1);
        org.junit.Assert.assertNull(timestampType13);
        org.junit.Assert.assertNotNull(wildcardClass14);
    }

    @Test
    public void test00251() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00251");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, java.io.Serializable> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.io.Serializable> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.io.Serializable>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00252() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00252");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, java.lang.Iterable<org.apache.kafka.common.header.Header>> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.Iterable<org.apache.kafka.common.header.Header>> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.Iterable<org.apache.kafka.common.header.Header>>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00253() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00253");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.lang.Comparable<java.lang.String>> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.Comparable<java.lang.String>> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.Comparable<java.lang.String>>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00254() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00254");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.Iterable<org.apache.kafka.common.header.Header>> objConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.Iterable<org.apache.kafka.common.header.Header>> objConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.Iterable<org.apache.kafka.common.header.Header>>(objConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00255() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00255");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        long long19 = objConsumerRecord18.timestamp();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord18.leaderEpoch();
        long long21 = objConsumerRecord18.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType4, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord18, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional24 = objConsumerRecord18.leaderEpoch();
        java.lang.String str25 = objConsumerRecord18.topic();
        java.lang.Object obj26 = objConsumerRecord18.key();
        org.apache.kafka.common.header.Headers headers27 = objConsumerRecord18.headers();
        java.lang.String str28 = objConsumerRecord18.toString();
        java.lang.Class<?> wildcardClass29 = objConsumerRecord18.getClass();
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertNotNull(intOptional24);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "" + "'", str25, "");
        org.junit.Assert.assertNull(obj26);
        org.junit.Assert.assertNotNull(headers27);
        org.junit.Assert.assertEquals("'" + str28 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str28, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass29);
    }

    @Test
    public void test00256() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00256");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        long long19 = objConsumerRecord18.timestamp();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord18.leaderEpoch();
        long long21 = objConsumerRecord18.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType4, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord18, (java.io.Serializable) '#');
        java.lang.String str24 = objConsumerRecord18.topic();
        java.lang.Class<?> wildcardClass25 = objConsumerRecord18.getClass();
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertEquals("'" + str24 + "' != '" + "" + "'", str24, "");
        org.junit.Assert.assertNotNull(wildcardClass25);
    }

    @Test
    public void test00257() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00257");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00258() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00258");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.header.Headers headers9 = null;
        org.apache.kafka.common.record.TimestampType timestampType14 = null;
        java.lang.Object obj18 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType14, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj18, (java.io.Serializable) 1);
        java.lang.String str21 = objConsumerRecord20.toString();
        java.lang.String str22 = objConsumerRecord20.toString();
        long long23 = objConsumerRecord20.offset();
        java.lang.String str24 = objConsumerRecord20.topic();
        long long25 = objConsumerRecord20.offset();
        org.apache.kafka.common.header.Headers headers26 = objConsumerRecord20.headers();
        int int27 = objConsumerRecord20.serializedKeySize();
        java.lang.Object obj28 = objConsumerRecord20.key();
        long long29 = objConsumerRecord20.checksum();
        org.apache.kafka.common.header.Headers headers30 = objConsumerRecord20.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, org.apache.kafka.common.header.Headers> serializableConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, org.apache.kafka.common.header.Headers>("ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", (int) '#', (long) (short) -1, (long) 0, timestampType4, (java.lang.Long) 100L, (int) (short) 100, (-1), (java.io.Serializable) (short) 10, headers9, headers30);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str21, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str22, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long23 + "' != '" + (-1L) + "'", long23 == (-1L));
        org.junit.Assert.assertEquals("'" + str24 + "' != '" + "" + "'", str24, "");
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + (-1L) + "'", long25 == (-1L));
        org.junit.Assert.assertNotNull(headers26);
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + 10 + "'", int27 == 10);
        org.junit.Assert.assertNull(obj28);
        org.junit.Assert.assertTrue("'" + long29 + "' != '" + 0L + "'", long29 == 0L);
        org.junit.Assert.assertNotNull(headers30);
    }

    @Test
    public void test00259() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00259");
        java.lang.Object obj19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj19, (java.io.Serializable) (byte) 100);
        java.lang.Object obj22 = objConsumerRecord21.key();
        java.lang.String str23 = objConsumerRecord21.toString();
        org.apache.kafka.common.record.TimestampType timestampType24 = objConsumerRecord21.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) -1, 10L, (long) (short) 100, timestampType24, (long) 0, 0, 35, (java.lang.Object) (-1), (java.io.Serializable) 1L);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.CharSequence> strComparableConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.CharSequence>("ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", (int) (byte) -1, (long) 1, (long) 100, timestampType24, (long) '4', 32, (int) (byte) 100, (java.lang.Comparable<java.lang.String>) "", (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.apache.kafka.common.record.TimestampType timestampType44 = null;
        java.lang.Object obj48 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType44, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj48, (java.io.Serializable) 1);
        java.lang.String str51 = objConsumerRecord50.toString();
        java.lang.String str52 = objConsumerRecord50.toString();
        long long53 = objConsumerRecord50.offset();
        java.lang.String str54 = objConsumerRecord50.topic();
        org.apache.kafka.common.record.TimestampType timestampType55 = objConsumerRecord50.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType61 = null;
        java.lang.Object obj65 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType61, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj65, (java.io.Serializable) 1);
        java.lang.String str68 = objConsumerRecord67.toString();
        long long69 = objConsumerRecord67.offset();
        org.apache.kafka.common.header.Headers headers70 = objConsumerRecord67.headers();
        java.lang.String str71 = objConsumerRecord67.toString();
        long long72 = objConsumerRecord67.offset();
        long long73 = objConsumerRecord67.checksum();
        java.lang.Object obj74 = objConsumerRecord67.key();
        java.util.Optional<java.lang.Integer> intOptional75 = objConsumerRecord67.leaderEpoch();
        org.apache.kafka.common.header.Headers headers76 = objConsumerRecord67.headers();
        org.apache.kafka.common.record.TimestampType timestampType81 = null;
        java.lang.Object obj85 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType81, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj85, (java.io.Serializable) 1);
        java.lang.String str88 = objConsumerRecord87.toString();
        long long89 = objConsumerRecord87.offset();
        org.apache.kafka.common.header.Headers headers90 = objConsumerRecord87.headers();
        java.lang.String str91 = objConsumerRecord87.toString();
        long long92 = objConsumerRecord87.offset();
        long long93 = objConsumerRecord87.checksum();
        java.util.Optional<java.lang.Integer> intOptional94 = objConsumerRecord87.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord95 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 0, (long) 35, (long) 10, timestampType24, (java.lang.Long) 100L, (int) (short) 100, (int) (short) 0, (java.lang.Object) timestampType55, (java.io.Serializable) 10.0f, headers76, intOptional94);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> strConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) 100, (long) (byte) 1, "", (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType24);
        org.junit.Assert.assertNull(obj22);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str23, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType24 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType24.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str51 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str51, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str52 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str52, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long53 + "' != '" + (-1L) + "'", long53 == (-1L));
        org.junit.Assert.assertEquals("'" + str54 + "' != '" + "" + "'", str54, "");
        org.junit.Assert.assertNull(timestampType55);
        org.junit.Assert.assertEquals("'" + str68 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str68, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long69 + "' != '" + (-1L) + "'", long69 == (-1L));
        org.junit.Assert.assertNotNull(headers70);
        org.junit.Assert.assertEquals("'" + str71 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str71, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + (-1L) + "'", long72 == (-1L));
        org.junit.Assert.assertTrue("'" + long73 + "' != '" + 0L + "'", long73 == 0L);
        org.junit.Assert.assertNull(obj74);
        org.junit.Assert.assertNotNull(intOptional75);
        org.junit.Assert.assertNotNull(headers76);
        org.junit.Assert.assertEquals("'" + str88 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str88, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long89 + "' != '" + (-1L) + "'", long89 == (-1L));
        org.junit.Assert.assertNotNull(headers90);
        org.junit.Assert.assertEquals("'" + str91 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str91, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long92 + "' != '" + (-1L) + "'", long92 == (-1L));
        org.junit.Assert.assertTrue("'" + long93 + "' != '" + 0L + "'", long93 == 0L);
        org.junit.Assert.assertNotNull(intOptional94);
    }

    @Test
    public void test00260() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00260");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, org.apache.kafka.common.record.TimestampType> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, org.apache.kafka.common.record.TimestampType> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, org.apache.kafka.common.record.TimestampType>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00261() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00261");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        int int15 = objConsumerRecord13.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional16 = objConsumerRecord13.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord13, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType19 = objConsumerRecord18.timestampType();
        long long20 = objConsumerRecord18.timestamp();
        java.io.Serializable serializable21 = objConsumerRecord18.value();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable21 + "' != '" + false + "'", serializable21, false);
    }

    @Test
    public void test00262() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00262");
        org.apache.kafka.common.record.TimestampType timestampType10 = null;
        java.lang.Object obj14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType10, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj14, (java.io.Serializable) 1);
        long long17 = objConsumerRecord16.timestamp();
        int int18 = objConsumerRecord16.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional19 = objConsumerRecord16.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord16, (java.io.Serializable) false);
        java.io.Serializable serializable22 = objConsumerRecord21.value();
        org.apache.kafka.common.header.Headers headers23 = objConsumerRecord21.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.lang.CharSequence> headersConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.lang.CharSequence>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 1, NoTimestampType = 1, serialized key size = 0, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = NoTimestampType)", 0, (long) (byte) 1, headers23, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 100, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = class org.apache.kafka.clients.consumer.ConsumerRecord, value = null)");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 100 + "'", int18 == 100);
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertEquals("'" + serializable22 + "' != '" + false + "'", serializable22, false);
        org.junit.Assert.assertNotNull(headers23);
    }

    @Test
    public void test00263() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00263");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.lang.Iterable<org.apache.kafka.common.header.Header>> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.Iterable<org.apache.kafka.common.header.Header>> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.Iterable<org.apache.kafka.common.header.Header>>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00264() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00264");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        java.lang.String str19 = objConsumerRecord18.toString();
        java.lang.String str20 = objConsumerRecord18.toString();
        org.apache.kafka.common.record.TimestampType timestampType26 = null;
        java.lang.Object obj30 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType26, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj30, (java.io.Serializable) 1);
        java.lang.String str33 = objConsumerRecord32.toString();
        long long34 = objConsumerRecord32.offset();
        org.apache.kafka.common.header.Headers headers35 = objConsumerRecord32.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) (byte) 100, (long) (byte) 1, (long) (short) 1, timestampType4, (java.lang.Long) 10L, (int) (short) 0, (int) (short) 1, (java.lang.Object) str20, (java.io.Serializable) 10, headers35);
        java.io.Serializable serializable37 = objConsumerRecord36.value();
        java.lang.Object obj38 = objConsumerRecord36.key();
        java.util.Optional<java.lang.Integer> intOptional39 = objConsumerRecord36.leaderEpoch();
        java.lang.Class<?> wildcardClass40 = intOptional39.getClass();
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str33, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertNotNull(headers35);
        org.junit.Assert.assertEquals("'" + serializable37 + "' != '" + 10 + "'", serializable37, 10);
        org.junit.Assert.assertEquals("'" + obj38 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", obj38, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional39);
        org.junit.Assert.assertNotNull(wildcardClass40);
    }

    @Test
    public void test00265() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00265");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.GenericDeclaration, java.lang.Iterable<org.apache.kafka.common.header.Header>> genericDeclarationKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.Iterable<org.apache.kafka.common.header.Header>> genericDeclarationKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.lang.Iterable<org.apache.kafka.common.header.Header>>(genericDeclarationKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00266() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00266");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00267() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00267");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, java.lang.reflect.AnnotatedElement> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.reflect.AnnotatedElement> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.reflect.AnnotatedElement>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00268() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00268");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, java.lang.CharSequence> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.CharSequence> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.CharSequence>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00269() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00269");
        org.apache.kafka.common.record.TimestampType timestampType15 = null;
        java.lang.Object obj19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType15, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj19, (java.io.Serializable) 1);
        long long22 = objConsumerRecord21.timestamp();
        int int23 = objConsumerRecord21.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional24 = objConsumerRecord21.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord21, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType27 = objConsumerRecord26.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType36 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType36, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        org.apache.kafka.common.header.Headers headers43 = objConsumerRecord42.headers();
        int int44 = objConsumerRecord42.partition();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> strComparableConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 1, null = 1, serialized key size = 0, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = 10)", 0, (long) ' ', (long) ' ', timestampType27, 0L, (int) '#', 1, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", objConsumerRecord42);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        java.lang.Object obj57 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType53, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj57, (java.io.Serializable) 1);
        long long60 = objConsumerRecord59.timestamp();
        java.lang.Object obj61 = objConsumerRecord59.key();
        long long62 = objConsumerRecord59.checksum();
        long long63 = objConsumerRecord59.checksum();
        long long64 = objConsumerRecord59.timestamp();
        java.lang.Object obj65 = objConsumerRecord59.key();
        java.lang.String str66 = objConsumerRecord59.toString();
        org.apache.kafka.common.record.TimestampType timestampType71 = null;
        java.lang.Object obj75 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType71, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj75, (java.io.Serializable) 1);
        long long78 = objConsumerRecord77.timestamp();
        java.util.Optional<java.lang.Integer> intOptional79 = objConsumerRecord77.leaderEpoch();
        long long80 = objConsumerRecord77.checksum();
        java.io.Serializable serializable81 = objConsumerRecord77.value();
        org.apache.kafka.common.header.Headers headers82 = objConsumerRecord77.headers();
        java.lang.Class<?> wildcardClass83 = headers82.getClass();
        org.apache.kafka.common.header.Headers headers84 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 0, leaderEpoch = null, offset = 1, NoTimestampType = 97, serialized key size = 35, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)", 52, (long) 10, 1L, timestampType27, (java.lang.Long) 10L, (int) (short) 10, 10, (java.lang.Object) str66, (java.io.Serializable) wildcardClass83, headers84);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 52L + "'", long22 == 52L);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 100 + "'", int23 == 100);
        org.junit.Assert.assertNotNull(intOptional24);
        org.junit.Assert.assertTrue("'" + timestampType27 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType27.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers43);
        org.junit.Assert.assertTrue("'" + int44 + "' != '" + (-1) + "'", int44 == (-1));
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + 52L + "'", long60 == 52L);
        org.junit.Assert.assertNull(obj61);
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + 0L + "'", long62 == 0L);
        org.junit.Assert.assertTrue("'" + long63 + "' != '" + 0L + "'", long63 == 0L);
        org.junit.Assert.assertTrue("'" + long64 + "' != '" + 52L + "'", long64 == 52L);
        org.junit.Assert.assertNull(obj65);
        org.junit.Assert.assertEquals("'" + str66 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str66, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long78 + "' != '" + 52L + "'", long78 == 52L);
        org.junit.Assert.assertNotNull(intOptional79);
        org.junit.Assert.assertTrue("'" + long80 + "' != '" + 0L + "'", long80 == 0L);
        org.junit.Assert.assertEquals("'" + serializable81 + "' != '" + 1 + "'", serializable81, 1);
        org.junit.Assert.assertNotNull(headers82);
        org.junit.Assert.assertNotNull(wildcardClass83);
    }

    @Test
    public void test00270() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00270");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        java.util.Optional<java.lang.Integer> intOptional15 = objConsumerRecord13.leaderEpoch();
        long long16 = objConsumerRecord13.checksum();
        java.lang.String str17 = objConsumerRecord13.topic();
        java.io.Serializable serializable18 = objConsumerRecord13.value();
        org.apache.kafka.common.record.TimestampType timestampType19 = objConsumerRecord13.timestampType();
        org.apache.kafka.common.header.Headers headers20 = objConsumerRecord13.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Comparable<java.lang.String>> headerIterableConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = -1, null = 1, serialized key size = 35, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) (byte) 1, 0L, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers20, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100), partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = -1)");
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertEquals("'" + serializable18 + "' != '" + 1 + "'", serializable18, 1);
        org.junit.Assert.assertNull(timestampType19);
        org.junit.Assert.assertNotNull(headers20);
    }

    @Test
    public void test00271() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00271");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.topic();
        long long12 = objConsumerRecord10.checksum();
        long long13 = objConsumerRecord10.checksum();
        long long14 = objConsumerRecord10.timestamp();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 0L + "'", long12 == 0L);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
    }

    @Test
    public void test00272() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00272");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers13 = objConsumerRecord10.headers();
        java.lang.String str14 = objConsumerRecord10.toString();
        long long15 = objConsumerRecord10.offset();
        long long16 = objConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional17 = objConsumerRecord10.leaderEpoch();
        java.lang.Object obj18 = objConsumerRecord10.key();
        long long19 = objConsumerRecord10.timestamp();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertNotNull(intOptional17);
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
    }

    @Test
    public void test00273() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00273");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, java.lang.reflect.GenericDeclaration> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.reflect.GenericDeclaration> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.reflect.GenericDeclaration>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00274() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00274");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)", 1, (long) (short) -1, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100), partition = 0, leaderEpoch = null, offset = 100, null = 52, serialized key size = 10, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = true)", (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)");
    }

    @Test
    public void test00275() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00275");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        long long13 = objConsumerRecord10.timestamp();
        java.io.Serializable serializable14 = objConsumerRecord10.value();
        long long15 = objConsumerRecord10.offset();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord10.timestampType();
        // The following exception was thrown during execution in test generation
        try {
            java.lang.Class<?> wildcardClass17 = timestampType16.getClass();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + 1 + "'", serializable14, 1);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNull(timestampType16);
    }

    @Test
    public void test00276() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00276");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, java.lang.String> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.String> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.String>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00277() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00277");
        java.lang.Object obj10 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj10, (java.io.Serializable) (byte) 100);
        org.apache.kafka.common.record.TimestampType timestampType17 = null;
        java.lang.Object obj21 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType17, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj21, (java.io.Serializable) 1);
        long long24 = objConsumerRecord23.timestamp();
        java.lang.Object obj25 = objConsumerRecord23.key();
        long long26 = objConsumerRecord23.checksum();
        java.lang.Class<?> wildcardClass27 = objConsumerRecord23.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) 1, (long) '#', obj10, (java.io.Serializable) wildcardClass27);
        java.lang.Object obj29 = objConsumerRecord28.key();
        long long30 = objConsumerRecord28.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType31 = objConsumerRecord28.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType32 = objConsumerRecord28.timestampType();
        org.apache.kafka.common.header.Headers headers38 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.CharSequence> strComparableConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.CharSequence>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 1, null = 1, serialized key size = 0, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = 10)", 10, (long) 32, (long) (byte) 1, timestampType32, (java.lang.Long) 100L, (int) (short) -1, 0, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)", (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", headers38);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 52L + "'", long24 == 52L);
        org.junit.Assert.assertNull(obj25);
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + 0L + "'", long26 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass27);
        org.junit.Assert.assertNull(obj29);
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType32 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType32.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test00278() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00278");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType14 = objConsumerRecord10.timestampType();
        long long15 = objConsumerRecord10.offset();
        java.lang.String str16 = objConsumerRecord10.toString();
        long long17 = objConsumerRecord10.checksum();
        java.lang.String str18 = objConsumerRecord10.toString();
        org.apache.kafka.common.header.Headers headers19 = objConsumerRecord10.headers();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str18, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(headers19);
    }

    @Test
    public void test00279() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00279");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        int int12 = objConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        java.io.Serializable serializable14 = objConsumerRecord10.value();
        int int15 = objConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional16 = objConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + 1 + "'", serializable14, 1);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertNotNull(intOptional16);
    }

    @Test
    public void test00280() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00280");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        int int15 = objConsumerRecord13.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional16 = objConsumerRecord13.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord13, (java.io.Serializable) false);
        java.lang.String str19 = objConsumerRecord18.toString();
        long long20 = objConsumerRecord18.timestamp();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)" + "'", str19, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)");
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
    }

    @Test
    public void test00281() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00281");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.topic();
        int int12 = objConsumerRecord10.serializedKeySize();
        long long13 = objConsumerRecord10.timestamp();
        java.lang.Class<?> wildcardClass14 = objConsumerRecord10.getClass();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass14);
    }

    @Test
    public void test00282() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00282");
        java.lang.Object obj10 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj10, (java.io.Serializable) (byte) 100);
        org.apache.kafka.common.record.TimestampType timestampType17 = null;
        java.lang.Object obj21 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType17, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj21, (java.io.Serializable) 1);
        long long24 = objConsumerRecord23.timestamp();
        java.lang.Object obj25 = objConsumerRecord23.key();
        long long26 = objConsumerRecord23.checksum();
        java.lang.Class<?> wildcardClass27 = objConsumerRecord23.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) 1, (long) '#', obj10, (java.io.Serializable) wildcardClass27);
        java.lang.Object obj29 = objConsumerRecord28.key();
        long long30 = objConsumerRecord28.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType31 = objConsumerRecord28.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType39 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType39, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        org.apache.kafka.common.record.TimestampType timestampType46 = objConsumerRecord45.timestampType();
        long long47 = objConsumerRecord45.timestamp();
        org.apache.kafka.common.header.Headers headers48 = objConsumerRecord45.headers();
        int int49 = objConsumerRecord45.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType57 = null;
        org.apache.kafka.common.record.TimestampType timestampType65 = null;
        java.lang.Object obj69 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType65, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj69, (java.io.Serializable) 1);
        long long72 = objConsumerRecord71.timestamp();
        java.util.Optional<java.lang.Integer> intOptional73 = objConsumerRecord71.leaderEpoch();
        long long74 = objConsumerRecord71.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType57, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord71, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional77 = objConsumerRecord71.leaderEpoch();
        java.lang.Object obj85 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj85, (java.io.Serializable) (byte) 100);
        java.lang.Object obj88 = objConsumerRecord87.key();
        java.lang.String str89 = objConsumerRecord87.toString();
        org.apache.kafka.common.record.TimestampType timestampType90 = objConsumerRecord87.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) -1, 10L, (long) (short) 100, timestampType90, (long) 0, 0, 35, (java.lang.Object) (-1), (java.io.Serializable) 1L);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType> intOptionalConsumerRecord97 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType>("", (-1), (long) (byte) -1, intOptional77, timestampType90);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)", (int) 'a', (long) '#', (long) 32, timestampType31, 97L, 100, (int) (short) 100, (java.lang.Object) objConsumerRecord45, (java.io.Serializable) (-1));
        long long99 = objConsumerRecord45.offset();
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 52L + "'", long24 == 52L);
        org.junit.Assert.assertNull(obj25);
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + 0L + "'", long26 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass27);
        org.junit.Assert.assertNull(obj29);
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNull(timestampType46);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 10L + "'", long47 == 10L);
        org.junit.Assert.assertNotNull(headers48);
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + (-1) + "'", int49 == (-1));
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + 52L + "'", long72 == 52L);
        org.junit.Assert.assertNotNull(intOptional73);
        org.junit.Assert.assertTrue("'" + long74 + "' != '" + 52L + "'", long74 == 52L);
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertNull(obj88);
        org.junit.Assert.assertEquals("'" + str89 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str89, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType90 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType90.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long99 + "' != '" + 100L + "'", long99 == 100L);
    }

    @Test
    public void test00283() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00283");
        java.lang.Object obj7 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj7, (java.io.Serializable) (byte) 100);
        java.lang.Object obj10 = objConsumerRecord9.key();
        java.lang.String str11 = objConsumerRecord9.toString();
        org.apache.kafka.common.record.TimestampType timestampType12 = objConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) -1, 10L, (long) (short) 100, timestampType12, (long) 0, 0, 35, (java.lang.Object) (-1), (java.io.Serializable) 1L);
        java.lang.Class<?> wildcardClass19 = timestampType12.getClass();
        org.junit.Assert.assertNull(obj10);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str11, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass19);
    }

    @Test
    public void test00284() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00284");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00285() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00285");
        org.apache.kafka.common.record.TimestampType timestampType10 = null;
        java.lang.Object obj14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType10, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj14, (java.io.Serializable) 1);
        long long17 = objConsumerRecord16.timestamp();
        java.lang.Object obj18 = objConsumerRecord16.key();
        long long19 = objConsumerRecord16.checksum();
        org.apache.kafka.common.record.TimestampType timestampType24 = null;
        java.lang.Object obj28 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType24, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj28, (java.io.Serializable) 1);
        long long31 = objConsumerRecord30.timestamp();
        java.util.Optional<java.lang.Integer> intOptional32 = objConsumerRecord30.leaderEpoch();
        long long33 = objConsumerRecord30.timestamp();
        java.lang.Class<?> wildcardClass34 = objConsumerRecord30.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (byte) -1, (long) 0, (java.lang.Object) objConsumerRecord16, (java.io.Serializable) wildcardClass34);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)", (int) (byte) -1, (long) 10, (java.lang.Object) objConsumerRecord16, (java.io.Serializable) (-1.0f));
        int int38 = objConsumerRecord37.partition();
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertTrue("'" + long31 + "' != '" + 52L + "'", long31 == 52L);
        org.junit.Assert.assertNotNull(intOptional32);
        org.junit.Assert.assertTrue("'" + long33 + "' != '" + 52L + "'", long33 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass34);
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + (-1) + "'", int38 == (-1));
    }

    @Test
    public void test00286() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00286");
        org.apache.kafka.common.record.TimestampType timestampType11 = null;
        java.lang.Object obj15 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType11, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj15, (java.io.Serializable) 1);
        long long18 = objConsumerRecord17.timestamp();
        int int19 = objConsumerRecord17.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord17.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord17, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType23 = objConsumerRecord22.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType39 = null;
        java.lang.Object obj43 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType39, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj43, (java.io.Serializable) 1);
        java.lang.String str46 = objConsumerRecord45.toString();
        java.lang.String str47 = objConsumerRecord45.toString();
        java.lang.Class<?> wildcardClass48 = objConsumerRecord45.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type> charSequenceConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '#', (long) (short) -1, (java.lang.CharSequence) "", (java.lang.reflect.Type) wildcardClass48);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 10, (long) (byte) 100, (java.lang.Object) "", (java.io.Serializable) (short) 10);
        long long52 = objConsumerRecord51.offset();
        org.apache.kafka.common.record.TimestampType timestampType53 = objConsumerRecord51.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType58 = null;
        org.apache.kafka.common.record.TimestampType timestampType66 = null;
        java.lang.Object obj70 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType66, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj70, (java.io.Serializable) 1);
        java.lang.String str73 = objConsumerRecord72.toString();
        java.lang.String str74 = objConsumerRecord72.toString();
        org.apache.kafka.common.record.TimestampType timestampType80 = null;
        java.lang.Object obj84 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType80, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj84, (java.io.Serializable) 1);
        java.lang.String str87 = objConsumerRecord86.toString();
        long long88 = objConsumerRecord86.offset();
        org.apache.kafka.common.header.Headers headers89 = objConsumerRecord86.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord90 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) (byte) 100, (long) (byte) 1, (long) (short) 1, timestampType58, (java.lang.Long) 10L, (int) (short) 0, (int) (short) 1, (java.lang.Object) str74, (java.io.Serializable) 10, headers89);
        java.io.Serializable serializable91 = objConsumerRecord90.value();
        java.lang.Object obj92 = objConsumerRecord90.key();
        int int93 = objConsumerRecord90.serializedKeySize();
        java.lang.String str94 = objConsumerRecord90.toString();
        org.apache.kafka.common.header.Headers headers95 = objConsumerRecord90.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.kafka.common.record.TimestampType> strConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.kafka.common.record.TimestampType>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 100, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = class org.apache.kafka.clients.consumer.ConsumerRecord, value = null)", (int) (byte) 0, (long) '#', (long) (short) 1, timestampType23, (java.lang.Long) 97L, (int) (short) 10, (int) '4', "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 1, null = 1, serialized key size = 0, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = 10)", timestampType53, headers95);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 52L + "'", long18 == 52L);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 100 + "'", int19 == 100);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str46 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str46, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str47 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str47, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass48);
        org.junit.Assert.assertTrue("'" + long52 + "' != '" + 100L + "'", long52 == 100L);
        org.junit.Assert.assertTrue("'" + timestampType53 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType53.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str73 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str73, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str74 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str74, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str87 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str87, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long88 + "' != '" + (-1L) + "'", long88 == (-1L));
        org.junit.Assert.assertNotNull(headers89);
        org.junit.Assert.assertEquals("'" + serializable91 + "' != '" + 10 + "'", serializable91, 10);
        org.junit.Assert.assertEquals("'" + obj92 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", obj92, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + int93 + "' != '" + 0 + "'", int93 == 0);
        org.junit.Assert.assertEquals("'" + str94 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 1, null = 1, serialized key size = 0, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = 10)" + "'", str94, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 1, null = 1, serialized key size = 0, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = 10)");
        org.junit.Assert.assertNotNull(headers95);
    }

    @Test
    public void test00287() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00287");
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj11, (java.io.Serializable) (byte) 100);
        java.lang.Object obj14 = objConsumerRecord13.key();
        java.lang.String str15 = objConsumerRecord13.toString();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) -1, 10L, (long) (short) 100, timestampType16, (long) 0, 0, 35, (java.lang.Object) (-1), (java.io.Serializable) 1L);
        org.apache.kafka.common.record.TimestampType timestampType30 = null;
        java.lang.Object obj34 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType30, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj34, (java.io.Serializable) 1);
        java.lang.String str37 = objConsumerRecord36.toString();
        long long38 = objConsumerRecord36.offset();
        org.apache.kafka.common.header.Headers headers39 = objConsumerRecord36.headers();
        java.lang.String str40 = objConsumerRecord36.topic();
        org.apache.kafka.common.header.Headers headers41 = objConsumerRecord36.headers();
        org.apache.kafka.common.record.TimestampType timestampType47 = null;
        java.lang.Object obj51 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType47, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj51, (java.io.Serializable) 1);
        java.lang.String str54 = objConsumerRecord53.toString();
        long long55 = objConsumerRecord53.offset();
        org.apache.kafka.common.header.Headers headers56 = objConsumerRecord53.headers();
        java.lang.String str57 = objConsumerRecord53.toString();
        long long58 = objConsumerRecord53.offset();
        long long59 = objConsumerRecord53.checksum();
        java.util.Optional<java.lang.Integer> intOptional60 = objConsumerRecord53.leaderEpoch();
        java.lang.Object obj61 = objConsumerRecord53.key();
        long long62 = objConsumerRecord53.offset();
        org.apache.kafka.common.header.Headers headers63 = objConsumerRecord53.headers();
        org.apache.kafka.common.record.TimestampType timestampType68 = null;
        java.lang.Object obj72 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType68, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj72, (java.io.Serializable) 1);
        java.lang.String str75 = objConsumerRecord74.toString();
        long long76 = objConsumerRecord74.offset();
        org.apache.kafka.common.header.Headers headers77 = objConsumerRecord74.headers();
        java.lang.String str78 = objConsumerRecord74.toString();
        long long79 = objConsumerRecord74.offset();
        long long80 = objConsumerRecord74.checksum();
        java.util.Optional<java.lang.Integer> intOptional81 = objConsumerRecord74.leaderEpoch();
        java.lang.Object obj82 = objConsumerRecord74.key();
        long long83 = objConsumerRecord74.offset();
        java.util.Optional<java.lang.Integer> intOptional84 = objConsumerRecord74.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 0, 0L, 0L, timestampType16, (java.lang.Long) 1L, 1, (int) (byte) 100, (java.lang.Object) headers41, (java.io.Serializable) 0L, headers63, intOptional84);
        int int86 = objConsumerRecord85.serializedKeySize();
        int int87 = objConsumerRecord85.partition();
        org.junit.Assert.assertNull(obj14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str15, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str37 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str37, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + (-1L) + "'", long38 == (-1L));
        org.junit.Assert.assertNotNull(headers39);
        org.junit.Assert.assertEquals("'" + str40 + "' != '" + "" + "'", str40, "");
        org.junit.Assert.assertNotNull(headers41);
        org.junit.Assert.assertEquals("'" + str54 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str54, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + (-1L) + "'", long55 == (-1L));
        org.junit.Assert.assertNotNull(headers56);
        org.junit.Assert.assertEquals("'" + str57 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str57, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long58 + "' != '" + (-1L) + "'", long58 == (-1L));
        org.junit.Assert.assertTrue("'" + long59 + "' != '" + 0L + "'", long59 == 0L);
        org.junit.Assert.assertNotNull(intOptional60);
        org.junit.Assert.assertNull(obj61);
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + (-1L) + "'", long62 == (-1L));
        org.junit.Assert.assertNotNull(headers63);
        org.junit.Assert.assertEquals("'" + str75 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str75, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long76 + "' != '" + (-1L) + "'", long76 == (-1L));
        org.junit.Assert.assertNotNull(headers77);
        org.junit.Assert.assertEquals("'" + str78 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str78, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long79 + "' != '" + (-1L) + "'", long79 == (-1L));
        org.junit.Assert.assertTrue("'" + long80 + "' != '" + 0L + "'", long80 == 0L);
        org.junit.Assert.assertNotNull(intOptional81);
        org.junit.Assert.assertNull(obj82);
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + (-1L) + "'", long83 == (-1L));
        org.junit.Assert.assertNotNull(intOptional84);
        org.junit.Assert.assertTrue("'" + int86 + "' != '" + 1 + "'", int86 == 1);
        org.junit.Assert.assertTrue("'" + int87 + "' != '" + 0 + "'", int87 == 0);
    }

    @Test
    public void test00288() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00288");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        long long19 = objConsumerRecord18.timestamp();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord18.leaderEpoch();
        long long21 = objConsumerRecord18.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType4, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord18, (java.io.Serializable) '#');
        org.apache.kafka.common.header.Headers headers24 = objConsumerRecord18.headers();
        java.lang.Class<?> wildcardClass25 = headers24.getClass();
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertNotNull(headers24);
        org.junit.Assert.assertNotNull(wildcardClass25);
    }

    @Test
    public void test00289() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00289");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        java.lang.String str19 = objConsumerRecord18.toString();
        java.lang.String str20 = objConsumerRecord18.toString();
        org.apache.kafka.common.record.TimestampType timestampType26 = null;
        java.lang.Object obj30 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType26, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj30, (java.io.Serializable) 1);
        java.lang.String str33 = objConsumerRecord32.toString();
        long long34 = objConsumerRecord32.offset();
        org.apache.kafka.common.header.Headers headers35 = objConsumerRecord32.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) (byte) 100, (long) (byte) 1, (long) (short) 1, timestampType4, (java.lang.Long) 10L, (int) (short) 0, (int) (short) 1, (java.lang.Object) str20, (java.io.Serializable) 10, headers35);
        java.lang.String str37 = objConsumerRecord36.topic();
        long long38 = objConsumerRecord36.offset();
        int int39 = objConsumerRecord36.serializedValueSize();
        long long40 = objConsumerRecord36.offset();
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str33, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertNotNull(headers35);
        org.junit.Assert.assertEquals("'" + str37 + "' != '" + "hi!" + "'", str37, "hi!");
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + 1L + "'", long38 == 1L);
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + 1 + "'", int39 == 1);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + 1L + "'", long40 == 1L);
    }

    @Test
    public void test00290() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00290");
        java.lang.Object obj7 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj7, (java.io.Serializable) (byte) 100);
        java.lang.Object obj10 = objConsumerRecord9.key();
        org.apache.kafka.common.record.TimestampType timestampType11 = objConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType19 = null;
        java.lang.Object obj23 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType19, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj23, (java.io.Serializable) 1);
        java.lang.String str26 = objConsumerRecord25.toString();
        long long27 = objConsumerRecord25.offset();
        org.apache.kafka.common.header.Headers headers28 = objConsumerRecord25.headers();
        java.lang.String str29 = objConsumerRecord25.topic();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", 0, 35L, (long) 32, timestampType11, (long) (byte) 0, 0, 1, (java.lang.Object) str29, (java.io.Serializable) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)");
        java.util.Optional<java.lang.Integer> intOptional32 = objConsumerRecord31.leaderEpoch();
        java.lang.Class<?> wildcardClass33 = intOptional32.getClass();
        org.junit.Assert.assertNull(obj10);
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str26, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + (-1L) + "'", long27 == (-1L));
        org.junit.Assert.assertNotNull(headers28);
        org.junit.Assert.assertEquals("'" + str29 + "' != '" + "" + "'", str29, "");
        org.junit.Assert.assertNotNull(intOptional32);
        org.junit.Assert.assertNotNull(wildcardClass33);
    }

    @Test
    public void test00291() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00291");
        java.lang.Object obj15 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj15, (java.io.Serializable) (byte) 100);
        java.lang.Object obj18 = objConsumerRecord17.key();
        java.lang.String str19 = objConsumerRecord17.toString();
        org.apache.kafka.common.record.TimestampType timestampType20 = objConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType33 = null;
        java.lang.Object obj37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType33, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj37, (java.io.Serializable) 1);
        java.lang.String str40 = objConsumerRecord39.toString();
        java.lang.String str41 = objConsumerRecord39.toString();
        java.lang.Class<?> wildcardClass42 = objConsumerRecord39.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type> charSequenceConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '#', (long) (short) -1, (java.lang.CharSequence) "", (java.lang.reflect.Type) wildcardClass42);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement> charSequenceConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) '#', 100L, (long) 'a', timestampType20, (long) (byte) 100, (int) (byte) -1, 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (java.lang.reflect.AnnotatedElement) wildcardClass42);
        org.apache.kafka.common.record.TimestampType timestampType52 = null;
        java.lang.Object obj56 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType52, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj56, (java.io.Serializable) 1);
        java.lang.String str59 = objConsumerRecord58.toString();
        long long60 = objConsumerRecord58.offset();
        java.lang.String str61 = objConsumerRecord58.toString();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", 100, (long) 97, (long) 'a', timestampType20, (long) (byte) 10, (int) (byte) 10, (int) (byte) -1, (java.lang.Object) objConsumerRecord58, (java.io.Serializable) (byte) 0);
        org.apache.kafka.common.record.TimestampType timestampType71 = null;
        org.apache.kafka.common.record.TimestampType timestampType80 = null;
        java.lang.Object obj84 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType80, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj84, (java.io.Serializable) 1);
        long long87 = objConsumerRecord86.timestamp();
        java.util.Optional<java.lang.Integer> intOptional88 = objConsumerRecord86.leaderEpoch();
        java.lang.Class<?> wildcardClass89 = objConsumerRecord86.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.GenericDeclaration> charSequenceConsumerRecord90 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '4', (long) 1, (long) 0, timestampType71, 100L, 1, (int) (short) 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (java.lang.reflect.GenericDeclaration) wildcardClass89);
        java.io.Serializable serializable91 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord92 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", 100, (long) (-1), (long) (short) -1, timestampType20, (long) 100, (int) (short) 0, (int) (byte) 100, (java.lang.Object) 1, serializable91);
        long long93 = objConsumerRecord92.timestamp();
        int int94 = objConsumerRecord92.serializedValueSize();
        java.lang.Class<?> wildcardClass95 = objConsumerRecord92.getClass();
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str19, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str40 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str40, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str41 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str41, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass42);
        org.junit.Assert.assertEquals("'" + str59 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str59, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str61, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long87 + "' != '" + 52L + "'", long87 == 52L);
        org.junit.Assert.assertNotNull(intOptional88);
        org.junit.Assert.assertNotNull(wildcardClass89);
        org.junit.Assert.assertTrue("'" + long93 + "' != '" + (-1L) + "'", long93 == (-1L));
        org.junit.Assert.assertTrue("'" + int94 + "' != '" + 100 + "'", int94 == 100);
        org.junit.Assert.assertNotNull(wildcardClass95);
    }

    @Test
    public void test00292() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00292");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.reflect.AnnotatedElement annotatedElement8 = null;
        org.apache.kafka.common.record.TimestampType timestampType13 = null;
        java.lang.Object obj17 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType13, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj17, (java.io.Serializable) 1);
        java.lang.String str20 = objConsumerRecord19.toString();
        long long21 = objConsumerRecord19.offset();
        org.apache.kafka.common.header.Headers headers22 = objConsumerRecord19.headers();
        java.lang.String str23 = objConsumerRecord19.toString();
        long long24 = objConsumerRecord19.offset();
        long long25 = objConsumerRecord19.checksum();
        java.util.Optional<java.lang.Integer> intOptional26 = objConsumerRecord19.leaderEpoch();
        java.lang.Object obj27 = objConsumerRecord19.key();
        long long28 = objConsumerRecord19.offset();
        java.util.Optional<java.lang.Integer> intOptional29 = objConsumerRecord19.leaderEpoch();
        org.apache.kafka.common.header.Headers headers30 = objConsumerRecord19.headers();
        org.apache.kafka.common.header.Headers headers31 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers> annotatedElementConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.header.Headers>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100), partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = -1)", 0, 35L, (long) (byte) -1, timestampType4, (java.lang.Long) 35L, (int) (byte) -1, (int) (byte) 10, annotatedElement8, headers30, headers31);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertNotNull(headers22);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str23, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + (-1L) + "'", long24 == (-1L));
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + 0L + "'", long25 == 0L);
        org.junit.Assert.assertNotNull(intOptional26);
        org.junit.Assert.assertNull(obj27);
        org.junit.Assert.assertTrue("'" + long28 + "' != '" + (-1L) + "'", long28 == (-1L));
        org.junit.Assert.assertNotNull(intOptional29);
        org.junit.Assert.assertNotNull(headers30);
    }

    @Test
    public void test00293() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00293");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, java.lang.reflect.Type> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.reflect.Type> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.reflect.Type>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00294() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00294");
        java.lang.Object obj6 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj6, (java.io.Serializable) (byte) 100);
        java.lang.Object obj9 = objConsumerRecord8.key();
        int int10 = objConsumerRecord8.partition();
        org.apache.kafka.common.header.Headers headers11 = objConsumerRecord8.headers();
        org.apache.kafka.common.record.TimestampType timestampType16 = null;
        org.apache.kafka.common.record.TimestampType timestampType24 = null;
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        java.lang.Object obj36 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType32, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj36, (java.io.Serializable) 1);
        long long39 = objConsumerRecord38.timestamp();
        java.lang.Object obj40 = objConsumerRecord38.key();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.io.Serializable> objConsumerRecordConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.io.Serializable>("", 100, (long) '#', (long) (byte) 0, timestampType24, (long) (-1), (int) (byte) 0, (int) (short) 100, objConsumerRecord38, (java.io.Serializable) (-1.0d));
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) (byte) -1, (long) 1, (long) (byte) 0, timestampType16, (long) '4', (int) (byte) 0, (int) 'a', (java.lang.Object) objConsumerRecordConsumerRecord42, (java.io.Serializable) 10.0f);
        java.lang.Class<?> wildcardClass45 = objConsumerRecord44.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 0, (long) ' ', (java.lang.Object) headers11, (java.io.Serializable) wildcardClass45);
        int int47 = objConsumerRecord46.partition();
        java.lang.String str48 = objConsumerRecord46.toString();
        java.lang.Class<?> wildcardClass49 = objConsumerRecord46.getClass();
        org.junit.Assert.assertNull(obj9);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 97 + "'", int10 == 97);
        org.junit.Assert.assertNotNull(headers11);
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + 52L + "'", long39 == 52L);
        org.junit.Assert.assertNull(obj40);
        org.junit.Assert.assertNotNull(wildcardClass45);
        org.junit.Assert.assertTrue("'" + int47 + "' != '" + 0 + "'", int47 == 0);
        org.junit.Assert.assertEquals("'" + str48 + "' != '" + "ConsumerRecord(topic = hi!, partition = 0, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = class org.apache.kafka.clients.consumer.ConsumerRecord)" + "'", str48, "ConsumerRecord(topic = hi!, partition = 0, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = class org.apache.kafka.clients.consumer.ConsumerRecord)");
        org.junit.Assert.assertNotNull(wildcardClass49);
    }

    @Test
    public void test00295() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00295");
        java.lang.Object obj10 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj10, (java.io.Serializable) (byte) 100);
        org.apache.kafka.common.record.TimestampType timestampType17 = null;
        java.lang.Object obj21 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType17, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj21, (java.io.Serializable) 1);
        long long24 = objConsumerRecord23.timestamp();
        java.lang.Object obj25 = objConsumerRecord23.key();
        long long26 = objConsumerRecord23.checksum();
        java.lang.Class<?> wildcardClass27 = objConsumerRecord23.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) 1, (long) '#', obj10, (java.io.Serializable) wildcardClass27);
        java.lang.Object obj29 = objConsumerRecord28.key();
        long long30 = objConsumerRecord28.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType31 = objConsumerRecord28.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType39 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType39, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        org.apache.kafka.common.record.TimestampType timestampType46 = objConsumerRecord45.timestampType();
        long long47 = objConsumerRecord45.timestamp();
        org.apache.kafka.common.header.Headers headers48 = objConsumerRecord45.headers();
        int int49 = objConsumerRecord45.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType57 = null;
        org.apache.kafka.common.record.TimestampType timestampType65 = null;
        java.lang.Object obj69 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType65, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj69, (java.io.Serializable) 1);
        long long72 = objConsumerRecord71.timestamp();
        java.util.Optional<java.lang.Integer> intOptional73 = objConsumerRecord71.leaderEpoch();
        long long74 = objConsumerRecord71.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType57, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord71, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional77 = objConsumerRecord71.leaderEpoch();
        java.lang.Object obj85 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj85, (java.io.Serializable) (byte) 100);
        java.lang.Object obj88 = objConsumerRecord87.key();
        java.lang.String str89 = objConsumerRecord87.toString();
        org.apache.kafka.common.record.TimestampType timestampType90 = objConsumerRecord87.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) -1, 10L, (long) (short) 100, timestampType90, (long) 0, 0, 35, (java.lang.Object) (-1), (java.io.Serializable) 1L);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType> intOptionalConsumerRecord97 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType>("", (-1), (long) (byte) -1, intOptional77, timestampType90);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)", (int) 'a', (long) '#', (long) 32, timestampType31, 97L, 100, (int) (short) 100, (java.lang.Object) objConsumerRecord45, (java.io.Serializable) (-1));
        org.apache.kafka.common.header.Headers headers99 = objConsumerRecord98.headers();
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 52L + "'", long24 == 52L);
        org.junit.Assert.assertNull(obj25);
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + 0L + "'", long26 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass27);
        org.junit.Assert.assertNull(obj29);
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNull(timestampType46);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 10L + "'", long47 == 10L);
        org.junit.Assert.assertNotNull(headers48);
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + (-1) + "'", int49 == (-1));
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + 52L + "'", long72 == 52L);
        org.junit.Assert.assertNotNull(intOptional73);
        org.junit.Assert.assertTrue("'" + long74 + "' != '" + 52L + "'", long74 == 52L);
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertNull(obj88);
        org.junit.Assert.assertEquals("'" + str89 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str89, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType90 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType90.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers99);
    }

    @Test
    public void test00296() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00296");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        java.lang.String str13 = objConsumerRecord10.toString();
        java.lang.String str14 = objConsumerRecord10.toString();
        org.apache.kafka.common.header.Headers headers15 = objConsumerRecord10.headers();
        long long16 = objConsumerRecord10.timestamp();
        java.io.Serializable serializable17 = objConsumerRecord10.value();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(headers15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 52L + "'", long16 == 52L);
        org.junit.Assert.assertEquals("'" + serializable17 + "' != '" + 1 + "'", serializable17, 1);
    }

    @Test
    public void test00297() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00297");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.record.TimestampType> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.record.TimestampType> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.record.TimestampType>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00298() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00298");
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj11, (java.io.Serializable) (byte) 100);
        java.lang.Object obj14 = objConsumerRecord13.key();
        java.lang.String str15 = objConsumerRecord13.toString();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType24 = null;
        java.lang.Object obj28 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType24, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj28, (java.io.Serializable) 1);
        long long31 = objConsumerRecord30.offset();
        long long32 = objConsumerRecord30.checksum();
        org.apache.kafka.common.header.Headers headers33 = objConsumerRecord30.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), (long) (short) 1, (long) 0, timestampType16, 10L, 97, (int) '4', (java.lang.Object) headers33, (java.io.Serializable) 0.0d);
        org.apache.kafka.common.record.TimestampType timestampType43 = null;
        java.lang.Object obj47 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType43, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj47, (java.io.Serializable) 1);
        java.lang.String str50 = objConsumerRecord49.toString();
        long long51 = objConsumerRecord49.offset();
        org.apache.kafka.common.header.Headers headers52 = objConsumerRecord49.headers();
        java.lang.String str53 = objConsumerRecord49.toString();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (int) 'a', 35L, (long) 0, timestampType16, 52L, (int) '#', 10, (java.lang.Object) objConsumerRecord49, (java.io.Serializable) true);
        java.lang.String str56 = objConsumerRecord55.toString();
        org.junit.Assert.assertNull(obj14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str15, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType16 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType16.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long31 + "' != '" + (-1L) + "'", long31 == (-1L));
        org.junit.Assert.assertTrue("'" + long32 + "' != '" + 0L + "'", long32 == 0L);
        org.junit.Assert.assertNotNull(headers33);
        org.junit.Assert.assertEquals("'" + str50 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str50, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + (-1L) + "'", long51 == (-1L));
        org.junit.Assert.assertNotNull(headers52);
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str53, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str56 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100), partition = 97, leaderEpoch = null, offset = 35, NoTimestampType = 0, serialized key size = 35, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = true)" + "'", str56, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100), partition = 97, leaderEpoch = null, offset = 35, NoTimestampType = 0, serialized key size = 35, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = true)");
    }

    @Test
    public void test00299() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00299");
        java.lang.Object obj7 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj7, (java.io.Serializable) (byte) 100);
        java.lang.Object obj10 = objConsumerRecord9.key();
        java.lang.String str11 = objConsumerRecord9.toString();
        org.apache.kafka.common.record.TimestampType timestampType12 = objConsumerRecord9.timestampType();
        java.lang.Object obj27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj27, (java.io.Serializable) (byte) 100);
        java.lang.Object obj30 = objConsumerRecord29.key();
        java.lang.String str31 = objConsumerRecord29.toString();
        org.apache.kafka.common.record.TimestampType timestampType32 = objConsumerRecord29.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (int) (short) -1, (long) (short) 10, (java.lang.Object) timestampType32, (java.io.Serializable) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        java.lang.Object obj38 = null;
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        java.lang.Object obj57 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType53, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj57, (java.io.Serializable) 1);
        long long60 = objConsumerRecord59.timestamp();
        int int61 = objConsumerRecord59.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional62 = objConsumerRecord59.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord59, (java.io.Serializable) false);
        java.lang.String str65 = objConsumerRecord64.toString();
        int int66 = objConsumerRecord64.partition();
        java.io.Serializable serializable67 = objConsumerRecord64.value();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 1, NoTimestampType = 1, serialized key size = 0, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = NoTimestampType)", (-1), (long) (byte) 0, (java.lang.Object) serializable67, (java.io.Serializable) 100L);
        org.apache.kafka.common.record.TimestampType timestampType70 = objConsumerRecord69.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType79 = null;
        java.lang.Object obj83 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType79, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj83, (java.io.Serializable) 1);
        long long86 = objConsumerRecord85.timestamp();
        java.util.Optional<java.lang.Integer> intOptional87 = objConsumerRecord85.leaderEpoch();
        long long88 = objConsumerRecord85.checksum();
        java.lang.String str89 = objConsumerRecord85.topic();
        java.io.Serializable serializable90 = objConsumerRecord85.value();
        org.apache.kafka.common.record.TimestampType timestampType91 = objConsumerRecord85.timestampType();
        int int92 = objConsumerRecord85.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional93 = objConsumerRecord85.leaderEpoch();
        int int94 = objConsumerRecord85.serializedKeySize();
        org.apache.kafka.common.header.Headers headers95 = objConsumerRecord85.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, org.apache.kafka.common.header.Headers> serializableConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, org.apache.kafka.common.header.Headers>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 100, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = class org.apache.kafka.clients.consumer.ConsumerRecord, value = null)", 0, (long) (short) -1, 100L, timestampType70, (long) (-1), (int) (byte) 1, (int) '#', (java.io.Serializable) 1L, headers95);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord97 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", 0, 100L, (long) 0, timestampType32, 97L, (int) (short) 100, (-1), obj38, (java.io.Serializable) timestampType70);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> charSequenceConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '4', (long) (byte) 100, (long) (short) 1, timestampType12, (long) 1, (-1), (int) (short) 1, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100), partition = 97, leaderEpoch = null, offset = 35, NoTimestampType = 0, serialized key size = 35, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = true)", (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType32);
        org.junit.Assert.assertNull(obj10);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str11, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNull(obj30);
        org.junit.Assert.assertEquals("'" + str31 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str31, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType32 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType32.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + 52L + "'", long60 == 52L);
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + 100 + "'", int61 == 100);
        org.junit.Assert.assertNotNull(intOptional62);
        org.junit.Assert.assertEquals("'" + str65 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)" + "'", str65, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)");
        org.junit.Assert.assertTrue("'" + int66 + "' != '" + 100 + "'", int66 == 100);
        org.junit.Assert.assertEquals("'" + serializable67 + "' != '" + false + "'", serializable67, false);
        org.junit.Assert.assertTrue("'" + timestampType70 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType70.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long86 + "' != '" + 52L + "'", long86 == 52L);
        org.junit.Assert.assertNotNull(intOptional87);
        org.junit.Assert.assertTrue("'" + long88 + "' != '" + 0L + "'", long88 == 0L);
        org.junit.Assert.assertEquals("'" + str89 + "' != '" + "" + "'", str89, "");
        org.junit.Assert.assertEquals("'" + serializable90 + "' != '" + 1 + "'", serializable90, 1);
        org.junit.Assert.assertNull(timestampType91);
        org.junit.Assert.assertTrue("'" + int92 + "' != '" + 100 + "'", int92 == 100);
        org.junit.Assert.assertNotNull(intOptional93);
        org.junit.Assert.assertTrue("'" + int94 + "' != '" + 10 + "'", int94 == 10);
        org.junit.Assert.assertNotNull(headers95);
    }

    @Test
    public void test00300() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00300");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Object> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Object> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Object>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00301() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00301");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.kafka.common.record.TimestampType timestampType15 = null;
        java.lang.Object obj19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType15, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj19, (java.io.Serializable) 1);
        long long22 = objConsumerRecord21.timestamp();
        java.util.Optional<java.lang.Integer> intOptional23 = objConsumerRecord21.leaderEpoch();
        long long24 = objConsumerRecord21.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType7, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord21, (java.io.Serializable) '#');
        java.io.Serializable serializable27 = objConsumerRecord26.value();
        org.apache.kafka.common.record.TimestampType timestampType28 = objConsumerRecord26.timestampType();
        java.lang.String str29 = objConsumerRecord26.toString();
        org.apache.kafka.common.record.TimestampType timestampType34 = null;
        org.apache.kafka.common.record.TimestampType timestampType42 = null;
        java.lang.Object obj46 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType42, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj46, (java.io.Serializable) 1);
        long long49 = objConsumerRecord48.timestamp();
        java.util.Optional<java.lang.Integer> intOptional50 = objConsumerRecord48.leaderEpoch();
        long long51 = objConsumerRecord48.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType34, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord48, (java.io.Serializable) '#');
        java.lang.Class<?> wildcardClass54 = objConsumerRecord53.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 32, (long) '#', (java.lang.Object) objConsumerRecord26, (java.io.Serializable) wildcardClass54);
        java.lang.String str56 = objConsumerRecord26.topic();
        long long57 = objConsumerRecord26.checksum();
        java.lang.String str58 = objConsumerRecord26.toString();
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 52L + "'", long22 == 52L);
        org.junit.Assert.assertNotNull(intOptional23);
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 52L + "'", long24 == 52L);
        org.junit.Assert.assertEquals("'" + serializable27 + "' != '" + '#' + "'", serializable27, '#');
        org.junit.Assert.assertNull(timestampType28);
        org.junit.Assert.assertEquals("'" + str29 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)" + "'", str29, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)");
        org.junit.Assert.assertTrue("'" + long49 + "' != '" + 52L + "'", long49 == 52L);
        org.junit.Assert.assertNotNull(intOptional50);
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + 52L + "'", long51 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass54);
        org.junit.Assert.assertEquals("'" + str56 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str56, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long57 + "' != '" + 1L + "'", long57 == 1L);
        org.junit.Assert.assertEquals("'" + str58 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)" + "'", str58, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)");
    }

    @Test
    public void test00302() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00302");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.lang.Object obj12 = objConsumerRecord10.key();
        long long13 = objConsumerRecord10.checksum();
        long long14 = objConsumerRecord10.checksum();
        org.apache.kafka.common.record.TimestampType timestampType15 = objConsumerRecord10.timestampType();
        org.apache.kafka.common.header.Headers headers16 = objConsumerRecord10.headers();
        long long17 = objConsumerRecord10.timestamp();
        java.lang.Object obj18 = objConsumerRecord10.key();
        int int19 = objConsumerRecord10.serializedValueSize();
        java.lang.String str20 = objConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNull(obj12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertNull(timestampType15);
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 100 + "'", int19 == 100);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "" + "'", str20, "");
    }

    @Test
    public void test00303() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00303");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType4, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        org.apache.kafka.common.record.TimestampType timestampType11 = objConsumerRecord10.timestampType();
        java.lang.String str12 = objConsumerRecord10.toString();
        long long13 = objConsumerRecord10.offset();
        org.apache.kafka.common.record.TimestampType timestampType14 = objConsumerRecord10.timestampType();
        int int15 = objConsumerRecord10.serializedKeySize();
        java.io.Serializable serializable16 = objConsumerRecord10.value();
        long long17 = objConsumerRecord10.offset();
        org.junit.Assert.assertNull(timestampType11);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)" + "'", str12, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 100L + "'", long13 == 100L);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertEquals("'" + serializable16 + "' != '" + 10 + "'", serializable16, 10);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 100L + "'", long17 == 100L);
    }

    @Test
    public void test00304() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00304");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.lang.String str12 = objConsumerRecord10.toString();
        long long13 = objConsumerRecord10.offset();
        java.lang.String str14 = objConsumerRecord10.topic();
        long long15 = objConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers16 = objConsumerRecord10.headers();
        int int17 = objConsumerRecord10.serializedKeySize();
        java.lang.Object obj18 = objConsumerRecord10.key();
        long long19 = objConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord10.leaderEpoch();
        java.lang.Class<?> wildcardClass21 = intOptional20.getClass();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str12, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertNotNull(wildcardClass21);
    }

    @Test
    public void test00305() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00305");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        java.util.Optional<java.lang.Integer> intOptional15 = objConsumerRecord13.leaderEpoch();
        long long16 = objConsumerRecord13.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType21 = null;
        java.lang.Object obj25 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType21, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj25, (java.io.Serializable) 1);
        java.lang.String str28 = objConsumerRecord27.toString();
        java.lang.String str29 = objConsumerRecord27.toString();
        java.lang.Class<?> wildcardClass30 = objConsumerRecord27.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (short) 10, (java.lang.Object) objConsumerRecord13, (java.io.Serializable) wildcardClass30);
        long long32 = objConsumerRecord31.checksum();
        long long33 = objConsumerRecord31.timestamp();
        java.lang.Class<?> wildcardClass34 = objConsumerRecord31.getClass();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 52L + "'", long16 == 52L);
        org.junit.Assert.assertEquals("'" + str28 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str28, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str29 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str29, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass30);
        org.junit.Assert.assertTrue("'" + long32 + "' != '" + (-1L) + "'", long32 == (-1L));
        org.junit.Assert.assertTrue("'" + long33 + "' != '" + (-1L) + "'", long33 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass34);
    }

    @Test
    public void test00306() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00306");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (int) (short) 10, (long) (short) 1, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)", (java.lang.CharSequence) "ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = -1, null = 1, serialized key size = 35, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = class org.apache.kafka.clients.consumer.ConsumerRecord)");
    }

    @Test
    public void test00307() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00307");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, java.lang.Iterable<org.apache.kafka.common.header.Header>> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.Iterable<org.apache.kafka.common.header.Header>> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.Iterable<org.apache.kafka.common.header.Header>>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00308() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00308");
        org.apache.kafka.common.record.TimestampType timestampType11 = null;
        java.lang.Object obj15 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType11, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj15, (java.io.Serializable) 1);
        long long18 = objConsumerRecord17.timestamp();
        java.util.Optional<java.lang.Integer> intOptional19 = objConsumerRecord17.leaderEpoch();
        long long20 = objConsumerRecord17.checksum();
        org.apache.kafka.common.record.TimestampType timestampType21 = objConsumerRecord17.timestampType();
        java.lang.Object obj28 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj28, (java.io.Serializable) (byte) 100);
        org.apache.kafka.common.record.TimestampType timestampType35 = null;
        java.lang.Object obj39 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType35, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj39, (java.io.Serializable) 1);
        long long42 = objConsumerRecord41.timestamp();
        java.lang.Object obj43 = objConsumerRecord41.key();
        long long44 = objConsumerRecord41.checksum();
        java.lang.Class<?> wildcardClass45 = objConsumerRecord41.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) 1, (long) '#', obj28, (java.io.Serializable) wildcardClass45);
        java.lang.Object obj47 = objConsumerRecord46.key();
        long long48 = objConsumerRecord46.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType49 = objConsumerRecord46.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType50 = objConsumerRecord46.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = -1, null = 1, serialized key size = 35, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 0, (-1L), (java.lang.Object) objConsumerRecord17, (java.io.Serializable) timestampType50);
        org.apache.kafka.common.record.TimestampType timestampType59 = null;
        org.apache.kafka.common.record.TimestampType timestampType67 = null;
        org.apache.kafka.common.record.TimestampType timestampType75 = null;
        java.lang.Object obj79 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType75, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj79, (java.io.Serializable) 1);
        long long82 = objConsumerRecord81.timestamp();
        java.util.Optional<java.lang.Integer> intOptional83 = objConsumerRecord81.leaderEpoch();
        long long84 = objConsumerRecord81.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType67, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord81, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional87 = objConsumerRecord81.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord89 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 1L, (long) (short) 10, timestampType59, (long) (byte) 1, (int) (byte) 0, (int) ' ', (java.lang.Object) intOptional87, (java.io.Serializable) 100L);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord91 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) (short) 1, 1L, (long) 32, timestampType50, (long) 52, (int) '#', (int) (short) 0, (java.lang.Object) ' ', (java.io.Serializable) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 0, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = Optional.empty, value = 100)");
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 52L + "'", long18 == 52L);
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 0L + "'", long20 == 0L);
        org.junit.Assert.assertNull(timestampType21);
        org.junit.Assert.assertTrue("'" + long42 + "' != '" + 52L + "'", long42 == 52L);
        org.junit.Assert.assertNull(obj43);
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + 0L + "'", long44 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass45);
        org.junit.Assert.assertNull(obj47);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType49 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType49.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType50 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType50.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long82 + "' != '" + 52L + "'", long82 == 52L);
        org.junit.Assert.assertNotNull(intOptional83);
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + 52L + "'", long84 == 52L);
        org.junit.Assert.assertNotNull(intOptional87);
    }

    @Test
    public void test00309() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00309");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        long long19 = objConsumerRecord18.timestamp();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord18.leaderEpoch();
        long long21 = objConsumerRecord18.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType4, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord18, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional24 = objConsumerRecord18.leaderEpoch();
        java.lang.String str25 = objConsumerRecord18.topic();
        java.io.Serializable serializable26 = objConsumerRecord18.value();
        long long27 = objConsumerRecord18.offset();
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertNotNull(intOptional24);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "" + "'", str25, "");
        org.junit.Assert.assertEquals("'" + serializable26 + "' != '" + 1 + "'", serializable26, 1);
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + (-1L) + "'", long27 == (-1L));
    }

    @Test
    public void test00310() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00310");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        long long13 = objConsumerRecord10.checksum();
        java.lang.String str14 = objConsumerRecord10.topic();
        java.io.Serializable serializable15 = objConsumerRecord10.value();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord10.timestampType();
        int int17 = objConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional18 = objConsumerRecord10.leaderEpoch();
        java.lang.Class<?> wildcardClass19 = objConsumerRecord10.getClass();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertEquals("'" + serializable15 + "' != '" + 1 + "'", serializable15, 1);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 100 + "'", int17 == 100);
        org.junit.Assert.assertNotNull(intOptional18);
        org.junit.Assert.assertNotNull(wildcardClass19);
    }

    @Test
    public void test00311() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00311");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        java.lang.String str13 = objConsumerRecord10.toString();
        java.lang.String str14 = objConsumerRecord10.toString();
        org.apache.kafka.common.header.Headers headers15 = objConsumerRecord10.headers();
        long long16 = objConsumerRecord10.timestamp();
        long long17 = objConsumerRecord10.checksum();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(headers15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 52L + "'", long16 == 52L);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
    }

    @Test
    public void test00312() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00312");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.Comparable<java.lang.String>> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.Comparable<java.lang.String>> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.Comparable<java.lang.String>>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00313() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00313");
        java.lang.Object obj7 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj7, (java.io.Serializable) (byte) 100);
        java.lang.Object obj10 = objConsumerRecord9.key();
        org.apache.kafka.common.record.TimestampType timestampType11 = objConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType19 = null;
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        java.lang.Object obj31 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType27, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj31, (java.io.Serializable) 1);
        long long34 = objConsumerRecord33.timestamp();
        java.util.Optional<java.lang.Integer> intOptional35 = objConsumerRecord33.leaderEpoch();
        long long36 = objConsumerRecord33.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType19, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord33, (java.io.Serializable) '#');
        int int39 = objConsumerRecord38.partition();
        java.util.Optional<java.lang.Integer> intOptional40 = objConsumerRecord38.leaderEpoch();
        long long41 = objConsumerRecord38.checksum();
        org.apache.kafka.common.header.Headers headers42 = objConsumerRecord38.headers();
        org.apache.kafka.common.record.TimestampType timestampType47 = null;
        org.apache.kafka.common.record.TimestampType timestampType56 = null;
        java.lang.Object obj60 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord62 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType56, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj60, (java.io.Serializable) 1);
        long long63 = objConsumerRecord62.timestamp();
        java.util.Optional<java.lang.Integer> intOptional64 = objConsumerRecord62.leaderEpoch();
        long long65 = objConsumerRecord62.offset();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> charSequenceConsumerRecord66 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>("", (int) '4', (long) 'a', 0L, timestampType47, 10L, (-1), (int) (short) 0, (java.lang.CharSequence) "hi!", objConsumerRecord62);
        java.lang.Class<?> wildcardClass67 = charSequenceConsumerRecord66.getClass();
        org.apache.kafka.common.record.TimestampType timestampType72 = null;
        org.apache.kafka.common.record.TimestampType timestampType80 = null;
        java.lang.Object obj84 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType80, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj84, (java.io.Serializable) 1);
        long long87 = objConsumerRecord86.offset();
        long long88 = objConsumerRecord86.checksum();
        long long89 = objConsumerRecord86.timestamp();
        java.lang.String str90 = objConsumerRecord86.topic();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord92 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", 0, (long) (short) 100, (long) '4', timestampType72, 0L, (int) (byte) 10, 35, (java.lang.Object) objConsumerRecord86, (java.io.Serializable) true);
        org.apache.kafka.common.header.Headers headers93 = objConsumerRecord92.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord94 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 100, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = class org.apache.kafka.clients.consumer.ConsumerRecord, value = null)", (int) (byte) 0, (long) 32, (long) 100, timestampType11, (java.lang.Long) 97L, (int) (short) 100, (int) (byte) 10, (java.lang.Object) objConsumerRecord38, (java.io.Serializable) wildcardClass67, headers93);
        java.util.Optional<java.lang.Integer> intOptional95 = objConsumerRecord38.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType96 = objConsumerRecord38.timestampType();
        org.junit.Assert.assertNull(obj10);
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + 52L + "'", long34 == 52L);
        org.junit.Assert.assertNotNull(intOptional35);
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + 52L + "'", long36 == 52L);
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + (-1) + "'", int39 == (-1));
        org.junit.Assert.assertNotNull(intOptional40);
        org.junit.Assert.assertTrue("'" + long41 + "' != '" + 1L + "'", long41 == 1L);
        org.junit.Assert.assertNotNull(headers42);
        org.junit.Assert.assertTrue("'" + long63 + "' != '" + 52L + "'", long63 == 52L);
        org.junit.Assert.assertNotNull(intOptional64);
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + (-1L) + "'", long65 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass67);
        org.junit.Assert.assertTrue("'" + long87 + "' != '" + (-1L) + "'", long87 == (-1L));
        org.junit.Assert.assertTrue("'" + long88 + "' != '" + 0L + "'", long88 == 0L);
        org.junit.Assert.assertTrue("'" + long89 + "' != '" + 52L + "'", long89 == 52L);
        org.junit.Assert.assertEquals("'" + str90 + "' != '" + "" + "'", str90, "");
        org.junit.Assert.assertNotNull(headers93);
        org.junit.Assert.assertNotNull(intOptional95);
        org.junit.Assert.assertNull(timestampType96);
    }

    @Test
    public void test00314() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00314");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        long long19 = objConsumerRecord18.offset();
        long long20 = objConsumerRecord18.checksum();
        long long21 = objConsumerRecord18.timestamp();
        java.lang.String str22 = objConsumerRecord18.topic();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", 0, (long) (short) 100, (long) '4', timestampType4, 0L, (int) (byte) 10, 35, (java.lang.Object) objConsumerRecord18, (java.io.Serializable) true);
        org.apache.kafka.common.header.Headers headers25 = objConsumerRecord24.headers();
        org.apache.kafka.common.record.TimestampType timestampType26 = objConsumerRecord24.timestampType();
        int int27 = objConsumerRecord24.partition();
        java.io.Serializable serializable28 = objConsumerRecord24.value();
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 0L + "'", long20 == 0L);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertNotNull(headers25);
        org.junit.Assert.assertNull(timestampType26);
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + 0 + "'", int27 == 0);
        org.junit.Assert.assertEquals("'" + serializable28 + "' != '" + true + "'", serializable28, true);
    }

    @Test
    public void test00315() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00315");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        java.util.Optional<java.lang.Integer> intOptional15 = objConsumerRecord13.leaderEpoch();
        java.lang.Class<?> wildcardClass16 = objConsumerRecord13.getClass();
        org.apache.kafka.common.record.TimestampType timestampType21 = null;
        org.apache.kafka.common.record.TimestampType timestampType29 = null;
        org.apache.kafka.common.record.TimestampType timestampType37 = null;
        java.lang.Object obj41 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType37, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj41, (java.io.Serializable) 1);
        long long44 = objConsumerRecord43.timestamp();
        java.util.Optional<java.lang.Integer> intOptional45 = objConsumerRecord43.leaderEpoch();
        long long46 = objConsumerRecord43.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType29, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord43, (java.io.Serializable) '#');
        java.lang.Class<?> wildcardClass49 = objConsumerRecord48.getClass();
        org.apache.kafka.common.record.TimestampType timestampType54 = null;
        java.lang.Object obj58 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType54, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj58, (java.io.Serializable) 1);
        java.lang.String str61 = objConsumerRecord60.toString();
        java.lang.String str62 = objConsumerRecord60.toString();
        long long63 = objConsumerRecord60.offset();
        java.lang.String str64 = objConsumerRecord60.topic();
        java.lang.Class<?> wildcardClass65 = objConsumerRecord60.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.AnnotatedElement> typeConsumerRecord66 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) '4', (long) '4', (long) '#', timestampType21, 0L, (int) (byte) 100, (int) ' ', (java.lang.reflect.Type) wildcardClass49, (java.lang.reflect.AnnotatedElement) wildcardClass65);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)", (int) (byte) 100, (long) 'a', (java.lang.Object) wildcardClass16, (java.io.Serializable) timestampType21);
        long long68 = objConsumerRecord67.checksum();
        java.lang.Object obj69 = objConsumerRecord67.key();
        java.lang.Class<?> wildcardClass70 = obj69.getClass();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertNotNull(wildcardClass16);
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + 52L + "'", long44 == 52L);
        org.junit.Assert.assertNotNull(intOptional45);
        org.junit.Assert.assertTrue("'" + long46 + "' != '" + 52L + "'", long46 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass49);
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str61, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str62 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str62, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long63 + "' != '" + (-1L) + "'", long63 == (-1L));
        org.junit.Assert.assertEquals("'" + str64 + "' != '" + "" + "'", str64, "");
        org.junit.Assert.assertNotNull(wildcardClass65);
        org.junit.Assert.assertTrue("'" + long68 + "' != '" + (-1L) + "'", long68 == (-1L));
        org.junit.Assert.assertNotNull(obj69);
        org.junit.Assert.assertEquals(obj69.toString(), "class org.apache.kafka.clients.consumer.ConsumerRecord");
        org.junit.Assert.assertEquals(java.lang.String.valueOf(obj69), "class org.apache.kafka.clients.consumer.ConsumerRecord");
        org.junit.Assert.assertEquals(java.util.Objects.toString(obj69), "class org.apache.kafka.clients.consumer.ConsumerRecord");
        org.junit.Assert.assertNotNull(wildcardClass70);
    }

    @Test
    public void test00316() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00316");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00317() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00317");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        long long15 = objConsumerRecord13.timestamp();
        int int16 = objConsumerRecord13.serializedKeySize();
        java.lang.Object obj17 = objConsumerRecord13.key();
        org.apache.kafka.common.header.Headers headers18 = objConsumerRecord13.headers();
        int int19 = objConsumerRecord13.partition();
        int int20 = objConsumerRecord13.serializedKeySize();
        java.lang.Object obj21 = objConsumerRecord13.key();
        org.apache.kafka.common.record.TimestampType timestampType22 = objConsumerRecord13.timestampType();
        org.apache.kafka.common.header.Headers headers23 = objConsumerRecord13.headers();
        org.apache.kafka.common.header.Headers headers24 = objConsumerRecord13.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.String> headerIterableConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100), partition = 0, leaderEpoch = null, offset = 100, null = 52, serialized key size = 10, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = true)", 52, 0L, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers24, "");
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertNull(obj17);
        org.junit.Assert.assertNotNull(headers18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 10 + "'", int20 == 10);
        org.junit.Assert.assertNull(obj21);
        org.junit.Assert.assertNull(timestampType22);
        org.junit.Assert.assertNotNull(headers23);
        org.junit.Assert.assertNotNull(headers24);
    }

    @Test
    public void test00318() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00318");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.io.Serializable serializable16 = null;
        org.apache.kafka.common.record.TimestampType timestampType21 = null;
        java.lang.Object obj25 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType21, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj25, (java.io.Serializable) 1);
        java.lang.String str28 = objConsumerRecord27.toString();
        java.lang.String str29 = objConsumerRecord27.toString();
        java.lang.Class<?> wildcardClass30 = objConsumerRecord27.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.reflect.Type> serializableConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.reflect.Type>("", (int) (short) 1, (long) 1, (long) 'a', timestampType12, (long) 10, 0, (int) (byte) 0, serializable16, (java.lang.reflect.Type) wildcardClass30);
        org.apache.kafka.common.record.TimestampType timestampType36 = null;
        java.lang.Object obj40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType36, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj40, (java.io.Serializable) 1);
        long long43 = objConsumerRecord42.timestamp();
        java.util.Optional<java.lang.Integer> intOptional44 = objConsumerRecord42.leaderEpoch();
        java.lang.Class<?> wildcardClass45 = objConsumerRecord42.getClass();
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        java.lang.Object obj57 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType53, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj57, (java.io.Serializable) 1);
        java.lang.String str60 = objConsumerRecord59.toString();
        long long61 = objConsumerRecord59.offset();
        org.apache.kafka.common.header.Headers headers62 = objConsumerRecord59.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable> headersConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable>("", (int) (short) 100, (long) 10, headers62, (java.io.Serializable) false);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (byte) -1, (long) (-1), 1L, timestampType4, (java.lang.Long) 1L, (int) '#', 0, (java.lang.Object) serializable16, (java.io.Serializable) wildcardClass45, headers62);
        java.util.Optional<java.lang.Integer> intOptional66 = objConsumerRecord65.leaderEpoch();
        java.lang.Class<?> wildcardClass67 = intOptional66.getClass();
        org.junit.Assert.assertEquals("'" + str28 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str28, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str29 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str29, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass30);
        org.junit.Assert.assertTrue("'" + long43 + "' != '" + 52L + "'", long43 == 52L);
        org.junit.Assert.assertNotNull(intOptional44);
        org.junit.Assert.assertNotNull(wildcardClass45);
        org.junit.Assert.assertEquals("'" + str60 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str60, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long61 + "' != '" + (-1L) + "'", long61 == (-1L));
        org.junit.Assert.assertNotNull(headers62);
        org.junit.Assert.assertNotNull(intOptional66);
        org.junit.Assert.assertNotNull(wildcardClass67);
    }

    @Test
    public void test00319() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00319");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, java.lang.Comparable<java.lang.String>> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.Comparable<java.lang.String>> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.Comparable<java.lang.String>>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00320() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00320");
        java.lang.Object obj14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj14, (java.io.Serializable) (byte) 100);
        java.lang.Object obj17 = objConsumerRecord16.key();
        java.lang.String str18 = objConsumerRecord16.toString();
        org.apache.kafka.common.record.TimestampType timestampType19 = objConsumerRecord16.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        java.lang.Object obj31 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType27, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj31, (java.io.Serializable) 1);
        long long34 = objConsumerRecord33.offset();
        long long35 = objConsumerRecord33.checksum();
        org.apache.kafka.common.header.Headers headers36 = objConsumerRecord33.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), (long) (short) 1, (long) 0, timestampType19, 10L, 97, (int) '4', (java.lang.Object) headers36, (java.io.Serializable) 0.0d);
        org.apache.kafka.common.record.TimestampType timestampType46 = null;
        java.lang.Object obj50 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType46, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj50, (java.io.Serializable) 1);
        java.lang.String str53 = objConsumerRecord52.toString();
        long long54 = objConsumerRecord52.offset();
        org.apache.kafka.common.header.Headers headers55 = objConsumerRecord52.headers();
        java.lang.String str56 = objConsumerRecord52.toString();
        long long57 = objConsumerRecord52.offset();
        long long58 = objConsumerRecord52.checksum();
        int int59 = objConsumerRecord52.partition();
        long long60 = objConsumerRecord52.offset();
        java.lang.Object obj61 = objConsumerRecord52.key();
        org.apache.kafka.common.record.TimestampType timestampType66 = null;
        java.lang.Object obj70 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType66, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj70, (java.io.Serializable) 1);
        long long73 = objConsumerRecord72.timestamp();
        long long74 = objConsumerRecord72.timestamp();
        java.lang.Class<?> wildcardClass75 = objConsumerRecord72.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (int) ' ', 52L, (long) (byte) 0, timestampType19, 0L, 32, 0, obj61, (java.io.Serializable) wildcardClass75);
        org.apache.kafka.common.record.TimestampType timestampType84 = null;
        java.lang.Object obj88 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord90 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType84, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj88, (java.io.Serializable) 1);
        long long91 = objConsumerRecord90.timestamp();
        int int92 = objConsumerRecord90.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional93 = objConsumerRecord90.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord95 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord90, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType96 = objConsumerRecord95.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.record.TimestampType> annotatedElementConsumerRecord97 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, org.apache.kafka.common.record.TimestampType>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100), partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = -1)", 52, 0L, (java.lang.reflect.AnnotatedElement) wildcardClass75, timestampType96);
        org.junit.Assert.assertNull(obj17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str18, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + 0L + "'", long35 == 0L);
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str53, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + (-1L) + "'", long54 == (-1L));
        org.junit.Assert.assertNotNull(headers55);
        org.junit.Assert.assertEquals("'" + str56 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str56, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long57 + "' != '" + (-1L) + "'", long57 == (-1L));
        org.junit.Assert.assertTrue("'" + long58 + "' != '" + 0L + "'", long58 == 0L);
        org.junit.Assert.assertTrue("'" + int59 + "' != '" + 10 + "'", int59 == 10);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertNull(obj61);
        org.junit.Assert.assertTrue("'" + long73 + "' != '" + 52L + "'", long73 == 52L);
        org.junit.Assert.assertTrue("'" + long74 + "' != '" + 52L + "'", long74 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass75);
        org.junit.Assert.assertTrue("'" + long91 + "' != '" + 52L + "'", long91 == 52L);
        org.junit.Assert.assertTrue("'" + int92 + "' != '" + 100 + "'", int92 == 100);
        org.junit.Assert.assertNotNull(intOptional93);
        org.junit.Assert.assertTrue("'" + timestampType96 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType96.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test00321() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00321");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        long long13 = objConsumerRecord10.checksum();
        long long14 = objConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
    }

    @Test
    public void test00322() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00322");
        java.lang.Object obj14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj14, (java.io.Serializable) (byte) 100);
        java.lang.Object obj17 = objConsumerRecord16.key();
        java.lang.String str18 = objConsumerRecord16.toString();
        org.apache.kafka.common.record.TimestampType timestampType19 = objConsumerRecord16.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.common.record.TimestampType timestampType35 = null;
        java.lang.Object obj39 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType35, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj39, (java.io.Serializable) 1);
        long long42 = objConsumerRecord41.timestamp();
        java.util.Optional<java.lang.Integer> intOptional43 = objConsumerRecord41.leaderEpoch();
        long long44 = objConsumerRecord41.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType27, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord41, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional47 = objConsumerRecord41.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.String> intOptionalConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.String>("hi!", (int) (short) -1, (long) (short) 0, (long) (short) 0, timestampType19, (long) (byte) 0, (int) (byte) 0, 0, intOptional47, "");
        org.apache.kafka.common.record.TimestampType timestampType57 = null;
        java.lang.Object obj61 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType57, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj61, (java.io.Serializable) 1);
        java.lang.String str64 = objConsumerRecord63.toString();
        long long65 = objConsumerRecord63.offset();
        org.apache.kafka.common.header.Headers headers66 = objConsumerRecord63.headers();
        java.lang.String str67 = objConsumerRecord63.topic();
        org.apache.kafka.common.header.Headers headers68 = objConsumerRecord63.headers();
        org.apache.kafka.common.record.TimestampType timestampType73 = null;
        java.lang.Object obj77 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType73, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj77, (java.io.Serializable) 1);
        org.apache.kafka.common.record.TimestampType timestampType80 = objConsumerRecord79.timestampType();
        java.util.Optional<java.lang.Integer> intOptional81 = objConsumerRecord79.leaderEpoch();
        java.lang.Class<?> wildcardClass82 = intOptional81.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 0, leaderEpoch = null, offset = 1, NoTimestampType = 97, serialized key size = 35, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)", (int) (byte) 0, (long) (byte) 10, 52L, timestampType19, (long) (byte) 100, (int) 'a', 0, (java.lang.Object) headers68, (java.io.Serializable) wildcardClass82);
        org.apache.kafka.common.record.TimestampType timestampType88 = null;
        java.lang.Object obj92 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord94 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType88, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj92, (java.io.Serializable) 1);
        java.lang.Class<?> wildcardClass95 = objConsumerRecord94.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)", 32, (-1L), (java.lang.Object) objConsumerRecord83, (java.io.Serializable) wildcardClass95);
        long long97 = objConsumerRecord83.checksum();
        long long98 = objConsumerRecord83.timestamp();
        org.apache.kafka.common.header.Headers headers99 = objConsumerRecord83.headers();
        org.junit.Assert.assertNull(obj17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str18, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long42 + "' != '" + 52L + "'", long42 == 52L);
        org.junit.Assert.assertNotNull(intOptional43);
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + 52L + "'", long44 == 52L);
        org.junit.Assert.assertNotNull(intOptional47);
        org.junit.Assert.assertEquals("'" + str64 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str64, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + (-1L) + "'", long65 == (-1L));
        org.junit.Assert.assertNotNull(headers66);
        org.junit.Assert.assertEquals("'" + str67 + "' != '" + "" + "'", str67, "");
        org.junit.Assert.assertNotNull(headers68);
        org.junit.Assert.assertNull(timestampType80);
        org.junit.Assert.assertNotNull(intOptional81);
        org.junit.Assert.assertNotNull(wildcardClass82);
        org.junit.Assert.assertNotNull(wildcardClass95);
        org.junit.Assert.assertTrue("'" + long97 + "' != '" + 100L + "'", long97 == 100L);
        org.junit.Assert.assertTrue("'" + long98 + "' != '" + 52L + "'", long98 == 52L);
        org.junit.Assert.assertNotNull(headers99);
    }

    @Test
    public void test00323() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00323");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers13 = objConsumerRecord10.headers();
        java.lang.String str14 = objConsumerRecord10.toString();
        long long15 = objConsumerRecord10.offset();
        long long16 = objConsumerRecord10.checksum();
        java.lang.Object obj17 = objConsumerRecord10.key();
        java.util.Optional<java.lang.Integer> intOptional18 = objConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.header.Headers headers19 = objConsumerRecord10.headers();
        int int20 = objConsumerRecord10.serializedKeySize();
        java.lang.Class<?> wildcardClass21 = objConsumerRecord10.getClass();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertNull(obj17);
        org.junit.Assert.assertNotNull(intOptional18);
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 10 + "'", int20 == 10);
        org.junit.Assert.assertNotNull(wildcardClass21);
    }

    @Test
    public void test00324() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00324");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        int int14 = objConsumerRecord10.partition();
        int int15 = objConsumerRecord10.serializedValueSize();
        java.io.Serializable serializable16 = objConsumerRecord10.value();
        java.util.Optional<java.lang.Integer> intOptional17 = objConsumerRecord10.leaderEpoch();
        java.lang.String str18 = objConsumerRecord10.toString();
        int int19 = objConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertEquals("'" + serializable16 + "' != '" + 1 + "'", serializable16, 1);
        org.junit.Assert.assertNotNull(intOptional17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str18, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
    }

    @Test
    public void test00325() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00325");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        long long19 = objConsumerRecord18.timestamp();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord18.leaderEpoch();
        long long21 = objConsumerRecord18.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType4, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord18, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional24 = objConsumerRecord18.leaderEpoch();
        java.lang.String str25 = objConsumerRecord18.topic();
        long long26 = objConsumerRecord18.offset();
        org.apache.kafka.common.header.Headers headers27 = objConsumerRecord18.headers();
        java.io.Serializable serializable28 = objConsumerRecord18.value();
        java.util.Optional<java.lang.Integer> intOptional29 = objConsumerRecord18.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertNotNull(intOptional24);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "" + "'", str25, "");
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + (-1L) + "'", long26 == (-1L));
        org.junit.Assert.assertNotNull(headers27);
        org.junit.Assert.assertEquals("'" + serializable28 + "' != '" + 1 + "'", serializable28, 1);
        org.junit.Assert.assertNotNull(intOptional29);
    }

    @Test
    public void test00326() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00326");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, java.lang.reflect.Type> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.reflect.Type> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.reflect.Type>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00327() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00327");
        java.lang.Comparable<java.lang.String> strComparable4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = -1, null = 1, serialized key size = 35, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) (short) 1, (long) 'a', (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 0, leaderEpoch = null, offset = 1, NoTimestampType = 97, serialized key size = 35, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)", strComparable4);
    }

    @Test
    public void test00328() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00328");
        java.lang.Object obj3 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj3, (java.io.Serializable) (byte) 100);
        long long6 = objConsumerRecord5.timestamp();
        java.util.Optional<java.lang.Integer> intOptional7 = objConsumerRecord5.leaderEpoch();
        java.lang.Class<?> wildcardClass8 = intOptional7.getClass();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertNotNull(wildcardClass8);
    }

    @Test
    public void test00329() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00329");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, org.apache.kafka.common.record.TimestampType> serializableConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, org.apache.kafka.common.record.TimestampType>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = -1, null = 1, serialized key size = 35, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) ' ', (long) 10, (java.io.Serializable) "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = 97, serialized key size = 0, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", timestampType4);
    }

    @Test
    public void test00330() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00330");
        org.apache.kafka.common.record.TimestampType timestampType8 = null;
        org.apache.kafka.common.record.TimestampType timestampType16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType16, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        org.apache.kafka.common.record.TimestampType timestampType23 = objConsumerRecord22.timestampType();
        long long24 = objConsumerRecord22.timestamp();
        org.apache.kafka.common.header.Headers headers25 = objConsumerRecord22.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.String> headerIterableConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.String>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 1, NoTimestampType = 1, serialized key size = 0, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = NoTimestampType)", 35, (long) (byte) -1, (long) 32, timestampType8, (long) '#', (int) (short) 10, 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers25, "ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.kafka.common.header.Headers> strConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.kafka.common.header.Headers>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)", (int) (short) 1, 35L, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)", headers25);
        org.junit.Assert.assertNull(timestampType23);
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 10L + "'", long24 == 10L);
        org.junit.Assert.assertNotNull(headers25);
    }

    @Test
    public void test00331() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00331");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.CharSequence> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.CharSequence>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100), partition = 0, leaderEpoch = null, offset = 100, null = 52, serialized key size = 10, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = true)", 0, 10L, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)", (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 35, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = class org.apache.kafka.clients.consumer.ConsumerRecord)");
    }

    @Test
    public void test00332() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00332");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        java.lang.String str14 = objConsumerRecord13.toString();
        long long15 = objConsumerRecord13.offset();
        org.apache.kafka.common.header.Headers headers16 = objConsumerRecord13.headers();
        java.lang.String str17 = objConsumerRecord13.toString();
        java.io.Serializable serializable18 = objConsumerRecord13.value();
        org.apache.kafka.common.header.Headers headers19 = objConsumerRecord13.headers();
        java.lang.Object obj30 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj30, (java.io.Serializable) (byte) 100);
        java.lang.Object obj33 = objConsumerRecord32.key();
        java.lang.String str34 = objConsumerRecord32.toString();
        org.apache.kafka.common.record.TimestampType timestampType35 = objConsumerRecord32.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType48 = null;
        java.lang.Object obj52 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType48, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj52, (java.io.Serializable) 1);
        java.lang.String str55 = objConsumerRecord54.toString();
        java.lang.String str56 = objConsumerRecord54.toString();
        java.lang.Class<?> wildcardClass57 = objConsumerRecord54.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type> charSequenceConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '#', (long) (short) -1, (java.lang.CharSequence) "", (java.lang.reflect.Type) wildcardClass57);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) '#', 100L, (long) 'a', timestampType35, (long) (byte) 100, (int) (byte) -1, 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (java.lang.reflect.AnnotatedElement) wildcardClass57);
        java.lang.Object obj67 = null;
        java.lang.Object obj71 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj71, (java.io.Serializable) (byte) 100);
        java.lang.Object obj74 = objConsumerRecord73.key();
        org.apache.kafka.common.record.TimestampType timestampType75 = objConsumerRecord73.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType76 = objConsumerRecord73.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 1, null = 1, serialized key size = 0, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = 10)", (int) (byte) 1, (long) (short) 0, obj67, (java.io.Serializable) timestampType76);
        java.lang.Object obj81 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 0, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) (short) 0, 97L, 10L, timestampType76, 0L, 0, 97, obj81, (java.io.Serializable) (short) 10);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> serializableConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)", 0, (long) 32, (java.io.Serializable) wildcardClass57, (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType76);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.AnnotatedElement> headerIterableConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = -1, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 32, (long) 'a', (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers19, (java.lang.reflect.AnnotatedElement) wildcardClass57);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str17, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + serializable18 + "' != '" + 1 + "'", serializable18, 1);
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertNull(obj33);
        org.junit.Assert.assertEquals("'" + str34 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str34, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType35 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType35.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str55 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str55, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str56 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str56, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass57);
        org.junit.Assert.assertNull(obj74);
        org.junit.Assert.assertTrue("'" + timestampType75 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType75.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType76 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType76.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test00333() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00333");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.kafka.common.record.TimestampType timestampType15 = null;
        java.lang.Object obj19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType15, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj19, (java.io.Serializable) 1);
        long long22 = objConsumerRecord21.timestamp();
        java.util.Optional<java.lang.Integer> intOptional23 = objConsumerRecord21.leaderEpoch();
        long long24 = objConsumerRecord21.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType7, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord21, (java.io.Serializable) '#');
        java.io.Serializable serializable27 = objConsumerRecord26.value();
        org.apache.kafka.common.record.TimestampType timestampType28 = objConsumerRecord26.timestampType();
        java.lang.String str29 = objConsumerRecord26.toString();
        org.apache.kafka.common.record.TimestampType timestampType34 = null;
        org.apache.kafka.common.record.TimestampType timestampType42 = null;
        java.lang.Object obj46 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType42, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj46, (java.io.Serializable) 1);
        long long49 = objConsumerRecord48.timestamp();
        java.util.Optional<java.lang.Integer> intOptional50 = objConsumerRecord48.leaderEpoch();
        long long51 = objConsumerRecord48.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType34, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord48, (java.io.Serializable) '#');
        java.lang.Class<?> wildcardClass54 = objConsumerRecord53.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 32, (long) '#', (java.lang.Object) objConsumerRecord26, (java.io.Serializable) wildcardClass54);
        int int56 = objConsumerRecord55.serializedValueSize();
        java.lang.Class<?> wildcardClass57 = objConsumerRecord55.getClass();
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 52L + "'", long22 == 52L);
        org.junit.Assert.assertNotNull(intOptional23);
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 52L + "'", long24 == 52L);
        org.junit.Assert.assertEquals("'" + serializable27 + "' != '" + '#' + "'", serializable27, '#');
        org.junit.Assert.assertNull(timestampType28);
        org.junit.Assert.assertEquals("'" + str29 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)" + "'", str29, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)");
        org.junit.Assert.assertTrue("'" + long49 + "' != '" + 52L + "'", long49 == 52L);
        org.junit.Assert.assertNotNull(intOptional50);
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + 52L + "'", long51 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass54);
        org.junit.Assert.assertTrue("'" + int56 + "' != '" + (-1) + "'", int56 == (-1));
        org.junit.Assert.assertNotNull(wildcardClass57);
    }

    @Test
    public void test00334() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00334");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType4, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        int int11 = objConsumerRecord10.serializedKeySize();
        int int12 = objConsumerRecord10.partition();
        int int13 = objConsumerRecord10.serializedKeySize();
        java.io.Serializable serializable14 = objConsumerRecord10.value();
        java.lang.String str15 = objConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + 10 + "'", serializable14, 10);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)" + "'", str15, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)");
    }

    @Test
    public void test00335() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00335");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        long long13 = objConsumerRecord10.timestamp();
        java.io.Serializable serializable14 = objConsumerRecord10.value();
        long long15 = objConsumerRecord10.offset();
        long long16 = objConsumerRecord10.timestamp();
        int int17 = objConsumerRecord10.serializedKeySize();
        java.lang.String str18 = objConsumerRecord10.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = objConsumerRecord10.timestampType();
        long long20 = objConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + 1 + "'", serializable14, 1);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 52L + "'", long16 == 52L);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertNull(timestampType19);
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 0L + "'", long20 == 0L);
    }

    @Test
    public void test00336() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00336");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Iterable<org.apache.kafka.common.header.Header>> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Iterable<org.apache.kafka.common.header.Header>> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Iterable<org.apache.kafka.common.header.Header>>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00337() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00337");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        java.lang.String str14 = objConsumerRecord13.topic();
        java.io.Serializable serializable15 = objConsumerRecord13.value();
        int int16 = objConsumerRecord13.partition();
        java.lang.Object obj17 = objConsumerRecord13.key();
        java.lang.Object obj28 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj28, (java.io.Serializable) (byte) 100);
        java.lang.Object obj31 = objConsumerRecord30.key();
        java.lang.String str32 = objConsumerRecord30.toString();
        org.apache.kafka.common.record.TimestampType timestampType33 = objConsumerRecord30.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (int) (short) -1, (long) (short) 10, (java.lang.Object) timestampType33, (java.io.Serializable) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        java.lang.Object obj39 = null;
        org.apache.kafka.common.record.TimestampType timestampType54 = null;
        java.lang.Object obj58 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType54, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj58, (java.io.Serializable) 1);
        long long61 = objConsumerRecord60.timestamp();
        int int62 = objConsumerRecord60.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional63 = objConsumerRecord60.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord60, (java.io.Serializable) false);
        java.lang.String str66 = objConsumerRecord65.toString();
        int int67 = objConsumerRecord65.partition();
        java.io.Serializable serializable68 = objConsumerRecord65.value();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 1, NoTimestampType = 1, serialized key size = 0, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = NoTimestampType)", (-1), (long) (byte) 0, (java.lang.Object) serializable68, (java.io.Serializable) 100L);
        org.apache.kafka.common.record.TimestampType timestampType71 = objConsumerRecord70.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType80 = null;
        java.lang.Object obj84 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType80, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj84, (java.io.Serializable) 1);
        long long87 = objConsumerRecord86.timestamp();
        java.util.Optional<java.lang.Integer> intOptional88 = objConsumerRecord86.leaderEpoch();
        long long89 = objConsumerRecord86.checksum();
        java.lang.String str90 = objConsumerRecord86.topic();
        java.io.Serializable serializable91 = objConsumerRecord86.value();
        org.apache.kafka.common.record.TimestampType timestampType92 = objConsumerRecord86.timestampType();
        int int93 = objConsumerRecord86.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional94 = objConsumerRecord86.leaderEpoch();
        int int95 = objConsumerRecord86.serializedKeySize();
        org.apache.kafka.common.header.Headers headers96 = objConsumerRecord86.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, org.apache.kafka.common.header.Headers> serializableConsumerRecord97 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, org.apache.kafka.common.header.Headers>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 100, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = class org.apache.kafka.clients.consumer.ConsumerRecord, value = null)", 0, (long) (short) -1, 100L, timestampType71, (long) (-1), (int) (byte) 1, (int) '#', (java.io.Serializable) 1L, headers96);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", 0, 100L, (long) 0, timestampType33, 97L, (int) (short) 100, (-1), obj39, (java.io.Serializable) timestampType71);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord99 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) (byte) 10, (long) 'a', obj17, (java.io.Serializable) timestampType71);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertEquals("'" + serializable15 + "' != '" + 1 + "'", serializable15, 1);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertNull(obj17);
        org.junit.Assert.assertNull(obj31);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str32, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType33 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType33.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long61 + "' != '" + 52L + "'", long61 == 52L);
        org.junit.Assert.assertTrue("'" + int62 + "' != '" + 100 + "'", int62 == 100);
        org.junit.Assert.assertNotNull(intOptional63);
        org.junit.Assert.assertEquals("'" + str66 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)" + "'", str66, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)");
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + 100 + "'", int67 == 100);
        org.junit.Assert.assertEquals("'" + serializable68 + "' != '" + false + "'", serializable68, false);
        org.junit.Assert.assertTrue("'" + timestampType71 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType71.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long87 + "' != '" + 52L + "'", long87 == 52L);
        org.junit.Assert.assertNotNull(intOptional88);
        org.junit.Assert.assertTrue("'" + long89 + "' != '" + 0L + "'", long89 == 0L);
        org.junit.Assert.assertEquals("'" + str90 + "' != '" + "" + "'", str90, "");
        org.junit.Assert.assertEquals("'" + serializable91 + "' != '" + 1 + "'", serializable91, 1);
        org.junit.Assert.assertNull(timestampType92);
        org.junit.Assert.assertTrue("'" + int93 + "' != '" + 100 + "'", int93 == 100);
        org.junit.Assert.assertNotNull(intOptional94);
        org.junit.Assert.assertTrue("'" + int95 + "' != '" + 10 + "'", int95 == 10);
        org.junit.Assert.assertNotNull(headers96);
    }

    @Test
    public void test00338() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00338");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers13 = objConsumerRecord10.headers();
        java.lang.String str14 = objConsumerRecord10.toString();
        long long15 = objConsumerRecord10.offset();
        long long16 = objConsumerRecord10.checksum();
        int int17 = objConsumerRecord10.partition();
        int int18 = objConsumerRecord10.serializedKeySize();
        java.lang.String str19 = objConsumerRecord10.toString();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 10 + "'", int18 == 10);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
    }

    @Test
    public void test00339() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00339");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        java.lang.String str19 = objConsumerRecord18.toString();
        java.lang.String str20 = objConsumerRecord18.toString();
        org.apache.kafka.common.record.TimestampType timestampType26 = null;
        java.lang.Object obj30 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType26, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj30, (java.io.Serializable) 1);
        java.lang.String str33 = objConsumerRecord32.toString();
        long long34 = objConsumerRecord32.offset();
        org.apache.kafka.common.header.Headers headers35 = objConsumerRecord32.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) (byte) 100, (long) (byte) 1, (long) (short) 1, timestampType4, (java.lang.Long) 10L, (int) (short) 0, (int) (short) 1, (java.lang.Object) str20, (java.io.Serializable) 10, headers35);
        java.io.Serializable serializable37 = objConsumerRecord36.value();
        java.lang.Object obj38 = objConsumerRecord36.key();
        int int39 = objConsumerRecord36.serializedKeySize();
        java.lang.String str40 = objConsumerRecord36.toString();
        long long41 = objConsumerRecord36.timestamp();
        java.util.Optional<java.lang.Integer> intOptional42 = objConsumerRecord36.leaderEpoch();
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str33, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertNotNull(headers35);
        org.junit.Assert.assertEquals("'" + serializable37 + "' != '" + 10 + "'", serializable37, 10);
        org.junit.Assert.assertEquals("'" + obj38 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", obj38, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + 0 + "'", int39 == 0);
        org.junit.Assert.assertEquals("'" + str40 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 1, null = 1, serialized key size = 0, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = 10)" + "'", str40, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 1, null = 1, serialized key size = 0, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = 10)");
        org.junit.Assert.assertTrue("'" + long41 + "' != '" + 1L + "'", long41 == 1L);
        org.junit.Assert.assertNotNull(intOptional42);
    }

    @Test
    public void test00340() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00340");
        java.lang.Object obj7 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj7, (java.io.Serializable) (byte) 100);
        java.lang.Object obj10 = objConsumerRecord9.key();
        org.apache.kafka.common.record.TimestampType timestampType11 = objConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType19 = null;
        java.lang.Object obj23 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType19, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj23, (java.io.Serializable) 1);
        java.lang.String str26 = objConsumerRecord25.toString();
        long long27 = objConsumerRecord25.offset();
        org.apache.kafka.common.header.Headers headers28 = objConsumerRecord25.headers();
        java.lang.String str29 = objConsumerRecord25.topic();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", 0, 35L, (long) 32, timestampType11, (long) (byte) 0, 0, 1, (java.lang.Object) str29, (java.io.Serializable) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)");
        java.io.Serializable serializable32 = objConsumerRecord31.value();
        int int33 = objConsumerRecord31.serializedValueSize();
        int int34 = objConsumerRecord31.partition();
        org.junit.Assert.assertNull(obj10);
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str26, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + (-1L) + "'", long27 == (-1L));
        org.junit.Assert.assertNotNull(headers28);
        org.junit.Assert.assertEquals("'" + str29 + "' != '" + "" + "'", str29, "");
        org.junit.Assert.assertEquals("'" + serializable32 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)" + "'", serializable32, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)");
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + 1 + "'", int33 == 1);
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + 0 + "'", int34 == 0);
    }

    @Test
    public void test00341() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00341");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, org.apache.kafka.common.record.TimestampType> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, org.apache.kafka.common.record.TimestampType> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, org.apache.kafka.common.record.TimestampType>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00342() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00342");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, org.apache.kafka.common.record.TimestampType> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, org.apache.kafka.common.record.TimestampType> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, org.apache.kafka.common.record.TimestampType>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00343() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00343");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        long long15 = objConsumerRecord13.timestamp();
        long long16 = objConsumerRecord13.offset();
        java.lang.Class<?> wildcardClass17 = objConsumerRecord13.getClass();
        org.apache.kafka.common.record.TimestampType timestampType25 = null;
        java.lang.Object obj29 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType25, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj29, (java.io.Serializable) 1);
        long long32 = objConsumerRecord31.timestamp();
        long long33 = objConsumerRecord31.timestamp();
        java.lang.Class<?> wildcardClass34 = objConsumerRecord31.getClass();
        org.apache.kafka.common.record.TimestampType timestampType42 = null;
        java.lang.Object obj46 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType42, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj46, (java.io.Serializable) 1);
        long long49 = objConsumerRecord48.timestamp();
        int int50 = objConsumerRecord48.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional51 = objConsumerRecord48.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord48, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType54 = objConsumerRecord53.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.io.Serializable> annotatedElementConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)", 10, 100L, (java.lang.reflect.AnnotatedElement) wildcardClass34, (java.io.Serializable) timestampType54);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)", 35, (long) (short) 1, (java.lang.Object) wildcardClass17, (java.io.Serializable) 10);
        java.lang.Object obj57 = objConsumerRecord56.key();
        java.lang.Class<?> wildcardClass58 = objConsumerRecord56.getClass();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass17);
        org.junit.Assert.assertTrue("'" + long32 + "' != '" + 52L + "'", long32 == 52L);
        org.junit.Assert.assertTrue("'" + long33 + "' != '" + 52L + "'", long33 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass34);
        org.junit.Assert.assertTrue("'" + long49 + "' != '" + 52L + "'", long49 == 52L);
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + 100 + "'", int50 == 100);
        org.junit.Assert.assertNotNull(intOptional51);
        org.junit.Assert.assertTrue("'" + timestampType54 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType54.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(obj57);
        org.junit.Assert.assertEquals(obj57.toString(), "class org.apache.kafka.clients.consumer.ConsumerRecord");
        org.junit.Assert.assertEquals(java.lang.String.valueOf(obj57), "class org.apache.kafka.clients.consumer.ConsumerRecord");
        org.junit.Assert.assertEquals(java.util.Objects.toString(obj57), "class org.apache.kafka.clients.consumer.ConsumerRecord");
        org.junit.Assert.assertNotNull(wildcardClass58);
    }

    @Test
    public void test00344() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00344");
        org.apache.kafka.common.record.TimestampType timestampType3 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Comparable<java.lang.String>> timestampTypeConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)", 32, (long) 97, timestampType3, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = 100, leaderEpoch = null, offset = 1, null = 0, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 0.0)");
    }

    @Test
    public void test00345() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00345");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.io.Serializable> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.io.Serializable> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.io.Serializable>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00346() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00346");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers13 = objConsumerRecord10.headers();
        java.lang.String str14 = objConsumerRecord10.toString();
        long long15 = objConsumerRecord10.offset();
        long long16 = objConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional17 = objConsumerRecord10.leaderEpoch();
        java.lang.Object obj18 = objConsumerRecord10.key();
        long long19 = objConsumerRecord10.offset();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.header.Headers headers21 = objConsumerRecord10.headers();
        java.lang.String str22 = objConsumerRecord10.topic();
        java.lang.Object obj23 = objConsumerRecord10.key();
        java.lang.String str24 = objConsumerRecord10.toString();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertNotNull(intOptional17);
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertNotNull(headers21);
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertNull(obj23);
        org.junit.Assert.assertEquals("'" + str24 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str24, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
    }

    @Test
    public void test00347() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00347");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.util.Optional<java.lang.Integer>> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.util.Optional<java.lang.Integer>> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.util.Optional<java.lang.Integer>>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00348() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00348");
        org.apache.kafka.common.record.TimestampType timestampType8 = null;
        org.apache.kafka.common.record.TimestampType timestampType16 = null;
        java.lang.Object obj20 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType16, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj20, (java.io.Serializable) 1);
        java.lang.String str23 = objConsumerRecord22.toString();
        long long24 = objConsumerRecord22.offset();
        java.lang.String str25 = objConsumerRecord22.toString();
        org.apache.kafka.common.header.Headers headers26 = objConsumerRecord22.headers();
        org.apache.kafka.common.record.TimestampType timestampType31 = null;
        java.lang.Object obj35 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType31, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj35, (java.io.Serializable) 1);
        java.lang.String str38 = objConsumerRecord37.toString();
        long long39 = objConsumerRecord37.offset();
        java.lang.String str40 = objConsumerRecord37.toString();
        java.lang.String str41 = objConsumerRecord37.toString();
        org.apache.kafka.common.header.Headers headers42 = objConsumerRecord37.headers();
        org.apache.kafka.common.record.TimestampType timestampType47 = null;
        org.apache.kafka.common.record.TimestampType timestampType55 = null;
        java.lang.Object obj59 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType55, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj59, (java.io.Serializable) 1);
        java.lang.String str62 = objConsumerRecord61.toString();
        java.lang.String str63 = objConsumerRecord61.toString();
        org.apache.kafka.common.record.TimestampType timestampType69 = null;
        java.lang.Object obj73 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType69, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj73, (java.io.Serializable) 1);
        java.lang.String str76 = objConsumerRecord75.toString();
        long long77 = objConsumerRecord75.offset();
        org.apache.kafka.common.header.Headers headers78 = objConsumerRecord75.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) (byte) 100, (long) (byte) 1, (long) (short) 1, timestampType47, (java.lang.Long) 10L, (int) (short) 0, (int) (short) 1, (java.lang.Object) str63, (java.io.Serializable) 10, headers78);
        java.util.Optional<java.lang.Integer> intOptional80 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, org.apache.kafka.common.header.Headers> headersConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, org.apache.kafka.common.header.Headers>("ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", (int) (short) -1, (long) 35, (long) (short) 10, timestampType8, (java.lang.Long) 100L, (int) ' ', (int) ' ', headers26, headers42, headers78, intOptional80);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.kafka.common.header.Headers> strComparableConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.kafka.common.header.Headers>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = -1, null = 1, serialized key size = 35, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) (byte) 100, 10L, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100), partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = -1)", headers26);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str23, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + (-1L) + "'", long24 == (-1L));
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str25, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(headers26);
        org.junit.Assert.assertEquals("'" + str38 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str38, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + (-1L) + "'", long39 == (-1L));
        org.junit.Assert.assertEquals("'" + str40 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str40, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str41 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str41, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(headers42);
        org.junit.Assert.assertEquals("'" + str62 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str62, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str63 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str63, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str76 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str76, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long77 + "' != '" + (-1L) + "'", long77 == (-1L));
        org.junit.Assert.assertNotNull(headers78);
    }

    @Test
    public void test00349() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00349");
        org.apache.kafka.common.record.TimestampType timestampType15 = null;
        java.lang.Object obj19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType15, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj19, (java.io.Serializable) 1);
        java.lang.String str22 = objConsumerRecord21.toString();
        java.lang.String str23 = objConsumerRecord21.toString();
        java.lang.Class<?> wildcardClass24 = objConsumerRecord21.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type> charSequenceConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '#', (long) (short) -1, (java.lang.CharSequence) "", (java.lang.reflect.Type) wildcardClass24);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 10, (long) (byte) 100, (java.lang.Object) "", (java.io.Serializable) (short) 10);
        long long28 = objConsumerRecord27.offset();
        org.apache.kafka.common.record.TimestampType timestampType29 = objConsumerRecord27.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType37, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        org.apache.kafka.common.record.TimestampType timestampType44 = objConsumerRecord43.timestampType();
        java.lang.String str45 = objConsumerRecord43.toString();
        org.apache.kafka.common.record.TimestampType timestampType56 = null;
        java.lang.Object obj60 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord62 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType56, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj60, (java.io.Serializable) 1);
        long long63 = objConsumerRecord62.timestamp();
        int int64 = objConsumerRecord62.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional65 = objConsumerRecord62.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord62, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType68 = objConsumerRecord62.timestampType();
        java.lang.String str69 = objConsumerRecord62.topic();
        long long70 = objConsumerRecord62.timestamp();
        java.lang.Object obj71 = objConsumerRecord62.key();
        org.apache.kafka.common.header.Headers headers72 = objConsumerRecord62.headers();
        org.apache.kafka.common.record.TimestampType timestampType77 = null;
        java.lang.Object obj81 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType77, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj81, (java.io.Serializable) 1);
        org.apache.kafka.common.record.TimestampType timestampType84 = objConsumerRecord83.timestampType();
        java.util.Optional<java.lang.Integer> intOptional85 = objConsumerRecord83.leaderEpoch();
        long long86 = objConsumerRecord83.offset();
        int int87 = objConsumerRecord83.partition();
        java.lang.Class<?> wildcardClass88 = objConsumerRecord83.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.GenericDeclaration> headerIterableConsumerRecord89 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)", (int) (byte) 1, (long) (byte) 0, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers72, (java.lang.reflect.GenericDeclaration) wildcardClass88);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord90 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = -1, null = 1, serialized key size = 35, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 100, (long) (byte) 100, (long) (byte) 10, timestampType29, (long) 'a', (int) '4', 97, (java.lang.Object) str45, (java.io.Serializable) "ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)");
        int int91 = objConsumerRecord90.serializedValueSize();
        java.io.Serializable serializable92 = objConsumerRecord90.value();
        org.apache.kafka.common.header.Headers headers93 = objConsumerRecord90.headers();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str22, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str23, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass24);
        org.junit.Assert.assertTrue("'" + long28 + "' != '" + 100L + "'", long28 == 100L);
        org.junit.Assert.assertTrue("'" + timestampType29 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType29.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNull(timestampType44);
        org.junit.Assert.assertEquals("'" + str45 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)" + "'", str45, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)");
        org.junit.Assert.assertTrue("'" + long63 + "' != '" + 52L + "'", long63 == 52L);
        org.junit.Assert.assertTrue("'" + int64 + "' != '" + 100 + "'", int64 == 100);
        org.junit.Assert.assertNotNull(intOptional65);
        org.junit.Assert.assertNull(timestampType68);
        org.junit.Assert.assertEquals("'" + str69 + "' != '" + "" + "'", str69, "");
        org.junit.Assert.assertTrue("'" + long70 + "' != '" + 52L + "'", long70 == 52L);
        org.junit.Assert.assertNull(obj71);
        org.junit.Assert.assertNotNull(headers72);
        org.junit.Assert.assertNull(timestampType84);
        org.junit.Assert.assertNotNull(intOptional85);
        org.junit.Assert.assertTrue("'" + long86 + "' != '" + (-1L) + "'", long86 == (-1L));
        org.junit.Assert.assertTrue("'" + int87 + "' != '" + 10 + "'", int87 == 10);
        org.junit.Assert.assertNotNull(wildcardClass88);
        org.junit.Assert.assertTrue("'" + int91 + "' != '" + 97 + "'", int91 == 97);
        org.junit.Assert.assertEquals("'" + serializable92 + "' != '" + "ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)" + "'", serializable92, "ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)");
        org.junit.Assert.assertNotNull(headers93);
    }

    @Test
    public void test00350() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00350");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        long long19 = objConsumerRecord18.timestamp();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord18.leaderEpoch();
        long long21 = objConsumerRecord18.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType4, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord18, (java.io.Serializable) '#');
        java.io.Serializable serializable24 = objConsumerRecord23.value();
        org.apache.kafka.common.record.TimestampType timestampType25 = objConsumerRecord23.timestampType();
        java.lang.String str26 = objConsumerRecord23.toString();
        java.lang.Object obj27 = objConsumerRecord23.key();
        java.lang.Class<?> wildcardClass28 = obj27.getClass();
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertEquals("'" + serializable24 + "' != '" + '#' + "'", serializable24, '#');
        org.junit.Assert.assertNull(timestampType25);
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)" + "'", str26, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)");
        org.junit.Assert.assertNotNull(obj27);
        org.junit.Assert.assertEquals(obj27.toString(), "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals(java.lang.String.valueOf(obj27), "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals(java.util.Objects.toString(obj27), "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass28);
    }

    @Test
    public void test00351() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00351");
        java.lang.Object obj3 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj3, (java.io.Serializable) (byte) 100);
        java.lang.Object obj6 = objConsumerRecord5.key();
        org.apache.kafka.common.record.TimestampType timestampType7 = objConsumerRecord5.timestampType();
        long long8 = objConsumerRecord5.timestamp();
        int int9 = objConsumerRecord5.serializedKeySize();
        long long10 = objConsumerRecord5.offset();
        int int11 = objConsumerRecord5.partition();
        org.junit.Assert.assertNull(obj6);
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + (-1L) + "'", long8 == (-1L));
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 97L + "'", long10 == 97L);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 97 + "'", int11 == 97);
    }

    @Test
    public void test00352() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00352");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        long long13 = objConsumerRecord10.checksum();
        java.io.Serializable serializable14 = objConsumerRecord10.value();
        org.apache.kafka.common.header.Headers headers15 = objConsumerRecord10.headers();
        long long16 = objConsumerRecord10.checksum();
        java.lang.String str17 = objConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + 1 + "'", serializable14, 1);
        org.junit.Assert.assertNotNull(headers15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str17, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
    }

    @Test
    public void test00353() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00353");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        long long15 = objConsumerRecord13.timestamp();
        int int16 = objConsumerRecord13.serializedKeySize();
        java.lang.Object obj17 = objConsumerRecord13.key();
        org.apache.kafka.common.header.Headers headers18 = objConsumerRecord13.headers();
        int int19 = objConsumerRecord13.partition();
        int int20 = objConsumerRecord13.serializedKeySize();
        org.apache.kafka.common.header.Headers headers21 = objConsumerRecord13.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.String> headerIterableConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.String>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 1, NoTimestampType = 1, serialized key size = 0, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = NoTimestampType)", 35, 1L, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers21, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)");
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertNull(obj17);
        org.junit.Assert.assertNotNull(headers18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 10 + "'", int20 == 10);
        org.junit.Assert.assertNotNull(headers21);
    }

    @Test
    public void test00354() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00354");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        java.lang.String str19 = objConsumerRecord18.toString();
        java.lang.String str20 = objConsumerRecord18.toString();
        long long21 = objConsumerRecord18.offset();
        java.lang.String str22 = objConsumerRecord18.topic();
        org.apache.kafka.common.record.TimestampType timestampType30 = null;
        java.lang.Object obj34 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType30, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj34, (java.io.Serializable) 1);
        long long37 = objConsumerRecord36.timestamp();
        java.util.Optional<java.lang.Integer> intOptional38 = objConsumerRecord36.leaderEpoch();
        long long39 = objConsumerRecord36.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType44 = null;
        java.lang.Object obj48 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType44, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj48, (java.io.Serializable) 1);
        java.lang.String str51 = objConsumerRecord50.toString();
        java.lang.String str52 = objConsumerRecord50.toString();
        java.lang.Class<?> wildcardClass53 = objConsumerRecord50.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (short) 10, (java.lang.Object) objConsumerRecord36, (java.io.Serializable) wildcardClass53);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) 100, (long) (byte) 0, (long) ' ', timestampType4, 1L, 1, (int) ' ', (java.lang.Object) objConsumerRecord18, (java.io.Serializable) (short) 10);
        long long56 = objConsumerRecord55.offset();
        java.lang.Class<?> wildcardClass57 = objConsumerRecord55.getClass();
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + long37 + "' != '" + 52L + "'", long37 == 52L);
        org.junit.Assert.assertNotNull(intOptional38);
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + 52L + "'", long39 == 52L);
        org.junit.Assert.assertEquals("'" + str51 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str51, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str52 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str52, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass53);
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + 0L + "'", long56 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass57);
    }

    @Test
    public void test00355() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00355");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.kafka.common.record.TimestampType timestampType16 = null;
        java.lang.Object obj20 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType16, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj20, (java.io.Serializable) 1);
        long long23 = objConsumerRecord22.timestamp();
        java.util.Optional<java.lang.Integer> intOptional24 = objConsumerRecord22.leaderEpoch();
        long long25 = objConsumerRecord22.offset();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> charSequenceConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>("", (int) '4', (long) 'a', 0L, timestampType7, 10L, (-1), (int) (short) 0, (java.lang.CharSequence) "hi!", objConsumerRecord22);
        org.apache.kafka.common.record.TimestampType timestampType31 = null;
        org.apache.kafka.common.record.TimestampType timestampType39 = null;
        org.apache.kafka.common.record.TimestampType timestampType48 = null;
        java.lang.Object obj52 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType48, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj52, (java.io.Serializable) 1);
        long long55 = objConsumerRecord54.timestamp();
        java.util.Optional<java.lang.Integer> intOptional56 = objConsumerRecord54.leaderEpoch();
        long long57 = objConsumerRecord54.offset();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> charSequenceConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>("", (int) '4', (long) 'a', 0L, timestampType39, 10L, (-1), (int) (short) 0, (java.lang.CharSequence) "hi!", objConsumerRecord54);
        java.lang.Class<?> wildcardClass59 = charSequenceConsumerRecord58.getClass();
        org.apache.kafka.common.record.TimestampType timestampType64 = null;
        java.lang.Object obj68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType64, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj68, (java.io.Serializable) 1);
        long long71 = objConsumerRecord70.timestamp();
        java.lang.Object obj72 = objConsumerRecord70.key();
        long long73 = objConsumerRecord70.checksum();
        java.lang.Class<?> wildcardClass74 = objConsumerRecord70.getClass();
        org.apache.kafka.common.record.TimestampType timestampType79 = null;
        java.lang.Object obj86 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj86, (java.io.Serializable) (byte) 100);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord90 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (byte) 100, (long) (byte) 10, (long) 0, timestampType79, (-1L), 1, (int) (short) 1, (java.lang.Object) 'a', (java.io.Serializable) (short) 1);
        org.apache.kafka.common.header.Headers headers91 = objConsumerRecord90.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.reflect.AnnotatedElement> genericDeclarationConsumerRecord92 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.reflect.AnnotatedElement>("hi!", 10, (long) (-1), 1L, timestampType31, (java.lang.Long) 52L, (int) (byte) 1, 10, (java.lang.reflect.GenericDeclaration) wildcardClass59, (java.lang.reflect.AnnotatedElement) wildcardClass74, headers91);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord93 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 0, leaderEpoch = null, offset = 1, NoTimestampType = 97, serialized key size = 35, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)", (int) '4', 0L, (java.lang.Object) 10L, (java.io.Serializable) (byte) 1);
        long long94 = objConsumerRecord93.offset();
        long long95 = objConsumerRecord93.offset();
        org.junit.Assert.assertTrue("'" + long23 + "' != '" + 52L + "'", long23 == 52L);
        org.junit.Assert.assertNotNull(intOptional24);
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + (-1L) + "'", long25 == (-1L));
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + 52L + "'", long55 == 52L);
        org.junit.Assert.assertNotNull(intOptional56);
        org.junit.Assert.assertTrue("'" + long57 + "' != '" + (-1L) + "'", long57 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass59);
        org.junit.Assert.assertTrue("'" + long71 + "' != '" + 52L + "'", long71 == 52L);
        org.junit.Assert.assertNull(obj72);
        org.junit.Assert.assertTrue("'" + long73 + "' != '" + 0L + "'", long73 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass74);
        org.junit.Assert.assertNotNull(headers91);
        org.junit.Assert.assertTrue("'" + long94 + "' != '" + 0L + "'", long94 == 0L);
        org.junit.Assert.assertTrue("'" + long95 + "' != '" + 0L + "'", long95 == 0L);
    }

    @Test
    public void test00356() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00356");
        java.lang.Object obj6 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj6, (java.io.Serializable) (byte) 100);
        org.apache.kafka.common.record.TimestampType timestampType13 = null;
        java.lang.Object obj17 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType13, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj17, (java.io.Serializable) 1);
        long long20 = objConsumerRecord19.timestamp();
        java.lang.Object obj21 = objConsumerRecord19.key();
        long long22 = objConsumerRecord19.checksum();
        java.lang.Class<?> wildcardClass23 = objConsumerRecord19.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) 1, (long) '#', obj6, (java.io.Serializable) wildcardClass23);
        java.lang.Object obj25 = objConsumerRecord24.key();
        int int26 = objConsumerRecord24.partition();
        java.lang.String str27 = objConsumerRecord24.topic();
        int int28 = objConsumerRecord24.serializedValueSize();
        long long29 = objConsumerRecord24.offset();
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 52L + "'", long20 == 52L);
        org.junit.Assert.assertNull(obj21);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 0L + "'", long22 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass23);
        org.junit.Assert.assertNull(obj25);
        org.junit.Assert.assertTrue("'" + int26 + "' != '" + 1 + "'", int26 == 1);
        org.junit.Assert.assertEquals("'" + str27 + "' != '" + "" + "'", str27, "");
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + (-1) + "'", int28 == (-1));
        org.junit.Assert.assertTrue("'" + long29 + "' != '" + 35L + "'", long29 == 35L);
    }

    @Test
    public void test00357() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00357");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.lang.reflect.Type> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.reflect.Type> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.reflect.Type>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00358() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00358");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, java.lang.Object> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.Object> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.lang.Object>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00359() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00359");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        java.lang.String str13 = objConsumerRecord10.toString();
        org.apache.kafka.common.header.Headers headers14 = objConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType15 = objConsumerRecord10.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord10.timestampType();
        int int17 = objConsumerRecord10.partition();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(headers14);
        org.junit.Assert.assertNull(timestampType15);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
    }

    @Test
    public void test00360() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00360");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, org.apache.kafka.common.header.Headers> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, org.apache.kafka.common.header.Headers> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, org.apache.kafka.common.header.Headers>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00361() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00361");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Comparable<java.lang.String>, org.apache.kafka.common.record.TimestampType> strComparableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, org.apache.kafka.common.record.TimestampType> strComparableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, org.apache.kafka.common.record.TimestampType>(strComparableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00362() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00362");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        java.lang.String str14 = objConsumerRecord13.toString();
        long long15 = objConsumerRecord13.timestamp();
        org.apache.kafka.common.header.Headers headers16 = objConsumerRecord13.headers();
        int int17 = objConsumerRecord13.partition();
        java.lang.Class<?> wildcardClass18 = objConsumerRecord13.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 0, leaderEpoch = null, offset = 1, NoTimestampType = 97, serialized key size = 35, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)", 0, 52L, (java.lang.Object) objConsumerRecord13, (java.io.Serializable) (byte) 100);
        java.io.Serializable serializable21 = objConsumerRecord20.value();
        java.lang.Class<?> wildcardClass22 = objConsumerRecord20.getClass();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNotNull(wildcardClass18);
        org.junit.Assert.assertEquals("'" + serializable21 + "' != '" + (byte) 100 + "'", serializable21, (byte) 100);
        org.junit.Assert.assertNotNull(wildcardClass22);
    }

    @Test
    public void test00363() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00363");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        int int15 = objConsumerRecord13.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional16 = objConsumerRecord13.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord13, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType19 = objConsumerRecord18.timestampType();
        long long20 = objConsumerRecord18.offset();
        long long21 = objConsumerRecord18.timestamp();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 100L + "'", long20 == 100L);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
    }

    @Test
    public void test00364() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00364");
        java.lang.Object obj6 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj6, (java.io.Serializable) (byte) 100);
        org.apache.kafka.common.record.TimestampType timestampType13 = null;
        java.lang.Object obj17 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType13, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj17, (java.io.Serializable) 1);
        long long20 = objConsumerRecord19.timestamp();
        java.lang.Object obj21 = objConsumerRecord19.key();
        long long22 = objConsumerRecord19.checksum();
        java.lang.Class<?> wildcardClass23 = objConsumerRecord19.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) 1, (long) '#', obj6, (java.io.Serializable) wildcardClass23);
        java.lang.Object obj25 = objConsumerRecord24.key();
        long long26 = objConsumerRecord24.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType27 = objConsumerRecord24.timestampType();
        java.util.Optional<java.lang.Integer> intOptional28 = objConsumerRecord24.leaderEpoch();
        int int29 = objConsumerRecord24.partition();
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 52L + "'", long20 == 52L);
        org.junit.Assert.assertNull(obj21);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 0L + "'", long22 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass23);
        org.junit.Assert.assertNull(obj25);
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + (-1L) + "'", long26 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType27 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType27.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(intOptional28);
        org.junit.Assert.assertTrue("'" + int29 + "' != '" + 1 + "'", int29 == 1);
    }

    @Test
    public void test00365() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00365");
        java.lang.Object obj15 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj15, (java.io.Serializable) (byte) 100);
        java.lang.Object obj18 = objConsumerRecord17.key();
        java.lang.String str19 = objConsumerRecord17.toString();
        org.apache.kafka.common.record.TimestampType timestampType20 = objConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType28 = null;
        java.lang.Object obj32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType28, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj32, (java.io.Serializable) 1);
        long long35 = objConsumerRecord34.offset();
        long long36 = objConsumerRecord34.checksum();
        org.apache.kafka.common.header.Headers headers37 = objConsumerRecord34.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), (long) (short) 1, (long) 0, timestampType20, 10L, 97, (int) '4', (java.lang.Object) headers37, (java.io.Serializable) 0.0d);
        org.apache.kafka.common.record.TimestampType timestampType47 = null;
        java.lang.Object obj51 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType47, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj51, (java.io.Serializable) 1);
        java.lang.String str54 = objConsumerRecord53.toString();
        java.util.Optional<java.lang.Integer> intOptional55 = objConsumerRecord53.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional56 = objConsumerRecord53.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) ' ', (long) (byte) 1, 0L, timestampType20, (-1L), (int) (byte) -1, (int) (short) 100, (java.lang.Object) objConsumerRecord53, (java.io.Serializable) 100.0f);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord63 = null;
        org.apache.kafka.common.header.Headers headers64 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> strConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) (byte) 1, 52L, (long) (byte) 10, timestampType20, (java.lang.Long) 0L, (int) '4', (int) (short) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", objConsumerRecord63, headers64);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str19, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + (-1L) + "'", long35 == (-1L));
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + 0L + "'", long36 == 0L);
        org.junit.Assert.assertNotNull(headers37);
        org.junit.Assert.assertEquals("'" + str54 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str54, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional55);
        org.junit.Assert.assertNotNull(intOptional56);
    }

    @Test
    public void test00366() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00366");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        long long12 = objConsumerRecord10.timestamp();
        int int13 = objConsumerRecord10.serializedKeySize();
        long long14 = objConsumerRecord10.timestamp();
        long long15 = objConsumerRecord10.offset();
        long long16 = objConsumerRecord10.offset();
        java.util.Optional<java.lang.Integer> intOptional17 = objConsumerRecord10.leaderEpoch();
        java.lang.Object obj18 = objConsumerRecord10.key();
        int int19 = objConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertNotNull(intOptional17);
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
    }

    @Test
    public void test00367() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00367");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        long long19 = objConsumerRecord18.timestamp();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord18.leaderEpoch();
        long long21 = objConsumerRecord18.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType4, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord18, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional24 = objConsumerRecord18.leaderEpoch();
        java.lang.String str25 = objConsumerRecord18.topic();
        org.apache.kafka.common.record.TimestampType timestampType26 = objConsumerRecord18.timestampType();
        // The following exception was thrown during execution in test generation
        try {
            java.lang.Class<?> wildcardClass27 = timestampType26.getClass();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertNotNull(intOptional24);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "" + "'", str25, "");
        org.junit.Assert.assertNull(timestampType26);
    }

    @Test
    public void test00368() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00368");
        org.apache.kafka.common.record.TimestampType timestampType10 = null;
        java.lang.Object obj14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType10, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj14, (java.io.Serializable) 1);
        long long17 = objConsumerRecord16.timestamp();
        int int18 = objConsumerRecord16.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional19 = objConsumerRecord16.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord16, (java.io.Serializable) false);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) 0, (long) 97, (java.lang.Object) false, (java.io.Serializable) (short) 100);
        org.apache.kafka.common.header.Headers headers24 = objConsumerRecord23.headers();
        long long25 = objConsumerRecord23.timestamp();
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 100 + "'", int18 == 100);
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertNotNull(headers24);
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + (-1L) + "'", long25 == (-1L));
    }

    @Test
    public void test00369() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00369");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        java.lang.String str14 = objConsumerRecord13.topic();
        java.io.Serializable serializable15 = objConsumerRecord13.value();
        int int16 = objConsumerRecord13.partition();
        int int17 = objConsumerRecord13.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType25 = null;
        java.lang.Object obj29 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType25, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj29, (java.io.Serializable) 1);
        long long32 = objConsumerRecord31.timestamp();
        java.util.Optional<java.lang.Integer> intOptional33 = objConsumerRecord31.leaderEpoch();
        java.lang.Class<?> wildcardClass34 = objConsumerRecord31.getClass();
        org.apache.kafka.common.record.TimestampType timestampType39 = null;
        org.apache.kafka.common.record.TimestampType timestampType47 = null;
        org.apache.kafka.common.record.TimestampType timestampType55 = null;
        java.lang.Object obj59 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType55, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj59, (java.io.Serializable) 1);
        long long62 = objConsumerRecord61.timestamp();
        java.util.Optional<java.lang.Integer> intOptional63 = objConsumerRecord61.leaderEpoch();
        long long64 = objConsumerRecord61.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord66 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType47, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord61, (java.io.Serializable) '#');
        java.lang.Class<?> wildcardClass67 = objConsumerRecord66.getClass();
        org.apache.kafka.common.record.TimestampType timestampType72 = null;
        java.lang.Object obj76 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType72, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj76, (java.io.Serializable) 1);
        java.lang.String str79 = objConsumerRecord78.toString();
        java.lang.String str80 = objConsumerRecord78.toString();
        long long81 = objConsumerRecord78.offset();
        java.lang.String str82 = objConsumerRecord78.topic();
        java.lang.Class<?> wildcardClass83 = objConsumerRecord78.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.AnnotatedElement> typeConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.Type, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) '4', (long) '4', (long) '#', timestampType39, 0L, (int) (byte) 100, (int) ' ', (java.lang.reflect.Type) wildcardClass67, (java.lang.reflect.AnnotatedElement) wildcardClass83);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)", (int) (byte) 100, (long) 'a', (java.lang.Object) wildcardClass34, (java.io.Serializable) timestampType39);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (byte) 0, (long) (byte) 1, (java.lang.Object) int17, (java.io.Serializable) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)");
        java.lang.String str87 = objConsumerRecord86.toString();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertEquals("'" + serializable15 + "' != '" + 1 + "'", serializable15, 1);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long32 + "' != '" + 52L + "'", long32 == 52L);
        org.junit.Assert.assertNotNull(intOptional33);
        org.junit.Assert.assertNotNull(wildcardClass34);
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + 52L + "'", long62 == 52L);
        org.junit.Assert.assertNotNull(intOptional63);
        org.junit.Assert.assertTrue("'" + long64 + "' != '" + 52L + "'", long64 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass67);
        org.junit.Assert.assertEquals("'" + str79 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str79, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str80, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long81 + "' != '" + (-1L) + "'", long81 == (-1L));
        org.junit.Assert.assertEquals("'" + str82 + "' != '" + "" + "'", str82, "");
        org.junit.Assert.assertNotNull(wildcardClass83);
        org.junit.Assert.assertEquals("'" + str87 + "' != '" + "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 10, value = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10))" + "'", str87, "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 10, value = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10))");
    }

    @Test
    public void test00370() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00370");
        java.lang.Object obj6 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj6, (java.io.Serializable) (byte) 100);
        java.lang.Object obj9 = objConsumerRecord8.key();
        int int10 = objConsumerRecord8.partition();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 1, NoTimestampType = 1, serialized key size = 0, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = NoTimestampType)", (int) ' ', (long) '#', (java.lang.Object) int10, (java.io.Serializable) "ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)");
        int int13 = objConsumerRecord12.partition();
        int int14 = objConsumerRecord12.partition();
        org.junit.Assert.assertNull(obj9);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 97 + "'", int10 == 97);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 32 + "'", int13 == 32);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 32 + "'", int14 == 32);
    }

    @Test
    public void test00371() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00371");
        java.lang.Object obj3 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj3, (java.io.Serializable) (byte) 100);
        java.lang.Object obj6 = objConsumerRecord5.key();
        org.apache.kafka.common.record.TimestampType timestampType7 = objConsumerRecord5.timestampType();
        long long8 = objConsumerRecord5.checksum();
        org.junit.Assert.assertNull(obj6);
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + (-1L) + "'", long8 == (-1L));
    }

    @Test
    public void test00372() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00372");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        java.lang.String str14 = objConsumerRecord13.toString();
        long long15 = objConsumerRecord13.offset();
        org.apache.kafka.common.header.Headers headers16 = objConsumerRecord13.headers();
        java.lang.String str17 = objConsumerRecord13.toString();
        long long18 = objConsumerRecord13.offset();
        long long19 = objConsumerRecord13.checksum();
        int int20 = objConsumerRecord13.partition();
        java.io.Serializable serializable21 = objConsumerRecord13.value();
        java.util.Optional<java.lang.Integer> intOptional22 = objConsumerRecord13.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 35, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) (short) 1, (long) (short) 100, (java.lang.Object) intOptional22, (java.io.Serializable) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        java.lang.Class<?> wildcardClass25 = intOptional22.getClass();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str17, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 10 + "'", int20 == 10);
        org.junit.Assert.assertEquals("'" + serializable21 + "' != '" + 1 + "'", serializable21, 1);
        org.junit.Assert.assertNotNull(intOptional22);
        org.junit.Assert.assertNotNull(wildcardClass25);
    }

    @Test
    public void test00373() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00373");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, org.apache.kafka.common.header.Headers> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, org.apache.kafka.common.header.Headers> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, org.apache.kafka.common.header.Headers>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00374() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00374");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        org.apache.kafka.common.record.TimestampType timestampType11 = objConsumerRecord10.timestampType();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        java.io.Serializable serializable13 = objConsumerRecord10.value();
        java.lang.String str14 = objConsumerRecord10.topic();
        org.junit.Assert.assertNull(timestampType11);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertEquals("'" + serializable13 + "' != '" + 1 + "'", serializable13, 1);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
    }

    @Test
    public void test00375() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00375");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.offset();
        long long12 = objConsumerRecord10.timestamp();
        int int13 = objConsumerRecord10.partition();
        java.lang.Object obj14 = objConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
        org.junit.Assert.assertNull(obj14);
    }

    @Test
    public void test00376() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00376");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        int int14 = objConsumerRecord10.partition();
        int int15 = objConsumerRecord10.serializedValueSize();
        java.io.Serializable serializable16 = objConsumerRecord10.value();
        java.util.Optional<java.lang.Integer> intOptional17 = objConsumerRecord10.leaderEpoch();
        java.lang.Class<?> wildcardClass18 = objConsumerRecord10.getClass();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertEquals("'" + serializable16 + "' != '" + 1 + "'", serializable16, 1);
        org.junit.Assert.assertNotNull(intOptional17);
        org.junit.Assert.assertNotNull(wildcardClass18);
    }

    @Test
    public void test00377() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00377");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        long long13 = objConsumerRecord10.timestamp();
        java.io.Serializable serializable14 = objConsumerRecord10.value();
        long long15 = objConsumerRecord10.offset();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord10.timestampType();
        int int17 = objConsumerRecord10.serializedValueSize();
        long long18 = objConsumerRecord10.timestamp();
        long long19 = objConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + 1 + "'", serializable14, 1);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 100 + "'", int17 == 100);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 52L + "'", long18 == 52L);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
    }

    @Test
    public void test00378() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00378");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.String> strComparableConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.String>("hi!", 0, (long) (byte) 100, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = 100, leaderEpoch = null, offset = 1, null = 0, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 0.0)", "hi!");
    }

    @Test
    public void test00379() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00379");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.common.record.TimestampType timestampType14 = null;
        org.apache.kafka.common.record.TimestampType timestampType22 = null;
        org.apache.kafka.common.record.TimestampType timestampType31 = null;
        java.lang.Object obj35 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType31, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj35, (java.io.Serializable) 1);
        long long38 = objConsumerRecord37.timestamp();
        java.util.Optional<java.lang.Integer> intOptional39 = objConsumerRecord37.leaderEpoch();
        long long40 = objConsumerRecord37.offset();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> charSequenceConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>("", (int) '4', (long) 'a', 0L, timestampType22, 10L, (-1), (int) (short) 0, (java.lang.CharSequence) "hi!", objConsumerRecord37);
        java.lang.Class<?> wildcardClass42 = charSequenceConsumerRecord41.getClass();
        org.apache.kafka.common.record.TimestampType timestampType47 = null;
        java.lang.Object obj51 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType47, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj51, (java.io.Serializable) 1);
        long long54 = objConsumerRecord53.timestamp();
        java.lang.Object obj55 = objConsumerRecord53.key();
        long long56 = objConsumerRecord53.checksum();
        java.lang.Class<?> wildcardClass57 = objConsumerRecord53.getClass();
        org.apache.kafka.common.record.TimestampType timestampType62 = null;
        java.lang.Object obj69 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj69, (java.io.Serializable) (byte) 100);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (byte) 100, (long) (byte) 10, (long) 0, timestampType62, (-1L), 1, (int) (short) 1, (java.lang.Object) 'a', (java.io.Serializable) (short) 1);
        org.apache.kafka.common.header.Headers headers74 = objConsumerRecord73.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.reflect.AnnotatedElement> genericDeclarationConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.reflect.AnnotatedElement>("hi!", 10, (long) (-1), 1L, timestampType14, (java.lang.Long) 52L, (int) (byte) 1, 10, (java.lang.reflect.GenericDeclaration) wildcardClass42, (java.lang.reflect.AnnotatedElement) wildcardClass57, headers74);
        org.apache.kafka.common.record.TimestampType timestampType80 = null;
        java.lang.Object obj84 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType80, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj84, (java.io.Serializable) 1);
        java.lang.String str87 = objConsumerRecord86.toString();
        java.util.Optional<java.lang.Integer> intOptional88 = objConsumerRecord86.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord89 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), (long) 'a', (long) 100, timestampType4, (java.lang.Long) 100L, (int) (byte) 10, (int) (byte) 1, obj8, (java.io.Serializable) 1, headers74, intOptional88);
        java.lang.Class<?> wildcardClass90 = objConsumerRecord89.getClass();
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + 52L + "'", long38 == 52L);
        org.junit.Assert.assertNotNull(intOptional39);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass42);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + 52L + "'", long54 == 52L);
        org.junit.Assert.assertNull(obj55);
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + 0L + "'", long56 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass57);
        org.junit.Assert.assertNotNull(headers74);
        org.junit.Assert.assertEquals("'" + str87 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str87, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional88);
        org.junit.Assert.assertNotNull(wildcardClass90);
    }

    @Test
    public void test00380() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00380");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.kafka.common.record.TimestampType timestampType15 = null;
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        java.lang.Object obj27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType23, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj27, (java.io.Serializable) 1);
        long long30 = objConsumerRecord29.timestamp();
        java.lang.Object obj31 = objConsumerRecord29.key();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.io.Serializable> objConsumerRecordConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.io.Serializable>("", 100, (long) '#', (long) (byte) 0, timestampType15, (long) (-1), (int) (byte) 0, (int) (short) 100, objConsumerRecord29, (java.io.Serializable) (-1.0d));
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) (byte) -1, (long) 1, (long) (byte) 0, timestampType7, (long) '4', (int) (byte) 0, (int) 'a', (java.lang.Object) objConsumerRecordConsumerRecord33, (java.io.Serializable) 10.0f);
        java.lang.Class<?> wildcardClass36 = objConsumerRecord35.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.CharSequence> genericDeclarationConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.CharSequence>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", 0, (long) 0, (java.lang.reflect.GenericDeclaration) wildcardClass36, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100), partition = 0, leaderEpoch = null, offset = 100, null = 52, serialized key size = 10, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = true)");
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + 52L + "'", long30 == 52L);
        org.junit.Assert.assertNull(obj31);
        org.junit.Assert.assertNotNull(wildcardClass36);
    }

    @Test
    public void test00381() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00381");
        java.lang.Object obj3 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj3, (java.io.Serializable) (byte) 100);
        long long6 = objConsumerRecord5.timestamp();
        int int7 = objConsumerRecord5.serializedValueSize();
        java.io.Serializable serializable8 = objConsumerRecord5.value();
        long long9 = objConsumerRecord5.timestamp();
        java.lang.String str10 = objConsumerRecord5.topic();
        int int11 = objConsumerRecord5.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertEquals("'" + serializable8 + "' != '" + (byte) 100 + "'", serializable8, (byte) 100);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "hi!" + "'", str10, "hi!");
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
    }

    @Test
    public void test00382() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00382");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        long long15 = objConsumerRecord13.timestamp();
        int int16 = objConsumerRecord13.serializedKeySize();
        java.lang.String str17 = objConsumerRecord13.topic();
        java.lang.Object obj28 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj28, (java.io.Serializable) (byte) 100);
        java.lang.Object obj31 = objConsumerRecord30.key();
        java.lang.String str32 = objConsumerRecord30.toString();
        org.apache.kafka.common.record.TimestampType timestampType33 = objConsumerRecord30.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (int) (short) -1, (long) (short) 10, (java.lang.Object) timestampType33, (java.io.Serializable) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        java.lang.Object obj39 = null;
        org.apache.kafka.common.record.TimestampType timestampType54 = null;
        java.lang.Object obj58 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType54, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj58, (java.io.Serializable) 1);
        long long61 = objConsumerRecord60.timestamp();
        int int62 = objConsumerRecord60.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional63 = objConsumerRecord60.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord60, (java.io.Serializable) false);
        java.lang.String str66 = objConsumerRecord65.toString();
        int int67 = objConsumerRecord65.partition();
        java.io.Serializable serializable68 = objConsumerRecord65.value();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 1, NoTimestampType = 1, serialized key size = 0, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = NoTimestampType)", (-1), (long) (byte) 0, (java.lang.Object) serializable68, (java.io.Serializable) 100L);
        org.apache.kafka.common.record.TimestampType timestampType71 = objConsumerRecord70.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType80 = null;
        java.lang.Object obj84 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType80, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj84, (java.io.Serializable) 1);
        long long87 = objConsumerRecord86.timestamp();
        java.util.Optional<java.lang.Integer> intOptional88 = objConsumerRecord86.leaderEpoch();
        long long89 = objConsumerRecord86.checksum();
        java.lang.String str90 = objConsumerRecord86.topic();
        java.io.Serializable serializable91 = objConsumerRecord86.value();
        org.apache.kafka.common.record.TimestampType timestampType92 = objConsumerRecord86.timestampType();
        int int93 = objConsumerRecord86.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional94 = objConsumerRecord86.leaderEpoch();
        int int95 = objConsumerRecord86.serializedKeySize();
        org.apache.kafka.common.header.Headers headers96 = objConsumerRecord86.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, org.apache.kafka.common.header.Headers> serializableConsumerRecord97 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, org.apache.kafka.common.header.Headers>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 100, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = class org.apache.kafka.clients.consumer.ConsumerRecord, value = null)", 0, (long) (short) -1, 100L, timestampType71, (long) (-1), (int) (byte) 1, (int) '#', (java.io.Serializable) 1L, headers96);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", 0, 100L, (long) 0, timestampType33, 97L, (int) (short) 100, (-1), obj39, (java.io.Serializable) timestampType71);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord99 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 35, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 100, 52L, (java.lang.Object) str17, (java.io.Serializable) timestampType33);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertNull(obj31);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str32, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType33 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType33.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long61 + "' != '" + 52L + "'", long61 == 52L);
        org.junit.Assert.assertTrue("'" + int62 + "' != '" + 100 + "'", int62 == 100);
        org.junit.Assert.assertNotNull(intOptional63);
        org.junit.Assert.assertEquals("'" + str66 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)" + "'", str66, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)");
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + 100 + "'", int67 == 100);
        org.junit.Assert.assertEquals("'" + serializable68 + "' != '" + false + "'", serializable68, false);
        org.junit.Assert.assertTrue("'" + timestampType71 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType71.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long87 + "' != '" + 52L + "'", long87 == 52L);
        org.junit.Assert.assertNotNull(intOptional88);
        org.junit.Assert.assertTrue("'" + long89 + "' != '" + 0L + "'", long89 == 0L);
        org.junit.Assert.assertEquals("'" + str90 + "' != '" + "" + "'", str90, "");
        org.junit.Assert.assertEquals("'" + serializable91 + "' != '" + 1 + "'", serializable91, 1);
        org.junit.Assert.assertNull(timestampType92);
        org.junit.Assert.assertTrue("'" + int93 + "' != '" + 100 + "'", int93 == 100);
        org.junit.Assert.assertNotNull(intOptional94);
        org.junit.Assert.assertTrue("'" + int95 + "' != '" + 10 + "'", int95 == 10);
        org.junit.Assert.assertNotNull(headers96);
    }

    @Test
    public void test00383() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00383");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        int int13 = objConsumerRecord10.serializedKeySize();
        long long14 = objConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers15 = objConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord10.timestampType();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertNotNull(headers15);
        org.junit.Assert.assertNull(timestampType16);
    }

    @Test
    public void test00384() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00384");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, java.lang.String> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.String> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.lang.String>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00385() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00385");
        java.lang.Object obj6 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj6, (java.io.Serializable) (byte) 100);
        org.apache.kafka.common.record.TimestampType timestampType13 = null;
        java.lang.Object obj17 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType13, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj17, (java.io.Serializable) 1);
        long long20 = objConsumerRecord19.timestamp();
        java.lang.Object obj21 = objConsumerRecord19.key();
        long long22 = objConsumerRecord19.checksum();
        java.lang.Class<?> wildcardClass23 = objConsumerRecord19.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) 1, (long) '#', obj6, (java.io.Serializable) wildcardClass23);
        java.lang.Object obj25 = objConsumerRecord24.key();
        long long26 = objConsumerRecord24.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType27 = objConsumerRecord24.timestampType();
        java.lang.Object obj28 = objConsumerRecord24.key();
        java.io.Serializable serializable29 = objConsumerRecord24.value();
        int int30 = objConsumerRecord24.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional31 = objConsumerRecord24.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 52L + "'", long20 == 52L);
        org.junit.Assert.assertNull(obj21);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 0L + "'", long22 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass23);
        org.junit.Assert.assertNull(obj25);
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + (-1L) + "'", long26 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType27 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType27.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNull(obj28);
        org.junit.Assert.assertNotNull(serializable29);
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertNotNull(intOptional31);
    }

    @Test
    public void test00386() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00386");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00387() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00387");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        org.apache.kafka.common.record.TimestampType timestampType20 = null;
        java.lang.Object obj24 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType20, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj24, (java.io.Serializable) 1);
        long long27 = objConsumerRecord26.timestamp();
        java.lang.Object obj28 = objConsumerRecord26.key();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.io.Serializable> objConsumerRecordConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.io.Serializable>("", 100, (long) '#', (long) (byte) 0, timestampType12, (long) (-1), (int) (byte) 0, (int) (short) 100, objConsumerRecord26, (java.io.Serializable) (-1.0d));
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) (byte) -1, (long) 1, (long) (byte) 0, timestampType4, (long) '4', (int) (byte) 0, (int) 'a', (java.lang.Object) objConsumerRecordConsumerRecord30, (java.io.Serializable) 10.0f);
        java.lang.String str33 = objConsumerRecord32.topic();
        org.apache.kafka.common.record.TimestampType timestampType34 = objConsumerRecord32.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType35 = objConsumerRecord32.timestampType();
        int int36 = objConsumerRecord32.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + 52L + "'", long27 == 52L);
        org.junit.Assert.assertNull(obj28);
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)" + "'", str33, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)");
        org.junit.Assert.assertNull(timestampType34);
        org.junit.Assert.assertNull(timestampType35);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + 97 + "'", int36 == 97);
    }

    @Test
    public void test00388() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00388");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.topic();
        java.io.Serializable serializable12 = objConsumerRecord10.value();
        int int13 = objConsumerRecord10.serializedValueSize();
        java.lang.String str14 = objConsumerRecord10.toString();
        java.io.Serializable serializable15 = objConsumerRecord10.value();
        java.lang.Class<?> wildcardClass16 = serializable15.getClass();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertEquals("'" + serializable12 + "' != '" + 1 + "'", serializable12, 1);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 100 + "'", int13 == 100);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + serializable15 + "' != '" + 1 + "'", serializable15, 1);
        org.junit.Assert.assertNotNull(wildcardClass16);
    }

    @Test
    public void test00389() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00389");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        long long12 = objConsumerRecord10.timestamp();
        int int13 = objConsumerRecord10.serializedKeySize();
        long long14 = objConsumerRecord10.timestamp();
        long long15 = objConsumerRecord10.offset();
        long long16 = objConsumerRecord10.offset();
        java.util.Optional<java.lang.Integer> intOptional17 = objConsumerRecord10.leaderEpoch();
        java.lang.String str18 = objConsumerRecord10.toString();
        int int19 = objConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType20 = objConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertNotNull(intOptional17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str18, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertNull(timestampType20);
    }

    @Test
    public void test00390() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00390");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.lang.String str12 = objConsumerRecord10.toString();
        long long13 = objConsumerRecord10.offset();
        java.lang.String str14 = objConsumerRecord10.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = objConsumerRecord10.timestampType();
        int int16 = objConsumerRecord10.serializedValueSize();
        java.lang.String str17 = objConsumerRecord10.toString();
        java.io.Serializable serializable18 = objConsumerRecord10.value();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str12, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertNull(timestampType15);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 100 + "'", int16 == 100);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str17, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + serializable18 + "' != '" + 1 + "'", serializable18, 1);
    }

    @Test
    public void test00391() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00391");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType4, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        org.apache.kafka.common.record.TimestampType timestampType11 = objConsumerRecord10.timestampType();
        java.lang.String str12 = objConsumerRecord10.toString();
        long long13 = objConsumerRecord10.offset();
        java.io.Serializable serializable14 = objConsumerRecord10.value();
        int int15 = objConsumerRecord10.partition();
        long long16 = objConsumerRecord10.offset();
        java.lang.String str17 = objConsumerRecord10.toString();
        long long18 = objConsumerRecord10.offset();
        java.lang.String str19 = objConsumerRecord10.topic();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord10.leaderEpoch();
        int int21 = objConsumerRecord10.partition();
        org.junit.Assert.assertNull(timestampType11);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)" + "'", str12, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 100L + "'", long13 == 100L);
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + 10 + "'", serializable14, 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 100L + "'", long16 == 100L);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)" + "'", str17, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)");
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 100L + "'", long18 == 100L);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
    }

    @Test
    public void test00392() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00392");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        int int13 = objConsumerRecord10.serializedKeySize();
        long long14 = objConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers15 = objConsumerRecord10.headers();
        java.io.Serializable serializable16 = objConsumerRecord10.value();
        java.lang.String str17 = objConsumerRecord10.toString();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertNotNull(headers15);
        org.junit.Assert.assertEquals("'" + serializable16 + "' != '" + 1 + "'", serializable16, 1);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str17, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
    }

    @Test
    public void test00393() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00393");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        long long19 = objConsumerRecord18.timestamp();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord18.leaderEpoch();
        long long21 = objConsumerRecord18.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType4, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord18, (java.io.Serializable) '#');
        java.lang.Object obj24 = objConsumerRecord23.key();
        org.apache.kafka.common.header.Headers headers25 = objConsumerRecord23.headers();
        int int26 = objConsumerRecord23.serializedKeySize();
        long long27 = objConsumerRecord23.offset();
        java.lang.String str28 = objConsumerRecord23.topic();
        java.lang.Class<?> wildcardClass29 = objConsumerRecord23.getClass();
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertNotNull(obj24);
        org.junit.Assert.assertEquals(obj24.toString(), "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals(java.lang.String.valueOf(obj24), "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals(java.util.Objects.toString(obj24), "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(headers25);
        org.junit.Assert.assertTrue("'" + int26 + "' != '" + 100 + "'", int26 == 100);
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + (-1L) + "'", long27 == (-1L));
        org.junit.Assert.assertEquals("'" + str28 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str28, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass29);
    }

    @Test
    public void test00394() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00394");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        int int15 = objConsumerRecord13.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional16 = objConsumerRecord13.leaderEpoch();
        int int17 = objConsumerRecord13.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType22 = null;
        org.apache.kafka.common.record.TimestampType timestampType30 = null;
        java.io.Serializable serializable34 = null;
        org.apache.kafka.common.record.TimestampType timestampType39 = null;
        java.lang.Object obj43 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType39, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj43, (java.io.Serializable) 1);
        java.lang.String str46 = objConsumerRecord45.toString();
        java.lang.String str47 = objConsumerRecord45.toString();
        java.lang.Class<?> wildcardClass48 = objConsumerRecord45.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.reflect.Type> serializableConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.reflect.Type>("", (int) (short) 1, (long) 1, (long) 'a', timestampType30, (long) 10, 0, (int) (byte) 0, serializable34, (java.lang.reflect.Type) wildcardClass48);
        org.apache.kafka.common.record.TimestampType timestampType54 = null;
        java.lang.Object obj58 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType54, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj58, (java.io.Serializable) 1);
        long long61 = objConsumerRecord60.timestamp();
        java.util.Optional<java.lang.Integer> intOptional62 = objConsumerRecord60.leaderEpoch();
        java.lang.Class<?> wildcardClass63 = objConsumerRecord60.getClass();
        org.apache.kafka.common.record.TimestampType timestampType71 = null;
        java.lang.Object obj75 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType71, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj75, (java.io.Serializable) 1);
        java.lang.String str78 = objConsumerRecord77.toString();
        long long79 = objConsumerRecord77.offset();
        org.apache.kafka.common.header.Headers headers80 = objConsumerRecord77.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable> headersConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable>("", (int) (short) 100, (long) 10, headers80, (java.io.Serializable) false);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (byte) -1, (long) (-1), 1L, timestampType22, (java.lang.Long) 1L, (int) '#', 0, (java.lang.Object) serializable34, (java.io.Serializable) wildcardClass63, headers80);
        java.lang.Class<?> wildcardClass84 = headers80.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 0, (long) (byte) 1, (java.lang.Object) int17, (java.io.Serializable) wildcardClass84);
        java.util.Optional<java.lang.Integer> intOptional86 = objConsumerRecord85.leaderEpoch();
        org.apache.kafka.common.header.Headers headers87 = objConsumerRecord85.headers();
        java.lang.Class<?> wildcardClass88 = objConsumerRecord85.getClass();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 100 + "'", int17 == 100);
        org.junit.Assert.assertEquals("'" + str46 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str46, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str47 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str47, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass48);
        org.junit.Assert.assertTrue("'" + long61 + "' != '" + 52L + "'", long61 == 52L);
        org.junit.Assert.assertNotNull(intOptional62);
        org.junit.Assert.assertNotNull(wildcardClass63);
        org.junit.Assert.assertEquals("'" + str78 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str78, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long79 + "' != '" + (-1L) + "'", long79 == (-1L));
        org.junit.Assert.assertNotNull(headers80);
        org.junit.Assert.assertNotNull(wildcardClass84);
        org.junit.Assert.assertNotNull(intOptional86);
        org.junit.Assert.assertNotNull(headers87);
        org.junit.Assert.assertNotNull(wildcardClass88);
    }

    @Test
    public void test00395() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00395");
        java.lang.Object obj15 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj15, (java.io.Serializable) (byte) 100);
        java.lang.Object obj18 = objConsumerRecord17.key();
        java.lang.String str19 = objConsumerRecord17.toString();
        org.apache.kafka.common.record.TimestampType timestampType20 = objConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType28 = null;
        java.lang.Object obj32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType28, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj32, (java.io.Serializable) 1);
        long long35 = objConsumerRecord34.offset();
        long long36 = objConsumerRecord34.checksum();
        org.apache.kafka.common.header.Headers headers37 = objConsumerRecord34.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), (long) (short) 1, (long) 0, timestampType20, 10L, 97, (int) '4', (java.lang.Object) headers37, (java.io.Serializable) 0.0d);
        org.apache.kafka.common.record.TimestampType timestampType47 = null;
        java.lang.Object obj51 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType47, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj51, (java.io.Serializable) 1);
        java.lang.String str54 = objConsumerRecord53.toString();
        long long55 = objConsumerRecord53.offset();
        org.apache.kafka.common.header.Headers headers56 = objConsumerRecord53.headers();
        java.lang.String str57 = objConsumerRecord53.toString();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (int) 'a', 35L, (long) 0, timestampType20, 52L, (int) '#', 10, (java.lang.Object) objConsumerRecord53, (java.io.Serializable) true);
        java.lang.Object obj63 = null;
        org.apache.kafka.common.record.TimestampType timestampType69 = null;
        java.lang.Object obj73 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType69, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj73, (java.io.Serializable) 1);
        long long76 = objConsumerRecord75.timestamp();
        long long77 = objConsumerRecord75.timestamp();
        int int78 = objConsumerRecord75.serializedKeySize();
        org.apache.kafka.common.header.Headers headers79 = objConsumerRecord75.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), 35L, (long) 'a', timestampType20, (java.lang.Long) 0L, 0, 97, obj63, (java.io.Serializable) (byte) 1, headers79);
        java.util.Optional<java.lang.Integer> intOptional81 = objConsumerRecord80.leaderEpoch();
        int int82 = objConsumerRecord80.serializedKeySize();
        java.lang.Class<?> wildcardClass83 = objConsumerRecord80.getClass();
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str19, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + (-1L) + "'", long35 == (-1L));
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + 0L + "'", long36 == 0L);
        org.junit.Assert.assertNotNull(headers37);
        org.junit.Assert.assertEquals("'" + str54 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str54, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + (-1L) + "'", long55 == (-1L));
        org.junit.Assert.assertNotNull(headers56);
        org.junit.Assert.assertEquals("'" + str57 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str57, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long76 + "' != '" + 52L + "'", long76 == 52L);
        org.junit.Assert.assertTrue("'" + long77 + "' != '" + 52L + "'", long77 == 52L);
        org.junit.Assert.assertTrue("'" + int78 + "' != '" + 10 + "'", int78 == 10);
        org.junit.Assert.assertNotNull(headers79);
        org.junit.Assert.assertNotNull(intOptional81);
        org.junit.Assert.assertTrue("'" + int82 + "' != '" + 0 + "'", int82 == 0);
        org.junit.Assert.assertNotNull(wildcardClass83);
    }

    @Test
    public void test00396() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00396");
        java.lang.Object obj14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj14, (java.io.Serializable) (byte) 100);
        java.lang.Object obj17 = objConsumerRecord16.key();
        java.lang.String str18 = objConsumerRecord16.toString();
        org.apache.kafka.common.record.TimestampType timestampType19 = objConsumerRecord16.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        java.lang.Object obj31 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType27, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj31, (java.io.Serializable) 1);
        long long34 = objConsumerRecord33.offset();
        long long35 = objConsumerRecord33.checksum();
        org.apache.kafka.common.header.Headers headers36 = objConsumerRecord33.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), (long) (short) 1, (long) 0, timestampType19, 10L, 97, (int) '4', (java.lang.Object) headers36, (java.io.Serializable) 0.0d);
        org.apache.kafka.common.record.TimestampType timestampType46 = null;
        java.lang.Object obj50 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType46, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj50, (java.io.Serializable) 1);
        java.lang.String str53 = objConsumerRecord52.toString();
        java.util.Optional<java.lang.Integer> intOptional54 = objConsumerRecord52.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional55 = objConsumerRecord52.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) ' ', (long) (byte) 1, 0L, timestampType19, (-1L), (int) (byte) -1, (int) (short) 100, (java.lang.Object) objConsumerRecord52, (java.io.Serializable) 100.0f);
        org.apache.kafka.common.record.TimestampType timestampType62 = null;
        java.lang.Object obj66 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType62, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj66, (java.io.Serializable) 1);
        java.lang.String str69 = objConsumerRecord68.toString();
        long long70 = objConsumerRecord68.offset();
        java.lang.String str71 = objConsumerRecord68.toString();
        org.apache.kafka.common.header.Headers headers72 = objConsumerRecord68.headers();
        java.lang.String str73 = objConsumerRecord68.toString();
        int int74 = objConsumerRecord68.serializedValueSize();
        int int75 = objConsumerRecord68.serializedValueSize();
        java.lang.String str76 = objConsumerRecord68.toString();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> timestampTypeConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.record.TimestampType, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 1, null = 1, serialized key size = 0, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = 10)", (-1), (long) '#', timestampType19, objConsumerRecord68);
        int int78 = objConsumerRecord68.serializedKeySize();
        int int79 = objConsumerRecord68.serializedKeySize();
        org.junit.Assert.assertNull(obj17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str18, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + 0L + "'", long35 == 0L);
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str53, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional54);
        org.junit.Assert.assertNotNull(intOptional55);
        org.junit.Assert.assertEquals("'" + str69 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str69, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long70 + "' != '" + (-1L) + "'", long70 == (-1L));
        org.junit.Assert.assertEquals("'" + str71 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str71, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(headers72);
        org.junit.Assert.assertEquals("'" + str73 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str73, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + int74 + "' != '" + 100 + "'", int74 == 100);
        org.junit.Assert.assertTrue("'" + int75 + "' != '" + 100 + "'", int75 == 100);
        org.junit.Assert.assertEquals("'" + str76 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str76, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + int78 + "' != '" + 10 + "'", int78 == 10);
        org.junit.Assert.assertTrue("'" + int79 + "' != '" + 10 + "'", int79 == 10);
    }

    @Test
    public void test00397() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00397");
        java.lang.Object obj6 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj6, (java.io.Serializable) (byte) 100);
        org.apache.kafka.common.record.TimestampType timestampType13 = null;
        java.lang.Object obj17 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType13, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj17, (java.io.Serializable) 1);
        long long20 = objConsumerRecord19.timestamp();
        java.lang.Object obj21 = objConsumerRecord19.key();
        long long22 = objConsumerRecord19.checksum();
        java.lang.Class<?> wildcardClass23 = objConsumerRecord19.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) 1, (long) '#', obj6, (java.io.Serializable) wildcardClass23);
        java.lang.Object obj25 = objConsumerRecord24.key();
        long long26 = objConsumerRecord24.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType27 = objConsumerRecord24.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType28 = objConsumerRecord24.timestampType();
        long long29 = objConsumerRecord24.checksum();
        org.apache.kafka.common.record.TimestampType timestampType30 = objConsumerRecord24.timestampType();
        long long31 = objConsumerRecord24.checksum();
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 52L + "'", long20 == 52L);
        org.junit.Assert.assertNull(obj21);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 0L + "'", long22 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass23);
        org.junit.Assert.assertNull(obj25);
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + (-1L) + "'", long26 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType27 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType27.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType28 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType28.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long29 + "' != '" + (-1L) + "'", long29 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType30 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType30.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long31 + "' != '" + (-1L) + "'", long31 == (-1L));
    }

    @Test
    public void test00398() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00398");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.lang.String str12 = objConsumerRecord10.toString();
        long long13 = objConsumerRecord10.offset();
        long long14 = objConsumerRecord10.checksum();
        java.lang.String str15 = objConsumerRecord10.toString();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str12, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str15, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
    }

    @Test
    public void test00399() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00399");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        int int12 = objConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        int int14 = objConsumerRecord10.serializedValueSize();
        int int15 = objConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 100 + "'", int14 == 100);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
    }

    @Test
    public void test00400() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00400");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00401() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00401");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers13 = objConsumerRecord10.headers();
        java.lang.String str14 = objConsumerRecord10.toString();
        long long15 = objConsumerRecord10.offset();
        long long16 = objConsumerRecord10.checksum();
        int int17 = objConsumerRecord10.partition();
        long long18 = objConsumerRecord10.offset();
        java.lang.Object obj19 = objConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers20 = objConsumerRecord10.headers();
        java.lang.Class<?> wildcardClass21 = headers20.getClass();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNull(obj19);
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertNotNull(wildcardClass21);
    }

    @Test
    public void test00402() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00402");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        long long13 = objConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType14 = objConsumerRecord10.timestampType();
        long long15 = objConsumerRecord10.timestamp();
        long long16 = objConsumerRecord10.checksum();
        int int17 = objConsumerRecord10.serializedValueSize();
        java.lang.String str18 = objConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 100 + "'", int17 == 100);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
    }

    @Test
    public void test00403() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00403");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.offset();
        long long12 = objConsumerRecord10.checksum();
        long long13 = objConsumerRecord10.timestamp();
        long long14 = objConsumerRecord10.checksum();
        java.lang.String str15 = objConsumerRecord10.toString();
        java.lang.Object obj16 = objConsumerRecord10.key();
        java.lang.Object obj17 = objConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 0L + "'", long12 == 0L);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str15, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNull(obj16);
        org.junit.Assert.assertNull(obj17);
    }

    @Test
    public void test00404() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00404");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        long long19 = objConsumerRecord18.timestamp();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord18.leaderEpoch();
        long long21 = objConsumerRecord18.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType4, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord18, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional24 = objConsumerRecord18.leaderEpoch();
        java.lang.String str25 = objConsumerRecord18.topic();
        long long26 = objConsumerRecord18.offset();
        org.apache.kafka.common.record.TimestampType timestampType27 = objConsumerRecord18.timestampType();
        long long28 = objConsumerRecord18.timestamp();
        java.lang.Object obj29 = objConsumerRecord18.key();
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertNotNull(intOptional24);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "" + "'", str25, "");
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + (-1L) + "'", long26 == (-1L));
        org.junit.Assert.assertNull(timestampType27);
        org.junit.Assert.assertTrue("'" + long28 + "' != '" + 52L + "'", long28 == 52L);
        org.junit.Assert.assertNull(obj29);
    }

    @Test
    public void test00405() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00405");
        java.lang.Object obj15 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj15, (java.io.Serializable) (byte) 100);
        java.lang.Object obj18 = objConsumerRecord17.key();
        java.lang.String str19 = objConsumerRecord17.toString();
        org.apache.kafka.common.record.TimestampType timestampType20 = objConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType28 = null;
        java.lang.Object obj32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType28, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj32, (java.io.Serializable) 1);
        long long35 = objConsumerRecord34.offset();
        long long36 = objConsumerRecord34.checksum();
        org.apache.kafka.common.header.Headers headers37 = objConsumerRecord34.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), (long) (short) 1, (long) 0, timestampType20, 10L, 97, (int) '4', (java.lang.Object) headers37, (java.io.Serializable) 0.0d);
        org.apache.kafka.common.record.TimestampType timestampType47 = null;
        java.lang.Object obj51 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType47, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj51, (java.io.Serializable) 1);
        java.lang.String str54 = objConsumerRecord53.toString();
        long long55 = objConsumerRecord53.offset();
        org.apache.kafka.common.header.Headers headers56 = objConsumerRecord53.headers();
        java.lang.String str57 = objConsumerRecord53.toString();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (int) 'a', 35L, (long) 0, timestampType20, 52L, (int) '#', 10, (java.lang.Object) objConsumerRecord53, (java.io.Serializable) true);
        java.lang.Object obj63 = null;
        org.apache.kafka.common.record.TimestampType timestampType69 = null;
        java.lang.Object obj73 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType69, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj73, (java.io.Serializable) 1);
        long long76 = objConsumerRecord75.timestamp();
        long long77 = objConsumerRecord75.timestamp();
        int int78 = objConsumerRecord75.serializedKeySize();
        org.apache.kafka.common.header.Headers headers79 = objConsumerRecord75.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), 35L, (long) 'a', timestampType20, (java.lang.Long) 0L, 0, 97, obj63, (java.io.Serializable) (byte) 1, headers79);
        java.util.Optional<java.lang.Integer> intOptional81 = objConsumerRecord80.leaderEpoch();
        java.io.Serializable serializable82 = objConsumerRecord80.value();
        java.lang.Object obj83 = objConsumerRecord80.key();
        java.lang.Object obj84 = objConsumerRecord80.key();
        java.lang.String str85 = objConsumerRecord80.toString();
        java.util.Optional<java.lang.Integer> intOptional86 = objConsumerRecord80.leaderEpoch();
        int int87 = objConsumerRecord80.serializedKeySize();
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str19, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + (-1L) + "'", long35 == (-1L));
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + 0L + "'", long36 == 0L);
        org.junit.Assert.assertNotNull(headers37);
        org.junit.Assert.assertEquals("'" + str54 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str54, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + (-1L) + "'", long55 == (-1L));
        org.junit.Assert.assertNotNull(headers56);
        org.junit.Assert.assertEquals("'" + str57 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str57, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long76 + "' != '" + 52L + "'", long76 == 52L);
        org.junit.Assert.assertTrue("'" + long77 + "' != '" + 52L + "'", long77 == 52L);
        org.junit.Assert.assertTrue("'" + int78 + "' != '" + 10 + "'", int78 == 10);
        org.junit.Assert.assertNotNull(headers79);
        org.junit.Assert.assertNotNull(intOptional81);
        org.junit.Assert.assertEquals("'" + serializable82 + "' != '" + (byte) 1 + "'", serializable82, (byte) 1);
        org.junit.Assert.assertNull(obj83);
        org.junit.Assert.assertNull(obj84);
        org.junit.Assert.assertEquals("'" + str85 + "' != '" + "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = 97, serialized key size = 0, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str85, "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = 97, serialized key size = 0, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional86);
        org.junit.Assert.assertTrue("'" + int87 + "' != '" + 0 + "'", int87 == 0);
    }

    @Test
    public void test00406() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00406");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        org.apache.kafka.common.record.TimestampType timestampType20 = null;
        java.lang.Object obj24 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType20, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj24, (java.io.Serializable) 1);
        long long27 = objConsumerRecord26.timestamp();
        java.util.Optional<java.lang.Integer> intOptional28 = objConsumerRecord26.leaderEpoch();
        long long29 = objConsumerRecord26.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType12, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord26, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional32 = objConsumerRecord26.leaderEpoch();
        java.lang.String str33 = objConsumerRecord26.topic();
        long long34 = objConsumerRecord26.checksum();
        java.util.Optional<java.lang.Integer> intOptional35 = objConsumerRecord26.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType44 = null;
        java.lang.Object obj48 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType44, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj48, (java.io.Serializable) 1);
        long long51 = objConsumerRecord50.timestamp();
        java.util.Optional<java.lang.Integer> intOptional52 = objConsumerRecord50.leaderEpoch();
        int int53 = objConsumerRecord50.serializedValueSize();
        java.lang.String str54 = objConsumerRecord50.topic();
        java.lang.String str55 = objConsumerRecord50.topic();
        java.lang.Class<?> wildcardClass56 = objConsumerRecord50.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement> charSequenceConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) (byte) 1, (long) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", (java.lang.reflect.AnnotatedElement) wildcardClass56);
        org.apache.kafka.common.record.TimestampType timestampType62 = null;
        java.lang.Object obj66 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType62, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj66, (java.io.Serializable) 1);
        java.lang.String str69 = objConsumerRecord68.toString();
        java.util.Optional<java.lang.Integer> intOptional70 = objConsumerRecord68.leaderEpoch();
        int int71 = objConsumerRecord68.serializedKeySize();
        long long72 = objConsumerRecord68.timestamp();
        org.apache.kafka.common.header.Headers headers73 = objConsumerRecord68.headers();
        org.apache.kafka.common.header.Headers headers74 = objConsumerRecord68.headers();
        java.lang.Object obj78 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj78, (java.io.Serializable) (byte) 100);
        long long81 = objConsumerRecord80.timestamp();
        java.util.Optional<java.lang.Integer> intOptional82 = objConsumerRecord80.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional83 = objConsumerRecord80.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 0, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 52, (long) (byte) 1, 10L, timestampType4, (java.lang.Long) 0L, (int) (byte) 100, 32, (java.lang.Object) objConsumerRecord26, (java.io.Serializable) "ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", headers74, intOptional83);
        java.io.Serializable serializable85 = objConsumerRecord84.value();
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + 52L + "'", long27 == 52L);
        org.junit.Assert.assertNotNull(intOptional28);
        org.junit.Assert.assertTrue("'" + long29 + "' != '" + 52L + "'", long29 == 52L);
        org.junit.Assert.assertNotNull(intOptional32);
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "" + "'", str33, "");
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + 0L + "'", long34 == 0L);
        org.junit.Assert.assertNotNull(intOptional35);
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + 52L + "'", long51 == 52L);
        org.junit.Assert.assertNotNull(intOptional52);
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + 100 + "'", int53 == 100);
        org.junit.Assert.assertEquals("'" + str54 + "' != '" + "" + "'", str54, "");
        org.junit.Assert.assertEquals("'" + str55 + "' != '" + "" + "'", str55, "");
        org.junit.Assert.assertNotNull(wildcardClass56);
        org.junit.Assert.assertEquals("'" + str69 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str69, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional70);
        org.junit.Assert.assertTrue("'" + int71 + "' != '" + 10 + "'", int71 == 10);
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + 52L + "'", long72 == 52L);
        org.junit.Assert.assertNotNull(headers73);
        org.junit.Assert.assertNotNull(headers74);
        org.junit.Assert.assertTrue("'" + long81 + "' != '" + (-1L) + "'", long81 == (-1L));
        org.junit.Assert.assertNotNull(intOptional82);
        org.junit.Assert.assertNotNull(intOptional83);
        org.junit.Assert.assertEquals("'" + serializable85 + "' != '" + "ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)" + "'", serializable85, "ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)");
    }

    @Test
    public void test00407() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00407");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers13 = objConsumerRecord10.headers();
        int int14 = objConsumerRecord10.partition();
        java.lang.String str15 = objConsumerRecord10.topic();
        long long16 = objConsumerRecord10.timestamp();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "" + "'", str15, "");
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 52L + "'", long16 == 52L);
    }

    @Test
    public void test00408() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00408");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        long long19 = objConsumerRecord18.timestamp();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord18.leaderEpoch();
        long long21 = objConsumerRecord18.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType4, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord18, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional24 = objConsumerRecord18.leaderEpoch();
        int int25 = objConsumerRecord18.serializedKeySize();
        int int26 = objConsumerRecord18.partition();
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertNotNull(intOptional24);
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + 10 + "'", int25 == 10);
        org.junit.Assert.assertTrue("'" + int26 + "' != '" + 10 + "'", int26 == 10);
    }

    @Test
    public void test00409() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00409");
        org.apache.kafka.common.record.TimestampType timestampType10 = null;
        java.lang.Object obj14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType10, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj14, (java.io.Serializable) 1);
        java.lang.String str17 = objConsumerRecord16.toString();
        long long18 = objConsumerRecord16.offset();
        org.apache.kafka.common.header.Headers headers19 = objConsumerRecord16.headers();
        java.lang.String str20 = objConsumerRecord16.toString();
        long long21 = objConsumerRecord16.offset();
        long long22 = objConsumerRecord16.checksum();
        java.lang.Object obj23 = objConsumerRecord16.key();
        org.apache.kafka.common.record.TimestampType timestampType24 = objConsumerRecord16.timestampType();
        long long25 = objConsumerRecord16.timestamp();
        long long26 = objConsumerRecord16.checksum();
        org.apache.kafka.common.record.TimestampType timestampType35 = null;
        java.lang.Object obj39 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType35, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj39, (java.io.Serializable) 1);
        long long42 = objConsumerRecord41.timestamp();
        java.util.Optional<java.lang.Integer> intOptional43 = objConsumerRecord41.leaderEpoch();
        int int44 = objConsumerRecord41.serializedValueSize();
        java.lang.String str45 = objConsumerRecord41.topic();
        java.lang.String str46 = objConsumerRecord41.topic();
        java.lang.Class<?> wildcardClass47 = objConsumerRecord41.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement> charSequenceConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) (byte) 1, (long) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", (java.lang.reflect.AnnotatedElement) wildcardClass47);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (byte) -1, (long) 35, (java.lang.Object) objConsumerRecord16, (java.io.Serializable) wildcardClass47);
        org.apache.kafka.common.record.TimestampType timestampType57 = null;
        java.lang.Object obj61 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType57, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj61, (java.io.Serializable) 1);
        long long64 = objConsumerRecord63.timestamp();
        long long65 = objConsumerRecord63.timestamp();
        int int66 = objConsumerRecord63.serializedKeySize();
        java.lang.Object obj67 = objConsumerRecord63.key();
        org.apache.kafka.common.header.Headers headers68 = objConsumerRecord63.headers();
        org.apache.kafka.common.record.TimestampType timestampType77 = null;
        java.lang.Object obj81 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType77, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj81, (java.io.Serializable) 1);
        java.lang.String str84 = objConsumerRecord83.toString();
        java.lang.String str85 = objConsumerRecord83.toString();
        java.lang.Class<?> wildcardClass86 = objConsumerRecord83.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type> charSequenceConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '#', (long) (short) -1, (java.lang.CharSequence) "", (java.lang.reflect.Type) wildcardClass86);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) (short) 100, (long) 100, (java.lang.Object) objConsumerRecord63, (java.io.Serializable) (short) -1);
        int int89 = objConsumerRecord63.partition();
        long long90 = objConsumerRecord63.timestamp();
        org.apache.kafka.common.header.Headers headers91 = objConsumerRecord63.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> annotatedElementConsumerRecord92 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 0, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 32, (long) '4', (java.lang.reflect.AnnotatedElement) wildcardClass47, objConsumerRecord63);
        java.lang.Class<?> wildcardClass93 = annotatedElementConsumerRecord92.getClass();
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str17, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 0L + "'", long22 == 0L);
        org.junit.Assert.assertNull(obj23);
        org.junit.Assert.assertNull(timestampType24);
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + 52L + "'", long25 == 52L);
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + 0L + "'", long26 == 0L);
        org.junit.Assert.assertTrue("'" + long42 + "' != '" + 52L + "'", long42 == 52L);
        org.junit.Assert.assertNotNull(intOptional43);
        org.junit.Assert.assertTrue("'" + int44 + "' != '" + 100 + "'", int44 == 100);
        org.junit.Assert.assertEquals("'" + str45 + "' != '" + "" + "'", str45, "");
        org.junit.Assert.assertEquals("'" + str46 + "' != '" + "" + "'", str46, "");
        org.junit.Assert.assertNotNull(wildcardClass47);
        org.junit.Assert.assertTrue("'" + long64 + "' != '" + 52L + "'", long64 == 52L);
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + 52L + "'", long65 == 52L);
        org.junit.Assert.assertTrue("'" + int66 + "' != '" + 10 + "'", int66 == 10);
        org.junit.Assert.assertNull(obj67);
        org.junit.Assert.assertNotNull(headers68);
        org.junit.Assert.assertEquals("'" + str84 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str84, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str85 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str85, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass86);
        org.junit.Assert.assertTrue("'" + int89 + "' != '" + 10 + "'", int89 == 10);
        org.junit.Assert.assertTrue("'" + long90 + "' != '" + 52L + "'", long90 == 52L);
        org.junit.Assert.assertNotNull(headers91);
        org.junit.Assert.assertNotNull(wildcardClass93);
    }

    @Test
    public void test00410() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00410");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        java.lang.String str13 = objConsumerRecord10.toString();
        java.lang.String str14 = objConsumerRecord10.toString();
        int int15 = objConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.header.Headers headers16 = objConsumerRecord10.headers();
        java.lang.Class<?> wildcardClass17 = headers16.getClass();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertNotNull(wildcardClass17);
    }

    @Test
    public void test00411() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00411");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        int int14 = objConsumerRecord10.partition();
        int int15 = objConsumerRecord10.serializedValueSize();
        java.io.Serializable serializable16 = objConsumerRecord10.value();
        long long17 = objConsumerRecord10.offset();
        long long18 = objConsumerRecord10.checksum();
        java.io.Serializable serializable19 = objConsumerRecord10.value();
        long long20 = objConsumerRecord10.timestamp();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertEquals("'" + serializable16 + "' != '" + 1 + "'", serializable16, 1);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertEquals("'" + serializable19 + "' != '" + 1 + "'", serializable19, 1);
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 52L + "'", long20 == 52L);
    }

    @Test
    public void test00412() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00412");
        org.apache.kafka.common.record.TimestampType timestampType10 = null;
        java.lang.Object obj14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType10, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj14, (java.io.Serializable) 1);
        long long17 = objConsumerRecord16.timestamp();
        int int18 = objConsumerRecord16.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional19 = objConsumerRecord16.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord16, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType22 = objConsumerRecord16.timestampType();
        java.lang.String str23 = objConsumerRecord16.topic();
        long long24 = objConsumerRecord16.timestamp();
        java.lang.Object obj25 = objConsumerRecord16.key();
        org.apache.kafka.common.header.Headers headers26 = objConsumerRecord16.headers();
        org.apache.kafka.common.record.TimestampType timestampType31 = null;
        java.lang.Object obj35 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType31, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj35, (java.io.Serializable) 1);
        org.apache.kafka.common.record.TimestampType timestampType38 = objConsumerRecord37.timestampType();
        java.util.Optional<java.lang.Integer> intOptional39 = objConsumerRecord37.leaderEpoch();
        long long40 = objConsumerRecord37.offset();
        int int41 = objConsumerRecord37.partition();
        java.lang.Class<?> wildcardClass42 = objConsumerRecord37.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.GenericDeclaration> headerIterableConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)", (int) (byte) 1, (long) (byte) 0, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers26, (java.lang.reflect.GenericDeclaration) wildcardClass42);
        java.lang.Class<?> wildcardClass44 = headers26.getClass();
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 100 + "'", int18 == 100);
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertNull(timestampType22);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "" + "'", str23, "");
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 52L + "'", long24 == 52L);
        org.junit.Assert.assertNull(obj25);
        org.junit.Assert.assertNotNull(headers26);
        org.junit.Assert.assertNull(timestampType38);
        org.junit.Assert.assertNotNull(intOptional39);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + 10 + "'", int41 == 10);
        org.junit.Assert.assertNotNull(wildcardClass42);
        org.junit.Assert.assertNotNull(wildcardClass44);
    }

    @Test
    public void test00413() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00413");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        java.lang.String str14 = objConsumerRecord13.toString();
        java.util.Optional<java.lang.Integer> intOptional15 = objConsumerRecord13.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional16 = objConsumerRecord13.leaderEpoch();
        int int17 = objConsumerRecord13.partition();
        long long18 = objConsumerRecord13.offset();
        org.apache.kafka.common.record.TimestampType timestampType19 = objConsumerRecord13.timestampType();
        java.lang.Object obj27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj27, (java.io.Serializable) (byte) 100);
        java.lang.Object obj30 = objConsumerRecord29.key();
        org.apache.kafka.common.record.TimestampType timestampType31 = objConsumerRecord29.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType45 = null;
        java.lang.Object obj49 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType45, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj49, (java.io.Serializable) 1);
        long long52 = objConsumerRecord51.timestamp();
        int int53 = objConsumerRecord51.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional54 = objConsumerRecord51.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord51, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType57 = objConsumerRecord51.timestampType();
        java.lang.String str58 = objConsumerRecord51.topic();
        long long59 = objConsumerRecord51.timestamp();
        java.lang.Object obj60 = objConsumerRecord51.key();
        org.apache.kafka.common.header.Headers headers61 = objConsumerRecord51.headers();
        org.apache.kafka.common.record.TimestampType timestampType66 = null;
        java.lang.Object obj70 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType66, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj70, (java.io.Serializable) 1);
        org.apache.kafka.common.record.TimestampType timestampType73 = objConsumerRecord72.timestampType();
        java.util.Optional<java.lang.Integer> intOptional74 = objConsumerRecord72.leaderEpoch();
        long long75 = objConsumerRecord72.offset();
        int int76 = objConsumerRecord72.partition();
        java.lang.Class<?> wildcardClass77 = objConsumerRecord72.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.GenericDeclaration> headerIterableConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)", (int) (byte) 1, (long) (byte) 0, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers61, (java.lang.reflect.GenericDeclaration) wildcardClass77);
        java.io.Serializable serializable79 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 1, null = 1, serialized key size = 0, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = 10)", (int) (byte) -1, (long) 'a', (long) 35, timestampType31, (long) '4', 100, (int) (byte) 100, (java.lang.Object) headers61, serializable79);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", 1, (long) 10, (java.lang.Object) timestampType19, (java.io.Serializable) timestampType31);
        long long82 = objConsumerRecord81.timestamp();
        long long83 = objConsumerRecord81.checksum();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNull(timestampType19);
        org.junit.Assert.assertNull(obj30);
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long52 + "' != '" + 52L + "'", long52 == 52L);
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + 100 + "'", int53 == 100);
        org.junit.Assert.assertNotNull(intOptional54);
        org.junit.Assert.assertNull(timestampType57);
        org.junit.Assert.assertEquals("'" + str58 + "' != '" + "" + "'", str58, "");
        org.junit.Assert.assertTrue("'" + long59 + "' != '" + 52L + "'", long59 == 52L);
        org.junit.Assert.assertNull(obj60);
        org.junit.Assert.assertNotNull(headers61);
        org.junit.Assert.assertNull(timestampType73);
        org.junit.Assert.assertNotNull(intOptional74);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + (-1L) + "'", long75 == (-1L));
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + 10 + "'", int76 == 10);
        org.junit.Assert.assertNotNull(wildcardClass77);
        org.junit.Assert.assertTrue("'" + long82 + "' != '" + (-1L) + "'", long82 == (-1L));
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + (-1L) + "'", long83 == (-1L));
    }

    @Test
    public void test00414() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00414");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.kafka.common.record.TimestampType timestampType15 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType15, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        org.apache.kafka.common.header.Headers headers22 = objConsumerRecord21.headers();
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.common.record.TimestampType timestampType35 = null;
        java.lang.Object obj39 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType35, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj39, (java.io.Serializable) 1);
        java.lang.String str42 = objConsumerRecord41.toString();
        java.lang.String str43 = objConsumerRecord41.toString();
        org.apache.kafka.common.record.TimestampType timestampType49 = null;
        java.lang.Object obj53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType49, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj53, (java.io.Serializable) 1);
        java.lang.String str56 = objConsumerRecord55.toString();
        long long57 = objConsumerRecord55.offset();
        org.apache.kafka.common.header.Headers headers58 = objConsumerRecord55.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) (byte) 100, (long) (byte) 1, (long) (short) 1, timestampType27, (java.lang.Long) 10L, (int) (short) 0, (int) (short) 1, (java.lang.Object) str43, (java.io.Serializable) 10, headers58);
        org.apache.kafka.common.record.TimestampType timestampType64 = null;
        org.apache.kafka.common.record.TimestampType timestampType72 = null;
        java.lang.Object obj76 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType72, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj76, (java.io.Serializable) 1);
        long long79 = objConsumerRecord78.timestamp();
        java.util.Optional<java.lang.Integer> intOptional80 = objConsumerRecord78.leaderEpoch();
        long long81 = objConsumerRecord78.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType64, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord78, (java.io.Serializable) '#');
        java.lang.Object obj84 = objConsumerRecord83.key();
        org.apache.kafka.common.header.Headers headers85 = objConsumerRecord83.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, org.apache.kafka.common.header.Headers> headersConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, org.apache.kafka.common.header.Headers>("", 35, 1L, (long) (byte) 10, timestampType7, (java.lang.Long) (-1L), 0, 10, headers22, headers58, headers85);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.CharSequence> headerIterableConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.CharSequence>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)", 0, (long) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers85, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 0, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = class org.apache.kafka.clients.consumer.ConsumerRecord)");
        java.lang.Class<?> wildcardClass89 = headerIterableConsumerRecord88.getClass();
        org.junit.Assert.assertNotNull(headers22);
        org.junit.Assert.assertEquals("'" + str42 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str42, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str43 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str43, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str56 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str56, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long57 + "' != '" + (-1L) + "'", long57 == (-1L));
        org.junit.Assert.assertNotNull(headers58);
        org.junit.Assert.assertTrue("'" + long79 + "' != '" + 52L + "'", long79 == 52L);
        org.junit.Assert.assertNotNull(intOptional80);
        org.junit.Assert.assertTrue("'" + long81 + "' != '" + 52L + "'", long81 == 52L);
        org.junit.Assert.assertNotNull(obj84);
        org.junit.Assert.assertEquals(obj84.toString(), "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals(java.lang.String.valueOf(obj84), "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals(java.util.Objects.toString(obj84), "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(headers85);
        org.junit.Assert.assertNotNull(wildcardClass89);
    }

    @Test
    public void test00415() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00415");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        java.lang.String str14 = objConsumerRecord13.toString();
        int int15 = objConsumerRecord13.serializedValueSize();
        java.lang.String str16 = objConsumerRecord13.toString();
        java.io.Serializable serializable17 = objConsumerRecord13.value();
        long long18 = objConsumerRecord13.offset();
        org.apache.kafka.common.header.Headers headers19 = objConsumerRecord13.headers();
        java.lang.Object obj20 = objConsumerRecord13.key();
        java.io.Serializable serializable21 = objConsumerRecord13.value();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.Comparable<java.lang.String>> objConsumerRecordConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '4', (long) (short) 0, objConsumerRecord13, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + serializable17 + "' != '" + 1 + "'", serializable17, 1);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertNull(obj20);
        org.junit.Assert.assertEquals("'" + serializable21 + "' != '" + 1 + "'", serializable21, 1);
    }

    @Test
    public void test00416() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00416");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        int int14 = objConsumerRecord10.partition();
        int int15 = objConsumerRecord10.serializedValueSize();
        java.io.Serializable serializable16 = objConsumerRecord10.value();
        long long17 = objConsumerRecord10.offset();
        long long18 = objConsumerRecord10.checksum();
        long long19 = objConsumerRecord10.offset();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertEquals("'" + serializable16 + "' != '" + 1 + "'", serializable16, 1);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
    }

    @Test
    public void test00417() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00417");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.AnnotatedElement, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> annotatedElementKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> annotatedElementKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.AnnotatedElement, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(annotatedElementKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00418() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00418");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        int int12 = objConsumerRecord10.serializedValueSize();
        int int13 = objConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
    }

    @Test
    public void test00419() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00419");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.kafka.common.record.TimestampType timestampType15 = null;
        java.lang.Object obj19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType15, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj19, (java.io.Serializable) 1);
        long long22 = objConsumerRecord21.timestamp();
        java.util.Optional<java.lang.Integer> intOptional23 = objConsumerRecord21.leaderEpoch();
        long long24 = objConsumerRecord21.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType7, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord21, (java.io.Serializable) '#');
        java.io.Serializable serializable27 = objConsumerRecord26.value();
        org.apache.kafka.common.record.TimestampType timestampType28 = objConsumerRecord26.timestampType();
        java.lang.String str29 = objConsumerRecord26.toString();
        org.apache.kafka.common.record.TimestampType timestampType34 = null;
        org.apache.kafka.common.record.TimestampType timestampType42 = null;
        java.lang.Object obj46 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType42, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj46, (java.io.Serializable) 1);
        long long49 = objConsumerRecord48.timestamp();
        java.util.Optional<java.lang.Integer> intOptional50 = objConsumerRecord48.leaderEpoch();
        long long51 = objConsumerRecord48.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType34, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord48, (java.io.Serializable) '#');
        java.lang.Class<?> wildcardClass54 = objConsumerRecord53.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 32, (long) '#', (java.lang.Object) objConsumerRecord26, (java.io.Serializable) wildcardClass54);
        java.lang.Class<?> wildcardClass56 = objConsumerRecord55.getClass();
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 52L + "'", long22 == 52L);
        org.junit.Assert.assertNotNull(intOptional23);
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 52L + "'", long24 == 52L);
        org.junit.Assert.assertEquals("'" + serializable27 + "' != '" + '#' + "'", serializable27, '#');
        org.junit.Assert.assertNull(timestampType28);
        org.junit.Assert.assertEquals("'" + str29 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)" + "'", str29, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)");
        org.junit.Assert.assertTrue("'" + long49 + "' != '" + 52L + "'", long49 == 52L);
        org.junit.Assert.assertNotNull(intOptional50);
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + 52L + "'", long51 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass54);
        org.junit.Assert.assertNotNull(wildcardClass56);
    }

    @Test
    public void test00420() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00420");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        java.util.Optional<java.lang.Integer> intOptional15 = objConsumerRecord13.leaderEpoch();
        long long16 = objConsumerRecord13.timestamp();
        java.io.Serializable serializable17 = objConsumerRecord13.value();
        long long18 = objConsumerRecord13.offset();
        org.apache.kafka.common.record.TimestampType timestampType19 = objConsumerRecord13.timestampType();
        java.lang.String str20 = objConsumerRecord13.toString();
        java.util.Optional<java.lang.Integer> intOptional21 = objConsumerRecord13.leaderEpoch();
        org.apache.kafka.common.header.Headers headers22 = objConsumerRecord13.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.String> objConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 100, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = class org.apache.kafka.clients.consumer.ConsumerRecord, value = null)", (int) (short) 100, 35L, (java.lang.Object) headers22, "ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)");
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 52L + "'", long16 == 52L);
        org.junit.Assert.assertEquals("'" + serializable17 + "' != '" + 1 + "'", serializable17, 1);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNull(timestampType19);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional21);
        org.junit.Assert.assertNotNull(headers22);
    }

    @Test
    public void test00421() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00421");
        org.apache.kafka.common.record.TimestampType timestampType10 = null;
        java.lang.Object obj14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType10, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj14, (java.io.Serializable) 1);
        long long17 = objConsumerRecord16.timestamp();
        int int18 = objConsumerRecord16.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional19 = objConsumerRecord16.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord16, (java.io.Serializable) false);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) 0, (long) 97, (java.lang.Object) false, (java.io.Serializable) (short) 100);
        org.apache.kafka.common.record.TimestampType timestampType24 = objConsumerRecord23.timestampType();
        int int25 = objConsumerRecord23.partition();
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 100 + "'", int18 == 100);
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertTrue("'" + timestampType24 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType24.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + 0 + "'", int25 == 0);
    }

    @Test
    public void test00422() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00422");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType7, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        java.lang.String str14 = objConsumerRecord13.topic();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)", (int) (short) 100, (long) '#', (java.lang.Object) objConsumerRecord13, (java.io.Serializable) 10L);
        int int17 = objConsumerRecord13.partition();
        java.lang.Class<?> wildcardClass18 = objConsumerRecord13.getClass();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + (-1) + "'", int17 == (-1));
        org.junit.Assert.assertNotNull(wildcardClass18);
    }

    @Test
    public void test00423() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00423");
        java.lang.Object obj3 = null;
        org.apache.kafka.common.record.TimestampType timestampType8 = null;
        java.lang.Object obj15 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj15, (java.io.Serializable) (byte) 100);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (byte) 100, (long) (byte) 10, (long) 0, timestampType8, (-1L), 1, (int) (short) 1, (java.lang.Object) 'a', (java.io.Serializable) (short) 1);
        org.apache.kafka.common.header.Headers headers20 = objConsumerRecord19.headers();
        java.lang.Class<?> wildcardClass21 = headers20.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 35, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 97, 97L, obj3, (java.io.Serializable) wildcardClass21);
        org.apache.kafka.common.header.Headers headers23 = objConsumerRecord22.headers();
        org.apache.kafka.common.header.Headers headers24 = objConsumerRecord22.headers();
        java.lang.Object obj25 = objConsumerRecord22.key();
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertNotNull(wildcardClass21);
        org.junit.Assert.assertNotNull(headers23);
        org.junit.Assert.assertNotNull(headers24);
        org.junit.Assert.assertNull(obj25);
    }

    @Test
    public void test00424() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00424");
        java.lang.Object obj14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj14, (java.io.Serializable) (byte) 100);
        java.lang.Object obj17 = objConsumerRecord16.key();
        java.lang.String str18 = objConsumerRecord16.toString();
        org.apache.kafka.common.record.TimestampType timestampType19 = objConsumerRecord16.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) -1, 10L, (long) (short) 100, timestampType19, (long) 0, 0, 35, (java.lang.Object) (-1), (java.io.Serializable) 1L);
        org.apache.kafka.common.record.TimestampType timestampType33 = null;
        java.lang.Object obj37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType33, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj37, (java.io.Serializable) 1);
        java.lang.String str40 = objConsumerRecord39.toString();
        long long41 = objConsumerRecord39.offset();
        org.apache.kafka.common.header.Headers headers42 = objConsumerRecord39.headers();
        java.lang.String str43 = objConsumerRecord39.topic();
        org.apache.kafka.common.header.Headers headers44 = objConsumerRecord39.headers();
        org.apache.kafka.common.record.TimestampType timestampType50 = null;
        java.lang.Object obj54 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType50, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj54, (java.io.Serializable) 1);
        java.lang.String str57 = objConsumerRecord56.toString();
        long long58 = objConsumerRecord56.offset();
        org.apache.kafka.common.header.Headers headers59 = objConsumerRecord56.headers();
        java.lang.String str60 = objConsumerRecord56.toString();
        long long61 = objConsumerRecord56.offset();
        long long62 = objConsumerRecord56.checksum();
        java.util.Optional<java.lang.Integer> intOptional63 = objConsumerRecord56.leaderEpoch();
        java.lang.Object obj64 = objConsumerRecord56.key();
        long long65 = objConsumerRecord56.offset();
        org.apache.kafka.common.header.Headers headers66 = objConsumerRecord56.headers();
        org.apache.kafka.common.record.TimestampType timestampType71 = null;
        java.lang.Object obj75 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType71, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj75, (java.io.Serializable) 1);
        java.lang.String str78 = objConsumerRecord77.toString();
        long long79 = objConsumerRecord77.offset();
        org.apache.kafka.common.header.Headers headers80 = objConsumerRecord77.headers();
        java.lang.String str81 = objConsumerRecord77.toString();
        long long82 = objConsumerRecord77.offset();
        long long83 = objConsumerRecord77.checksum();
        java.util.Optional<java.lang.Integer> intOptional84 = objConsumerRecord77.leaderEpoch();
        java.lang.Object obj85 = objConsumerRecord77.key();
        long long86 = objConsumerRecord77.offset();
        java.util.Optional<java.lang.Integer> intOptional87 = objConsumerRecord77.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 0, 0L, 0L, timestampType19, (java.lang.Long) 1L, 1, (int) (byte) 100, (java.lang.Object) headers44, (java.io.Serializable) 0L, headers66, intOptional87);
        java.lang.Iterable<org.apache.kafka.common.header.Header> headerIterable89 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Iterable<org.apache.kafka.common.header.Header>> timestampTypeEnumConsumerRecord90 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.lang.Iterable<org.apache.kafka.common.header.Header>>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", 0, (long) (-1), (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType19, headerIterable89);
        org.junit.Assert.assertNull(obj17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str18, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str40 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str40, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long41 + "' != '" + (-1L) + "'", long41 == (-1L));
        org.junit.Assert.assertNotNull(headers42);
        org.junit.Assert.assertEquals("'" + str43 + "' != '" + "" + "'", str43, "");
        org.junit.Assert.assertNotNull(headers44);
        org.junit.Assert.assertEquals("'" + str57 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str57, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long58 + "' != '" + (-1L) + "'", long58 == (-1L));
        org.junit.Assert.assertNotNull(headers59);
        org.junit.Assert.assertEquals("'" + str60 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str60, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long61 + "' != '" + (-1L) + "'", long61 == (-1L));
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + 0L + "'", long62 == 0L);
        org.junit.Assert.assertNotNull(intOptional63);
        org.junit.Assert.assertNull(obj64);
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + (-1L) + "'", long65 == (-1L));
        org.junit.Assert.assertNotNull(headers66);
        org.junit.Assert.assertEquals("'" + str78 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str78, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long79 + "' != '" + (-1L) + "'", long79 == (-1L));
        org.junit.Assert.assertNotNull(headers80);
        org.junit.Assert.assertEquals("'" + str81 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str81, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long82 + "' != '" + (-1L) + "'", long82 == (-1L));
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + 0L + "'", long83 == 0L);
        org.junit.Assert.assertNotNull(intOptional84);
        org.junit.Assert.assertNull(obj85);
        org.junit.Assert.assertTrue("'" + long86 + "' != '" + (-1L) + "'", long86 == (-1L));
        org.junit.Assert.assertNotNull(intOptional87);
    }

    @Test
    public void test00425() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00425");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        long long19 = objConsumerRecord18.timestamp();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord18.leaderEpoch();
        long long21 = objConsumerRecord18.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType4, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord18, (java.io.Serializable) '#');
        java.io.Serializable serializable24 = objConsumerRecord23.value();
        org.apache.kafka.common.record.TimestampType timestampType25 = objConsumerRecord23.timestampType();
        java.lang.String str26 = objConsumerRecord23.toString();
        int int27 = objConsumerRecord23.serializedKeySize();
        long long28 = objConsumerRecord23.timestamp();
        java.lang.Object obj29 = objConsumerRecord23.key();
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertEquals("'" + serializable24 + "' != '" + '#' + "'", serializable24, '#');
        org.junit.Assert.assertNull(timestampType25);
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)" + "'", str26, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)");
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + 100 + "'", int27 == 100);
        org.junit.Assert.assertTrue("'" + long28 + "' != '" + 10L + "'", long28 == 10L);
        org.junit.Assert.assertNotNull(obj29);
        org.junit.Assert.assertEquals(obj29.toString(), "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals(java.lang.String.valueOf(obj29), "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals(java.util.Objects.toString(obj29), "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
    }

    @Test
    public void test00426() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00426");
        java.lang.Object obj3 = null;
        org.apache.kafka.common.record.TimestampType timestampType8 = null;
        org.apache.kafka.common.record.TimestampType timestampType16 = null;
        java.io.Serializable serializable20 = null;
        org.apache.kafka.common.record.TimestampType timestampType25 = null;
        java.lang.Object obj29 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType25, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj29, (java.io.Serializable) 1);
        java.lang.String str32 = objConsumerRecord31.toString();
        java.lang.String str33 = objConsumerRecord31.toString();
        java.lang.Class<?> wildcardClass34 = objConsumerRecord31.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.reflect.Type> serializableConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.reflect.Type>("", (int) (short) 1, (long) 1, (long) 'a', timestampType16, (long) 10, 0, (int) (byte) 0, serializable20, (java.lang.reflect.Type) wildcardClass34);
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        java.lang.Object obj44 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType40, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj44, (java.io.Serializable) 1);
        long long47 = objConsumerRecord46.timestamp();
        java.util.Optional<java.lang.Integer> intOptional48 = objConsumerRecord46.leaderEpoch();
        java.lang.Class<?> wildcardClass49 = objConsumerRecord46.getClass();
        org.apache.kafka.common.record.TimestampType timestampType57 = null;
        java.lang.Object obj61 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType57, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj61, (java.io.Serializable) 1);
        java.lang.String str64 = objConsumerRecord63.toString();
        long long65 = objConsumerRecord63.offset();
        org.apache.kafka.common.header.Headers headers66 = objConsumerRecord63.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable> headersConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.io.Serializable>("", (int) (short) 100, (long) 10, headers66, (java.io.Serializable) false);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (byte) -1, (long) (-1), 1L, timestampType8, (java.lang.Long) 1L, (int) '#', 0, (java.lang.Object) serializable20, (java.io.Serializable) wildcardClass49, headers66);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 1, NoTimestampType = 1, serialized key size = 0, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = NoTimestampType)", 1, (long) '#', obj3, (java.io.Serializable) (-1));
        int int71 = objConsumerRecord70.serializedKeySize();
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str32, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str33, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass34);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 52L + "'", long47 == 52L);
        org.junit.Assert.assertNotNull(intOptional48);
        org.junit.Assert.assertNotNull(wildcardClass49);
        org.junit.Assert.assertEquals("'" + str64 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str64, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + (-1L) + "'", long65 == (-1L));
        org.junit.Assert.assertNotNull(headers66);
        org.junit.Assert.assertTrue("'" + int71 + "' != '" + (-1) + "'", int71 == (-1));
    }

    @Test
    public void test00427() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00427");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        java.lang.String str14 = objConsumerRecord13.toString();
        java.util.Optional<java.lang.Integer> intOptional15 = objConsumerRecord13.leaderEpoch();
        int int16 = objConsumerRecord13.serializedKeySize();
        long long17 = objConsumerRecord13.timestamp();
        int int18 = objConsumerRecord13.serializedValueSize();
        long long19 = objConsumerRecord13.checksum();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.CharSequence> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.CharSequence>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 1, null = 1, serialized key size = 0, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = 10)", (-1), 0L, (java.lang.Object) long19, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 100, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = class org.apache.kafka.clients.consumer.ConsumerRecord, value = null)");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 100 + "'", int18 == 100);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
    }

    @Test
    public void test00428() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00428");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers13 = objConsumerRecord10.headers();
        java.lang.String str14 = objConsumerRecord10.toString();
        java.io.Serializable serializable15 = objConsumerRecord10.value();
        int int16 = objConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType17 = objConsumerRecord10.timestampType();
        java.io.Serializable serializable18 = objConsumerRecord10.value();
        java.io.Serializable serializable19 = objConsumerRecord10.value();
        java.lang.String str20 = objConsumerRecord10.topic();
        int int21 = objConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + serializable15 + "' != '" + 1 + "'", serializable15, 1);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertEquals("'" + serializable18 + "' != '" + 1 + "'", serializable18, 1);
        org.junit.Assert.assertEquals("'" + serializable19 + "' != '" + 1 + "'", serializable19, 1);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "" + "'", str20, "");
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 100 + "'", int21 == 100);
    }

    @Test
    public void test00429() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00429");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.io.Serializable serializable11 = null;
        org.apache.kafka.common.record.TimestampType timestampType16 = null;
        java.lang.Object obj20 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType16, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj20, (java.io.Serializable) 1);
        java.lang.String str23 = objConsumerRecord22.toString();
        java.lang.String str24 = objConsumerRecord22.toString();
        java.lang.Class<?> wildcardClass25 = objConsumerRecord22.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.reflect.Type> serializableConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, java.lang.reflect.Type>("", (int) (short) 1, (long) 1, (long) 'a', timestampType7, (long) 10, 0, (int) (byte) 0, serializable11, (java.lang.reflect.Type) wildcardClass25);
        org.apache.kafka.common.record.TimestampType timestampType37 = null;
        java.lang.Object obj41 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType37, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj41, (java.io.Serializable) 1);
        long long44 = objConsumerRecord43.timestamp();
        long long45 = objConsumerRecord43.timestamp();
        int int46 = objConsumerRecord43.serializedKeySize();
        java.lang.Object obj47 = objConsumerRecord43.key();
        org.apache.kafka.common.header.Headers headers48 = objConsumerRecord43.headers();
        org.apache.kafka.common.record.TimestampType timestampType57 = null;
        java.lang.Object obj61 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType57, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj61, (java.io.Serializable) 1);
        java.lang.String str64 = objConsumerRecord63.toString();
        java.lang.String str65 = objConsumerRecord63.toString();
        java.lang.Class<?> wildcardClass66 = objConsumerRecord63.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type> charSequenceConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '#', (long) (short) -1, (java.lang.CharSequence) "", (java.lang.reflect.Type) wildcardClass66);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) (short) 100, (long) 100, (java.lang.Object) objConsumerRecord43, (java.io.Serializable) (short) -1);
        int int69 = objConsumerRecord43.partition();
        java.lang.Class<?> wildcardClass70 = objConsumerRecord43.getClass();
        org.apache.kafka.common.record.TimestampType timestampType75 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType75, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        org.apache.kafka.common.record.TimestampType timestampType82 = objConsumerRecord81.timestampType();
        long long83 = objConsumerRecord81.timestamp();
        java.util.Optional<java.lang.Integer> intOptional84 = objConsumerRecord81.leaderEpoch();
        int int85 = objConsumerRecord81.partition();
        java.lang.Class<?> wildcardClass86 = objConsumerRecord81.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.lang.reflect.GenericDeclaration> annotatedElementConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (int) (short) 1, (long) 32, (java.lang.reflect.AnnotatedElement) wildcardClass70, (java.lang.reflect.GenericDeclaration) wildcardClass86);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", 100, 52L, (java.lang.Object) "", (java.io.Serializable) 32);
        long long89 = objConsumerRecord88.offset();
        java.lang.Object obj90 = objConsumerRecord88.key();
        int int91 = objConsumerRecord88.serializedKeySize();
        java.lang.Class<?> wildcardClass92 = objConsumerRecord88.getClass();
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str23, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str24 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str24, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass25);
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + 52L + "'", long44 == 52L);
        org.junit.Assert.assertTrue("'" + long45 + "' != '" + 52L + "'", long45 == 52L);
        org.junit.Assert.assertTrue("'" + int46 + "' != '" + 10 + "'", int46 == 10);
        org.junit.Assert.assertNull(obj47);
        org.junit.Assert.assertNotNull(headers48);
        org.junit.Assert.assertEquals("'" + str64 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str64, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str65 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str65, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass66);
        org.junit.Assert.assertTrue("'" + int69 + "' != '" + 10 + "'", int69 == 10);
        org.junit.Assert.assertNotNull(wildcardClass70);
        org.junit.Assert.assertNull(timestampType82);
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + 10L + "'", long83 == 10L);
        org.junit.Assert.assertNotNull(intOptional84);
        org.junit.Assert.assertTrue("'" + int85 + "' != '" + (-1) + "'", int85 == (-1));
        org.junit.Assert.assertNotNull(wildcardClass86);
        org.junit.Assert.assertTrue("'" + long89 + "' != '" + 52L + "'", long89 == 52L);
        org.junit.Assert.assertEquals("'" + obj90 + "' != '" + "" + "'", obj90, "");
        org.junit.Assert.assertTrue("'" + int91 + "' != '" + (-1) + "'", int91 == (-1));
        org.junit.Assert.assertNotNull(wildcardClass92);
    }

    @Test
    public void test00430() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00430");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        long long13 = objConsumerRecord10.timestamp();
        java.io.Serializable serializable14 = objConsumerRecord10.value();
        long long15 = objConsumerRecord10.offset();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord10.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType17 = objConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + 1 + "'", serializable14, 1);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertNull(timestampType17);
    }

    @Test
    public void test00431() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00431");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) 0, (long) (byte) 10, (java.lang.Object) "ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", (java.io.Serializable) 1L);
        long long6 = objConsumerRecord5.checksum();
        int int7 = objConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional8 = objConsumerRecord5.leaderEpoch();
        long long9 = objConsumerRecord5.timestamp();
        long long10 = objConsumerRecord5.timestamp();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
    }

    @Test
    public void test00432() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00432");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        long long12 = objConsumerRecord10.timestamp();
        int int13 = objConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.header.Headers headers14 = objConsumerRecord10.headers();
        java.lang.Object obj15 = objConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord10.timestampType();
        int int17 = objConsumerRecord10.partition();
        java.io.Serializable serializable18 = objConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
        org.junit.Assert.assertNotNull(headers14);
        org.junit.Assert.assertNull(obj15);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertEquals("'" + serializable18 + "' != '" + 1 + "'", serializable18, 1);
    }

    @Test
    public void test00433() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00433");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        org.apache.kafka.common.record.TimestampType timestampType20 = null;
        java.lang.Object obj24 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType20, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj24, (java.io.Serializable) 1);
        long long27 = objConsumerRecord26.timestamp();
        java.lang.Object obj28 = objConsumerRecord26.key();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.io.Serializable> objConsumerRecordConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>, java.io.Serializable>("", 100, (long) '#', (long) (byte) 0, timestampType12, (long) (-1), (int) (byte) 0, (int) (short) 100, objConsumerRecord26, (java.io.Serializable) (-1.0d));
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) (byte) -1, (long) 1, (long) (byte) 0, timestampType4, (long) '4', (int) (byte) 0, (int) 'a', (java.lang.Object) objConsumerRecordConsumerRecord30, (java.io.Serializable) 10.0f);
        java.lang.String str33 = objConsumerRecord32.topic();
        org.apache.kafka.common.header.Headers headers34 = objConsumerRecord32.headers();
        int int35 = objConsumerRecord32.partition();
        java.lang.Object obj36 = objConsumerRecord32.key();
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + 52L + "'", long27 == 52L);
        org.junit.Assert.assertNull(obj28);
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)" + "'", str33, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)");
        org.junit.Assert.assertNotNull(headers34);
        org.junit.Assert.assertTrue("'" + int35 + "' != '" + (-1) + "'", int35 == (-1));
        org.junit.Assert.assertNotNull(obj36);
        org.junit.Assert.assertEquals(obj36.toString(), "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 35, null = 0, serialized key size = 0, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = -1.0)");
        org.junit.Assert.assertEquals(java.lang.String.valueOf(obj36), "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 35, null = 0, serialized key size = 0, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = -1.0)");
        org.junit.Assert.assertEquals(java.util.Objects.toString(obj36), "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 35, null = 0, serialized key size = 0, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = -1.0)");
    }

    @Test
    public void test00434() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00434");
        java.lang.Object obj14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj14, (java.io.Serializable) (byte) 100);
        java.lang.Object obj17 = objConsumerRecord16.key();
        java.lang.String str18 = objConsumerRecord16.toString();
        org.apache.kafka.common.record.TimestampType timestampType19 = objConsumerRecord16.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) -1, 10L, (long) (short) 100, timestampType19, (long) 0, 0, 35, (java.lang.Object) (-1), (java.io.Serializable) 1L);
        org.apache.kafka.common.record.TimestampType timestampType33 = null;
        java.lang.Object obj37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType33, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj37, (java.io.Serializable) 1);
        java.lang.String str40 = objConsumerRecord39.toString();
        long long41 = objConsumerRecord39.offset();
        org.apache.kafka.common.header.Headers headers42 = objConsumerRecord39.headers();
        java.lang.String str43 = objConsumerRecord39.topic();
        org.apache.kafka.common.header.Headers headers44 = objConsumerRecord39.headers();
        org.apache.kafka.common.record.TimestampType timestampType50 = null;
        java.lang.Object obj54 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType50, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj54, (java.io.Serializable) 1);
        java.lang.String str57 = objConsumerRecord56.toString();
        long long58 = objConsumerRecord56.offset();
        org.apache.kafka.common.header.Headers headers59 = objConsumerRecord56.headers();
        java.lang.String str60 = objConsumerRecord56.toString();
        long long61 = objConsumerRecord56.offset();
        long long62 = objConsumerRecord56.checksum();
        java.util.Optional<java.lang.Integer> intOptional63 = objConsumerRecord56.leaderEpoch();
        java.lang.Object obj64 = objConsumerRecord56.key();
        long long65 = objConsumerRecord56.offset();
        org.apache.kafka.common.header.Headers headers66 = objConsumerRecord56.headers();
        org.apache.kafka.common.record.TimestampType timestampType71 = null;
        java.lang.Object obj75 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType71, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj75, (java.io.Serializable) 1);
        java.lang.String str78 = objConsumerRecord77.toString();
        long long79 = objConsumerRecord77.offset();
        org.apache.kafka.common.header.Headers headers80 = objConsumerRecord77.headers();
        java.lang.String str81 = objConsumerRecord77.toString();
        long long82 = objConsumerRecord77.offset();
        long long83 = objConsumerRecord77.checksum();
        java.util.Optional<java.lang.Integer> intOptional84 = objConsumerRecord77.leaderEpoch();
        java.lang.Object obj85 = objConsumerRecord77.key();
        long long86 = objConsumerRecord77.offset();
        java.util.Optional<java.lang.Integer> intOptional87 = objConsumerRecord77.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 0, 0L, 0L, timestampType19, (java.lang.Long) 1L, 1, (int) (byte) 100, (java.lang.Object) headers44, (java.io.Serializable) 0L, headers66, intOptional87);
        java.lang.Class<?> wildcardClass89 = intOptional87.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.CharSequence> genericDeclarationConsumerRecord91 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.CharSequence>("ConsumerRecord(topic = hi!, partition = 0, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = class org.apache.kafka.clients.consumer.ConsumerRecord)", (int) (byte) 0, (long) (-1), (java.lang.reflect.GenericDeclaration) wildcardClass89, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 10, value = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10))");
        java.lang.Class<?> wildcardClass92 = genericDeclarationConsumerRecord91.getClass();
        org.junit.Assert.assertNull(obj17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str18, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str40 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str40, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long41 + "' != '" + (-1L) + "'", long41 == (-1L));
        org.junit.Assert.assertNotNull(headers42);
        org.junit.Assert.assertEquals("'" + str43 + "' != '" + "" + "'", str43, "");
        org.junit.Assert.assertNotNull(headers44);
        org.junit.Assert.assertEquals("'" + str57 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str57, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long58 + "' != '" + (-1L) + "'", long58 == (-1L));
        org.junit.Assert.assertNotNull(headers59);
        org.junit.Assert.assertEquals("'" + str60 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str60, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long61 + "' != '" + (-1L) + "'", long61 == (-1L));
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + 0L + "'", long62 == 0L);
        org.junit.Assert.assertNotNull(intOptional63);
        org.junit.Assert.assertNull(obj64);
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + (-1L) + "'", long65 == (-1L));
        org.junit.Assert.assertNotNull(headers66);
        org.junit.Assert.assertEquals("'" + str78 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str78, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long79 + "' != '" + (-1L) + "'", long79 == (-1L));
        org.junit.Assert.assertNotNull(headers80);
        org.junit.Assert.assertEquals("'" + str81 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str81, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long82 + "' != '" + (-1L) + "'", long82 == (-1L));
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + 0L + "'", long83 == 0L);
        org.junit.Assert.assertNotNull(intOptional84);
        org.junit.Assert.assertNull(obj85);
        org.junit.Assert.assertTrue("'" + long86 + "' != '" + (-1L) + "'", long86 == (-1L));
        org.junit.Assert.assertNotNull(intOptional87);
        org.junit.Assert.assertNotNull(wildcardClass89);
        org.junit.Assert.assertNotNull(wildcardClass92);
    }

    @Test
    public void test00435() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00435");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        int int12 = objConsumerRecord10.serializedValueSize();
        java.lang.Object obj13 = objConsumerRecord10.key();
        int int14 = objConsumerRecord10.serializedValueSize();
        java.io.Serializable serializable15 = objConsumerRecord10.value();
        int int16 = objConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
        org.junit.Assert.assertNull(obj13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 100 + "'", int14 == 100);
        org.junit.Assert.assertEquals("'" + serializable15 + "' != '" + 1 + "'", serializable15, 1);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
    }

    @Test
    public void test00436() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00436");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        java.lang.Object obj15 = objConsumerRecord13.key();
        long long16 = objConsumerRecord13.checksum();
        long long17 = objConsumerRecord13.checksum();
        org.apache.kafka.common.record.TimestampType timestampType18 = objConsumerRecord13.timestampType();
        org.apache.kafka.common.header.Headers headers19 = objConsumerRecord13.headers();
        long long20 = objConsumerRecord13.timestamp();
        java.lang.Class<?> wildcardClass21 = objConsumerRecord13.getClass();
        org.apache.kafka.common.record.TimestampType timestampType26 = null;
        org.apache.kafka.common.record.TimestampType timestampType34 = null;
        java.lang.Object obj38 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord40 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType34, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj38, (java.io.Serializable) 1);
        long long41 = objConsumerRecord40.timestamp();
        java.util.Optional<java.lang.Integer> intOptional42 = objConsumerRecord40.leaderEpoch();
        long long43 = objConsumerRecord40.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType26, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord40, (java.io.Serializable) '#');
        java.io.Serializable serializable46 = objConsumerRecord45.value();
        org.apache.kafka.common.record.TimestampType timestampType47 = objConsumerRecord45.timestampType();
        java.lang.Class<?> wildcardClass48 = objConsumerRecord45.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.lang.reflect.GenericDeclaration> annotatedElementConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.AnnotatedElement, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = 100, leaderEpoch = null, offset = 1, null = 0, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 0.0)", 32, (long) (short) 0, (java.lang.reflect.AnnotatedElement) wildcardClass21, (java.lang.reflect.GenericDeclaration) wildcardClass48);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertNull(obj15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 52L + "'", long20 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass21);
        org.junit.Assert.assertTrue("'" + long41 + "' != '" + 52L + "'", long41 == 52L);
        org.junit.Assert.assertNotNull(intOptional42);
        org.junit.Assert.assertTrue("'" + long43 + "' != '" + 52L + "'", long43 == 52L);
        org.junit.Assert.assertEquals("'" + serializable46 + "' != '" + '#' + "'", serializable46, '#');
        org.junit.Assert.assertNull(timestampType47);
        org.junit.Assert.assertNotNull(wildcardClass48);
    }

    @Test
    public void test00437() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00437");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        java.lang.Object obj15 = objConsumerRecord13.key();
        long long16 = objConsumerRecord13.checksum();
        org.apache.kafka.common.record.TimestampType timestampType21 = null;
        java.lang.Object obj25 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType21, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj25, (java.io.Serializable) 1);
        long long28 = objConsumerRecord27.timestamp();
        java.util.Optional<java.lang.Integer> intOptional29 = objConsumerRecord27.leaderEpoch();
        long long30 = objConsumerRecord27.timestamp();
        java.lang.Class<?> wildcardClass31 = objConsumerRecord27.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (byte) -1, (long) 0, (java.lang.Object) objConsumerRecord13, (java.io.Serializable) wildcardClass31);
        java.lang.String str33 = objConsumerRecord32.topic();
        java.lang.Class<?> wildcardClass34 = objConsumerRecord32.getClass();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertNull(obj15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + long28 + "' != '" + 52L + "'", long28 == 52L);
        org.junit.Assert.assertNotNull(intOptional29);
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + 52L + "'", long30 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass31);
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "" + "'", str33, "");
        org.junit.Assert.assertNotNull(wildcardClass34);
    }

    @Test
    public void test00438() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00438");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        int int12 = objConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        java.io.Serializable serializable14 = objConsumerRecord10.value();
        int int15 = objConsumerRecord10.serializedValueSize();
        long long16 = objConsumerRecord10.timestamp();
        java.lang.Class<?> wildcardClass17 = objConsumerRecord10.getClass();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + 1 + "'", serializable14, 1);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 52L + "'", long16 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass17);
    }

    @Test
    public void test00439() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00439");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType14 = objConsumerRecord10.timestampType();
        long long15 = objConsumerRecord10.offset();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord10.timestampType();
        org.apache.kafka.common.header.Headers headers17 = objConsumerRecord10.headers();
        org.apache.kafka.common.header.Headers headers18 = objConsumerRecord10.headers();
        int int19 = objConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertNotNull(headers17);
        org.junit.Assert.assertNotNull(headers18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 100 + "'", int19 == 100);
    }

    @Test
    public void test00440() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00440");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        java.io.Serializable serializable14 = objConsumerRecord10.value();
        long long15 = objConsumerRecord10.timestamp();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + 1 + "'", serializable14, 1);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
    }

    @Test
    public void test00441() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00441");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        java.lang.String str19 = objConsumerRecord18.toString();
        java.lang.String str20 = objConsumerRecord18.toString();
        org.apache.kafka.common.record.TimestampType timestampType26 = null;
        java.lang.Object obj30 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType26, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj30, (java.io.Serializable) 1);
        java.lang.String str33 = objConsumerRecord32.toString();
        long long34 = objConsumerRecord32.offset();
        org.apache.kafka.common.header.Headers headers35 = objConsumerRecord32.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) (byte) 100, (long) (byte) 1, (long) (short) 1, timestampType4, (java.lang.Long) 10L, (int) (short) 0, (int) (short) 1, (java.lang.Object) str20, (java.io.Serializable) 10, headers35);
        java.io.Serializable serializable37 = objConsumerRecord36.value();
        java.lang.Object obj38 = objConsumerRecord36.key();
        int int39 = objConsumerRecord36.serializedKeySize();
        java.lang.String str40 = objConsumerRecord36.topic();
        int int41 = objConsumerRecord36.serializedValueSize();
        java.io.Serializable serializable42 = objConsumerRecord36.value();
        org.apache.kafka.common.header.Headers headers43 = objConsumerRecord36.headers();
        long long44 = objConsumerRecord36.timestamp();
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str33, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertNotNull(headers35);
        org.junit.Assert.assertEquals("'" + serializable37 + "' != '" + 10 + "'", serializable37, 10);
        org.junit.Assert.assertEquals("'" + obj38 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", obj38, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + 0 + "'", int39 == 0);
        org.junit.Assert.assertEquals("'" + str40 + "' != '" + "hi!" + "'", str40, "hi!");
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + 1 + "'", int41 == 1);
        org.junit.Assert.assertEquals("'" + serializable42 + "' != '" + 10 + "'", serializable42, 10);
        org.junit.Assert.assertNotNull(headers43);
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + 1L + "'", long44 == 1L);
    }

    @Test
    public void test00442() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00442");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType14 = objConsumerRecord10.timestampType();
        long long15 = objConsumerRecord10.offset();
        int int16 = objConsumerRecord10.serializedKeySize();
        java.io.Serializable serializable17 = objConsumerRecord10.value();
        java.lang.String str18 = objConsumerRecord10.topic();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertEquals("'" + serializable17 + "' != '" + 1 + "'", serializable17, 1);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
    }

    @Test
    public void test00443() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00443");
        java.lang.Object obj3 = null;
        org.apache.kafka.common.record.TimestampType timestampType15 = null;
        java.lang.Object obj19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType15, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj19, (java.io.Serializable) 1);
        long long22 = objConsumerRecord21.timestamp();
        java.util.Optional<java.lang.Integer> intOptional23 = objConsumerRecord21.leaderEpoch();
        long long24 = objConsumerRecord21.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType29 = null;
        java.lang.Object obj33 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType29, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj33, (java.io.Serializable) 1);
        java.lang.String str36 = objConsumerRecord35.toString();
        java.lang.String str37 = objConsumerRecord35.toString();
        java.lang.Class<?> wildcardClass38 = objConsumerRecord35.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (short) 10, (java.lang.Object) objConsumerRecord21, (java.io.Serializable) wildcardClass38);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.reflect.AnnotatedElement> objConsumerRecord40 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) 10, 10L, (java.lang.Object) (-1.0f), (java.lang.reflect.AnnotatedElement) wildcardClass38);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) '4', (long) (short) -1, obj3, (java.io.Serializable) (-1.0f));
        int int42 = objConsumerRecord41.partition();
        int int43 = objConsumerRecord41.partition();
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 52L + "'", long22 == 52L);
        org.junit.Assert.assertNotNull(intOptional23);
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 52L + "'", long24 == 52L);
        org.junit.Assert.assertEquals("'" + str36 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str36, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str37 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str37, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass38);
        org.junit.Assert.assertTrue("'" + int42 + "' != '" + 52 + "'", int42 == 52);
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + 52 + "'", int43 == 52);
    }

    @Test
    public void test00444() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00444");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        java.util.Optional<java.lang.Integer> intOptional15 = objConsumerRecord13.leaderEpoch();
        long long16 = objConsumerRecord13.checksum();
        java.lang.String str17 = objConsumerRecord13.toString();
        java.lang.String str18 = objConsumerRecord13.topic();
        org.apache.kafka.common.header.Headers headers19 = objConsumerRecord13.headers();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord13.leaderEpoch();
        java.lang.Object obj28 = null;
        org.apache.kafka.common.record.TimestampType timestampType39 = null;
        java.lang.Object obj43 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord45 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType39, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj43, (java.io.Serializable) 1);
        long long46 = objConsumerRecord45.timestamp();
        int int47 = objConsumerRecord45.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional48 = objConsumerRecord45.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord45, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType51 = objConsumerRecord45.timestampType();
        java.lang.String str52 = objConsumerRecord45.topic();
        long long53 = objConsumerRecord45.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType58 = null;
        java.lang.Object obj62 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType58, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj62, (java.io.Serializable) 1);
        java.lang.String str65 = objConsumerRecord64.toString();
        java.lang.String str66 = objConsumerRecord64.toString();
        long long67 = objConsumerRecord64.offset();
        java.lang.String str68 = objConsumerRecord64.topic();
        java.lang.Class<?> wildcardClass69 = objConsumerRecord64.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", 0, (long) 100, (java.lang.Object) long53, (java.io.Serializable) wildcardClass69);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.reflect.Type> objConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.reflect.Type>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 1, null = 1, serialized key size = 0, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = 10)", 35, 97L, obj28, (java.lang.reflect.Type) wildcardClass69);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.reflect.Type> strComparableConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.reflect.Type>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)", (int) (byte) 10, 97L, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 100, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = class org.apache.kafka.clients.consumer.ConsumerRecord, value = null)", (java.lang.reflect.Type) wildcardClass69);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.io.Serializable> intOptionalConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)", (int) (byte) -1, 0L, intOptional20, (java.io.Serializable) (byte) 10);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str17, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long46 + "' != '" + 52L + "'", long46 == 52L);
        org.junit.Assert.assertTrue("'" + int47 + "' != '" + 100 + "'", int47 == 100);
        org.junit.Assert.assertNotNull(intOptional48);
        org.junit.Assert.assertNull(timestampType51);
        org.junit.Assert.assertEquals("'" + str52 + "' != '" + "" + "'", str52, "");
        org.junit.Assert.assertTrue("'" + long53 + "' != '" + 52L + "'", long53 == 52L);
        org.junit.Assert.assertEquals("'" + str65 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str65, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str66 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str66, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long67 + "' != '" + (-1L) + "'", long67 == (-1L));
        org.junit.Assert.assertEquals("'" + str68 + "' != '" + "" + "'", str68, "");
        org.junit.Assert.assertNotNull(wildcardClass69);
    }

    @Test
    public void test00445() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00445");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        int int13 = objConsumerRecord10.serializedValueSize();
        java.lang.String str14 = objConsumerRecord10.topic();
        java.util.Optional<java.lang.Integer> intOptional15 = objConsumerRecord10.leaderEpoch();
        java.lang.Object obj16 = objConsumerRecord10.key();
        long long17 = objConsumerRecord10.timestamp();
        java.io.Serializable serializable18 = objConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 100 + "'", int13 == 100);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertNull(obj16);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertEquals("'" + serializable18 + "' != '" + 1 + "'", serializable18, 1);
    }

    @Test
    public void test00446() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00446");
        java.lang.Object obj10 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj10, (java.io.Serializable) (byte) 100);
        java.lang.Object obj13 = objConsumerRecord12.key();
        int int14 = objConsumerRecord12.partition();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 1, NoTimestampType = 1, serialized key size = 0, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = NoTimestampType)", (int) ' ', (long) '#', (java.lang.Object) int14, (java.io.Serializable) "ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)");
        int int17 = objConsumerRecord16.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = objConsumerRecord16.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType26 = null;
        java.lang.Object obj30 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType26, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj30, (java.io.Serializable) 1);
        org.apache.kafka.common.record.TimestampType timestampType33 = objConsumerRecord32.timestampType();
        java.util.Optional<java.lang.Integer> intOptional34 = objConsumerRecord32.leaderEpoch();
        long long35 = objConsumerRecord32.offset();
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        java.lang.Object obj44 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType40, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj44, (java.io.Serializable) 1);
        long long47 = objConsumerRecord46.timestamp();
        long long48 = objConsumerRecord46.timestamp();
        int int49 = objConsumerRecord46.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional50 = objConsumerRecord46.leaderEpoch();
        java.lang.Class<?> wildcardClass51 = intOptional50.getClass();
        org.apache.kafka.common.record.TimestampType timestampType56 = null;
        org.apache.kafka.common.record.TimestampType timestampType64 = null;
        java.lang.Object obj68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType64, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj68, (java.io.Serializable) 1);
        long long71 = objConsumerRecord70.timestamp();
        java.util.Optional<java.lang.Integer> intOptional72 = objConsumerRecord70.leaderEpoch();
        long long73 = objConsumerRecord70.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType56, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord70, (java.io.Serializable) '#');
        int int76 = objConsumerRecord75.partition();
        org.apache.kafka.common.header.Headers headers77 = objConsumerRecord75.headers();
        org.apache.kafka.common.record.TimestampType timestampType82 = null;
        java.lang.Object obj86 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType82, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj86, (java.io.Serializable) 1);
        org.apache.kafka.common.record.TimestampType timestampType89 = objConsumerRecord88.timestampType();
        java.util.Optional<java.lang.Integer> intOptional90 = objConsumerRecord88.leaderEpoch();
        long long91 = objConsumerRecord88.offset();
        java.lang.String str92 = objConsumerRecord88.toString();
        java.lang.Object obj93 = objConsumerRecord88.key();
        java.io.Serializable serializable94 = objConsumerRecord88.value();
        java.util.Optional<java.lang.Integer> intOptional95 = objConsumerRecord88.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", 10, (long) 52, (long) (short) 10, timestampType18, (java.lang.Long) 35L, (int) (short) 0, (int) (short) 1, (java.lang.Object) long35, (java.io.Serializable) wildcardClass51, headers77, intOptional95);
        org.junit.Assert.assertNull(obj13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 97 + "'", int14 == 97);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 32 + "'", int17 == 32);
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNull(timestampType33);
        org.junit.Assert.assertNotNull(intOptional34);
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + (-1L) + "'", long35 == (-1L));
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 52L + "'", long47 == 52L);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + 52L + "'", long48 == 52L);
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 10 + "'", int49 == 10);
        org.junit.Assert.assertNotNull(intOptional50);
        org.junit.Assert.assertNotNull(wildcardClass51);
        org.junit.Assert.assertTrue("'" + long71 + "' != '" + 52L + "'", long71 == 52L);
        org.junit.Assert.assertNotNull(intOptional72);
        org.junit.Assert.assertTrue("'" + long73 + "' != '" + 52L + "'", long73 == 52L);
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + (-1) + "'", int76 == (-1));
        org.junit.Assert.assertNotNull(headers77);
        org.junit.Assert.assertNull(timestampType89);
        org.junit.Assert.assertNotNull(intOptional90);
        org.junit.Assert.assertTrue("'" + long91 + "' != '" + (-1L) + "'", long91 == (-1L));
        org.junit.Assert.assertEquals("'" + str92 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str92, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNull(obj93);
        org.junit.Assert.assertEquals("'" + serializable94 + "' != '" + 1 + "'", serializable94, 1);
        org.junit.Assert.assertNotNull(intOptional95);
    }

    @Test
    public void test00447() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00447");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        java.lang.String str14 = objConsumerRecord13.toString();
        long long15 = objConsumerRecord13.offset();
        java.lang.String str16 = objConsumerRecord13.toString();
        long long17 = objConsumerRecord13.checksum();
        int int18 = objConsumerRecord13.serializedValueSize();
        long long19 = objConsumerRecord13.checksum();
        org.apache.kafka.common.header.Headers headers20 = objConsumerRecord13.headers();
        org.apache.kafka.common.record.TimestampType timestampType28 = null;
        java.lang.Object obj32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType28, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj32, (java.io.Serializable) 1);
        long long35 = objConsumerRecord34.timestamp();
        java.util.Optional<java.lang.Integer> intOptional36 = objConsumerRecord34.leaderEpoch();
        long long37 = objConsumerRecord34.checksum();
        org.apache.kafka.common.record.TimestampType timestampType38 = objConsumerRecord34.timestampType();
        java.lang.Object obj45 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj45, (java.io.Serializable) (byte) 100);
        org.apache.kafka.common.record.TimestampType timestampType52 = null;
        java.lang.Object obj56 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType52, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj56, (java.io.Serializable) 1);
        long long59 = objConsumerRecord58.timestamp();
        java.lang.Object obj60 = objConsumerRecord58.key();
        long long61 = objConsumerRecord58.checksum();
        java.lang.Class<?> wildcardClass62 = objConsumerRecord58.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) 1, (long) '#', obj45, (java.io.Serializable) wildcardClass62);
        java.lang.Object obj64 = objConsumerRecord63.key();
        long long65 = objConsumerRecord63.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType66 = objConsumerRecord63.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType67 = objConsumerRecord63.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = -1, null = 1, serialized key size = 35, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 0, (-1L), (java.lang.Object) objConsumerRecord34, (java.io.Serializable) timestampType67);
        java.lang.Class<?> wildcardClass69 = objConsumerRecord68.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 0, leaderEpoch = null, offset = 1, NoTimestampType = 97, serialized key size = 35, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)", 0, (long) 97, (java.lang.Object) headers20, (java.io.Serializable) wildcardClass69);
        long long71 = objConsumerRecord70.checksum();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 100 + "'", int18 == 100);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + 52L + "'", long35 == 52L);
        org.junit.Assert.assertNotNull(intOptional36);
        org.junit.Assert.assertTrue("'" + long37 + "' != '" + 0L + "'", long37 == 0L);
        org.junit.Assert.assertNull(timestampType38);
        org.junit.Assert.assertTrue("'" + long59 + "' != '" + 52L + "'", long59 == 52L);
        org.junit.Assert.assertNull(obj60);
        org.junit.Assert.assertTrue("'" + long61 + "' != '" + 0L + "'", long61 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass62);
        org.junit.Assert.assertNull(obj64);
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + (-1L) + "'", long65 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType66 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType66.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType67 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType67.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass69);
        org.junit.Assert.assertTrue("'" + long71 + "' != '" + (-1L) + "'", long71 == (-1L));
    }

    @Test
    public void test00448() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00448");
        java.lang.Object obj15 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj15, (java.io.Serializable) (byte) 100);
        java.lang.Object obj18 = objConsumerRecord17.key();
        java.lang.String str19 = objConsumerRecord17.toString();
        org.apache.kafka.common.record.TimestampType timestampType20 = objConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) -1, 10L, (long) (short) 100, timestampType20, (long) 0, 0, 35, (java.lang.Object) (-1), (java.io.Serializable) 1L);
        org.apache.kafka.common.record.TimestampType timestampType34 = null;
        org.apache.kafka.common.record.TimestampType timestampType42 = null;
        java.lang.Object obj46 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType42, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj46, (java.io.Serializable) 1);
        long long49 = objConsumerRecord48.timestamp();
        java.util.Optional<java.lang.Integer> intOptional50 = objConsumerRecord48.leaderEpoch();
        long long51 = objConsumerRecord48.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType34, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord48, (java.io.Serializable) '#');
        int int54 = objConsumerRecord53.partition();
        java.util.Optional<java.lang.Integer> intOptional55 = objConsumerRecord53.leaderEpoch();
        long long56 = objConsumerRecord53.checksum();
        org.apache.kafka.common.header.Headers headers57 = objConsumerRecord53.headers();
        java.lang.Object obj62 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj62, (java.io.Serializable) (byte) 100);
        long long65 = objConsumerRecord64.timestamp();
        org.apache.kafka.common.header.Headers headers66 = objConsumerRecord64.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 0, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 0, (long) (short) 1, (long) '4', timestampType20, (java.lang.Long) 0L, (int) '4', (int) (byte) 10, (java.lang.Object) headers57, (java.io.Serializable) 10, headers66);
        org.apache.kafka.common.record.TimestampType timestampType80 = null;
        java.lang.Object obj84 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType80, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj84, (java.io.Serializable) 1);
        long long87 = objConsumerRecord86.timestamp();
        int int88 = objConsumerRecord86.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional89 = objConsumerRecord86.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord91 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord86, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType92 = objConsumerRecord86.timestampType();
        java.lang.String str93 = objConsumerRecord86.topic();
        long long94 = objConsumerRecord86.timestamp();
        java.lang.Object obj95 = objConsumerRecord86.key();
        org.apache.kafka.common.header.Headers headers96 = objConsumerRecord86.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.String> strComparableConsumerRecord97 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.String>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 1, null = 1, serialized key size = 0, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = 10)", (int) ' ', 0L, (long) (-1), timestampType20, (java.lang.Long) 32L, (int) (byte) 1, 0, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100), partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = -1)", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = 100, leaderEpoch = null, offset = 1, null = 0, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 0.0)", headers96);
        java.lang.Class<?> wildcardClass98 = headers96.getClass();
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str19, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long49 + "' != '" + 52L + "'", long49 == 52L);
        org.junit.Assert.assertNotNull(intOptional50);
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + 52L + "'", long51 == 52L);
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + (-1) + "'", int54 == (-1));
        org.junit.Assert.assertNotNull(intOptional55);
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + 1L + "'", long56 == 1L);
        org.junit.Assert.assertNotNull(headers57);
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + (-1L) + "'", long65 == (-1L));
        org.junit.Assert.assertNotNull(headers66);
        org.junit.Assert.assertTrue("'" + long87 + "' != '" + 52L + "'", long87 == 52L);
        org.junit.Assert.assertTrue("'" + int88 + "' != '" + 100 + "'", int88 == 100);
        org.junit.Assert.assertNotNull(intOptional89);
        org.junit.Assert.assertNull(timestampType92);
        org.junit.Assert.assertEquals("'" + str93 + "' != '" + "" + "'", str93, "");
        org.junit.Assert.assertTrue("'" + long94 + "' != '" + 52L + "'", long94 == 52L);
        org.junit.Assert.assertNull(obj95);
        org.junit.Assert.assertNotNull(headers96);
        org.junit.Assert.assertNotNull(wildcardClass98);
    }

    @Test
    public void test00449() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00449");
        java.lang.Object obj15 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj15, (java.io.Serializable) (byte) 100);
        java.lang.Object obj18 = objConsumerRecord17.key();
        java.lang.String str19 = objConsumerRecord17.toString();
        org.apache.kafka.common.record.TimestampType timestampType20 = objConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType28 = null;
        java.lang.Object obj32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType28, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj32, (java.io.Serializable) 1);
        long long35 = objConsumerRecord34.offset();
        long long36 = objConsumerRecord34.checksum();
        org.apache.kafka.common.header.Headers headers37 = objConsumerRecord34.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), (long) (short) 1, (long) 0, timestampType20, 10L, 97, (int) '4', (java.lang.Object) headers37, (java.io.Serializable) 0.0d);
        org.apache.kafka.common.record.TimestampType timestampType47 = null;
        java.lang.Object obj51 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType47, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj51, (java.io.Serializable) 1);
        java.lang.String str54 = objConsumerRecord53.toString();
        long long55 = objConsumerRecord53.offset();
        org.apache.kafka.common.header.Headers headers56 = objConsumerRecord53.headers();
        java.lang.String str57 = objConsumerRecord53.toString();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (int) 'a', 35L, (long) 0, timestampType20, 52L, (int) '#', 10, (java.lang.Object) objConsumerRecord53, (java.io.Serializable) true);
        java.lang.Object obj67 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj67, (java.io.Serializable) (byte) 100);
        java.lang.Class<?> wildcardClass70 = objConsumerRecord69.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) 1, (long) (short) 0, (-1L), timestampType20, 52L, 100, (int) (short) 1, (java.lang.Object) (short) 100, (java.io.Serializable) wildcardClass70);
        java.lang.String str72 = objConsumerRecord71.topic();
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str19, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + (-1L) + "'", long35 == (-1L));
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + 0L + "'", long36 == 0L);
        org.junit.Assert.assertNotNull(headers37);
        org.junit.Assert.assertEquals("'" + str54 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str54, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + (-1L) + "'", long55 == (-1L));
        org.junit.Assert.assertNotNull(headers56);
        org.junit.Assert.assertEquals("'" + str57 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str57, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass70);
        org.junit.Assert.assertEquals("'" + str72 + "' != '" + "" + "'", str72, "");
    }

    @Test
    public void test00450() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00450");
        java.lang.Object obj4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.Object> strComparableConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.Object>("ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", (int) ' ', (long) 97, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100), partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = -1)", obj4);
    }

    @Test
    public void test00451() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00451");
        org.apache.kafka.common.record.TimestampType timestampType8 = null;
        java.lang.Object obj12 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType8, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj12, (java.io.Serializable) 1);
        long long15 = objConsumerRecord14.timestamp();
        int int16 = objConsumerRecord14.serializedValueSize();
        java.lang.Object obj17 = objConsumerRecord14.key();
        long long18 = objConsumerRecord14.offset();
        java.io.Serializable serializable19 = objConsumerRecord14.value();
        long long20 = objConsumerRecord14.offset();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.Object> strConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.Object>("", (int) (byte) -1, (long) (byte) 1, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 1, null = 1, serialized key size = 0, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = 10)", (java.lang.Object) long20);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 100 + "'", int16 == 100);
        org.junit.Assert.assertNull(obj17);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertEquals("'" + serializable19 + "' != '" + 1 + "'", serializable19, 1);
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
    }

    @Test
    public void test00452() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00452");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.String> strConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.String>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 35, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 97, (long) (byte) 0, "", "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 0, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = class org.apache.kafka.clients.consumer.ConsumerRecord)");
    }

    @Test
    public void test00453() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00453");
        java.lang.Object obj14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj14, (java.io.Serializable) (byte) 100);
        java.lang.Object obj17 = objConsumerRecord16.key();
        java.lang.String str18 = objConsumerRecord16.toString();
        org.apache.kafka.common.record.TimestampType timestampType19 = objConsumerRecord16.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        java.lang.Object obj31 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType27, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj31, (java.io.Serializable) 1);
        long long34 = objConsumerRecord33.offset();
        long long35 = objConsumerRecord33.checksum();
        org.apache.kafka.common.header.Headers headers36 = objConsumerRecord33.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), (long) (short) 1, (long) 0, timestampType19, 10L, 97, (int) '4', (java.lang.Object) headers36, (java.io.Serializable) 0.0d);
        org.apache.kafka.common.record.TimestampType timestampType46 = null;
        java.lang.Object obj50 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType46, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj50, (java.io.Serializable) 1);
        java.lang.String str53 = objConsumerRecord52.toString();
        java.util.Optional<java.lang.Integer> intOptional54 = objConsumerRecord52.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional55 = objConsumerRecord52.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) ' ', (long) (byte) 1, 0L, timestampType19, (-1L), (int) (byte) -1, (int) (short) 100, (java.lang.Object) objConsumerRecord52, (java.io.Serializable) 100.0f);
        org.apache.kafka.common.record.TimestampType timestampType65 = null;
        java.lang.Object obj69 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType65, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj69, (java.io.Serializable) 1);
        long long72 = objConsumerRecord71.timestamp();
        java.util.Optional<java.lang.Integer> intOptional73 = objConsumerRecord71.leaderEpoch();
        int int74 = objConsumerRecord71.serializedValueSize();
        java.lang.String str75 = objConsumerRecord71.topic();
        long long76 = objConsumerRecord71.offset();
        org.apache.kafka.common.record.TimestampType timestampType81 = null;
        java.lang.Object obj85 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType81, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj85, (java.io.Serializable) 1);
        long long88 = objConsumerRecord87.timestamp();
        java.lang.Object obj89 = objConsumerRecord87.key();
        long long90 = objConsumerRecord87.checksum();
        long long91 = objConsumerRecord87.checksum();
        org.apache.kafka.common.record.TimestampType timestampType92 = objConsumerRecord87.timestampType();
        org.apache.kafka.common.header.Headers headers93 = objConsumerRecord87.headers();
        long long94 = objConsumerRecord87.timestamp();
        java.lang.Class<?> wildcardClass95 = objConsumerRecord87.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord96 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)", (int) (byte) 100, (long) 0, (java.lang.Object) objConsumerRecord71, (java.io.Serializable) wildcardClass95);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord97 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 0, null = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '4', (long) 52, (java.lang.Object) (-1L), (java.io.Serializable) (byte) 100);
        long long98 = objConsumerRecord97.checksum();
        int int99 = objConsumerRecord97.partition();
        org.junit.Assert.assertNull(obj17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str18, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + 0L + "'", long35 == 0L);
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str53, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional54);
        org.junit.Assert.assertNotNull(intOptional55);
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + 52L + "'", long72 == 52L);
        org.junit.Assert.assertNotNull(intOptional73);
        org.junit.Assert.assertTrue("'" + int74 + "' != '" + 100 + "'", int74 == 100);
        org.junit.Assert.assertEquals("'" + str75 + "' != '" + "" + "'", str75, "");
        org.junit.Assert.assertTrue("'" + long76 + "' != '" + (-1L) + "'", long76 == (-1L));
        org.junit.Assert.assertTrue("'" + long88 + "' != '" + 52L + "'", long88 == 52L);
        org.junit.Assert.assertNull(obj89);
        org.junit.Assert.assertTrue("'" + long90 + "' != '" + 0L + "'", long90 == 0L);
        org.junit.Assert.assertTrue("'" + long91 + "' != '" + 0L + "'", long91 == 0L);
        org.junit.Assert.assertNull(timestampType92);
        org.junit.Assert.assertNotNull(headers93);
        org.junit.Assert.assertTrue("'" + long94 + "' != '" + 52L + "'", long94 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass95);
        org.junit.Assert.assertTrue("'" + long98 + "' != '" + (-1L) + "'", long98 == (-1L));
        org.junit.Assert.assertTrue("'" + int99 + "' != '" + 52 + "'", int99 == 52);
    }

    @Test
    public void test00454() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00454");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        org.apache.kafka.common.record.TimestampType timestampType14 = objConsumerRecord13.timestampType();
        long long15 = objConsumerRecord13.checksum();
        long long16 = objConsumerRecord13.timestamp();
        java.lang.String str17 = objConsumerRecord13.toString();
        org.apache.kafka.common.header.Headers headers18 = objConsumerRecord13.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 1, NoTimestampType = 1, serialized key size = 0, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = NoTimestampType)", 100, (long) ' ', (java.lang.Object) headers18, (java.io.Serializable) (byte) -1);
        long long21 = objConsumerRecord20.timestamp();
        java.lang.Class<?> wildcardClass22 = objConsumerRecord20.getClass();
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 0L + "'", long15 == 0L);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 52L + "'", long16 == 52L);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str17, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(headers18);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass22);
    }

    @Test
    public void test00455() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00455");
        java.lang.Object obj15 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj15, (java.io.Serializable) (byte) 100);
        java.lang.Object obj18 = objConsumerRecord17.key();
        java.lang.String str19 = objConsumerRecord17.toString();
        org.apache.kafka.common.record.TimestampType timestampType20 = objConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType33 = null;
        java.lang.Object obj37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType33, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj37, (java.io.Serializable) 1);
        java.lang.String str40 = objConsumerRecord39.toString();
        java.lang.String str41 = objConsumerRecord39.toString();
        java.lang.Class<?> wildcardClass42 = objConsumerRecord39.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type> charSequenceConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.Type>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '#', (long) (short) -1, (java.lang.CharSequence) "", (java.lang.reflect.Type) wildcardClass42);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement> charSequenceConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.AnnotatedElement>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", (int) '#', 100L, (long) 'a', timestampType20, (long) (byte) 100, (int) (byte) -1, 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (java.lang.reflect.AnnotatedElement) wildcardClass42);
        org.apache.kafka.common.record.TimestampType timestampType52 = null;
        java.lang.Object obj56 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType52, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj56, (java.io.Serializable) 1);
        java.lang.String str59 = objConsumerRecord58.toString();
        long long60 = objConsumerRecord58.offset();
        java.lang.String str61 = objConsumerRecord58.toString();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", 100, (long) 97, (long) 'a', timestampType20, (long) (byte) 10, (int) (byte) 10, (int) (byte) -1, (java.lang.Object) objConsumerRecord58, (java.io.Serializable) (byte) 0);
        org.apache.kafka.common.record.TimestampType timestampType71 = null;
        org.apache.kafka.common.record.TimestampType timestampType80 = null;
        java.lang.Object obj84 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType80, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj84, (java.io.Serializable) 1);
        long long87 = objConsumerRecord86.timestamp();
        java.util.Optional<java.lang.Integer> intOptional88 = objConsumerRecord86.leaderEpoch();
        java.lang.Class<?> wildcardClass89 = objConsumerRecord86.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.GenericDeclaration> charSequenceConsumerRecord90 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) '4', (long) 1, (long) 0, timestampType71, 100L, 1, (int) (short) 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (java.lang.reflect.GenericDeclaration) wildcardClass89);
        java.io.Serializable serializable91 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord92 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", 100, (long) (-1), (long) (short) -1, timestampType20, (long) 100, (int) (short) 0, (int) (byte) 100, (java.lang.Object) 1, serializable91);
        int int93 = objConsumerRecord92.partition();
        long long94 = objConsumerRecord92.checksum();
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str19, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str40 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str40, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str41 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str41, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass42);
        org.junit.Assert.assertEquals("'" + str59 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str59, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str61, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long87 + "' != '" + 52L + "'", long87 == 52L);
        org.junit.Assert.assertNotNull(intOptional88);
        org.junit.Assert.assertNotNull(wildcardClass89);
        org.junit.Assert.assertTrue("'" + int93 + "' != '" + 100 + "'", int93 == 100);
        org.junit.Assert.assertTrue("'" + long94 + "' != '" + 100L + "'", long94 == 100L);
    }

    @Test
    public void test00456() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00456");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        long long13 = objConsumerRecord10.timestamp();
        long long14 = objConsumerRecord10.checksum();
        int int15 = objConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional16 = objConsumerRecord10.leaderEpoch();
        java.io.Serializable serializable17 = objConsumerRecord10.value();
        java.lang.String str18 = objConsumerRecord10.topic();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertEquals("'" + serializable17 + "' != '" + 1 + "'", serializable17, 1);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
    }

    @Test
    public void test00457() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00457");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        long long19 = objConsumerRecord18.timestamp();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord18.leaderEpoch();
        long long21 = objConsumerRecord18.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType4, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord18, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional24 = objConsumerRecord18.leaderEpoch();
        java.lang.String str25 = objConsumerRecord18.topic();
        long long26 = objConsumerRecord18.checksum();
        long long27 = objConsumerRecord18.timestamp();
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertNotNull(intOptional24);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "" + "'", str25, "");
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + 0L + "'", long26 == 0L);
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + 52L + "'", long27 == 52L);
    }

    @Test
    public void test00458() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00458");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        long long12 = objConsumerRecord10.timestamp();
        int int13 = objConsumerRecord10.serializedKeySize();
        java.lang.Object obj14 = objConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers15 = objConsumerRecord10.headers();
        int int16 = objConsumerRecord10.partition();
        java.lang.Class<?> wildcardClass17 = objConsumerRecord10.getClass();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
        org.junit.Assert.assertNull(obj14);
        org.junit.Assert.assertNotNull(headers15);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertNotNull(wildcardClass17);
    }

    @Test
    public void test00459() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00459");
        org.apache.kafka.common.record.TimestampType timestampType11 = null;
        org.apache.kafka.common.record.TimestampType timestampType19 = null;
        java.lang.Object obj23 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType19, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj23, (java.io.Serializable) 1);
        long long26 = objConsumerRecord25.timestamp();
        java.util.Optional<java.lang.Integer> intOptional27 = objConsumerRecord25.leaderEpoch();
        long long28 = objConsumerRecord25.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType11, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord25, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional31 = objConsumerRecord25.leaderEpoch();
        java.lang.Object obj39 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj39, (java.io.Serializable) (byte) 100);
        java.lang.Object obj42 = objConsumerRecord41.key();
        java.lang.String str43 = objConsumerRecord41.toString();
        org.apache.kafka.common.record.TimestampType timestampType44 = objConsumerRecord41.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) -1, 10L, (long) (short) 100, timestampType44, (long) 0, 0, 35, (java.lang.Object) (-1), (java.io.Serializable) 1L);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType> intOptionalConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.kafka.common.record.TimestampType>("", (-1), (long) (byte) -1, intOptional31, timestampType44);
        java.io.Serializable serializable56 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = -1, null = 10, serialized key size = 100, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = #)", (int) '#', (long) (short) 100, 10L, timestampType44, (long) 52, (int) (short) -1, (int) (short) 100, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 0, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = class org.apache.kafka.clients.consumer.ConsumerRecord)", serializable56);
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + 52L + "'", long26 == 52L);
        org.junit.Assert.assertNotNull(intOptional27);
        org.junit.Assert.assertTrue("'" + long28 + "' != '" + 52L + "'", long28 == 52L);
        org.junit.Assert.assertNotNull(intOptional31);
        org.junit.Assert.assertNull(obj42);
        org.junit.Assert.assertEquals("'" + str43 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str43, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType44 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType44.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test00460() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00460");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers12 = objConsumerRecord10.headers();
        org.apache.kafka.common.header.Headers headers13 = objConsumerRecord10.headers();
        long long14 = objConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
    }

    @Test
    public void test00461() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00461");
        org.apache.kafka.common.record.TimestampType timestampType10 = null;
        java.lang.Object obj14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType10, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj14, (java.io.Serializable) 1);
        long long17 = objConsumerRecord16.timestamp();
        int int18 = objConsumerRecord16.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional19 = objConsumerRecord16.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", 100, (long) 100, (java.lang.Object) objConsumerRecord16, (java.io.Serializable) false);
        org.apache.kafka.common.record.TimestampType timestampType22 = objConsumerRecord16.timestampType();
        java.lang.String str23 = objConsumerRecord16.topic();
        long long24 = objConsumerRecord16.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType29 = null;
        java.lang.Object obj33 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType29, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj33, (java.io.Serializable) 1);
        java.lang.String str36 = objConsumerRecord35.toString();
        java.lang.String str37 = objConsumerRecord35.toString();
        long long38 = objConsumerRecord35.offset();
        java.lang.String str39 = objConsumerRecord35.topic();
        java.lang.Class<?> wildcardClass40 = objConsumerRecord35.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", 0, (long) 100, (java.lang.Object) long24, (java.io.Serializable) wildcardClass40);
        java.util.Optional<java.lang.Integer> intOptional42 = objConsumerRecord41.leaderEpoch();
        int int43 = objConsumerRecord41.partition();
        long long44 = objConsumerRecord41.checksum();
        int int45 = objConsumerRecord41.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 100 + "'", int18 == 100);
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertNull(timestampType22);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "" + "'", str23, "");
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 52L + "'", long24 == 52L);
        org.junit.Assert.assertEquals("'" + str36 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str36, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str37 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str37, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + (-1L) + "'", long38 == (-1L));
        org.junit.Assert.assertEquals("'" + str39 + "' != '" + "" + "'", str39, "");
        org.junit.Assert.assertNotNull(wildcardClass40);
        org.junit.Assert.assertNotNull(intOptional42);
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + 0 + "'", int43 == 0);
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + (-1L) + "'", long44 == (-1L));
        org.junit.Assert.assertTrue("'" + int45 + "' != '" + (-1) + "'", int45 == (-1));
    }

    @Test
    public void test00462() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00462");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers13 = objConsumerRecord10.headers();
        java.lang.String str14 = objConsumerRecord10.toString();
        long long15 = objConsumerRecord10.offset();
        long long16 = objConsumerRecord10.checksum();
        int int17 = objConsumerRecord10.partition();
        int int18 = objConsumerRecord10.serializedKeySize();
        int int19 = objConsumerRecord10.partition();
        org.apache.kafka.common.header.Headers headers20 = objConsumerRecord10.headers();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 10 + "'", int18 == 10);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertNotNull(headers20);
    }

    @Test
    public void test00463() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00463");
        java.lang.Object obj15 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj15, (java.io.Serializable) (byte) 100);
        java.lang.Object obj18 = objConsumerRecord17.key();
        java.lang.String str19 = objConsumerRecord17.toString();
        org.apache.kafka.common.record.TimestampType timestampType20 = objConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType28 = null;
        java.lang.Object obj32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType28, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj32, (java.io.Serializable) 1);
        long long35 = objConsumerRecord34.offset();
        long long36 = objConsumerRecord34.checksum();
        org.apache.kafka.common.header.Headers headers37 = objConsumerRecord34.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), (long) (short) 1, (long) 0, timestampType20, 10L, 97, (int) '4', (java.lang.Object) headers37, (java.io.Serializable) 0.0d);
        org.apache.kafka.common.record.TimestampType timestampType47 = null;
        java.lang.Object obj51 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType47, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj51, (java.io.Serializable) 1);
        java.lang.String str54 = objConsumerRecord53.toString();
        long long55 = objConsumerRecord53.offset();
        org.apache.kafka.common.header.Headers headers56 = objConsumerRecord53.headers();
        java.lang.String str57 = objConsumerRecord53.toString();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (int) 'a', 35L, (long) 0, timestampType20, 52L, (int) '#', 10, (java.lang.Object) objConsumerRecord53, (java.io.Serializable) true);
        java.lang.Object obj63 = null;
        org.apache.kafka.common.record.TimestampType timestampType69 = null;
        java.lang.Object obj73 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType69, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj73, (java.io.Serializable) 1);
        long long76 = objConsumerRecord75.timestamp();
        long long77 = objConsumerRecord75.timestamp();
        int int78 = objConsumerRecord75.serializedKeySize();
        org.apache.kafka.common.header.Headers headers79 = objConsumerRecord75.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), 35L, (long) 'a', timestampType20, (java.lang.Long) 0L, 0, 97, obj63, (java.io.Serializable) (byte) 1, headers79);
        java.util.Optional<java.lang.Integer> intOptional81 = objConsumerRecord80.leaderEpoch();
        java.io.Serializable serializable82 = objConsumerRecord80.value();
        java.lang.Object obj83 = objConsumerRecord80.key();
        java.lang.Object obj84 = objConsumerRecord80.key();
        java.lang.String str85 = objConsumerRecord80.toString();
        java.lang.String str86 = objConsumerRecord80.toString();
        java.lang.Class<?> wildcardClass87 = objConsumerRecord80.getClass();
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str19, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + (-1L) + "'", long35 == (-1L));
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + 0L + "'", long36 == 0L);
        org.junit.Assert.assertNotNull(headers37);
        org.junit.Assert.assertEquals("'" + str54 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str54, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + (-1L) + "'", long55 == (-1L));
        org.junit.Assert.assertNotNull(headers56);
        org.junit.Assert.assertEquals("'" + str57 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str57, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long76 + "' != '" + 52L + "'", long76 == 52L);
        org.junit.Assert.assertTrue("'" + long77 + "' != '" + 52L + "'", long77 == 52L);
        org.junit.Assert.assertTrue("'" + int78 + "' != '" + 10 + "'", int78 == 10);
        org.junit.Assert.assertNotNull(headers79);
        org.junit.Assert.assertNotNull(intOptional81);
        org.junit.Assert.assertEquals("'" + serializable82 + "' != '" + (byte) 1 + "'", serializable82, (byte) 1);
        org.junit.Assert.assertNull(obj83);
        org.junit.Assert.assertNull(obj84);
        org.junit.Assert.assertEquals("'" + str85 + "' != '" + "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = 97, serialized key size = 0, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str85, "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = 97, serialized key size = 0, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str86 + "' != '" + "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = 97, serialized key size = 0, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str86, "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = 97, serialized key size = 0, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(wildcardClass87);
    }

    @Test
    public void test00464() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00464");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        long long19 = objConsumerRecord18.timestamp();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord18.leaderEpoch();
        long long21 = objConsumerRecord18.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType4, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord18, (java.io.Serializable) '#');
        java.util.Optional<java.lang.Integer> intOptional24 = objConsumerRecord18.leaderEpoch();
        java.lang.String str25 = objConsumerRecord18.topic();
        java.lang.Object obj26 = objConsumerRecord18.key();
        java.io.Serializable serializable27 = objConsumerRecord18.value();
        java.lang.String str28 = objConsumerRecord18.topic();
        org.apache.kafka.common.header.Headers headers29 = objConsumerRecord18.headers();
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertNotNull(intOptional24);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "" + "'", str25, "");
        org.junit.Assert.assertNull(obj26);
        org.junit.Assert.assertEquals("'" + serializable27 + "' != '" + 1 + "'", serializable27, 1);
        org.junit.Assert.assertEquals("'" + str28 + "' != '" + "" + "'", str28, "");
        org.junit.Assert.assertNotNull(headers29);
    }

    @Test
    public void test00465() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00465");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        java.lang.String str13 = objConsumerRecord10.toString();
        java.lang.String str14 = objConsumerRecord10.toString();
        java.lang.String str15 = objConsumerRecord10.topic();
        java.lang.String str16 = objConsumerRecord10.toString();
        long long17 = objConsumerRecord10.checksum();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "" + "'", str15, "");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
    }

    @Test
    public void test00466() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00466");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Iterable<org.apache.kafka.common.header.Header>> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Iterable<org.apache.kafka.common.header.Header>> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.lang.Iterable<org.apache.kafka.common.header.Header>>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test00467() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00467");
        java.lang.Object obj15 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj15, (java.io.Serializable) (byte) 100);
        java.lang.Object obj18 = objConsumerRecord17.key();
        java.lang.String str19 = objConsumerRecord17.toString();
        org.apache.kafka.common.record.TimestampType timestampType20 = objConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType28 = null;
        java.lang.Object obj32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType28, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj32, (java.io.Serializable) 1);
        long long35 = objConsumerRecord34.offset();
        long long36 = objConsumerRecord34.checksum();
        org.apache.kafka.common.header.Headers headers37 = objConsumerRecord34.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), (long) (short) 1, (long) 0, timestampType20, 10L, 97, (int) '4', (java.lang.Object) headers37, (java.io.Serializable) 0.0d);
        org.apache.kafka.common.record.TimestampType timestampType47 = null;
        java.lang.Object obj51 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType47, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj51, (java.io.Serializable) 1);
        java.lang.String str54 = objConsumerRecord53.toString();
        long long55 = objConsumerRecord53.offset();
        org.apache.kafka.common.header.Headers headers56 = objConsumerRecord53.headers();
        java.lang.String str57 = objConsumerRecord53.toString();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (int) 'a', 35L, (long) 0, timestampType20, 52L, (int) '#', 10, (java.lang.Object) objConsumerRecord53, (java.io.Serializable) true);
        java.lang.Object obj63 = null;
        org.apache.kafka.common.record.TimestampType timestampType69 = null;
        java.lang.Object obj73 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType69, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj73, (java.io.Serializable) 1);
        long long76 = objConsumerRecord75.timestamp();
        long long77 = objConsumerRecord75.timestamp();
        int int78 = objConsumerRecord75.serializedKeySize();
        org.apache.kafka.common.header.Headers headers79 = objConsumerRecord75.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), 35L, (long) 'a', timestampType20, (java.lang.Long) 0L, 0, 97, obj63, (java.io.Serializable) (byte) 1, headers79);
        java.util.Optional<java.lang.Integer> intOptional81 = objConsumerRecord80.leaderEpoch();
        java.io.Serializable serializable82 = objConsumerRecord80.value();
        java.lang.Object obj83 = objConsumerRecord80.key();
        java.lang.Object obj84 = objConsumerRecord80.key();
        java.lang.String str85 = objConsumerRecord80.toString();
        long long86 = objConsumerRecord80.timestamp();
        java.lang.Class<?> wildcardClass87 = objConsumerRecord80.getClass();
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str19, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType20 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType20.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + (-1L) + "'", long35 == (-1L));
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + 0L + "'", long36 == 0L);
        org.junit.Assert.assertNotNull(headers37);
        org.junit.Assert.assertEquals("'" + str54 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str54, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + (-1L) + "'", long55 == (-1L));
        org.junit.Assert.assertNotNull(headers56);
        org.junit.Assert.assertEquals("'" + str57 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str57, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long76 + "' != '" + 52L + "'", long76 == 52L);
        org.junit.Assert.assertTrue("'" + long77 + "' != '" + 52L + "'", long77 == 52L);
        org.junit.Assert.assertTrue("'" + int78 + "' != '" + 10 + "'", int78 == 10);
        org.junit.Assert.assertNotNull(headers79);
        org.junit.Assert.assertNotNull(intOptional81);
        org.junit.Assert.assertEquals("'" + serializable82 + "' != '" + (byte) 1 + "'", serializable82, (byte) 1);
        org.junit.Assert.assertNull(obj83);
        org.junit.Assert.assertNull(obj84);
        org.junit.Assert.assertEquals("'" + str85 + "' != '" + "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = 97, serialized key size = 0, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str85, "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 35, NoTimestampType = 97, serialized key size = 0, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long86 + "' != '" + 97L + "'", long86 == 97L);
        org.junit.Assert.assertNotNull(wildcardClass87);
    }

    @Test
    public void test00468() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00468");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.lang.String str12 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        java.lang.String str14 = objConsumerRecord10.topic();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str12, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
    }

    @Test
    public void test00469() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00469");
        java.lang.Object obj3 = null;
        org.apache.kafka.common.record.TimestampType timestampType15 = null;
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        java.lang.Object obj27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType23, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj27, (java.io.Serializable) 1);
        long long30 = objConsumerRecord29.timestamp();
        java.util.Optional<java.lang.Integer> intOptional31 = objConsumerRecord29.leaderEpoch();
        long long32 = objConsumerRecord29.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType15, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord29, (java.io.Serializable) '#');
        org.apache.kafka.common.header.Headers headers35 = objConsumerRecord29.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, org.apache.kafka.common.header.Headers> serializableConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.io.Serializable, org.apache.kafka.common.header.Headers>("hi!", (int) ' ', (long) 0, (java.io.Serializable) (byte) -1, headers35);
        org.apache.kafka.common.record.TimestampType timestampType41 = null;
        java.lang.Object obj45 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType41, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj45, (java.io.Serializable) 1);
        java.lang.String str48 = objConsumerRecord47.toString();
        java.util.Optional<java.lang.Integer> intOptional49 = objConsumerRecord47.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional50 = objConsumerRecord47.leaderEpoch();
        int int51 = objConsumerRecord47.partition();
        java.lang.Class<?> wildcardClass52 = objConsumerRecord47.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", (int) ' ', (long) (short) 100, (java.lang.Object) 0, (java.io.Serializable) wildcardClass52);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", 97, (long) (byte) 0, obj3, (java.io.Serializable) (short) 100);
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + 52L + "'", long30 == 52L);
        org.junit.Assert.assertNotNull(intOptional31);
        org.junit.Assert.assertTrue("'" + long32 + "' != '" + 52L + "'", long32 == 52L);
        org.junit.Assert.assertNotNull(headers35);
        org.junit.Assert.assertEquals("'" + str48 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str48, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional49);
        org.junit.Assert.assertNotNull(intOptional50);
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 10 + "'", int51 == 10);
        org.junit.Assert.assertNotNull(wildcardClass52);
    }

    @Test
    public void test00470() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00470");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.offset();
        long long12 = objConsumerRecord10.checksum();
        long long13 = objConsumerRecord10.timestamp();
        java.lang.String str14 = objConsumerRecord10.topic();
        long long15 = objConsumerRecord10.offset();
        long long16 = objConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType17 = objConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 0L + "'", long12 == 0L);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 52L + "'", long16 == 52L);
        org.junit.Assert.assertNull(timestampType17);
    }

    @Test
    public void test00471() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00471");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType4, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        org.apache.kafka.common.record.TimestampType timestampType11 = objConsumerRecord10.timestampType();
        long long12 = objConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers13 = objConsumerRecord10.headers();
        int int14 = objConsumerRecord10.serializedKeySize();
        int int15 = objConsumerRecord10.serializedValueSize();
        org.apache.kafka.common.header.Headers headers16 = objConsumerRecord10.headers();
        int int17 = objConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertNull(timestampType11);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 10L + "'", long12 == 10L);
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + (-1) + "'", int17 == (-1));
    }

    @Test
    public void test00472() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00472");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        long long13 = objConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType14 = objConsumerRecord10.timestampType();
        long long15 = objConsumerRecord10.timestamp();
        int int16 = objConsumerRecord10.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType17 = objConsumerRecord10.timestampType();
        int int18 = objConsumerRecord10.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType19 = objConsumerRecord10.timestampType();
        long long20 = objConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 100 + "'", int16 == 100);
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 100 + "'", int18 == 100);
        org.junit.Assert.assertNull(timestampType19);
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 0L + "'", long20 == 0L);
    }

    @Test
    public void test00473() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00473");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        java.lang.String str14 = objConsumerRecord13.toString();
        java.util.Optional<java.lang.Integer> intOptional15 = objConsumerRecord13.leaderEpoch();
        long long16 = objConsumerRecord13.timestamp();
        long long17 = objConsumerRecord13.checksum();
        int int18 = objConsumerRecord13.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional19 = objConsumerRecord13.leaderEpoch();
        java.io.Serializable serializable20 = objConsumerRecord13.value();
        java.lang.Object obj34 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj34, (java.io.Serializable) (byte) 100);
        java.lang.Object obj37 = objConsumerRecord36.key();
        java.lang.String str38 = objConsumerRecord36.toString();
        org.apache.kafka.common.record.TimestampType timestampType39 = objConsumerRecord36.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType47 = null;
        java.lang.Object obj51 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType47, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj51, (java.io.Serializable) 1);
        long long54 = objConsumerRecord53.offset();
        long long55 = objConsumerRecord53.checksum();
        org.apache.kafka.common.header.Headers headers56 = objConsumerRecord53.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), (long) (short) 1, (long) 0, timestampType39, 10L, 97, (int) '4', (java.lang.Object) headers56, (java.io.Serializable) 0.0d);
        org.apache.kafka.common.record.TimestampType timestampType63 = null;
        java.lang.Object obj67 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType63, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj67, (java.io.Serializable) 1);
        java.lang.String str70 = objConsumerRecord69.toString();
        long long71 = objConsumerRecord69.offset();
        java.util.Optional<java.lang.Integer> intOptional72 = objConsumerRecord69.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.util.Optional<java.lang.Integer>> timestampTypeEnumConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.util.Optional<java.lang.Integer>>("hi!", (int) (byte) 100, (long) 'a', (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType39, intOptional72);
        java.lang.Class<?> wildcardClass74 = timestampTypeEnumConsumerRecord73.getClass();
        org.apache.kafka.common.record.TimestampType timestampType79 = null;
        java.lang.Object obj83 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType79, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj83, (java.io.Serializable) 1);
        long long86 = objConsumerRecord85.timestamp();
        java.util.Optional<java.lang.Integer> intOptional87 = objConsumerRecord85.leaderEpoch();
        int int88 = objConsumerRecord85.serializedValueSize();
        java.lang.String str89 = objConsumerRecord85.topic();
        java.lang.String str90 = objConsumerRecord85.topic();
        java.lang.Class<?> wildcardClass91 = objConsumerRecord85.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.reflect.GenericDeclaration> genericDeclarationConsumerRecord92 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, java.lang.reflect.GenericDeclaration>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", 1, (long) (short) 10, (java.lang.reflect.GenericDeclaration) wildcardClass74, (java.lang.reflect.GenericDeclaration) wildcardClass91);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord93 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)", 32, (long) (short) 1, (java.lang.Object) serializable20, (java.io.Serializable) wildcardClass74);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 52L + "'", long16 == 52L);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 100 + "'", int18 == 100);
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertEquals("'" + serializable20 + "' != '" + 1 + "'", serializable20, 1);
        org.junit.Assert.assertNull(obj37);
        org.junit.Assert.assertEquals("'" + str38 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str38, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType39 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType39.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + (-1L) + "'", long54 == (-1L));
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + 0L + "'", long55 == 0L);
        org.junit.Assert.assertNotNull(headers56);
        org.junit.Assert.assertEquals("'" + str70 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str70, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long71 + "' != '" + (-1L) + "'", long71 == (-1L));
        org.junit.Assert.assertNotNull(intOptional72);
        org.junit.Assert.assertNotNull(wildcardClass74);
        org.junit.Assert.assertTrue("'" + long86 + "' != '" + 52L + "'", long86 == 52L);
        org.junit.Assert.assertNotNull(intOptional87);
        org.junit.Assert.assertTrue("'" + int88 + "' != '" + 100 + "'", int88 == 100);
        org.junit.Assert.assertEquals("'" + str89 + "' != '" + "" + "'", str89, "");
        org.junit.Assert.assertEquals("'" + str90 + "' != '" + "" + "'", str90, "");
        org.junit.Assert.assertNotNull(wildcardClass91);
    }

    @Test
    public void test00474() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00474");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType13 = null;
        java.lang.Object obj17 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType13, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj17, (java.io.Serializable) 1);
        long long20 = objConsumerRecord19.timestamp();
        java.util.Optional<java.lang.Integer> intOptional21 = objConsumerRecord19.leaderEpoch();
        long long22 = objConsumerRecord19.offset();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> charSequenceConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>("", (int) '4', (long) 'a', 0L, timestampType4, 10L, (-1), (int) (short) 0, (java.lang.CharSequence) "hi!", objConsumerRecord19);
        long long24 = objConsumerRecord19.checksum();
        long long25 = objConsumerRecord19.timestamp();
        long long26 = objConsumerRecord19.timestamp();
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 52L + "'", long20 == 52L);
        org.junit.Assert.assertNotNull(intOptional21);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 0L + "'", long24 == 0L);
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + 52L + "'", long25 == 52L);
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + 52L + "'", long26 == 52L);
    }

    @Test
    public void test00475() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00475");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        long long12 = objConsumerRecord10.timestamp();
        int int13 = objConsumerRecord10.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional14 = objConsumerRecord10.leaderEpoch();
        java.lang.String str15 = objConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 52L + "'", long12 == 52L);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
        org.junit.Assert.assertNotNull(intOptional14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "" + "'", str15, "");
    }

    @Test
    public void test00476() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00476");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.offset();
        long long12 = objConsumerRecord10.checksum();
        long long13 = objConsumerRecord10.timestamp();
        java.lang.String str14 = objConsumerRecord10.topic();
        java.lang.String str15 = objConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 0L + "'", long12 == 0L);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str15, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
    }

    @Test
    public void test00477() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00477");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers13 = objConsumerRecord10.headers();
        java.lang.String str14 = objConsumerRecord10.toString();
        long long15 = objConsumerRecord10.offset();
        long long16 = objConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional17 = objConsumerRecord10.leaderEpoch();
        java.lang.Object obj18 = objConsumerRecord10.key();
        long long19 = objConsumerRecord10.offset();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord10.leaderEpoch();
        long long21 = objConsumerRecord10.checksum();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertNotNull(intOptional17);
        org.junit.Assert.assertNull(obj18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 0L + "'", long21 == 0L);
    }

    @Test
    public void test00478() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00478");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        int int14 = objConsumerRecord10.partition();
        int int15 = objConsumerRecord10.serializedValueSize();
        java.io.Serializable serializable16 = objConsumerRecord10.value();
        long long17 = objConsumerRecord10.offset();
        long long18 = objConsumerRecord10.checksum();
        java.io.Serializable serializable19 = objConsumerRecord10.value();
        org.apache.kafka.common.header.Headers headers20 = objConsumerRecord10.headers();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
        org.junit.Assert.assertEquals("'" + serializable16 + "' != '" + 1 + "'", serializable16, 1);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertEquals("'" + serializable19 + "' != '" + 1 + "'", serializable19, 1);
        org.junit.Assert.assertNotNull(headers20);
    }

    @Test
    public void test00479() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00479");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.lang.Object obj12 = objConsumerRecord10.key();
        long long13 = objConsumerRecord10.checksum();
        long long14 = objConsumerRecord10.checksum();
        org.apache.kafka.common.record.TimestampType timestampType15 = objConsumerRecord10.timestampType();
        long long16 = objConsumerRecord10.offset();
        int int17 = objConsumerRecord10.serializedValueSize();
        int int18 = objConsumerRecord10.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional19 = objConsumerRecord10.leaderEpoch();
        java.lang.String str20 = objConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNull(obj12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertNull(timestampType15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 100 + "'", int17 == 100);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 10 + "'", int18 == 10);
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
    }

    @Test
    public void test00480() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00480");
        java.lang.Object obj6 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj6, (java.io.Serializable) (byte) 100);
        org.apache.kafka.common.record.TimestampType timestampType13 = null;
        java.lang.Object obj17 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType13, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj17, (java.io.Serializable) 1);
        long long20 = objConsumerRecord19.timestamp();
        java.lang.Object obj21 = objConsumerRecord19.key();
        long long22 = objConsumerRecord19.checksum();
        java.lang.Class<?> wildcardClass23 = objConsumerRecord19.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) 1, (long) '#', obj6, (java.io.Serializable) wildcardClass23);
        java.lang.Object obj25 = objConsumerRecord24.key();
        int int26 = objConsumerRecord24.partition();
        java.lang.String str27 = objConsumerRecord24.topic();
        long long28 = objConsumerRecord24.timestamp();
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 52L + "'", long20 == 52L);
        org.junit.Assert.assertNull(obj21);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 0L + "'", long22 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass23);
        org.junit.Assert.assertNull(obj25);
        org.junit.Assert.assertTrue("'" + int26 + "' != '" + 1 + "'", int26 == 1);
        org.junit.Assert.assertEquals("'" + str27 + "' != '" + "" + "'", str27, "");
        org.junit.Assert.assertTrue("'" + long28 + "' != '" + (-1L) + "'", long28 == (-1L));
    }

    @Test
    public void test00481() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00481");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType4, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        org.apache.kafka.common.header.Headers headers11 = objConsumerRecord10.headers();
        long long12 = objConsumerRecord10.offset();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        int int14 = objConsumerRecord10.serializedKeySize();
        long long15 = objConsumerRecord10.offset();
        java.lang.Object obj16 = objConsumerRecord10.key();
        org.junit.Assert.assertNotNull(headers11);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 100L + "'", long12 == 100L);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 100L + "'", long15 == 100L);
        org.junit.Assert.assertEquals("'" + obj16 + "' != '" + 0L + "'", obj16, 0L);
    }

    @Test
    public void test00482() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00482");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        long long13 = objConsumerRecord10.timestamp();
        long long14 = objConsumerRecord10.checksum();
        int int15 = objConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
    }

    @Test
    public void test00483() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00483");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        java.util.Optional<java.lang.Integer> intOptional15 = objConsumerRecord13.leaderEpoch();
        int int16 = objConsumerRecord13.serializedValueSize();
        java.lang.String str17 = objConsumerRecord13.topic();
        long long18 = objConsumerRecord13.offset();
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        java.lang.Object obj27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType23, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj27, (java.io.Serializable) 1);
        long long30 = objConsumerRecord29.timestamp();
        java.lang.Object obj31 = objConsumerRecord29.key();
        long long32 = objConsumerRecord29.checksum();
        long long33 = objConsumerRecord29.checksum();
        org.apache.kafka.common.record.TimestampType timestampType34 = objConsumerRecord29.timestampType();
        org.apache.kafka.common.header.Headers headers35 = objConsumerRecord29.headers();
        long long36 = objConsumerRecord29.timestamp();
        java.lang.Class<?> wildcardClass37 = objConsumerRecord29.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = 1.0, value = class org.apache.kafka.common.header.internals.RecordHeaders)", (int) (byte) 100, (long) 0, (java.lang.Object) objConsumerRecord13, (java.io.Serializable) wildcardClass37);
        java.util.Optional<java.lang.Integer> intOptional39 = objConsumerRecord13.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 100 + "'", int16 == 100);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + 52L + "'", long30 == 52L);
        org.junit.Assert.assertNull(obj31);
        org.junit.Assert.assertTrue("'" + long32 + "' != '" + 0L + "'", long32 == 0L);
        org.junit.Assert.assertTrue("'" + long33 + "' != '" + 0L + "'", long33 == 0L);
        org.junit.Assert.assertNull(timestampType34);
        org.junit.Assert.assertNotNull(headers35);
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + 52L + "'", long36 == 52L);
        org.junit.Assert.assertNotNull(wildcardClass37);
        org.junit.Assert.assertNotNull(intOptional39);
    }

    @Test
    public void test00484() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00484");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        java.lang.String str19 = objConsumerRecord18.toString();
        java.lang.String str20 = objConsumerRecord18.toString();
        org.apache.kafka.common.record.TimestampType timestampType26 = null;
        java.lang.Object obj30 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType26, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj30, (java.io.Serializable) 1);
        java.lang.String str33 = objConsumerRecord32.toString();
        long long34 = objConsumerRecord32.offset();
        org.apache.kafka.common.header.Headers headers35 = objConsumerRecord32.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) (byte) 100, (long) (byte) 1, (long) (short) 1, timestampType4, (java.lang.Long) 10L, (int) (short) 0, (int) (short) 1, (java.lang.Object) str20, (java.io.Serializable) 10, headers35);
        java.lang.Class<?> wildcardClass37 = objConsumerRecord36.getClass();
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str33, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertNotNull(headers35);
        org.junit.Assert.assertNotNull(wildcardClass37);
    }

    @Test
    public void test00485() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00485");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        java.lang.String str14 = objConsumerRecord13.toString();
        long long15 = objConsumerRecord13.offset();
        org.apache.kafka.common.header.Headers headers16 = objConsumerRecord13.headers();
        java.lang.String str17 = objConsumerRecord13.toString();
        long long18 = objConsumerRecord13.offset();
        long long19 = objConsumerRecord13.checksum();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord13.leaderEpoch();
        java.lang.Object obj21 = objConsumerRecord13.key();
        long long22 = objConsumerRecord13.offset();
        java.util.Optional<java.lang.Integer> intOptional23 = objConsumerRecord13.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType28 = null;
        org.apache.kafka.common.record.TimestampType timestampType36 = null;
        java.lang.Object obj40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType36, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj40, (java.io.Serializable) 1);
        long long43 = objConsumerRecord42.timestamp();
        java.util.Optional<java.lang.Integer> intOptional44 = objConsumerRecord42.leaderEpoch();
        long long45 = objConsumerRecord42.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType28, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord42, (java.io.Serializable) '#');
        int int48 = objConsumerRecord47.partition();
        java.util.Optional<java.lang.Integer> intOptional49 = objConsumerRecord47.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>> intOptionalConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>>("hi!", (int) (byte) 1, (long) 97, intOptional23, objConsumerRecord47);
        java.lang.Object obj51 = objConsumerRecord47.key();
        long long52 = objConsumerRecord47.timestamp();
        java.util.Optional<java.lang.Integer> intOptional53 = objConsumerRecord47.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType54 = objConsumerRecord47.timestampType();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str17, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertNull(obj21);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
        org.junit.Assert.assertNotNull(intOptional23);
        org.junit.Assert.assertTrue("'" + long43 + "' != '" + 52L + "'", long43 == 52L);
        org.junit.Assert.assertNotNull(intOptional44);
        org.junit.Assert.assertTrue("'" + long45 + "' != '" + 52L + "'", long45 == 52L);
        org.junit.Assert.assertTrue("'" + int48 + "' != '" + (-1) + "'", int48 == (-1));
        org.junit.Assert.assertNotNull(intOptional49);
        org.junit.Assert.assertNotNull(obj51);
        org.junit.Assert.assertEquals(obj51.toString(), "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals(java.lang.String.valueOf(obj51), "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals(java.util.Objects.toString(obj51), "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long52 + "' != '" + 10L + "'", long52 == 10L);
        org.junit.Assert.assertNotNull(intOptional53);
        org.junit.Assert.assertNull(timestampType54);
    }

    @Test
    public void test00486() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00486");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        long long13 = objConsumerRecord10.checksum();
        org.apache.kafka.common.record.TimestampType timestampType14 = objConsumerRecord10.timestampType();
        java.io.Serializable serializable15 = objConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertEquals("'" + serializable15 + "' != '" + 1 + "'", serializable15, 1);
    }

    @Test
    public void test00487() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00487");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        java.lang.String str14 = objConsumerRecord13.toString();
        long long15 = objConsumerRecord13.offset();
        java.lang.String str16 = objConsumerRecord13.toString();
        long long17 = objConsumerRecord13.checksum();
        int int18 = objConsumerRecord13.serializedValueSize();
        long long19 = objConsumerRecord13.checksum();
        org.apache.kafka.common.header.Headers headers20 = objConsumerRecord13.headers();
        org.apache.kafka.common.record.TimestampType timestampType28 = null;
        java.lang.Object obj32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType28, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj32, (java.io.Serializable) 1);
        long long35 = objConsumerRecord34.timestamp();
        java.util.Optional<java.lang.Integer> intOptional36 = objConsumerRecord34.leaderEpoch();
        long long37 = objConsumerRecord34.checksum();
        org.apache.kafka.common.record.TimestampType timestampType38 = objConsumerRecord34.timestampType();
        java.lang.Object obj45 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj45, (java.io.Serializable) (byte) 100);
        org.apache.kafka.common.record.TimestampType timestampType52 = null;
        java.lang.Object obj56 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType52, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj56, (java.io.Serializable) 1);
        long long59 = objConsumerRecord58.timestamp();
        java.lang.Object obj60 = objConsumerRecord58.key();
        long long61 = objConsumerRecord58.checksum();
        java.lang.Class<?> wildcardClass62 = objConsumerRecord58.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", (int) (short) 1, (long) '#', obj45, (java.io.Serializable) wildcardClass62);
        java.lang.Object obj64 = objConsumerRecord63.key();
        long long65 = objConsumerRecord63.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType66 = objConsumerRecord63.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType67 = objConsumerRecord63.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = -1, leaderEpoch = null, offset = -1, null = 1, serialized key size = 35, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", 0, (-1L), (java.lang.Object) objConsumerRecord34, (java.io.Serializable) timestampType67);
        java.lang.Class<?> wildcardClass69 = objConsumerRecord68.getClass();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10), partition = 0, leaderEpoch = null, offset = 1, NoTimestampType = 97, serialized key size = 35, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)", 0, (long) 97, (java.lang.Object) headers20, (java.io.Serializable) wildcardClass69);
        java.lang.Class<?> wildcardClass71 = headers20.getClass();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 100 + "'", int18 == 100);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + 52L + "'", long35 == 52L);
        org.junit.Assert.assertNotNull(intOptional36);
        org.junit.Assert.assertTrue("'" + long37 + "' != '" + 0L + "'", long37 == 0L);
        org.junit.Assert.assertNull(timestampType38);
        org.junit.Assert.assertTrue("'" + long59 + "' != '" + 52L + "'", long59 == 52L);
        org.junit.Assert.assertNull(obj60);
        org.junit.Assert.assertTrue("'" + long61 + "' != '" + 0L + "'", long61 == 0L);
        org.junit.Assert.assertNotNull(wildcardClass62);
        org.junit.Assert.assertNull(obj64);
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + (-1L) + "'", long65 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType66 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType66.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType67 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType67.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass69);
        org.junit.Assert.assertNotNull(wildcardClass71);
    }

    @Test
    public void test00488() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00488");
        java.lang.Object obj14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord16 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj14, (java.io.Serializable) (byte) 100);
        java.lang.Object obj17 = objConsumerRecord16.key();
        java.lang.String str18 = objConsumerRecord16.toString();
        org.apache.kafka.common.record.TimestampType timestampType19 = objConsumerRecord16.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        java.lang.Object obj31 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType27, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj31, (java.io.Serializable) 1);
        long long34 = objConsumerRecord33.offset();
        long long35 = objConsumerRecord33.checksum();
        org.apache.kafka.common.header.Headers headers36 = objConsumerRecord33.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (-1), (long) (short) 1, (long) 0, timestampType19, 10L, 97, (int) '4', (java.lang.Object) headers36, (java.io.Serializable) 0.0d);
        org.apache.kafka.common.record.TimestampType timestampType43 = null;
        java.lang.Object obj47 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType43, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj47, (java.io.Serializable) 1);
        java.lang.String str50 = objConsumerRecord49.toString();
        long long51 = objConsumerRecord49.offset();
        java.util.Optional<java.lang.Integer> intOptional52 = objConsumerRecord49.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.util.Optional<java.lang.Integer>> timestampTypeEnumConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.util.Optional<java.lang.Integer>>("hi!", (int) (byte) 100, (long) 'a', (java.lang.Enum<org.apache.kafka.common.record.TimestampType>) timestampType19, intOptional52);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.util.Optional<java.lang.Integer>> strComparableConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.util.Optional<java.lang.Integer>>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)", (int) (byte) 100, (long) (byte) 100, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 35, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = class org.apache.kafka.clients.consumer.ConsumerRecord)", intOptional52);
        org.junit.Assert.assertNull(obj17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)" + "'", str18, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 100)");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + 0L + "'", long35 == 0L);
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertEquals("'" + str50 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str50, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + (-1L) + "'", long51 == (-1L));
        org.junit.Assert.assertNotNull(intOptional52);
    }

    @Test
    public void test00489() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00489");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        java.lang.Object obj16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType12, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj16, (java.io.Serializable) 1);
        long long19 = objConsumerRecord18.timestamp();
        java.util.Optional<java.lang.Integer> intOptional20 = objConsumerRecord18.leaderEpoch();
        long long21 = objConsumerRecord18.timestamp();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (short) -1, (long) (short) -1, (long) (byte) 10, timestampType4, 1L, (int) (short) 100, (int) (short) 100, (java.lang.Object) objConsumerRecord18, (java.io.Serializable) '#');
        java.io.Serializable serializable24 = objConsumerRecord23.value();
        org.apache.kafka.common.record.TimestampType timestampType25 = objConsumerRecord23.timestampType();
        long long26 = objConsumerRecord23.timestamp();
        int int27 = objConsumerRecord23.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional28 = objConsumerRecord23.leaderEpoch();
        org.apache.kafka.common.header.Headers headers29 = objConsumerRecord23.headers();
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 52L + "'", long19 == 52L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 52L + "'", long21 == 52L);
        org.junit.Assert.assertEquals("'" + serializable24 + "' != '" + '#' + "'", serializable24, '#');
        org.junit.Assert.assertNull(timestampType25);
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + 10L + "'", long26 == 10L);
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + 100 + "'", int27 == 100);
        org.junit.Assert.assertNotNull(intOptional28);
        org.junit.Assert.assertNotNull(headers29);
    }

    @Test
    public void test00490() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00490");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        java.lang.String str14 = objConsumerRecord13.toString();
        long long15 = objConsumerRecord13.offset();
        java.lang.String str16 = objConsumerRecord13.toString();
        org.apache.kafka.common.header.Headers headers17 = objConsumerRecord13.headers();
        java.lang.String str18 = objConsumerRecord13.toString();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)", 1, (-1L), (java.lang.Object) str18, (java.io.Serializable) 'a');
        int int21 = objConsumerRecord20.serializedKeySize();
        int int22 = objConsumerRecord20.serializedKeySize();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(headers17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str18, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
    }

    @Test
    public void test00491() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00491");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType14 = objConsumerRecord10.timestampType();
        long long15 = objConsumerRecord10.offset();
        java.lang.String str16 = objConsumerRecord10.toString();
        int int17 = objConsumerRecord10.serializedKeySize();
        java.lang.String str18 = objConsumerRecord10.toString();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str18, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
    }

    @Test
    public void test00492() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00492");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional13 = objConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType14 = objConsumerRecord10.timestampType();
        long long15 = objConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers16 = objConsumerRecord10.headers();
        long long17 = objConsumerRecord10.offset();
        java.lang.Class<?> wildcardClass18 = objConsumerRecord10.getClass();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass18);
    }

    @Test
    public void test00493() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00493");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.topic();
        long long12 = objConsumerRecord10.checksum();
        long long13 = objConsumerRecord10.checksum();
        int int14 = objConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 0L + "'", long12 == 0L);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
    }

    @Test
    public void test00494() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00494");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        java.lang.String str11 = objConsumerRecord10.toString();
        long long12 = objConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers13 = objConsumerRecord10.headers();
        java.lang.String str14 = objConsumerRecord10.toString();
        java.io.Serializable serializable15 = objConsumerRecord10.value();
        org.apache.kafka.common.header.Headers headers16 = objConsumerRecord10.headers();
        long long17 = objConsumerRecord10.timestamp();
        long long18 = objConsumerRecord10.checksum();
        java.lang.Object obj19 = objConsumerRecord10.key();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertEquals("'" + serializable15 + "' != '" + 1 + "'", serializable15, 1);
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 52L + "'", long17 == 52L);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertNull(obj19);
    }

    @Test
    public void test00495() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00495");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType7, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj11, (java.io.Serializable) 1);
        long long14 = objConsumerRecord13.timestamp();
        java.lang.Object obj15 = objConsumerRecord13.key();
        long long16 = objConsumerRecord13.checksum();
        long long17 = objConsumerRecord13.checksum();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", (int) 'a', (-1L), (java.lang.Object) long17, (java.io.Serializable) 35L);
        java.io.Serializable serializable20 = objConsumerRecord19.value();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 52L + "'", long14 == 52L);
        org.junit.Assert.assertNull(obj15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertEquals("'" + serializable20 + "' != '" + 35L + "'", serializable20, 35L);
    }

    @Test
    public void test00496() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00496");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType4, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        org.apache.kafka.common.record.TimestampType timestampType11 = objConsumerRecord10.timestampType();
        java.lang.String str12 = objConsumerRecord10.toString();
        long long13 = objConsumerRecord10.offset();
        long long14 = objConsumerRecord10.checksum();
        java.lang.String str15 = objConsumerRecord10.topic();
        int int16 = objConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertNull(timestampType11);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)" + "'", str12, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 100L + "'", long13 == 100L);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 10L + "'", long14 == 10L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str15, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 100 + "'", int16 == 100);
    }

    @Test
    public void test00497() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00497");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        java.lang.Object obj8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType4, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj8, (java.io.Serializable) 1);
        long long11 = objConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional12 = objConsumerRecord10.leaderEpoch();
        long long13 = objConsumerRecord10.checksum();
        java.io.Serializable serializable14 = objConsumerRecord10.value();
        java.lang.Class<?> wildcardClass15 = objConsumerRecord10.getClass();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 52L + "'", long11 == 52L);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertEquals("'" + serializable14 + "' != '" + 1 + "'", serializable14, 1);
        org.junit.Assert.assertNotNull(wildcardClass15);
    }

    @Test
    public void test00498() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00498");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", (int) (byte) -1, 100L, (long) 10, timestampType4, (long) 10, (int) (byte) -1, 100, (java.lang.Object) 0L, (java.io.Serializable) 10);
        int int11 = objConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.header.Headers headers12 = objConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType13 = objConsumerRecord10.timestampType();
        java.lang.String str14 = objConsumerRecord10.toString();
        java.lang.String str15 = objConsumerRecord10.toString();
        org.apache.kafka.common.record.TimestampType timestampType16 = objConsumerRecord10.timestampType();
        // The following exception was thrown during execution in test generation
        try {
            java.lang.Class<?> wildcardClass17 = timestampType16.getClass();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertNull(timestampType13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)" + "'", str14, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)");
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)" + "'", str15, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 100, null = 10, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = 0, value = 10)");
        org.junit.Assert.assertNull(timestampType16);
    }

    @Test
    public void test00499() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00499");
        java.lang.Object obj11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("hi!", (int) 'a', (long) 'a', obj11, (java.io.Serializable) (byte) 100);
        java.lang.Object obj14 = objConsumerRecord13.key();
        org.apache.kafka.common.record.TimestampType timestampType15 = objConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        java.lang.Object obj27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("", 10, (long) (byte) -1, (long) '4', timestampType23, (long) (byte) 0, (int) (short) 10, (int) (byte) 100, obj27, (java.io.Serializable) 1);
        java.lang.String str30 = objConsumerRecord29.toString();
        long long31 = objConsumerRecord29.offset();
        org.apache.kafka.common.header.Headers headers32 = objConsumerRecord29.headers();
        java.lang.String str33 = objConsumerRecord29.topic();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable> objConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.io.Serializable>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)", 0, 35L, (long) 32, timestampType15, (long) (byte) 0, 0, 1, (java.lang.Object) str33, (java.io.Serializable) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = false)");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.kafka.common.record.TimestampType> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.kafka.common.record.TimestampType>("", (int) (byte) 10, (long) (byte) 100, "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 1, NoTimestampType = 1, serialized key size = 0, serialized value size = 35, headers = RecordHeaders(headers = [], isReadOnly = false), key = RecordHeaders(headers = [], isReadOnly = false), value = NoTimestampType)", timestampType15);
        java.lang.Class<?> wildcardClass37 = strConsumerRecord36.getClass();
        org.junit.Assert.assertNull(obj14);
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str30 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)" + "'", str30, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1)");
        org.junit.Assert.assertTrue("'" + long31 + "' != '" + (-1L) + "'", long31 == (-1L));
        org.junit.Assert.assertNotNull(headers32);
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "" + "'", str33, "");
        org.junit.Assert.assertNotNull(wildcardClass37);
    }

    @Test
    public void test00500() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest0.test00500");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = 1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), value = -1.0)", 32, (long) (byte) 100, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 35, leaderEpoch = null, offset = 0, null = 35, serialized key size = 32, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = #)", (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = -1, null = 52, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = 1), partition = -1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 0, serialized value size = 32, headers = RecordHeaders(headers = [], isReadOnly = false), key = Optional.empty, value = 100)");
    }
}

