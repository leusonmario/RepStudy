import org.junit.FixMethodOrder;
import org.junit.Test;
import org.junit.runners.MethodSorters;

@FixMethodOrder(MethodSorters.NAME_ASCENDING)
public class RegressionTest4 {

    public static boolean debug = false;

    @Test
    public void test2001() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2001");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        java.lang.String str13 = charSequenceConsumerRecord10.toString();
        org.apache.kafka.common.header.Headers headers14 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.header.Headers headers15 = charSequenceConsumerRecord10.headers();
        java.lang.String str16 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers14);
        org.junit.Assert.assertNotNull(headers15);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "hi!" + "'", str16, "hi!");
    }

    @Test
    public void test2002() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2002");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        boolean boolean2 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService3 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService3;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str5 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertTrue("'" + boolean2 + "' != '" + false + "'", boolean2 == false);
    }

    @Test
    public void test2003() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2003");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.io.Serializable> kafkaSpoutMessageIdListKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.io.Serializable> kafkaSpoutMessageIdListKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.io.Serializable>(kafkaSpoutMessageIdListKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test2004() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2004");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator3 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator3;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator5 = offsetComparator3.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator10 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator10;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator10);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = kafkaSpoutMessageIdComparator5.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator10);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = offsetComparator10.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator10.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator15;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator17 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator17;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = offsetComparator17.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator24 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator24;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator24);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = kafkaSpoutMessageIdComparator19.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator24);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = kafkaSpoutMessageIdComparator19.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator29 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator30 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator30;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = offsetComparator30.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator37 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator37;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator37);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator40 = kafkaSpoutMessageIdComparator32.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator37);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = offsetComparator29.thenComparing(kafkaSpoutMessageIdComparator40);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator42 = kafkaSpoutMessageIdComparator28.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator29);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator42;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = kafkaSpoutMessageIdComparator15.thenComparing(kafkaSpoutMessageIdComparator42);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator45 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator44);
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId46 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId47 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int48 = offsetComparator0.compare(kafkaSpoutMessageId46, kafkaSpoutMessageId47);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator5);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator40);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator42);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator45);
    }

    @Test
    public void test2005() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2005");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator4 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator4;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator6 = offsetComparator4.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator6);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator8 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator8;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = offsetComparator8.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator15 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator15;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator15);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = kafkaSpoutMessageIdComparator10.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator15);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator19 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator19;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = offsetComparator19.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator26 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator26);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = kafkaSpoutMessageIdComparator21.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator26);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = kafkaSpoutMessageIdComparator10.thenComparing(kafkaSpoutMessageIdComparator29);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = kafkaSpoutMessageIdComparator7.thenComparing(kafkaSpoutMessageIdComparator29);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = kafkaSpoutMessageIdComparator29.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator6);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
    }

    @Test
    public void test2006() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2006");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray6 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet7 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean8 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet7, kafkaSpoutMessageIdArray6);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet7;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer10 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService11 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService11;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams14 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams14;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray6);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
        org.junit.Assert.assertNull(timer10);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder13);
    }

    @Test
    public void test2007() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2007");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType17 = null;
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int34 = charSequenceConsumerRecord33.serializedValueSize();
        java.lang.CharSequence charSequence35 = charSequenceConsumerRecord33.key();
        org.apache.kafka.common.header.Headers headers36 = charSequenceConsumerRecord33.headers();
        java.util.Optional<java.lang.Integer> intOptional37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType17, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers36, intOptional37);
        org.apache.kafka.common.record.TimestampType timestampType46 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType46, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int53 = charSequenceConsumerRecord52.serializedValueSize();
        java.lang.CharSequence charSequence54 = charSequenceConsumerRecord52.key();
        org.apache.kafka.common.header.Headers headers55 = charSequenceConsumerRecord52.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray56 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList57 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean58 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57, kafkaSpoutMessageIdArray56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers55, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headersConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("", (int) '#', 1L, headers36, kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType4, (java.lang.Long) (-1L), (int) (short) 100, 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}", headers36);
        int int62 = charSequenceConsumerRecord61.partition();
        java.lang.String str63 = charSequenceConsumerRecord61.topic();
        java.lang.String str64 = charSequenceConsumerRecord61.toString();
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + (-1) + "'", int34 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence35 + "' != '" + "" + "'", charSequence35, "");
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + (-1) + "'", int53 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence54 + "' != '" + "" + "'", charSequence54, "");
        org.junit.Assert.assertNotNull(headers55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray56);
        org.junit.Assert.assertTrue("'" + boolean58 + "' != '" + false + "'", boolean58 == false);
        org.junit.Assert.assertTrue("'" + int62 + "' != '" + 97 + "'", int62 == 97);
        org.junit.Assert.assertEquals("'" + str63 + "' != '" + "hi!" + "'", str63, "hi!");
        org.junit.Assert.assertEquals("'" + str64 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", str64, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
    }

    @Test
    public void test2008() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2008");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer16;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector18 = null;
        strKafkaSpout0.collector = spoutOutputCollector18;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout20 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout20.maxRetries = (byte) -1;
        int int23 = strKafkaSpout20.maxRetries;
        strKafkaSpout20.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray26 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet27 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean28 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet27, kafkaSpoutMessageIdArray26);
        strKafkaSpout20.emitted = kafkaSpoutMessageIdSet27;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet27;
        long long31 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService32 = strKafkaSpout0.retryService;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor33 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor33;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray26);
        org.junit.Assert.assertTrue("'" + boolean28 + "' != '" + false + "'", boolean28 == false);
        org.junit.Assert.assertTrue("'" + long31 + "' != '" + 0L + "'", long31 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutRetryService32);
    }

    @Test
    public void test2009() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2009");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        boolean boolean11 = strKafkaSpout0.consumerAutoCommitMode;
        boolean boolean12 = strKafkaSpout0.waitingToEmit();
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str13 = strKafkaSpout0.getNamedTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + false + "'", boolean12 == false);
    }

    @Test
    public void test2010() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2010");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer12 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector13 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams14 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams14;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout16 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout16.maxRetries = (byte) -1;
        int int19 = strKafkaSpout16.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor20 = null;
        strKafkaSpout16.waitingToEmit = strConsumerRecordItor20;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig22 = null;
        strKafkaSpout16.kafkaSpoutConfig = strKafkaSpoutConfig22;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams24 = null;
        strKafkaSpout16.kafkaSpoutStreams = kafkaSpoutStreams24;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor26 = null;
        strKafkaSpout16.waitingToEmit = strConsumerRecordItor26;
        org.apache.kafka.common.TopicPartition topicPartition28 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection29 = strKafkaSpout16.toArrayList(topicPartition28);
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy30 = null;
        strKafkaSpout16.firstPollOffsetStrategy = firstPollOffsetStrategy30;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.fail((java.lang.Object) firstPollOffsetStrategy30);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertNull(strKafkaConsumer12);
        org.junit.Assert.assertNull(spoutOutputCollector13);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection29);
    }

    @Test
    public void test2011() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2011");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType13 = charSequenceConsumerRecord10.timestampType();
        java.util.Optional<java.lang.Integer> intOptional14 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNull(timestampType13);
        org.junit.Assert.assertNotNull(intOptional14);
    }

    @Test
    public void test2012() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2012");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        java.lang.String str8 = strKafkaSpout0.toString();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor9 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams12;
        boolean boolean14 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService15 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService15;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector17 = null;
        strKafkaSpout0.collector = spoutOutputCollector17;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator23;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator23.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator27 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator28 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator28;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = offsetComparator28.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = offsetComparator27.thenComparing(kafkaSpoutMessageIdComparator30);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator32 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator32;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator32.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = offsetComparator32.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = kafkaSpoutMessageIdComparator30.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator32);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator36;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = offsetComparator23.thenComparing(kafkaSpoutMessageIdComparator36);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = kafkaSpoutMessageIdComparator38.reversed();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.ack((java.lang.Object) kafkaSpoutMessageIdComparator39);
            org.junit.Assert.fail("Expected exception of type java.lang.ClassCastException; message: java.util.Collections$ReverseComparator2 cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId");
        } catch (java.lang.ClassCastException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strConsumerRecordItor9);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + true + "'", boolean14 == true);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
    }

    @Test
    public void test2013() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2013");
        org.apache.storm.kafka.spout.KafkaSpout<org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> offsetComparatorKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>();
    }

    @Test
    public void test2014() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2014");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.numUncommittedOffsets = (byte) 1;
        strKafkaSpout0.initialized = false;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet14 = strKafkaSpout0.emitted;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.kafka.common.TopicPartition topicPartition17 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setAcked(topicPartition17, (long) ' ');
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet14);
    }

    @Test
    public void test2015() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2015");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout10 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout10.maxRetries = (byte) -1;
        int int13 = strKafkaSpout10.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray14 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet15 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean16 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet15, kafkaSpoutMessageIdArray14);
        strKafkaSpout10.emitted = kafkaSpoutMessageIdSet15;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet15;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy19 = strKafkaSpout0.firstPollOffsetStrategy;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str20 = strKafkaSpout0.getNamedTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(spoutOutputCollector9);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray14);
        org.junit.Assert.assertTrue("'" + boolean16 + "' != '" + false + "'", boolean16 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy19);
    }

    @Test
    public void test2016() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2016");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator1 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator2 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator2;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator4 = offsetComparator2.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator2;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator6 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator6;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator8 = offsetComparator6.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator9 = offsetComparator2.thenComparing(kafkaSpoutMessageIdComparator8);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = offsetComparator2.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator12 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator12;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = offsetComparator12.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator11.thenComparing(kafkaSpoutMessageIdComparator14);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator16 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator16;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = offsetComparator16.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator23;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = kafkaSpoutMessageIdComparator18.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = offsetComparator11.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = offsetComparator23.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator29 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator29;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = offsetComparator29.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator36 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator36;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator36);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = kafkaSpoutMessageIdComparator31.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator36);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator40 = offsetComparator36.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = kafkaSpoutMessageIdComparator28.thenComparing(kafkaSpoutMessageIdComparator40);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator42 = kafkaSpoutMessageIdComparator10.thenComparing(kafkaSpoutMessageIdComparator28);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator43 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator44 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator45 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator45;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator47 = offsetComparator45.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator52 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator52;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator52);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator55 = kafkaSpoutMessageIdComparator47.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator52);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator56 = offsetComparator44.thenComparing(kafkaSpoutMessageIdComparator55);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator57 = kafkaSpoutMessageIdComparator55.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator58 = offsetComparator43.thenComparing(kafkaSpoutMessageIdComparator57);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator59 = kafkaSpoutMessageIdComparator28.thenComparing(kafkaSpoutMessageIdComparator57);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator60 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator28);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator61 = kafkaSpoutMessageIdComparator60.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator61;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator1);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator4);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator8);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator9);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator40);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator42);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator47);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator56);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator57);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator58);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator59);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator60);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator61);
    }

    @Test
    public void test2017() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2017");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder2 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder2;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy4 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = strKafkaSpout0.kafkaSpoutConfig;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str7 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strKafkaSpoutConfig6);
    }

    @Test
    public void test2018() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2018");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.util.Optional<java.lang.Integer> intOptional16 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str17 = charSequenceConsumerRecord10.value();
        int int18 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.String str19 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 52 + "'", int18 == 52);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
    }

    @Test
    public void test2019() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2019");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = strKafkaSpout0.kafkaConsumer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor5 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor5;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        java.lang.String str8 = strKafkaSpout0.toString();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer4);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test2020() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2020");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray6 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet7 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean8 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet7, kafkaSpoutMessageIdArray6);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet7;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer10 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService11 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService11;
        boolean boolean13 = strKafkaSpout0.initialized;
        boolean boolean14 = strKafkaSpout0.waitingToEmit();
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean15 = strKafkaSpout0.poll();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray6);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
        org.junit.Assert.assertNull(timer10);
        org.junit.Assert.assertTrue("'" + boolean13 + "' != '" + false + "'", boolean13 == false);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
    }

    @Test
    public void test2021() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2021");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams10;
        strKafkaSpout0.numUncommittedOffsets = ' ';
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean14 = strKafkaSpout0.commit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
    }

    @Test
    public void test2022() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2022");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        long long19 = charSequenceConsumerRecord10.offset();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        long long21 = charSequenceConsumerRecord10.offset();
        java.lang.CharSequence charSequence22 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 0L + "'", long21 == 0L);
        org.junit.Assert.assertEquals("'" + charSequence22 + "' != '" + "" + "'", charSequence22, "");
    }

    @Test
    public void test2023() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2023");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords8 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords8);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
    }

    @Test
    public void test2024() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2024");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType14, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long21 = charSequenceConsumerRecord20.offset();
        int int22 = charSequenceConsumerRecord20.serializedValueSize();
        org.apache.kafka.common.header.Headers headers23 = charSequenceConsumerRecord20.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 100, (long) (short) 1, 52L, timestampType4, (java.lang.Long) (-1L), 1, (int) (byte) 100, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", headers23);
        long long25 = charSequenceConsumerRecord24.timestamp();
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 0L + "'", long21 == 0L);
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertNotNull(headers23);
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + 52L + "'", long25 == 52L);
    }

    @Test
    public void test2025() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2025");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator4 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator4;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator6 = offsetComparator4.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator6);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator8 = kafkaSpoutMessageIdComparator6.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator9 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator9;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = offsetComparator9.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator16 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator16;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator16);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = kafkaSpoutMessageIdComparator11.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator16);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator20 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator20;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = offsetComparator20.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator27 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator27;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator27);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = kafkaSpoutMessageIdComparator22.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator27);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = kafkaSpoutMessageIdComparator11.thenComparing(kafkaSpoutMessageIdComparator30);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = kafkaSpoutMessageIdComparator31.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator33 = kafkaSpoutMessageIdComparator6.thenComparing(kafkaSpoutMessageIdComparator31);
        java.lang.Class<?> wildcardClass34 = kafkaSpoutMessageIdComparator31.getClass();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator6);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator8);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator33);
        org.junit.Assert.assertNotNull(wildcardClass34);
    }

    @Test
    public void test2026() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2026");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray6 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet7 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean8 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet7, kafkaSpoutMessageIdArray6);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet7;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy11 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy11;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder13;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Map<java.lang.String, java.lang.Object> strMap15 = strKafkaSpout0.getComponentConfiguration();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray6);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
        org.junit.Assert.assertNull(strKafkaConsumer10);
    }

    @Test
    public void test2027() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2027");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer3 = strKafkaSpout0.commitTimer;
        java.util.Map map4 = null;
        org.apache.storm.task.TopologyContext topologyContext5 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map4, topologyContext5, spoutOutputCollector6);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(timer3);
    }

    @Test
    public void test2028() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2028");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        long long16 = charSequenceConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional17 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str18 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertNotNull(intOptional17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "hi!" + "'", str18, "hi!");
    }

    @Test
    public void test2029() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2029");
        org.apache.storm.kafka.spout.KafkaSpout<java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.Class<?>> kafkaSpoutMessageIdListKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.Class<?>>();
    }

    @Test
    public void test2030() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2030");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType31 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType31, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long38 = charSequenceConsumerRecord37.checksum();
        int int39 = charSequenceConsumerRecord37.partition();
        long long40 = charSequenceConsumerRecord37.timestamp();
        java.lang.String str41 = charSequenceConsumerRecord37.toString();
        long long42 = charSequenceConsumerRecord37.timestamp();
        org.apache.kafka.common.header.Headers headers43 = charSequenceConsumerRecord37.headers();
        org.apache.kafka.common.record.TimestampType timestampType44 = charSequenceConsumerRecord37.timestampType();
        java.util.Optional<java.lang.Integer> intOptional45 = charSequenceConsumerRecord37.leaderEpoch();
        org.apache.storm.topology.IComponent iComponent46 = null;
        org.apache.kafka.common.record.TimestampType timestampType51 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType51, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long58 = charSequenceConsumerRecord57.checksum();
        int int59 = charSequenceConsumerRecord57.partition();
        long long60 = charSequenceConsumerRecord57.timestamp();
        java.lang.String str61 = charSequenceConsumerRecord57.toString();
        org.apache.kafka.common.header.Headers headers62 = charSequenceConsumerRecord57.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent> intOptionalConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent>("hi!", (int) ' ', (long) (byte) -1, (long) (-1), timestampType23, (java.lang.Long) 100L, (int) 'a', (-1), intOptional45, iComponent46, headers62);
        org.apache.storm.topology.IRichSpout iRichSpout68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.storm.topology.IRichSpout> strComparableConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.storm.topology.IRichSpout>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", (int) (byte) 0, (long) 10, (long) (-1), timestampType23, (long) 0, (int) (short) 10, (int) (byte) 1, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", iRichSpout68);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", (int) (byte) 100, 100L, (long) (short) 100, timestampType23, (long) 'a', (int) ' ', (-1), (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", 52, 0L, (long) 97, timestampType23, (long) (byte) -1, (int) ' ', 10, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        java.lang.String str82 = charSequenceConsumerRecord81.value();
        java.lang.String str83 = charSequenceConsumerRecord81.topic();
        int int84 = charSequenceConsumerRecord81.serializedKeySize();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + (-1L) + "'", long38 == (-1L));
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + 10 + "'", int39 == 10);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertEquals("'" + str41 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str41, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long42 + "' != '" + (-1L) + "'", long42 == (-1L));
        org.junit.Assert.assertNotNull(headers43);
        org.junit.Assert.assertNull(timestampType44);
        org.junit.Assert.assertNotNull(intOptional45);
        org.junit.Assert.assertTrue("'" + long58 + "' != '" + (-1L) + "'", long58 == (-1L));
        org.junit.Assert.assertTrue("'" + int59 + "' != '" + 10 + "'", int59 == 10);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str61, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers62);
        org.junit.Assert.assertEquals("'" + str82 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", str82, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.junit.Assert.assertEquals("'" + str83 + "' != '" + "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", str83, "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.junit.Assert.assertTrue("'" + int84 + "' != '" + 32 + "'", int84 == 32);
    }

    @Test
    public void test2031() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2031");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        int int16 = charSequenceConsumerRecord10.serializedValueSize();
        long long17 = charSequenceConsumerRecord10.checksum();
        java.lang.String str18 = charSequenceConsumerRecord10.value();
        java.lang.String str19 = charSequenceConsumerRecord10.value();
        long long20 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + (-1) + "'", int16 == (-1));
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "hi!" + "'", str18, "hi!");
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 0L + "'", long20 == 0L);
    }

    @Test
    public void test2032() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2032");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        long long7 = charSequenceConsumerRecord5.timestamp();
        long long8 = charSequenceConsumerRecord5.timestamp();
        java.lang.String str9 = charSequenceConsumerRecord5.value();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + (-1L) + "'", long8 == (-1L));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str9, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test2033() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2033");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType23, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long30 = charSequenceConsumerRecord29.checksum();
        int int31 = charSequenceConsumerRecord29.partition();
        java.lang.String str32 = charSequenceConsumerRecord29.value();
        int int33 = charSequenceConsumerRecord29.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional34 = charSequenceConsumerRecord29.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet36 = strKafkaSpout35.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor37 = null;
        strKafkaSpout35.waitingToEmit = strConsumerRecordItor37;
        boolean boolean39 = strKafkaSpout35.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig40 = null;
        strKafkaSpout35.kafkaSpoutConfig = strKafkaSpoutConfig40;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy42 = strKafkaSpout35.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType15, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord29, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout35);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType53, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long60 = charSequenceConsumerRecord59.checksum();
        int int61 = charSequenceConsumerRecord59.partition();
        java.lang.String str62 = charSequenceConsumerRecord59.value();
        int int63 = charSequenceConsumerRecord59.serializedKeySize();
        org.apache.kafka.common.header.Headers headers64 = charSequenceConsumerRecord59.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str71 = charSequenceConsumerRecord70.topic();
        java.util.Optional<java.lang.Integer> intOptional72 = charSequenceConsumerRecord70.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 0, (long) (short) 10, (long) (-1), timestampType15, (java.lang.Long) 35L, 10, (int) (short) 10, (java.lang.CharSequence) "", "KafkaSpout{acked=null, emitted=null}", headers64, intOptional72);
        java.util.Optional<java.lang.Integer> intOptional74 = charSequenceConsumerRecord73.leaderEpoch();
        long long75 = charSequenceConsumerRecord73.checksum();
        java.lang.CharSequence charSequence76 = charSequenceConsumerRecord73.key();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 10 + "'", int31 == 10);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "hi!" + "'", str32, "hi!");
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + 52 + "'", int33 == 52);
        org.junit.Assert.assertNotNull(intOptional34);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet36);
        org.junit.Assert.assertTrue("'" + boolean39 + "' != '" + false + "'", boolean39 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy42);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + 10 + "'", int61 == 10);
        org.junit.Assert.assertEquals("'" + str62 + "' != '" + "hi!" + "'", str62, "hi!");
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 52 + "'", int63 == 52);
        org.junit.Assert.assertNotNull(headers64);
        org.junit.Assert.assertEquals("'" + str71 + "' != '" + "" + "'", str71, "");
        org.junit.Assert.assertNotNull(intOptional72);
        org.junit.Assert.assertNotNull(intOptional74);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + 35L + "'", long75 == 35L);
        org.junit.Assert.assertEquals("'" + charSequence76 + "' != '" + "" + "'", charSequence76, "");
    }

    @Test
    public void test2034() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2034");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams3 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = strKafkaSpout0.kafkaSpoutStreams;
        int int8 = strKafkaSpout0.maxRetries;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean9 = strKafkaSpout0.commit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
    }

    @Test
    public void test2035() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2035");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = offsetComparator7.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator7.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator13.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator20 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator20;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = kafkaSpoutMessageIdComparator15.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator15.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator7.thenComparing(kafkaSpoutMessageIdComparator24);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator7.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = offsetComparator7.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator27;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator29 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator29;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = offsetComparator29.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator36 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator36;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator36);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = kafkaSpoutMessageIdComparator31.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator36);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator36;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = kafkaSpoutMessageIdComparator27.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator36);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator41;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
    }

    @Test
    public void test2036() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2036");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer10 = strKafkaSpout0.commitTimer;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer11 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer11);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(spoutOutputCollector9);
        org.junit.Assert.assertNull(timer10);
    }

    @Test
    public void test2037() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2037");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer1 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy2 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams3 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams3;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder5 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder5;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.junit.Assert.assertNull(timer1);
        org.junit.Assert.assertNull(firstPollOffsetStrategy2);
        org.junit.Assert.assertNull(strKafkaConsumer7);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
    }

    @Test
    public void test2038() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2038");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        boolean boolean6 = strKafkaSpout0.waitingToEmit();
        org.apache.kafka.common.TopicPartition topicPartition7 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection8 = strKafkaSpout0.toArrayList(topicPartition7);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService9;
        long long11 = strKafkaSpout0.numUncommittedOffsets;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection8);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 35L + "'", long11 == 35L);
    }

    @Test
    public void test2039() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2039");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer16;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor18 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig19 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig19;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor21 = strKafkaSpout0.waitingToEmit;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor18);
        org.junit.Assert.assertNull(strConsumerRecordItor21);
    }

    @Test
    public void test2040() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2040");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = strKafkaSpout0.firstPollOffsetStrategy;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer9 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer9;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = strKafkaSpout0.collector;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Map<java.lang.String, java.lang.Object> strMap12 = strKafkaSpout0.getComponentConfiguration();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 0 + "'", int8 == 0);
        org.junit.Assert.assertNull(spoutOutputCollector11);
    }

    @Test
    public void test2041() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2041");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", (int) (short) 100, 52L, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
    }

    @Test
    public void test2042() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2042");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> genericDeclarationKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.GenericDeclaration, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>();
    }

    @Test
    public void test2043() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2043");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout11 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = strKafkaSpout11.kafkaSpoutStreams;
        strKafkaSpout11.consumerAutoCommitMode = false;
        java.lang.String str15 = strKafkaSpout11.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout16 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout16.maxRetries = (byte) -1;
        int int19 = strKafkaSpout16.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray20 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet21 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean22 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, kafkaSpoutMessageIdArray20);
        strKafkaSpout16.emitted = kafkaSpoutMessageIdSet21;
        strKafkaSpout11.emitted = kafkaSpoutMessageIdSet21;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout25 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout25.maxRetries = (byte) -1;
        int int28 = strKafkaSpout25.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor29 = null;
        strKafkaSpout25.waitingToEmit = strConsumerRecordItor29;
        org.apache.kafka.common.TopicPartition topicPartition31 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection32 = strKafkaSpout25.toArrayList(topicPartition31);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout25.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector34 = strKafkaSpout25.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout35.maxRetries = (byte) -1;
        int int38 = strKafkaSpout35.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray39 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet40 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean41 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40, kafkaSpoutMessageIdArray39);
        strKafkaSpout35.emitted = kafkaSpoutMessageIdSet40;
        strKafkaSpout25.emitted = kafkaSpoutMessageIdSet40;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType7, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet40;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector46 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer47 = strKafkaSpout0.commitTimer;
        boolean boolean48 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder49 = strKafkaSpout0.tuplesBuilder;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(strKafkaSpoutConfig2);
        org.junit.Assert.assertNull(kafkaSpoutStreams12);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray20);
        org.junit.Assert.assertTrue("'" + boolean22 + "' != '" + false + "'", boolean22 == false);
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + (-1) + "'", int28 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection32);
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(spoutOutputCollector34);
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + (-1) + "'", int38 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray39);
        org.junit.Assert.assertTrue("'" + boolean41 + "' != '" + false + "'", boolean41 == false);
        org.junit.Assert.assertNull(spoutOutputCollector46);
        org.junit.Assert.assertNull(timer47);
        org.junit.Assert.assertTrue("'" + boolean48 + "' != '" + false + "'", boolean48 == false);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder49);
    }

    @Test
    public void test2044() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2044");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (-1), (long) (byte) 100, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str6 = charSequenceConsumerRecord5.value();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str6, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test2045() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2045");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        long long8 = strKafkaSpout0.numUncommittedOffsets;
        strKafkaSpout0.numUncommittedOffsets = (-1L);
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams11 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService12 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService12;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams14 = strKafkaSpout0.kafkaSpoutStreams;
        long long15 = strKafkaSpout0.numUncommittedOffsets;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 0L + "'", long8 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutStreams11);
        org.junit.Assert.assertNull(kafkaSpoutStreams14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
    }

    @Test
    public void test2046() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2046");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        strKafkaSpout0.numUncommittedOffsets = 0L;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder10 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder10;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer12 = strKafkaSpout0.commitTimer;
        org.apache.kafka.common.TopicPartition topicPartition13 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setAcked(topicPartition13, (long) ' ');
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer12);
    }

    @Test
    public void test2047() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2047");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords11 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords11);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
    }

    @Test
    public void test2048() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2048");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder12 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder12;
        boolean boolean14 = strKafkaSpout0.initialized;
        java.lang.String str15 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService16 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService16;
        int int18 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy19 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy19;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + (-1) + "'", int18 == (-1));
    }

    @Test
    public void test2049() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2049");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams10;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder9);
    }

    @Test
    public void test2050() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2050");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (-1), (long) (short) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "KafkaSpout{acked=null, emitted=[]}");
        long long6 = charSequenceConsumerRecord5.offset();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + 0L + "'", long6 == 0L);
    }

    @Test
    public void test2051() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2051");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        strKafkaSpout0.maxRetries = (byte) 1;
        int int10 = strKafkaSpout0.maxRetries;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
// flaky:             org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 1 + "'", int10 == 1);
    }

    @Test
    public void test2052() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2052");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy3 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout4 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout4.maxRetries = (byte) -1;
        int int7 = strKafkaSpout4.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray8 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet9 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean10 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet9, kafkaSpoutMessageIdArray8);
        strKafkaSpout4.emitted = kafkaSpoutMessageIdSet9;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig13 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig13;
        strKafkaSpout0.initialized = true;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean17 = strKafkaSpout0.commit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(firstPollOffsetStrategy3);
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray8);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
    }

    @Test
    public void test2053() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2053");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence17 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence18 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType20 = charSequenceConsumerRecord10.timestampType();
        long long21 = charSequenceConsumerRecord10.offset();
        java.lang.String str22 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertEquals("'" + charSequence17 + "' != '" + "" + "'", charSequence17, "");
        org.junit.Assert.assertEquals("'" + charSequence18 + "' != '" + "" + "'", charSequence18, "");
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertNull(timestampType20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 0L + "'", long21 == 0L);
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "hi!" + "'", str22, "hi!");
    }

    @Test
    public void test2054() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2054");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        long long18 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        int int20 = charSequenceConsumerRecord10.partition();
        java.lang.String str21 = charSequenceConsumerRecord10.toString();
        java.lang.String str22 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 10 + "'", int20 == 10);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str21, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
    }

    @Test
    public void test2055() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2055");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>(kafkaSpoutMessageIdSetKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test2056() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2056");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams9 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams10;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator12 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator13.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator20 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator20;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = kafkaSpoutMessageIdComparator15.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = offsetComparator12.thenComparing(kafkaSpoutMessageIdComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = kafkaSpoutMessageIdComparator23.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator26 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = offsetComparator26.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator30 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator30;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = offsetComparator30.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator33 = offsetComparator26.thenComparing(kafkaSpoutMessageIdComparator32);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator26.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = kafkaSpoutMessageIdComparator25.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator26);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = kafkaSpoutMessageIdComparator35.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = kafkaSpoutMessageIdComparator36.reversed();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.ack((java.lang.Object) kafkaSpoutMessageIdComparator37);
            org.junit.Assert.fail("Expected exception of type java.lang.ClassCastException; message: java.util.Comparator$$Lambda$228/1195282792 cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId");
        } catch (java.lang.ClassCastException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(kafkaSpoutStreams9);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator33);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
    }

    @Test
    public void test2057() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2057");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.numUncommittedOffsets = (byte) 1;
        strKafkaSpout0.numUncommittedOffsets = (short) 0;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.commitOffsetsForAckedTuples();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
    }

    @Test
    public void test2058() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2058");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)", (int) (byte) 1, (long) (byte) 100, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        int int6 = charSequenceConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional7 = charSequenceConsumerRecord5.leaderEpoch();
        java.lang.Class<?> wildcardClass8 = intOptional7.getClass();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertNotNull(wildcardClass8);
    }

    @Test
    public void test2059() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2059");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService10;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer12 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer12);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
    }

    @Test
    public void test2060() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2060");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator2 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator3 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator3;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator5 = offsetComparator3.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator6 = offsetComparator2.thenComparing(kafkaSpoutMessageIdComparator5);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator6);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId9 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId10 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int11 = offsetComparator0.compare(kafkaSpoutMessageId9, kafkaSpoutMessageId10);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator5);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator6);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
    }

    @Test
    public void test2061() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2061");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        long long19 = charSequenceConsumerRecord10.offset();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        long long21 = charSequenceConsumerRecord10.offset();
        org.apache.kafka.common.record.TimestampType timestampType22 = charSequenceConsumerRecord10.timestampType();
        long long23 = charSequenceConsumerRecord10.checksum();
        java.lang.String str24 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 0L + "'", long21 == 0L);
        org.junit.Assert.assertNull(timestampType22);
        org.junit.Assert.assertTrue("'" + long23 + "' != '" + (-1L) + "'", long23 == (-1L));
        org.junit.Assert.assertEquals("'" + str24 + "' != '" + "" + "'", str24, "");
    }

    @Test
    public void test2062() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2062");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer4 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy7;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer9 = strKafkaSpout0.commitTimer;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy12 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy12;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer4);
        org.junit.Assert.assertNull(timer9);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
    }

    @Test
    public void test2063() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2063");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector3 = null;
        strKafkaSpout0.collector = spoutOutputCollector3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = strKafkaSpout0.kafkaSpoutConfig;
        java.lang.String str6 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy7;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer9 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer9);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(strKafkaSpoutConfig5);
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str6, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test2064() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2064");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout6 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = strKafkaSpout6.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig8 = strKafkaSpout6.kafkaSpoutConfig;
        org.apache.kafka.common.record.TimestampType timestampType13 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout17 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams18 = strKafkaSpout17.kafkaSpoutStreams;
        strKafkaSpout17.consumerAutoCommitMode = false;
        java.lang.String str21 = strKafkaSpout17.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout22 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout22.maxRetries = (byte) -1;
        int int25 = strKafkaSpout22.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray26 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet27 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean28 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet27, kafkaSpoutMessageIdArray26);
        strKafkaSpout22.emitted = kafkaSpoutMessageIdSet27;
        strKafkaSpout17.emitted = kafkaSpoutMessageIdSet27;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout31 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout31.maxRetries = (byte) -1;
        int int34 = strKafkaSpout31.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor35 = null;
        strKafkaSpout31.waitingToEmit = strConsumerRecordItor35;
        org.apache.kafka.common.TopicPartition topicPartition37 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection38 = strKafkaSpout31.toArrayList(topicPartition37);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer39 = strKafkaSpout31.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector40 = strKafkaSpout31.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout41 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout41.maxRetries = (byte) -1;
        int int44 = strKafkaSpout41.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray45 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet46 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean47 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet46, kafkaSpoutMessageIdArray45);
        strKafkaSpout41.emitted = kafkaSpoutMessageIdSet46;
        strKafkaSpout31.emitted = kafkaSpoutMessageIdSet46;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType13, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet27, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet46);
        strKafkaSpout6.emitted = kafkaSpoutMessageIdSet46;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet46;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer53 = strKafkaSpout0.kafkaConsumer;
        strKafkaSpout0.initialized = true;
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutStreams7);
        org.junit.Assert.assertNull(strKafkaSpoutConfig8);
        org.junit.Assert.assertNull(kafkaSpoutStreams18);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str21, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + (-1) + "'", int25 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray26);
        org.junit.Assert.assertTrue("'" + boolean28 + "' != '" + false + "'", boolean28 == false);
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + (-1) + "'", int34 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection38);
        org.junit.Assert.assertNull(timer39);
        org.junit.Assert.assertNull(spoutOutputCollector40);
        org.junit.Assert.assertTrue("'" + int44 + "' != '" + (-1) + "'", int44 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray45);
        org.junit.Assert.assertTrue("'" + boolean47 + "' != '" + false + "'", boolean47 == false);
        org.junit.Assert.assertNull(strKafkaConsumer53);
    }

    @Test
    public void test2065() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2065");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams7;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = strKafkaSpout0.retryService;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer13 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer13);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(kafkaSpoutRetryService9);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertNull(spoutOutputCollector11);
        org.junit.Assert.assertNull(kafkaSpoutStreams12);
    }

    @Test
    public void test2066() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2066");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        long long16 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 52 + "'", int14 == 52);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
    }

    @Test
    public void test2067() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2067");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService8;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder10 = strKafkaSpout0.tuplesBuilder;
        org.apache.kafka.common.TopicPartition topicPartition11 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection12 = strKafkaSpout0.toArrayList(topicPartition11);
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str13 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder10);
        org.junit.Assert.assertNotNull(topicPartitionCollection12);
    }

    @Test
    public void test2068() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2068");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        java.lang.String str4 = strKafkaSpout0.toString();
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer7;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = strKafkaSpout0.retryService;
        strKafkaSpout0.maxRetries = 10;
        java.util.Map map13 = null;
        org.apache.storm.task.TopologyContext topologyContext14 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector15 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map13, topologyContext14, spoutOutputCollector15);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertEquals("'" + str4 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str4, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(firstPollOffsetStrategy9);
        org.junit.Assert.assertNull(kafkaSpoutRetryService10);
    }

    @Test
    public void test2069() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2069");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService10;
        java.util.Map map12 = null;
        org.apache.storm.task.TopologyContext topologyContext13 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector14 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map12, topologyContext13, spoutOutputCollector14);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
    }

    @Test
    public void test2070() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2070");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.header.Headers, org.apache.storm.spout.ISpout> headersKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, org.apache.storm.spout.ISpout> headersKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, org.apache.storm.spout.ISpout>(headersKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test2071() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2071");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.offset();
        int int14 = charSequenceConsumerRecord10.partition();
        long long15 = charSequenceConsumerRecord10.checksum();
        int int16 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
    }

    @Test
    public void test2072() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2072");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService8;
        boolean boolean10 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition11 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection12 = strKafkaSpout0.toArrayList(topicPartition11);
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
// flaky:             org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection12);
    }

    @Test
    public void test2073() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2073");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer10;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.kafka.common.TopicPartition topicPartition14 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setAcked(topicPartition14, (long) '#');
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
    }

    @Test
    public void test2074() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2074");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType23, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long30 = charSequenceConsumerRecord29.checksum();
        int int31 = charSequenceConsumerRecord29.partition();
        java.lang.String str32 = charSequenceConsumerRecord29.value();
        int int33 = charSequenceConsumerRecord29.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional34 = charSequenceConsumerRecord29.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet36 = strKafkaSpout35.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor37 = null;
        strKafkaSpout35.waitingToEmit = strConsumerRecordItor37;
        boolean boolean39 = strKafkaSpout35.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig40 = null;
        strKafkaSpout35.kafkaSpoutConfig = strKafkaSpoutConfig40;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy42 = strKafkaSpout35.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType15, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord29, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout35);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType53, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long60 = charSequenceConsumerRecord59.checksum();
        int int61 = charSequenceConsumerRecord59.partition();
        java.lang.String str62 = charSequenceConsumerRecord59.value();
        int int63 = charSequenceConsumerRecord59.serializedKeySize();
        org.apache.kafka.common.header.Headers headers64 = charSequenceConsumerRecord59.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str71 = charSequenceConsumerRecord70.topic();
        java.util.Optional<java.lang.Integer> intOptional72 = charSequenceConsumerRecord70.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 0, (long) (short) 10, (long) (-1), timestampType15, (java.lang.Long) 35L, 10, (int) (short) 10, (java.lang.CharSequence) "", "KafkaSpout{acked=null, emitted=null}", headers64, intOptional72);
        long long74 = charSequenceConsumerRecord73.timestamp();
        java.util.Optional<java.lang.Integer> intOptional75 = charSequenceConsumerRecord73.leaderEpoch();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 10 + "'", int31 == 10);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "hi!" + "'", str32, "hi!");
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + 52 + "'", int33 == 52);
        org.junit.Assert.assertNotNull(intOptional34);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet36);
        org.junit.Assert.assertTrue("'" + boolean39 + "' != '" + false + "'", boolean39 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy42);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + 10 + "'", int61 == 10);
        org.junit.Assert.assertEquals("'" + str62 + "' != '" + "hi!" + "'", str62, "hi!");
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 52 + "'", int63 == 52);
        org.junit.Assert.assertNotNull(headers64);
        org.junit.Assert.assertEquals("'" + str71 + "' != '" + "" + "'", str71, "");
        org.junit.Assert.assertNotNull(intOptional72);
        org.junit.Assert.assertTrue("'" + long74 + "' != '" + (-1L) + "'", long74 == (-1L));
        org.junit.Assert.assertNotNull(intOptional75);
    }

    @Test
    public void test2075() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2075");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        boolean boolean11 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor12 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor12;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService14 = strKafkaSpout0.retryService;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord15 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean16 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord15);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(kafkaSpoutRetryService14);
    }

    @Test
    public void test2076() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2076");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer5 = strKafkaSpout0.commitTimer;
        java.lang.String str6 = strKafkaSpout0.toString();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(strConsumerRecordItor4);
        org.junit.Assert.assertNull(timer5);
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str6, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test2077() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2077");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig5;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector7 = strKafkaSpout0.collector;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout16 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams17 = strKafkaSpout16.kafkaSpoutStreams;
        strKafkaSpout16.consumerAutoCommitMode = false;
        java.lang.String str20 = strKafkaSpout16.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout21 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout21.maxRetries = (byte) -1;
        int int24 = strKafkaSpout21.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray25 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet26 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean27 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet26, kafkaSpoutMessageIdArray25);
        strKafkaSpout21.emitted = kafkaSpoutMessageIdSet26;
        strKafkaSpout16.emitted = kafkaSpoutMessageIdSet26;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout30 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout30.maxRetries = (byte) -1;
        int int33 = strKafkaSpout30.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor34 = null;
        strKafkaSpout30.waitingToEmit = strConsumerRecordItor34;
        org.apache.kafka.common.TopicPartition topicPartition36 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection37 = strKafkaSpout30.toArrayList(topicPartition36);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer38 = strKafkaSpout30.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector39 = strKafkaSpout30.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout40 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout40.maxRetries = (byte) -1;
        int int43 = strKafkaSpout40.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray44 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet45 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean46 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet45, kafkaSpoutMessageIdArray44);
        strKafkaSpout40.emitted = kafkaSpoutMessageIdSet45;
        strKafkaSpout30.emitted = kafkaSpoutMessageIdSet45;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType12, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet26, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet45);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet45;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector51 = null;
        strKafkaSpout0.collector = spoutOutputCollector51;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams53 = strKafkaSpout0.kafkaSpoutStreams;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean54 = strKafkaSpout0.commit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertNull(spoutOutputCollector7);
        org.junit.Assert.assertNull(kafkaSpoutStreams17);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str20, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray25);
        org.junit.Assert.assertTrue("'" + boolean27 + "' != '" + false + "'", boolean27 == false);
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + (-1) + "'", int33 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection37);
        org.junit.Assert.assertNull(timer38);
        org.junit.Assert.assertNull(spoutOutputCollector39);
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + (-1) + "'", int43 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray44);
        org.junit.Assert.assertTrue("'" + boolean46 + "' != '" + false + "'", boolean46 == false);
        org.junit.Assert.assertNull(kafkaSpoutStreams53);
    }

    @Test
    public void test2078() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2078");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.Class<?>, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> wildcardClassKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Class<?>, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>();
    }

    @Test
    public void test2079() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2079");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        strKafkaSpout0.initialized = true;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams10;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords12 = strKafkaSpout0.pollKafkaBroker();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
    }

    @Test
    public void test2080() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2080");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (-1), 35L, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
        int int6 = charSequenceConsumerRecord5.serializedValueSize();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
    }

    @Test
    public void test2081() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2081");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig5;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector7 = strKafkaSpout0.collector;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout16 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams17 = strKafkaSpout16.kafkaSpoutStreams;
        strKafkaSpout16.consumerAutoCommitMode = false;
        java.lang.String str20 = strKafkaSpout16.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout21 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout21.maxRetries = (byte) -1;
        int int24 = strKafkaSpout21.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray25 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet26 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean27 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet26, kafkaSpoutMessageIdArray25);
        strKafkaSpout21.emitted = kafkaSpoutMessageIdSet26;
        strKafkaSpout16.emitted = kafkaSpoutMessageIdSet26;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout30 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout30.maxRetries = (byte) -1;
        int int33 = strKafkaSpout30.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor34 = null;
        strKafkaSpout30.waitingToEmit = strConsumerRecordItor34;
        org.apache.kafka.common.TopicPartition topicPartition36 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection37 = strKafkaSpout30.toArrayList(topicPartition36);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer38 = strKafkaSpout30.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector39 = strKafkaSpout30.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout40 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout40.maxRetries = (byte) -1;
        int int43 = strKafkaSpout40.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray44 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet45 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean46 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet45, kafkaSpoutMessageIdArray44);
        strKafkaSpout40.emitted = kafkaSpoutMessageIdSet45;
        strKafkaSpout30.emitted = kafkaSpoutMessageIdSet45;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType12, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet26, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet45);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet45;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector51 = null;
        strKafkaSpout0.collector = spoutOutputCollector51;
        strKafkaSpout0.numUncommittedOffsets = 35;
        int int55 = strKafkaSpout0.maxRetries;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertNull(spoutOutputCollector7);
        org.junit.Assert.assertNull(kafkaSpoutStreams17);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str20, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray25);
        org.junit.Assert.assertTrue("'" + boolean27 + "' != '" + false + "'", boolean27 == false);
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + (-1) + "'", int33 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection37);
        org.junit.Assert.assertNull(timer38);
        org.junit.Assert.assertNull(spoutOutputCollector39);
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + (-1) + "'", int43 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray44);
        org.junit.Assert.assertTrue("'" + boolean46 + "' != '" + false + "'", boolean46 == false);
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + 0 + "'", int55 == 0);
    }

    @Test
    public void test2082() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2082");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams2 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig3 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig3;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer5 = strKafkaSpout0.kafkaConsumer;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet6 = strKafkaSpout0.emitted;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer7 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer7);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(kafkaSpoutStreams2);
        org.junit.Assert.assertNull(strKafkaConsumer5);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet6);
    }

    @Test
    public void test2083() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2083");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer16;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector18 = null;
        strKafkaSpout0.collector = spoutOutputCollector18;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout20 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout20.maxRetries = (byte) -1;
        int int23 = strKafkaSpout20.maxRetries;
        strKafkaSpout20.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray26 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet27 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean28 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet27, kafkaSpoutMessageIdArray26);
        strKafkaSpout20.emitted = kafkaSpoutMessageIdSet27;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet27;
        long long31 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.kafka.common.TopicPartition topicPartition32 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection33 = strKafkaSpout0.toArrayList(topicPartition32);
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.emit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray26);
        org.junit.Assert.assertTrue("'" + boolean28 + "' != '" + false + "'", boolean28 == false);
        org.junit.Assert.assertTrue("'" + long31 + "' != '" + 0L + "'", long31 == 0L);
        org.junit.Assert.assertNotNull(topicPartitionCollection33);
    }

    @Test
    public void test2084() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2084");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        int int16 = charSequenceConsumerRecord10.serializedValueSize();
        int int17 = charSequenceConsumerRecord10.serializedValueSize();
        long long18 = charSequenceConsumerRecord10.checksum();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + (-1) + "'", int16 == (-1));
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + (-1) + "'", int17 == (-1));
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertNotNull(intOptional20);
    }

    @Test
    public void test2085() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2085");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer5 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer5;
        boolean boolean7 = strKafkaSpout0.consumerAutoCommitMode;
        boolean boolean8 = strKafkaSpout0.waitingToEmit();
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str9 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
    }

    @Test
    public void test2086() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2086");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType4, (long) (short) -1, (int) (byte) 1, (int) (short) -1, (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str11 = charSequenceConsumerRecord10.topic();
        long long12 = charSequenceConsumerRecord10.checksum();
        java.lang.CharSequence charSequence13 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "hi!" + "'", str11, "hi!");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence13 + "' != '" + "hi!" + "'", charSequence13, "hi!");
    }

    @Test
    public void test2087() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2087");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = strKafkaSpout0.tuplesBuilder;
        java.lang.String str8 = strKafkaSpout0.toString();
        strKafkaSpout0.maxRetries = ' ';
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout12 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = strKafkaSpout12.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor14 = null;
        strKafkaSpout12.waitingToEmit = strConsumerRecordItor14;
        boolean boolean16 = strKafkaSpout12.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig17 = null;
        strKafkaSpout12.kafkaSpoutConfig = strKafkaSpoutConfig17;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector19 = strKafkaSpout12.collector;
        org.apache.kafka.common.record.TimestampType timestampType24 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout28 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams29 = strKafkaSpout28.kafkaSpoutStreams;
        strKafkaSpout28.consumerAutoCommitMode = false;
        java.lang.String str32 = strKafkaSpout28.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout33 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout33.maxRetries = (byte) -1;
        int int36 = strKafkaSpout33.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray37 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet38 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean39 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet38, kafkaSpoutMessageIdArray37);
        strKafkaSpout33.emitted = kafkaSpoutMessageIdSet38;
        strKafkaSpout28.emitted = kafkaSpoutMessageIdSet38;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout42 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout42.maxRetries = (byte) -1;
        int int45 = strKafkaSpout42.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor46 = null;
        strKafkaSpout42.waitingToEmit = strConsumerRecordItor46;
        org.apache.kafka.common.TopicPartition topicPartition48 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection49 = strKafkaSpout42.toArrayList(topicPartition48);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer50 = strKafkaSpout42.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector51 = strKafkaSpout42.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout52 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout52.maxRetries = (byte) -1;
        int int55 = strKafkaSpout52.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray56 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet57 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean58 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet57, kafkaSpoutMessageIdArray56);
        strKafkaSpout52.emitted = kafkaSpoutMessageIdSet57;
        strKafkaSpout42.emitted = kafkaSpoutMessageIdSet57;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType24, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet38, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet57);
        strKafkaSpout12.emitted = kafkaSpoutMessageIdSet57;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet57;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer64 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer64;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet13);
        org.junit.Assert.assertTrue("'" + boolean16 + "' != '" + false + "'", boolean16 == false);
        org.junit.Assert.assertNull(spoutOutputCollector19);
        org.junit.Assert.assertNull(kafkaSpoutStreams29);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str32, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray37);
        org.junit.Assert.assertTrue("'" + boolean39 + "' != '" + false + "'", boolean39 == false);
        org.junit.Assert.assertTrue("'" + int45 + "' != '" + (-1) + "'", int45 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection49);
        org.junit.Assert.assertNull(timer50);
        org.junit.Assert.assertNull(spoutOutputCollector51);
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + (-1) + "'", int55 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray56);
        org.junit.Assert.assertTrue("'" + boolean58 + "' != '" + false + "'", boolean58 == false);
    }

    @Test
    public void test2088() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2088");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy11 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy11;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams13 = strKafkaSpout0.kafkaSpoutStreams;
        boolean boolean14 = strKafkaSpout0.initialized;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str15 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(kafkaSpoutStreams13);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
    }

    @Test
    public void test2089() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2089");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        strKafkaSpout0.consumerAutoCommitMode = true;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str10 = strKafkaSpout0.getNamedTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
    }

    @Test
    public void test2090() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2090");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator1 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator1;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator3 = offsetComparator1.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator8 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator8;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator8);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = kafkaSpoutMessageIdComparator3.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator8);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator12 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator12;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = offsetComparator12.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator12.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator8.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator16);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator19 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator19;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = offsetComparator19.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = offsetComparator18.thenComparing(kafkaSpoutMessageIdComparator21);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator23;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator23.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator30 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator30;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator30);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator33 = kafkaSpoutMessageIdComparator25.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator30);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator18.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator30);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator34;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = kafkaSpoutMessageIdComparator34.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator37 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator38 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator38;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator40 = offsetComparator38.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator45 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator45;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator45);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator48 = kafkaSpoutMessageIdComparator40.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator45);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator49 = offsetComparator37.thenComparing(kafkaSpoutMessageIdComparator48);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator50 = kafkaSpoutMessageIdComparator34.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator37);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator51 = offsetComparator0.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator37);
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId52 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId53 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int54 = offsetComparator0.compare(kafkaSpoutMessageId52, kafkaSpoutMessageId53);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator3);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator33);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator40);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator48);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator49);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator50);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator51);
    }

    @Test
    public void test2091() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2091");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        boolean boolean7 = strKafkaSpout0.initialized;
        strKafkaSpout0.maxRetries = (byte) 10;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector10 = strKafkaSpout0.collector;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = null;
        strKafkaSpout0.collector = spoutOutputCollector11;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords13 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords13);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNull(spoutOutputCollector10);
    }

    @Test
    public void test2092() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2092");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        strKafkaSpout0.maxRetries = (short) 0;
        boolean boolean5 = strKafkaSpout0.consumerAutoCommitMode;
        boolean boolean6 = strKafkaSpout0.waitingToEmit();
        int int7 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords8 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords8);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 0 + "'", int7 == 0);
    }

    @Test
    public void test2093() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2093");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
    }

    @Test
    public void test2094() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2094");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition8 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection9 = strKafkaSpout0.toArrayList(topicPartition8);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer10;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer12 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer12;
        strKafkaSpout0.initialized = true;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection9);
    }

    @Test
    public void test2095() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2095");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout9 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout9.maxRetries = (byte) -1;
        int int12 = strKafkaSpout9.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor13 = null;
        strKafkaSpout9.waitingToEmit = strConsumerRecordItor13;
        org.apache.kafka.common.TopicPartition topicPartition15 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection16 = strKafkaSpout9.toArrayList(topicPartition15);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer17 = strKafkaSpout9.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector18 = strKafkaSpout9.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout19 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout19.maxRetries = (byte) -1;
        int int22 = strKafkaSpout19.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray23 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet24 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean25 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet24, kafkaSpoutMessageIdArray23);
        strKafkaSpout19.emitted = kafkaSpoutMessageIdSet24;
        strKafkaSpout9.emitted = kafkaSpoutMessageIdSet24;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet24;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder29 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder29;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig31 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy32 = strKafkaSpout0.firstPollOffsetStrategy;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.doSeekRetriableTopicPartitions();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection16);
        org.junit.Assert.assertNull(timer17);
        org.junit.Assert.assertNull(spoutOutputCollector18);
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray23);
        org.junit.Assert.assertTrue("'" + boolean25 + "' != '" + false + "'", boolean25 == false);
        org.junit.Assert.assertNull(strKafkaSpoutConfig31);
        org.junit.Assert.assertNull(firstPollOffsetStrategy32);
    }

    @Test
    public void test2096() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2096");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        boolean boolean7 = strKafkaSpout0.initialized;
        strKafkaSpout0.maxRetries = (byte) 10;
        strKafkaSpout0.maxRetries = 97;
        boolean boolean12 = strKafkaSpout0.initialized;
        boolean boolean13 = strKafkaSpout0.waitingToEmit();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + false + "'", boolean12 == false);
        org.junit.Assert.assertTrue("'" + boolean13 + "' != '" + false + "'", boolean13 == false);
    }

    @Test
    public void test2097() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2097");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", (int) (short) 100, 0L, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)", "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
    }

    @Test
    public void test2098() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2098");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", 10, 100L, (long) 10, timestampType4, (-1L), (int) (short) 10, (int) (byte) 100, (java.lang.CharSequence) "", "KafkaSpout{acked=null, emitted=null}");
        java.util.Optional<java.lang.Integer> intOptional11 = charSequenceConsumerRecord10.leaderEpoch();
        long long12 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertNotNull(intOptional11);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 100L + "'", long12 == 100L);
    }

    @Test
    public void test2099() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2099");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer12 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector13 = strKafkaSpout0.collector;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.deactivate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertNull(strKafkaConsumer12);
        org.junit.Assert.assertNull(spoutOutputCollector13);
    }

    @Test
    public void test2100() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2100");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType4, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord10.timestampType();
        java.lang.CharSequence charSequence13 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 35L + "'", long11 == 35L);
        org.junit.Assert.assertNull(timestampType12);
        org.junit.Assert.assertEquals("'" + charSequence13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test2101() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2101");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 10, 0L, (java.lang.CharSequence) "", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        long long6 = charSequenceConsumerRecord5.offset();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + 0L + "'", long6 == 0L);
    }

    @Test
    public void test2102() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2102");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>(kafkaSpoutMessageIdSetKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test2103() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2103");
        org.apache.storm.kafka.spout.KafkaSpout kafkaSpout0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, org.apache.kafka.common.header.Headers>.Timer timer1 = kafkaSpout0.new Timer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: reflection call to org.apache.storm.kafka.spout.KafkaSpout$Timer with null for superclass argument");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test2104() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2104");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        strKafkaSpout0.consumerAutoCommitMode = false;
        java.lang.String str6 = strKafkaSpout0.toString();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str6, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test2105() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2105");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        int int8 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor9 = strKafkaSpout0.waitingToEmit;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet10 = strKafkaSpout0.emitted;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = strKafkaSpout0.collector;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean12 = strKafkaSpout0.commit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strConsumerRecordItor9);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet10);
        org.junit.Assert.assertNull(spoutOutputCollector11);
    }

    @Test
    public void test2106() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2106");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.String str13 = charSequenceConsumerRecord10.toString();
        java.lang.String str14 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
    }

    @Test
    public void test2107() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2107");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        int int11 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams12;
        boolean boolean14 = strKafkaSpout0.waitingToEmit();
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 0 + "'", int11 == 0);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
    }

    @Test
    public void test2108() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2108");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long18 = charSequenceConsumerRecord17.checksum();
        long long19 = charSequenceConsumerRecord17.timestamp();
        org.apache.kafka.common.header.Headers headers20 = charSequenceConsumerRecord17.headers();
        java.lang.String str21 = charSequenceConsumerRecord17.toString();
        org.apache.kafka.common.header.Headers headers22 = charSequenceConsumerRecord17.headers();
        java.lang.String str23 = charSequenceConsumerRecord17.topic();
        long long24 = charSequenceConsumerRecord17.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType25 = charSequenceConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (byte) 1, (long) 100, timestampType25, (long) 1, 35, (int) (byte) 10, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.apache.kafka.common.record.TimestampType timestampType41 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType41, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int48 = charSequenceConsumerRecord47.serializedValueSize();
        java.lang.CharSequence charSequence49 = charSequenceConsumerRecord47.key();
        int int50 = charSequenceConsumerRecord47.serializedKeySize();
        int int51 = charSequenceConsumerRecord47.serializedKeySize();
        org.apache.kafka.common.header.Headers headers52 = charSequenceConsumerRecord47.headers();
        org.apache.kafka.common.record.TimestampType timestampType57 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType57, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long64 = charSequenceConsumerRecord63.checksum();
        int int65 = charSequenceConsumerRecord63.partition();
        java.lang.String str66 = charSequenceConsumerRecord63.value();
        int int67 = charSequenceConsumerRecord63.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional68 = charSequenceConsumerRecord63.leaderEpoch();
        long long69 = charSequenceConsumerRecord63.timestamp();
        java.util.Optional<java.lang.Integer> intOptional70 = charSequenceConsumerRecord63.leaderEpoch();
        int int71 = charSequenceConsumerRecord63.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional72 = charSequenceConsumerRecord63.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", 0, 0L, 0L, timestampType25, (java.lang.Long) 35L, (int) (short) -1, (int) '#', (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "hi!", headers52, intOptional72);
        org.apache.kafka.common.record.TimestampType timestampType83 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord89 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType83, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long90 = charSequenceConsumerRecord89.checksum();
        int int91 = charSequenceConsumerRecord89.partition();
        long long92 = charSequenceConsumerRecord89.timestamp();
        long long93 = charSequenceConsumerRecord89.offset();
        java.lang.String str94 = charSequenceConsumerRecord89.toString();
        java.lang.String str95 = charSequenceConsumerRecord89.topic();
        org.apache.kafka.common.header.Headers headers96 = charSequenceConsumerRecord89.headers();
        java.util.Optional<java.lang.Integer> intOptional97 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", (int) ' ', (long) 1, (long) (byte) 1, timestampType25, (java.lang.Long) 0L, (int) (byte) 10, (int) (byte) 0, (java.lang.CharSequence) "hi!", "", headers96, intOptional97);
        java.util.Optional<java.lang.Integer> intOptional99 = charSequenceConsumerRecord98.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str21, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers22);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "" + "'", str23, "");
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + (-1L) + "'", long24 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType25 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType25.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int48 + "' != '" + (-1) + "'", int48 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence49 + "' != '" + "" + "'", charSequence49, "");
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + 52 + "'", int50 == 52);
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 52 + "'", int51 == 52);
        org.junit.Assert.assertNotNull(headers52);
        org.junit.Assert.assertTrue("'" + long64 + "' != '" + (-1L) + "'", long64 == (-1L));
        org.junit.Assert.assertTrue("'" + int65 + "' != '" + 10 + "'", int65 == 10);
        org.junit.Assert.assertEquals("'" + str66 + "' != '" + "hi!" + "'", str66, "hi!");
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + 52 + "'", int67 == 52);
        org.junit.Assert.assertNotNull(intOptional68);
        org.junit.Assert.assertTrue("'" + long69 + "' != '" + (-1L) + "'", long69 == (-1L));
        org.junit.Assert.assertNotNull(intOptional70);
        org.junit.Assert.assertTrue("'" + int71 + "' != '" + (-1) + "'", int71 == (-1));
        org.junit.Assert.assertNotNull(intOptional72);
        org.junit.Assert.assertTrue("'" + long90 + "' != '" + (-1L) + "'", long90 == (-1L));
        org.junit.Assert.assertTrue("'" + int91 + "' != '" + 10 + "'", int91 == 10);
        org.junit.Assert.assertTrue("'" + long92 + "' != '" + (-1L) + "'", long92 == (-1L));
        org.junit.Assert.assertTrue("'" + long93 + "' != '" + 0L + "'", long93 == 0L);
        org.junit.Assert.assertEquals("'" + str94 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str94, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str95 + "' != '" + "" + "'", str95, "");
        org.junit.Assert.assertNotNull(headers96);
        org.junit.Assert.assertNull(intOptional99);
    }

    @Test
    public void test2109() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2109");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        strKafkaSpout0.maxRetries = 32;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.emit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
    }

    @Test
    public void test2110() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2110");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator1 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator2 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator2;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator4 = offsetComparator2.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator9 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator9;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord11 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator9);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = kafkaSpoutMessageIdComparator4.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator9);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator1.thenComparing(kafkaSpoutMessageIdComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = kafkaSpoutMessageIdComparator12.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator12);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator16 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator16;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = offsetComparator16.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator23;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = kafkaSpoutMessageIdComparator18.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator23);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator27 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator27;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = offsetComparator27.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator34 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator34;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = kafkaSpoutMessageIdComparator29.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = kafkaSpoutMessageIdComparator18.thenComparing(kafkaSpoutMessageIdComparator37);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator38);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator40 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId41 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId42 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int43 = offsetComparator0.compare(kafkaSpoutMessageId41, kafkaSpoutMessageId42);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator4);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator40);
    }

    @Test
    public void test2111() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2111");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.timestamp();
        long long16 = charSequenceConsumerRecord10.offset();
        long long17 = charSequenceConsumerRecord10.offset();
        int int18 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        int int20 = charSequenceConsumerRecord10.serializedKeySize();
        int int21 = charSequenceConsumerRecord10.partition();
        java.lang.String str22 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 52 + "'", int18 == 52);
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 52 + "'", int20 == 52);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 10 + "'", int21 == 10);
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "hi!" + "'", str22, "hi!");
    }

    @Test
    public void test2112() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2112");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str19 = charSequenceConsumerRecord10.toString();
        java.lang.String str20 = charSequenceConsumerRecord10.topic();
        int int21 = charSequenceConsumerRecord10.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType22 = charSequenceConsumerRecord10.timestampType();
        int int23 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "" + "'", str20, "");
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertNull(timestampType22);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 10 + "'", int23 == 10);
    }

    @Test
    public void test2113() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2113");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams9 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        boolean boolean11 = strKafkaSpout0.waitingToEmit();
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer12 = strKafkaSpout0.kafkaConsumer;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.activate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
        org.junit.Assert.assertNull(kafkaSpoutStreams9);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(strKafkaConsumer12);
    }

    @Test
    public void test2114() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2114");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig12 = strKafkaSpout0.kafkaSpoutConfig;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
// flaky:             org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertNull(strKafkaSpoutConfig12);
    }

    @Test
    public void test2115() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2115");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.checksum();
        int int16 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.String str17 = charSequenceConsumerRecord10.value();
        java.util.Optional<java.lang.Integer> intOptional18 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType19 = charSequenceConsumerRecord10.timestampType();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        int int21 = charSequenceConsumerRecord10.serializedKeySize();
        int int22 = charSequenceConsumerRecord10.partition();
        int int23 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.header.Headers headers24 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 52 + "'", int16 == 52);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertNotNull(intOptional18);
        org.junit.Assert.assertNull(timestampType19);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 52 + "'", int21 == 52);
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 10 + "'", int22 == 10);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 10 + "'", int23 == 10);
        org.junit.Assert.assertNotNull(headers24);
    }

    @Test
    public void test2116() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2116");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str14 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord10.timestampType();
        int int16 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertNull(timestampType15);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + (-1) + "'", int16 == (-1));
    }

    @Test
    public void test2117() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2117");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer5 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer5;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector8 = null;
        strKafkaSpout0.collector = spoutOutputCollector8;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor10 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy11 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy11;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
// flaky:             org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertNull(strConsumerRecordItor10);
    }

    @Test
    public void test2118() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2118");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 10, 1L, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=[]}");
        int int6 = charSequenceConsumerRecord5.partition();
        long long7 = charSequenceConsumerRecord5.offset();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + 10 + "'", int6 == 10);
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + 1L + "'", long7 == 1L);
    }

    @Test
    public void test2119() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2119");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.numUncommittedOffsets = (byte) 1;
        strKafkaSpout0.initialized = false;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector14 = strKafkaSpout0.collector;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(spoutOutputCollector14);
    }

    @Test
    public void test2120() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2120");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        java.lang.String str13 = charSequenceConsumerRecord10.topic();
        int int14 = charSequenceConsumerRecord10.serializedValueSize();
        int int15 = charSequenceConsumerRecord10.serializedValueSize();
        long long16 = charSequenceConsumerRecord10.timestamp();
        long long17 = charSequenceConsumerRecord10.offset();
        int int18 = charSequenceConsumerRecord10.partition();
        java.lang.String str19 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 10 + "'", int18 == 10);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test2121() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2121");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 1, 1L, (long) (byte) 10, timestampType4, (long) '#', (int) (byte) 100, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        java.util.Optional<java.lang.Integer> intOptional14 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 10L + "'", long11 == 10L);
        org.junit.Assert.assertNull(timestampType12);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
        org.junit.Assert.assertNotNull(intOptional14);
    }

    @Test
    public void test2122() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2122");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        int int19 = charSequenceConsumerRecord10.partition();
        long long20 = charSequenceConsumerRecord10.checksum();
        int int21 = charSequenceConsumerRecord10.partition();
        long long22 = charSequenceConsumerRecord10.offset();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord10.timestampType();
        long long24 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 10 + "'", int21 == 10);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 0L + "'", long22 == 0L);
        org.junit.Assert.assertNull(timestampType23);
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + (-1L) + "'", long24 == (-1L));
    }

    @Test
    public void test2123() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2123");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout3 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout3.maxRetries = (byte) -1;
        int int6 = strKafkaSpout3.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout3.waitingToEmit = strConsumerRecordItor7;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout3.toArrayList(topicPartition9);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = strKafkaSpout3.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType16 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout20 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout20.maxRetries = (byte) -1;
        int int23 = strKafkaSpout20.maxRetries;
        strKafkaSpout20.numUncommittedOffsets = '#';
        strKafkaSpout20.initialized = true;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet28 = strKafkaSpout20.emitted;
        org.apache.kafka.common.record.TimestampType timestampType36 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType36, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int43 = charSequenceConsumerRecord42.serializedValueSize();
        java.lang.CharSequence charSequence44 = charSequenceConsumerRecord42.key();
        org.apache.kafka.common.header.Headers headers45 = charSequenceConsumerRecord42.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray46 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList47 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean48 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47, kafkaSpoutMessageIdArray46);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers45, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47);
        org.apache.kafka.common.record.TimestampType timestampType54 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType54, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int61 = charSequenceConsumerRecord60.serializedValueSize();
        java.lang.CharSequence charSequence62 = charSequenceConsumerRecord60.key();
        org.apache.kafka.common.header.Headers headers63 = charSequenceConsumerRecord60.headers();
        org.apache.kafka.common.record.TimestampType timestampType68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType68, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long75 = charSequenceConsumerRecord74.offset();
        int int76 = charSequenceConsumerRecord74.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional77 = charSequenceConsumerRecord74.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> objConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) '4', (long) (short) 0, (long) 100, timestampType16, (java.lang.Long) 1L, (int) (short) 0, 0, (java.lang.Object) kafkaSpoutMessageIdSet28, (java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47, headers63, intOptional77);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.common.header.Headers> iSpoutConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.common.header.Headers>("KafkaSpout{acked=null, emitted=null}", (int) '#', (long) 1, (org.apache.storm.spout.ISpout) strKafkaSpout3, headers63);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService80 = null;
        strKafkaSpout3.retryService = kafkaSpoutRetryService80;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy82 = null;
        strKafkaSpout3.firstPollOffsetStrategy = firstPollOffsetStrategy82;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer84 = strKafkaSpout3.commitTimer;
        strKafkaSpout3.maxRetries = (byte) 10;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Map<java.lang.String, java.lang.Object> strMap87 = strKafkaSpout3.getComponentConfiguration();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(strKafkaConsumer11);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet28);
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + (-1) + "'", int43 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence44 + "' != '" + "" + "'", charSequence44, "");
        org.junit.Assert.assertNotNull(headers45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray46);
        org.junit.Assert.assertTrue("'" + boolean48 + "' != '" + false + "'", boolean48 == false);
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + (-1) + "'", int61 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence62 + "' != '" + "" + "'", charSequence62, "");
        org.junit.Assert.assertNotNull(headers63);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + 0L + "'", long75 == 0L);
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + (-1) + "'", int76 == (-1));
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertNull(timer84);
    }

    @Test
    public void test2124() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2124");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        java.lang.String str18 = charSequenceConsumerRecord10.value();
        java.lang.CharSequence charSequence19 = charSequenceConsumerRecord10.key();
        int int20 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "hi!" + "'", str18, "hi!");
        org.junit.Assert.assertEquals("'" + charSequence19 + "' != '" + "" + "'", charSequence19, "");
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + (-1) + "'", int20 == (-1));
    }

    @Test
    public void test2125() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2125");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder2 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder2;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy4 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = strKafkaSpout0.kafkaSpoutConfig;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor7;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer11;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strKafkaSpoutConfig6);
    }

    @Test
    public void test2126() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2126");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy11 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy11;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams13 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig14 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig15 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig15;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str17 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(kafkaSpoutStreams13);
        org.junit.Assert.assertNull(strKafkaSpoutConfig14);
    }

    @Test
    public void test2127() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2127");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        java.lang.String str8 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer9 = strKafkaSpout0.commitTimer;
        int int10 = strKafkaSpout0.maxRetries;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = strKafkaSpout0.collector;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords12 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords12);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(timer9);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 0 + "'", int10 == 0);
        org.junit.Assert.assertNull(spoutOutputCollector11);
    }

    @Test
    public void test2128() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2128");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams7;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = strKafkaSpout0.retryService;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy11 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy11;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(kafkaSpoutRetryService9);
        org.junit.Assert.assertNull(strKafkaConsumer10);
    }

    @Test
    public void test2129() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2129");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer9 = strKafkaSpout0.kafkaConsumer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.doSeekRetriableTopicPartitions();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertNull(strKafkaConsumer9);
        org.junit.Assert.assertNull(strKafkaConsumer10);
    }

    @Test
    public void test2130() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2130");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) ' ', (long) (byte) 100, (long) (byte) -1, timestampType4, (long) (byte) -1, (int) (byte) 10, 10, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long11 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str12 = charSequenceConsumerRecord10.toString();
        org.apache.kafka.common.record.TimestampType timestampType13 = charSequenceConsumerRecord10.timestampType();
        java.lang.CharSequence charSequence14 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers15 = charSequenceConsumerRecord10.headers();
        int int16 = charSequenceConsumerRecord10.partition();
        java.util.Optional<java.lang.Integer> intOptional17 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str12, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNull(timestampType13);
        org.junit.Assert.assertEquals("'" + charSequence14 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", charSequence14, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNotNull(headers15);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 32 + "'", int16 == 32);
        org.junit.Assert.assertNotNull(intOptional17);
    }

    @Test
    public void test2131() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2131");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        int int13 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence14 = charSequenceConsumerRecord10.key();
        java.lang.String str15 = charSequenceConsumerRecord10.topic();
        int int16 = charSequenceConsumerRecord10.serializedKeySize();
        int int17 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
        org.junit.Assert.assertEquals("'" + charSequence14 + "' != '" + "" + "'", charSequence14, "");
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "" + "'", str15, "");
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 52 + "'", int16 == 52);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + (-1) + "'", int17 == (-1));
    }

    @Test
    public void test2132() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2132");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet4 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer5 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy6 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy6;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str8 = strKafkaSpout0.getNamedTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet4);
        org.junit.Assert.assertNull(timer5);
    }

    @Test
    public void test2133() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2133");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        java.lang.String str4 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout5 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout5.maxRetries = (byte) -1;
        int int8 = strKafkaSpout5.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray9 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet10 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean11 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet10, kafkaSpoutMessageIdArray9);
        strKafkaSpout5.emitted = kafkaSpoutMessageIdSet10;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet10;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector14 = null;
        strKafkaSpout0.collector = spoutOutputCollector14;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector16 = strKafkaSpout0.collector;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.deactivate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertEquals("'" + str4 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str4, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray9);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(spoutOutputCollector16);
    }

    @Test
    public void test2134() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2134");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = strKafkaSpout0.kafkaConsumer;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer4);
        org.junit.Assert.assertNull(strKafkaSpoutConfig5);
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertNull(strKafkaConsumer7);
    }

    @Test
    public void test2135() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2135");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy2 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy2;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy4 = strKafkaSpout0.firstPollOffsetStrategy;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
// flaky:             org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(firstPollOffsetStrategy4);
    }

    @Test
    public void test2136() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2136");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        long long7 = charSequenceConsumerRecord5.timestamp();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        int int9 = charSequenceConsumerRecord5.serializedValueSize();
        java.lang.String str10 = charSequenceConsumerRecord5.value();
        long long11 = charSequenceConsumerRecord5.timestamp();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str10, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
    }

    @Test
    public void test2137() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2137");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) -1, (long) (-1), (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        long long6 = charSequenceConsumerRecord5.offset();
        int int7 = charSequenceConsumerRecord5.partition();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
    }

    @Test
    public void test2138() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2138");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType14, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int21 = charSequenceConsumerRecord20.serializedValueSize();
        java.lang.CharSequence charSequence22 = charSequenceConsumerRecord20.key();
        org.apache.kafka.common.header.Headers headers23 = charSequenceConsumerRecord20.headers();
        java.util.Optional<java.lang.Integer> intOptional24 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType4, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers23, intOptional24);
        java.lang.String str26 = charSequenceConsumerRecord25.value();
        java.lang.String str27 = charSequenceConsumerRecord25.value();
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence22 + "' != '" + "" + "'", charSequence22, "");
        org.junit.Assert.assertNotNull(headers23);
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str26, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str27 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str27, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test2139() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2139");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder9;
        org.apache.kafka.common.TopicPartition topicPartition11 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setAcked(topicPartition11, (long) (short) 10);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
    }

    @Test
    public void test2140() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2140");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        boolean boolean11 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy12 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.kafka.common.TopicPartition topicPartition13 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection14 = strKafkaSpout0.toArrayList(topicPartition13);
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str15 = strKafkaSpout0.getNamedTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy12);
        org.junit.Assert.assertNotNull(topicPartitionCollection14);
    }

    @Test
    public void test2141() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2141");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams10;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams13 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = true;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(spoutOutputCollector12);
        org.junit.Assert.assertNull(kafkaSpoutStreams13);
    }

    @Test
    public void test2142() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2142");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord10.headers();
        java.lang.String str17 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
    }

    @Test
    public void test2143() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2143");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        int int18 = charSequenceConsumerRecord10.serializedValueSize();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.header.Headers headers20 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + (-1) + "'", int18 == (-1));
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertNotNull(headers20);
    }

    @Test
    public void test2144() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2144");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType31 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType31, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long38 = charSequenceConsumerRecord37.checksum();
        int int39 = charSequenceConsumerRecord37.partition();
        long long40 = charSequenceConsumerRecord37.timestamp();
        java.lang.String str41 = charSequenceConsumerRecord37.toString();
        long long42 = charSequenceConsumerRecord37.timestamp();
        org.apache.kafka.common.header.Headers headers43 = charSequenceConsumerRecord37.headers();
        org.apache.kafka.common.record.TimestampType timestampType44 = charSequenceConsumerRecord37.timestampType();
        java.util.Optional<java.lang.Integer> intOptional45 = charSequenceConsumerRecord37.leaderEpoch();
        org.apache.storm.topology.IComponent iComponent46 = null;
        org.apache.kafka.common.record.TimestampType timestampType51 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType51, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long58 = charSequenceConsumerRecord57.checksum();
        int int59 = charSequenceConsumerRecord57.partition();
        long long60 = charSequenceConsumerRecord57.timestamp();
        java.lang.String str61 = charSequenceConsumerRecord57.toString();
        org.apache.kafka.common.header.Headers headers62 = charSequenceConsumerRecord57.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent> intOptionalConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent>("hi!", (int) ' ', (long) (byte) -1, (long) (-1), timestampType23, (java.lang.Long) 100L, (int) 'a', (-1), intOptional45, iComponent46, headers62);
        org.apache.storm.topology.IRichSpout iRichSpout68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.storm.topology.IRichSpout> strComparableConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.storm.topology.IRichSpout>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", (int) (byte) 0, (long) 10, (long) (-1), timestampType23, (long) 0, (int) (short) 10, (int) (byte) 1, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", iRichSpout68);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", (int) (byte) 100, 100L, (long) (short) 100, timestampType23, (long) 'a', (int) ' ', (-1), (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", 52, 0L, (long) 97, timestampType23, (long) (byte) -1, (int) ' ', 10, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.apache.kafka.common.header.Headers headers82 = charSequenceConsumerRecord81.headers();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + (-1L) + "'", long38 == (-1L));
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + 10 + "'", int39 == 10);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertEquals("'" + str41 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str41, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long42 + "' != '" + (-1L) + "'", long42 == (-1L));
        org.junit.Assert.assertNotNull(headers43);
        org.junit.Assert.assertNull(timestampType44);
        org.junit.Assert.assertNotNull(intOptional45);
        org.junit.Assert.assertTrue("'" + long58 + "' != '" + (-1L) + "'", long58 == (-1L));
        org.junit.Assert.assertTrue("'" + int59 + "' != '" + 10 + "'", int59 == 10);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str61, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers62);
        org.junit.Assert.assertNotNull(headers82);
    }

    @Test
    public void test2145() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2145");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService8;
        long long10 = strKafkaSpout0.numUncommittedOffsets;
        boolean boolean11 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer12 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService13 = strKafkaSpout0.retryService;
        org.apache.kafka.common.TopicPartition topicPartition14 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setAcked(topicPartition14, (long) 32);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 0L + "'", long10 == 0L);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(timer12);
        org.junit.Assert.assertNull(kafkaSpoutRetryService13);
    }

    @Test
    public void test2146() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2146");
        org.apache.storm.kafka.spout.KafkaSpout<java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.HashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdComparatorKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.HashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>();
    }

    @Test
    public void test2147() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2147");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy3 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout4 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout4.maxRetries = (byte) -1;
        int int7 = strKafkaSpout4.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray8 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet9 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean10 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet9, kafkaSpoutMessageIdArray8);
        strKafkaSpout4.emitted = kafkaSpoutMessageIdSet9;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig13 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig13;
        strKafkaSpout0.initialized = true;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(firstPollOffsetStrategy3);
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray8);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
    }

    @Test
    public void test2148() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2148");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = offsetComparator11.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator7.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator11);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator7.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = offsetComparator7.reversed();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId18 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId19 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int20 = offsetComparator7.compare(kafkaSpoutMessageId18, kafkaSpoutMessageId19);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
    }

    @Test
    public void test2149() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2149");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer1 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy2 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams3 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams3;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords5 = strKafkaSpout0.pollKafkaBroker();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(timer1);
        org.junit.Assert.assertNull(firstPollOffsetStrategy2);
    }

    @Test
    public void test2150() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2150");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray6 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet7 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean8 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet7, kafkaSpoutMessageIdArray6);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet7;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer10 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService11 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService11;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService14 = strKafkaSpout0.retryService;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray6);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
        org.junit.Assert.assertNull(timer10);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder13);
        org.junit.Assert.assertNull(kafkaSpoutRetryService14);
    }

    @Test
    public void test2151() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2151");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams9 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        int int11 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig14 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig14;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams16 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams16;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer18 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy19 = strKafkaSpout0.firstPollOffsetStrategy;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
        org.junit.Assert.assertNull(kafkaSpoutStreams9);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertNull(timer18);
        org.junit.Assert.assertNull(firstPollOffsetStrategy19);
    }

    @Test
    public void test2152() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2152");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder9;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService12 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService12;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertNull(strKafkaConsumer11);
    }

    @Test
    public void test2153() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2153");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)", (int) '4', (long) 0, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 35, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)))");
        int int6 = charSequenceConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
    }

    @Test
    public void test2154() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2154");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        java.lang.String str17 = charSequenceConsumerRecord10.topic();
        java.lang.String str18 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "hi!" + "'", str18, "hi!");
    }

    @Test
    public void test2155() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2155");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = strKafkaSpout0.kafkaConsumer;
        boolean boolean17 = strKafkaSpout0.waitingToEmit();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertNull(strKafkaConsumer16);
        org.junit.Assert.assertTrue("'" + boolean17 + "' != '" + false + "'", boolean17 == false);
    }

    @Test
    public void test2156() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2156");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType17 = null;
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int34 = charSequenceConsumerRecord33.serializedValueSize();
        java.lang.CharSequence charSequence35 = charSequenceConsumerRecord33.key();
        org.apache.kafka.common.header.Headers headers36 = charSequenceConsumerRecord33.headers();
        java.util.Optional<java.lang.Integer> intOptional37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType17, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers36, intOptional37);
        org.apache.kafka.common.record.TimestampType timestampType46 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType46, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int53 = charSequenceConsumerRecord52.serializedValueSize();
        java.lang.CharSequence charSequence54 = charSequenceConsumerRecord52.key();
        org.apache.kafka.common.header.Headers headers55 = charSequenceConsumerRecord52.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray56 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList57 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean58 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57, kafkaSpoutMessageIdArray56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers55, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headersConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("", (int) '#', 1L, headers36, kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType4, (java.lang.Long) (-1L), (int) (short) 100, 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}", headers36);
        int int62 = charSequenceConsumerRecord61.partition();
        java.util.Optional<java.lang.Integer> intOptional63 = charSequenceConsumerRecord61.leaderEpoch();
        org.apache.kafka.common.header.Headers headers64 = charSequenceConsumerRecord61.headers();
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + (-1) + "'", int34 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence35 + "' != '" + "" + "'", charSequence35, "");
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + (-1) + "'", int53 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence54 + "' != '" + "" + "'", charSequence54, "");
        org.junit.Assert.assertNotNull(headers55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray56);
        org.junit.Assert.assertTrue("'" + boolean58 + "' != '" + false + "'", boolean58 == false);
        org.junit.Assert.assertTrue("'" + int62 + "' != '" + 97 + "'", int62 == 97);
        org.junit.Assert.assertNotNull(intOptional63);
        org.junit.Assert.assertNotNull(headers64);
    }

    @Test
    public void test2157() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2157");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional15 = charSequenceConsumerRecord10.leaderEpoch();
        long long16 = charSequenceConsumerRecord10.checksum();
        int int17 = charSequenceConsumerRecord10.serializedKeySize();
        int int18 = charSequenceConsumerRecord10.partition();
        long long19 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 52 + "'", int14 == 52);
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 52 + "'", int17 == 52);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 10 + "'", int18 == 10);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
    }

    @Test
    public void test2158() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2158");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder8;
        long long10 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        java.lang.Class<?> wildcardClass14 = offsetComparator11.getClass();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.fail((java.lang.Object) offsetComparator11);
            org.junit.Assert.fail("Expected exception of type java.lang.ClassCastException; message: org.apache.storm.kafka.spout.KafkaSpout$OffsetComparator cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId");
        } catch (java.lang.ClassCastException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 0L + "'", long10 == 0L);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(wildcardClass14);
    }

    @Test
    public void test2159() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2159");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.toString();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.header.Headers headers17 = charSequenceConsumerRecord10.headers();
        long long18 = charSequenceConsumerRecord10.checksum();
        long long19 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str15, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertNotNull(headers17);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
    }

    @Test
    public void test2160() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2160");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        boolean boolean7 = strKafkaSpout0.initialized;
        strKafkaSpout0.consumerAutoCommitMode = true;
        boolean boolean10 = strKafkaSpout0.commit();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer11 = strKafkaSpout0.commitTimer;
        long long12 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.kafka.common.record.TimestampType timestampType20 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType20, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long27 = charSequenceConsumerRecord26.checksum();
        int int28 = charSequenceConsumerRecord26.partition();
        long long29 = charSequenceConsumerRecord26.timestamp();
        long long30 = charSequenceConsumerRecord26.offset();
        int int31 = charSequenceConsumerRecord26.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType32 = charSequenceConsumerRecord26.timestampType();
        int int33 = charSequenceConsumerRecord26.partition();
        long long34 = charSequenceConsumerRecord26.checksum();
        java.util.Optional<java.lang.Integer> intOptional35 = charSequenceConsumerRecord26.leaderEpoch();
        int int36 = charSequenceConsumerRecord26.serializedKeySize();
        int int37 = charSequenceConsumerRecord26.serializedValueSize();
        int int38 = charSequenceConsumerRecord26.serializedKeySize();
        org.apache.kafka.common.header.Headers headers39 = charSequenceConsumerRecord26.headers();
        org.apache.kafka.common.record.TimestampType timestampType44 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout48 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams49 = strKafkaSpout48.kafkaSpoutStreams;
        strKafkaSpout48.consumerAutoCommitMode = false;
        java.lang.String str52 = strKafkaSpout48.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout53 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout53.maxRetries = (byte) -1;
        int int56 = strKafkaSpout53.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray57 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet58 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean59 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet58, kafkaSpoutMessageIdArray57);
        strKafkaSpout53.emitted = kafkaSpoutMessageIdSet58;
        strKafkaSpout48.emitted = kafkaSpoutMessageIdSet58;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout62 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout62.maxRetries = (byte) -1;
        int int65 = strKafkaSpout62.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor66 = null;
        strKafkaSpout62.waitingToEmit = strConsumerRecordItor66;
        org.apache.kafka.common.TopicPartition topicPartition68 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection69 = strKafkaSpout62.toArrayList(topicPartition68);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer70 = strKafkaSpout62.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector71 = strKafkaSpout62.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout72 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout72.maxRetries = (byte) -1;
        int int75 = strKafkaSpout72.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray76 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet77 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean78 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet77, kafkaSpoutMessageIdArray76);
        strKafkaSpout72.emitted = kafkaSpoutMessageIdSet77;
        strKafkaSpout62.emitted = kafkaSpoutMessageIdSet77;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType44, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet58, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet77);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.AbstractCollection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headersConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.AbstractCollection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", 97, (long) 97, headers39, (java.util.AbstractCollection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet77);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet77;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNull(timer11);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 35L + "'", long12 == 35L);
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + (-1L) + "'", long27 == (-1L));
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 10 + "'", int28 == 10);
        org.junit.Assert.assertTrue("'" + long29 + "' != '" + (-1L) + "'", long29 == (-1L));
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + 0L + "'", long30 == 0L);
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 52 + "'", int31 == 52);
        org.junit.Assert.assertNull(timestampType32);
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + 10 + "'", int33 == 10);
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertNotNull(intOptional35);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + 52 + "'", int36 == 52);
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + (-1) + "'", int37 == (-1));
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + 52 + "'", int38 == 52);
        org.junit.Assert.assertNotNull(headers39);
        org.junit.Assert.assertNull(kafkaSpoutStreams49);
        org.junit.Assert.assertEquals("'" + str52 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str52, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int56 + "' != '" + (-1) + "'", int56 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray57);
        org.junit.Assert.assertTrue("'" + boolean59 + "' != '" + false + "'", boolean59 == false);
        org.junit.Assert.assertTrue("'" + int65 + "' != '" + (-1) + "'", int65 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection69);
        org.junit.Assert.assertNull(timer70);
        org.junit.Assert.assertNull(spoutOutputCollector71);
        org.junit.Assert.assertTrue("'" + int75 + "' != '" + (-1) + "'", int75 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray76);
        org.junit.Assert.assertTrue("'" + boolean78 + "' != '" + false + "'", boolean78 == false);
    }

    @Test
    public void test2161() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2161");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType14 = null;
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.common.record.TimestampType timestampType37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType37, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int44 = charSequenceConsumerRecord43.serializedValueSize();
        java.lang.CharSequence charSequence45 = charSequenceConsumerRecord43.key();
        org.apache.kafka.common.header.Headers headers46 = charSequenceConsumerRecord43.headers();
        java.util.Optional<java.lang.Integer> intOptional47 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType27, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers46, intOptional47);
        org.apache.kafka.common.record.TimestampType timestampType56 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord62 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType56, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int63 = charSequenceConsumerRecord62.serializedValueSize();
        java.lang.CharSequence charSequence64 = charSequenceConsumerRecord62.key();
        org.apache.kafka.common.header.Headers headers65 = charSequenceConsumerRecord62.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray66 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList67 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean68 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList67, kafkaSpoutMessageIdArray66);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers65, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList67);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headersConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("", (int) '#', 1L, headers46, kafkaSpoutMessageIdList67);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType14, (java.lang.Long) (-1L), (int) (short) 100, 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}", headers46);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) 10, (long) (byte) -1, (long) '#', timestampType4, (java.lang.Long) 100L, (int) (byte) -1, 100, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers46);
        java.util.Optional<java.lang.Integer> intOptional73 = charSequenceConsumerRecord72.leaderEpoch();
        org.junit.Assert.assertTrue("'" + int44 + "' != '" + (-1) + "'", int44 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence45 + "' != '" + "" + "'", charSequence45, "");
        org.junit.Assert.assertNotNull(headers46);
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + (-1) + "'", int63 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence64 + "' != '" + "" + "'", charSequence64, "");
        org.junit.Assert.assertNotNull(headers65);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray66);
        org.junit.Assert.assertTrue("'" + boolean68 + "' != '" + false + "'", boolean68 == false);
        org.junit.Assert.assertNotNull(intOptional73);
    }

    @Test
    public void test2162() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2162");
        org.apache.storm.kafka.spout.KafkaSpout kafkaSpout0 = null;
        java.util.concurrent.TimeUnit timeUnit3 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Class<?>, java.lang.Object>.Timer timer4 = kafkaSpout0.new Timer((long) (-1), (long) 'a', timeUnit3);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: reflection call to org.apache.storm.kafka.spout.KafkaSpout$Timer with null for superclass argument");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test2163() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2163");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams4;
        boolean boolean6 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout7 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean8 = strKafkaSpout7.waitingToEmit();
        boolean boolean9 = strKafkaSpout7.consumerAutoCommitMode;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout7.toArrayList(topicPartition10);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer12 = strKafkaSpout7.commitTimer;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.ack((java.lang.Object) strKafkaSpout7);
            org.junit.Assert.fail("Expected exception of type java.lang.ClassCastException; message: org.apache.storm.kafka.spout.KafkaSpout cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId");
        } catch (java.lang.ClassCastException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + 0 + "'", int3 == 0);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
        org.junit.Assert.assertTrue("'" + boolean9 + "' != '" + false + "'", boolean9 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertNull(timer12);
    }

    @Test
    public void test2164() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2164");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy6 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy6;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet8 = strKafkaSpout0.emitted;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet8);
    }

    @Test
    public void test2165() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2165");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        java.lang.String str17 = charSequenceConsumerRecord10.toString();
        java.lang.CharSequence charSequence18 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence19 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType20 = charSequenceConsumerRecord10.timestampType();
        long long21 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str17, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + charSequence18 + "' != '" + "" + "'", charSequence18, "");
        org.junit.Assert.assertEquals("'" + charSequence19 + "' != '" + "" + "'", charSequence19, "");
        org.junit.Assert.assertNull(timestampType20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
    }

    @Test
    public void test2166() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2166");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        boolean boolean2 = strKafkaSpout0.waitingToEmit();
        boolean boolean3 = strKafkaSpout0.initialized;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertTrue("'" + boolean2 + "' != '" + false + "'", boolean2 == false);
        org.junit.Assert.assertTrue("'" + boolean3 + "' != '" + false + "'", boolean3 == false);
    }

    @Test
    public void test2167() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2167");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType4, (long) (short) -1, (int) (byte) 1, (int) (short) -1, (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long11 = charSequenceConsumerRecord10.offset();
        long long12 = charSequenceConsumerRecord10.timestamp();
        long long13 = charSequenceConsumerRecord10.offset();
        int int14 = charSequenceConsumerRecord10.partition();
        long long15 = charSequenceConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional16 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str17 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 1L + "'", long11 == 1L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 0L + "'", long12 == 0L);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 1L + "'", long13 == 1L);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 97 + "'", int14 == 97);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 0L + "'", long15 == 0L);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str17, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test2168() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2168");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.numUncommittedOffsets = (byte) 1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer12 = strKafkaSpout0.kafkaConsumer;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer12);
    }

    @Test
    public void test2169() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2169");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (-1), (long) ' ', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.util.Optional<java.lang.Integer> intOptional6 = charSequenceConsumerRecord5.leaderEpoch();
        int int7 = charSequenceConsumerRecord5.partition();
        long long8 = charSequenceConsumerRecord5.timestamp();
        java.lang.String str9 = charSequenceConsumerRecord5.topic();
        java.lang.String str10 = charSequenceConsumerRecord5.value();
        org.junit.Assert.assertNotNull(intOptional6);
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + (-1L) + "'", long8 == (-1L));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "hi!" + "'", str9, "hi!");
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str10, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test2170() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2170");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy3 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout4 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout4.maxRetries = (byte) -1;
        int int7 = strKafkaSpout4.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray8 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet9 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean10 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet9, kafkaSpoutMessageIdArray8);
        strKafkaSpout4.emitted = kafkaSpoutMessageIdSet9;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig13 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig13;
        strKafkaSpout0.initialized = true;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer17 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer17;
        org.junit.Assert.assertNull(firstPollOffsetStrategy3);
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray8);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
    }

    @Test
    public void test2171() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2171");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) 0, (long) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 0, leaderEpoch = null, offset = -1, null = 100, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
    }

    @Test
    public void test2172() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2172");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector10 = strKafkaSpout0.collector;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(spoutOutputCollector10);
    }

    @Test
    public void test2173() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2173");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = offsetComparator7.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator11;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator17 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator17;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator17);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = offsetComparator17.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator21 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator22 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator22;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = offsetComparator22.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator29 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator29;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator29);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = kafkaSpoutMessageIdComparator24.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator29);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator33 = offsetComparator21.thenComparing(kafkaSpoutMessageIdComparator32);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = kafkaSpoutMessageIdComparator32.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator32;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = kafkaSpoutMessageIdComparator20.thenComparing(kafkaSpoutMessageIdComparator32);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator20;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = kafkaSpoutMessageIdComparator11.thenComparing(kafkaSpoutMessageIdComparator20);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator38;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator33);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
    }

    @Test
    public void test2174() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2174");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService8;
        long long10 = strKafkaSpout0.numUncommittedOffsets;
        strKafkaSpout0.initialized = false;
        strKafkaSpout0.maxRetries = 10;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord15 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean16 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord15);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 0L + "'", long10 == 0L);
    }

    @Test
    public void test2175() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2175");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long18 = charSequenceConsumerRecord17.checksum();
        long long19 = charSequenceConsumerRecord17.timestamp();
        org.apache.kafka.common.header.Headers headers20 = charSequenceConsumerRecord17.headers();
        java.lang.String str21 = charSequenceConsumerRecord17.toString();
        org.apache.kafka.common.header.Headers headers22 = charSequenceConsumerRecord17.headers();
        java.lang.String str23 = charSequenceConsumerRecord17.topic();
        long long24 = charSequenceConsumerRecord17.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType25 = charSequenceConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (byte) 1, (long) 100, timestampType25, (long) 1, 35, (int) (byte) 10, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.apache.kafka.common.record.TimestampType timestampType41 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType41, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long48 = charSequenceConsumerRecord47.checksum();
        int int49 = charSequenceConsumerRecord47.partition();
        long long50 = charSequenceConsumerRecord47.timestamp();
        long long51 = charSequenceConsumerRecord47.offset();
        java.lang.String str52 = charSequenceConsumerRecord47.toString();
        java.lang.String str53 = charSequenceConsumerRecord47.topic();
        org.apache.kafka.common.header.Headers headers54 = charSequenceConsumerRecord47.headers();
        org.apache.kafka.common.record.TimestampType timestampType59 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType59, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long66 = charSequenceConsumerRecord65.checksum();
        int int67 = charSequenceConsumerRecord65.partition();
        long long68 = charSequenceConsumerRecord65.timestamp();
        java.lang.String str69 = charSequenceConsumerRecord65.toString();
        long long70 = charSequenceConsumerRecord65.timestamp();
        long long71 = charSequenceConsumerRecord65.offset();
        long long72 = charSequenceConsumerRecord65.offset();
        org.apache.kafka.common.header.Headers headers73 = charSequenceConsumerRecord65.headers();
        int int74 = charSequenceConsumerRecord65.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional75 = charSequenceConsumerRecord65.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", 32, 52L, (long) 32, timestampType25, (java.lang.Long) 10L, (int) (byte) 1, 1, (java.lang.CharSequence) "", "", headers54, intOptional75);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) 100, (long) 'a', (long) 97, timestampType25, 10L, (int) (short) 100, (int) (byte) -1, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}))");
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str21, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers22);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "" + "'", str23, "");
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + (-1L) + "'", long24 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType25 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType25.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 10 + "'", int49 == 10);
        org.junit.Assert.assertTrue("'" + long50 + "' != '" + (-1L) + "'", long50 == (-1L));
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + 0L + "'", long51 == 0L);
        org.junit.Assert.assertEquals("'" + str52 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str52, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "" + "'", str53, "");
        org.junit.Assert.assertNotNull(headers54);
        org.junit.Assert.assertTrue("'" + long66 + "' != '" + (-1L) + "'", long66 == (-1L));
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + 10 + "'", int67 == 10);
        org.junit.Assert.assertTrue("'" + long68 + "' != '" + (-1L) + "'", long68 == (-1L));
        org.junit.Assert.assertEquals("'" + str69 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str69, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long70 + "' != '" + (-1L) + "'", long70 == (-1L));
        org.junit.Assert.assertTrue("'" + long71 + "' != '" + 0L + "'", long71 == 0L);
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + 0L + "'", long72 == 0L);
        org.junit.Assert.assertNotNull(headers73);
        org.junit.Assert.assertTrue("'" + int74 + "' != '" + (-1) + "'", int74 == (-1));
        org.junit.Assert.assertNotNull(intOptional75);
    }

    @Test
    public void test2176() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2176");
        java.lang.CharSequence charSequence3 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) ' ', (long) (byte) -1, charSequence3, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)");
        java.lang.String str6 = charSequenceConsumerRecord5.value();
        java.lang.String str7 = charSequenceConsumerRecord5.topic();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)" + "'", str6, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)");
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str7, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
    }

    @Test
    public void test2177() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2177");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder11 = strKafkaSpout0.tuplesBuilder;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
// flaky:             org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder11);
    }

    @Test
    public void test2178() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2178");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        long long21 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType22 = charSequenceConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertNull(timestampType22);
    }

    @Test
    public void test2179() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2179");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType14 = null;
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.common.record.TimestampType timestampType37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType37, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int44 = charSequenceConsumerRecord43.serializedValueSize();
        java.lang.CharSequence charSequence45 = charSequenceConsumerRecord43.key();
        org.apache.kafka.common.header.Headers headers46 = charSequenceConsumerRecord43.headers();
        java.util.Optional<java.lang.Integer> intOptional47 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType27, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers46, intOptional47);
        org.apache.kafka.common.record.TimestampType timestampType56 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord62 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType56, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int63 = charSequenceConsumerRecord62.serializedValueSize();
        java.lang.CharSequence charSequence64 = charSequenceConsumerRecord62.key();
        org.apache.kafka.common.header.Headers headers65 = charSequenceConsumerRecord62.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray66 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList67 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean68 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList67, kafkaSpoutMessageIdArray66);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers65, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList67);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headersConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("", (int) '#', 1L, headers46, kafkaSpoutMessageIdList67);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType14, (java.lang.Long) (-1L), (int) (short) 100, 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}", headers46);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) 10, (long) (byte) -1, (long) '#', timestampType4, (java.lang.Long) 100L, (int) (byte) -1, 100, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers46);
        java.lang.String str73 = charSequenceConsumerRecord72.toString();
        java.util.Optional<java.lang.Integer> intOptional74 = charSequenceConsumerRecord72.leaderEpoch();
        org.junit.Assert.assertTrue("'" + int44 + "' != '" + (-1) + "'", int44 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence45 + "' != '" + "" + "'", charSequence45, "");
        org.junit.Assert.assertNotNull(headers46);
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + (-1) + "'", int63 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence64 + "' != '" + "" + "'", charSequence64, "");
        org.junit.Assert.assertNotNull(headers65);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray66);
        org.junit.Assert.assertTrue("'" + boolean68 + "' != '" + false + "'", boolean68 == false);
        org.junit.Assert.assertEquals("'" + str73 + "' != '" + "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str73, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(intOptional74);
    }

    @Test
    public void test2180() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2180");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder2 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder2;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy4 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = strKafkaSpout0.kafkaConsumer;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str8 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strKafkaSpoutConfig6);
        org.junit.Assert.assertNull(strKafkaConsumer7);
    }

    @Test
    public void test2181() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2181");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        strKafkaSpout0.maxRetries = (short) 1;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
// flaky:             org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
    }

    @Test
    public void test2182() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2182");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector3 = null;
        strKafkaSpout0.collector = spoutOutputCollector3;
        boolean boolean5 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy6 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy6;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService9;
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertNull(timer8);
    }

    @Test
    public void test2183() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2183");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams9 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        boolean boolean11 = strKafkaSpout0.waitingToEmit();
        int int12 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy13 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer14 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer14;
        org.apache.kafka.common.TopicPartition topicPartition16 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setAcked(topicPartition16, 97L);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
        org.junit.Assert.assertNull(kafkaSpoutStreams9);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNull(firstPollOffsetStrategy13);
    }

    @Test
    public void test2184() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2184");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer16;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector18 = null;
        strKafkaSpout0.collector = spoutOutputCollector18;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor20 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor20;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService22 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService22;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor24 = strKafkaSpout0.waitingToEmit;
        org.apache.kafka.common.TopicPartition topicPartition25 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection26 = strKafkaSpout0.toArrayList(topicPartition25);
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor27 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer28 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout29 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet30 = strKafkaSpout29.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig31 = null;
        strKafkaSpout29.kafkaSpoutConfig = strKafkaSpoutConfig31;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector33 = strKafkaSpout29.collector;
        long long34 = strKafkaSpout29.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector35 = null;
        strKafkaSpout29.collector = spoutOutputCollector35;
        strKafkaSpout29.consumerAutoCommitMode = false;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer39 = strKafkaSpout29.kafkaConsumer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor40 = strKafkaSpout29.waitingToEmit;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.ack((java.lang.Object) strConsumerRecordItor40);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor24);
        org.junit.Assert.assertNotNull(topicPartitionCollection26);
        org.junit.Assert.assertNull(strConsumerRecordItor27);
        org.junit.Assert.assertNull(timer28);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet30);
        org.junit.Assert.assertNull(spoutOutputCollector33);
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + 0L + "'", long34 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer39);
        org.junit.Assert.assertNull(strConsumerRecordItor40);
    }

    @Test
    public void test2185() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2185");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        boolean boolean5 = strKafkaSpout0.waitingToEmit();
        long long6 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder7;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str9 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + 0L + "'", long6 == 0L);
    }

    @Test
    public void test2186() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2186");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        long long12 = charSequenceConsumerRecord10.checksum();
        int int13 = charSequenceConsumerRecord10.serializedKeySize();
        long long14 = charSequenceConsumerRecord10.offset();
        java.util.Optional<java.lang.Integer> intOptional15 = charSequenceConsumerRecord10.leaderEpoch();
        long long16 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 52 + "'", int13 == 52);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
    }

    @Test
    public void test2187() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2187");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        int int12 = strKafkaSpout0.maxRetries;
        long long13 = strKafkaSpout0.numUncommittedOffsets;
        java.lang.String str14 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams15 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams15;
        boolean boolean17 = strKafkaSpout0.waitingToEmit();
        org.apache.kafka.common.TopicPartition topicPartition18 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setAcked(topicPartition18, 35L);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str14, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + boolean17 + "' != '" + false + "'", boolean17 == false);
    }

    @Test
    public void test2188() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2188");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.timestamp();
        long long19 = charSequenceConsumerRecord10.offset();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        long long21 = charSequenceConsumerRecord10.offset();
        java.lang.CharSequence charSequence22 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 0L + "'", long21 == 0L);
        org.junit.Assert.assertEquals("'" + charSequence22 + "' != '" + "" + "'", charSequence22, "");
    }

    @Test
    public void test2189() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2189");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord10.headers();
        long long17 = charSequenceConsumerRecord10.timestamp();
        long long18 = charSequenceConsumerRecord10.checksum();
        java.lang.String str19 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
    }

    @Test
    public void test2190() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2190");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer6 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService7 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService7;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig9 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig9;
        strKafkaSpout0.numUncommittedOffsets = 35L;
        strKafkaSpout0.initialized = true;
        int int15 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord16 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean17 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord16);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer6);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 0 + "'", int15 == 0);
    }

    @Test
    public void test2191() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2191");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig9 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig9;
        java.lang.String str11 = strKafkaSpout0.toString();
        java.util.Map map12 = null;
        org.apache.storm.task.TopologyContext topologyContext13 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector14 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map12, topologyContext13, spoutOutputCollector14);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "KafkaSpout{acked=null, emitted=[]}" + "'", str11, "KafkaSpout{acked=null, emitted=[]}");
    }

    @Test
    public void test2192() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2192");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams9 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector10 = null;
        strKafkaSpout0.collector = spoutOutputCollector10;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder12 = strKafkaSpout0.tuplesBuilder;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.commitOffsetsForAckedTuples();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
        org.junit.Assert.assertNull(kafkaSpoutStreams9);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder12);
    }

    @Test
    public void test2193() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2193");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer16;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder18 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder18;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams20 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams20;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str22 = strKafkaSpout0.getNamedTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
    }

    @Test
    public void test2194() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2194");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 1, 1L, (long) (byte) 10, timestampType4, (long) '#', (int) (byte) 100, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord10.timestampType();
        java.lang.CharSequence charSequence13 = charSequenceConsumerRecord10.key();
        java.util.Optional<java.lang.Integer> intOptional14 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 10L + "'", long11 == 10L);
        org.junit.Assert.assertNull(timestampType12);
        org.junit.Assert.assertEquals("'" + charSequence13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(intOptional14);
    }

    @Test
    public void test2195() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2195");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout27 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout27.maxRetries = (byte) -1;
        int int30 = strKafkaSpout27.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor31 = null;
        strKafkaSpout27.waitingToEmit = strConsumerRecordItor31;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout27.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer34 = strKafkaSpout27.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType40, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long47 = charSequenceConsumerRecord46.offset();
        long long48 = charSequenceConsumerRecord46.checksum();
        int int49 = charSequenceConsumerRecord46.serializedKeySize();
        org.apache.kafka.common.header.Headers headers50 = charSequenceConsumerRecord46.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType23, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout27, (java.lang.CharSequence) "hi!", headers50);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 1, 0L, (long) (byte) 0, timestampType23, (long) ' ', (int) (short) -1, (int) (byte) 10, (java.lang.CharSequence) "", "");
        java.lang.CharSequence charSequence58 = charSequenceConsumerRecord57.key();
        java.lang.String str59 = charSequenceConsumerRecord57.value();
        int int60 = charSequenceConsumerRecord57.serializedValueSize();
        java.lang.String str61 = charSequenceConsumerRecord57.value();
        org.apache.kafka.common.record.TimestampType timestampType62 = charSequenceConsumerRecord57.timestampType();
        java.lang.CharSequence charSequence66 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 35, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)))", 32, 100L, (long) 'a', timestampType62, 52L, (int) ' ', 0, charSequence66, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.apache.kafka.common.header.Headers headers74 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) 100, (long) 52, (long) 32, timestampType62, (java.lang.Long) 1L, (int) (byte) 100, 97, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", headers74);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(strKafkaConsumer34);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 0L + "'", long47 == 0L);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 52 + "'", int49 == 52);
        org.junit.Assert.assertNotNull(headers50);
        org.junit.Assert.assertEquals("'" + charSequence58 + "' != '" + "" + "'", charSequence58, "");
        org.junit.Assert.assertEquals("'" + str59 + "' != '" + "" + "'", str59, "");
        org.junit.Assert.assertTrue("'" + int60 + "' != '" + 10 + "'", int60 == 10);
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "" + "'", str61, "");
        org.junit.Assert.assertTrue("'" + timestampType62 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType62.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test2196() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2196");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        long long15 = charSequenceConsumerRecord10.checksum();
        long long16 = charSequenceConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional17 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertNotNull(intOptional17);
    }

    @Test
    public void test2197() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2197");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor6 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor6;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder9;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.deactivate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
    }

    @Test
    public void test2198() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2198");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService5 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy8 = strKafkaSpout0.firstPollOffsetStrategy;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertNull(firstPollOffsetStrategy7);
        org.junit.Assert.assertNull(firstPollOffsetStrategy8);
    }

    @Test
    public void test2199() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2199");
        org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.Cloneable> intOptionalKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.Cloneable>();
    }

    @Test
    public void test2200() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2200");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        boolean boolean11 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder12 = strKafkaSpout0.tuplesBuilder;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder12);
    }

    @Test
    public void test2201() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2201");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        int int8 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor9 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.consumerAutoCommitMode = false;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.commitOffsetsForAckedTuples();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strConsumerRecordItor9);
    }

    @Test
    public void test2202() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2202");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, org.apache.storm.topology.base.BaseRichSpout> strComparableKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, org.apache.storm.topology.base.BaseRichSpout>();
    }

    @Test
    public void test2203() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2203");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        int int12 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder13;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.doSeekRetriableTopicPartitions();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
    }

    @Test
    public void test2204() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2204");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str12 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
    }

    @Test
    public void test2205() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2205");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        int int7 = strKafkaSpout0.maxRetries;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 0 + "'", int7 == 0);
    }

    @Test
    public void test2206() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2206");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (byte) 0, (long) (byte) -1, (long) (short) 100, timestampType4, (long) (short) 1, (int) (byte) 1, (int) (short) 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        long long11 = charSequenceConsumerRecord10.offset();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord10.timestampType();
        // The following exception was thrown during execution in test generation
        try {
            java.lang.Class<?> wildcardClass13 = timestampType12.getClass();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNull(timestampType12);
    }

    @Test
    public void test2207() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2207");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        int int20 = charSequenceConsumerRecord10.partition();
        int int21 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 10 + "'", int20 == 10);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 52 + "'", int21 == 52);
    }

    @Test
    public void test2208() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2208");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.initialized = false;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy10 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy10;
        boolean boolean12 = strKafkaSpout0.initialized;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean13 = strKafkaSpout0.poll();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + false + "'", boolean12 == false);
    }

    @Test
    public void test2209() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2209");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType17 = null;
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int34 = charSequenceConsumerRecord33.serializedValueSize();
        java.lang.CharSequence charSequence35 = charSequenceConsumerRecord33.key();
        org.apache.kafka.common.header.Headers headers36 = charSequenceConsumerRecord33.headers();
        java.util.Optional<java.lang.Integer> intOptional37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType17, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers36, intOptional37);
        org.apache.kafka.common.record.TimestampType timestampType46 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType46, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int53 = charSequenceConsumerRecord52.serializedValueSize();
        java.lang.CharSequence charSequence54 = charSequenceConsumerRecord52.key();
        org.apache.kafka.common.header.Headers headers55 = charSequenceConsumerRecord52.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray56 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList57 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean58 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57, kafkaSpoutMessageIdArray56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers55, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headersConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("", (int) '#', 1L, headers36, kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType4, (java.lang.Long) (-1L), (int) (short) 100, 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}", headers36);
        long long62 = charSequenceConsumerRecord61.offset();
        long long63 = charSequenceConsumerRecord61.timestamp();
        long long64 = charSequenceConsumerRecord61.offset();
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + (-1) + "'", int34 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence35 + "' != '" + "" + "'", charSequence35, "");
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + (-1) + "'", int53 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence54 + "' != '" + "" + "'", charSequence54, "");
        org.junit.Assert.assertNotNull(headers55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray56);
        org.junit.Assert.assertTrue("'" + boolean58 + "' != '" + false + "'", boolean58 == false);
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + 1L + "'", long62 == 1L);
        org.junit.Assert.assertTrue("'" + long63 + "' != '" + 0L + "'", long63 == 0L);
        org.junit.Assert.assertTrue("'" + long64 + "' != '" + 1L + "'", long64 == 1L);
    }

    @Test
    public void test2210() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2210");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str21 = charSequenceConsumerRecord10.value();
        java.util.Optional<java.lang.Integer> intOptional22 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str23 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "hi!" + "'", str21, "hi!");
        org.junit.Assert.assertNotNull(intOptional22);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "hi!" + "'", str23, "hi!");
    }

    @Test
    public void test2211() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2211");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator5 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator5;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator5.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator12 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator12;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = kafkaSpoutMessageIdComparator7.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator12);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator16 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator16;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = offsetComparator16.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator23;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = kafkaSpoutMessageIdComparator18.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = kafkaSpoutMessageIdComparator7.thenComparing(kafkaSpoutMessageIdComparator26);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = kafkaSpoutMessageIdComparator27.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = kafkaSpoutMessageIdComparator27.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator27);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator30;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
    }

    @Test
    public void test2212() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2212");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams10;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams13 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = true;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean16 = strKafkaSpout0.poll();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(spoutOutputCollector12);
        org.junit.Assert.assertNull(kafkaSpoutStreams13);
    }

    @Test
    public void test2213() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2213");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.reflect.GenericDeclaration> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.reflect.GenericDeclaration>();
    }

    @Test
    public void test2214() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2214");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.offset();
        int int19 = charSequenceConsumerRecord10.partition();
        int int20 = charSequenceConsumerRecord10.serializedKeySize();
        int int21 = charSequenceConsumerRecord10.serializedKeySize();
        int int22 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 52 + "'", int20 == 52);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 52 + "'", int21 == 52);
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 52 + "'", int22 == 52);
    }

    @Test
    public void test2215() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2215");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional12 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.CharSequence charSequence13 = charSequenceConsumerRecord10.key();
        long long14 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertEquals("'" + charSequence13 + "' != '" + "" + "'", charSequence13, "");
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
    }

    @Test
    public void test2216() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2216");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType31 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType31, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long38 = charSequenceConsumerRecord37.checksum();
        int int39 = charSequenceConsumerRecord37.partition();
        long long40 = charSequenceConsumerRecord37.timestamp();
        java.lang.String str41 = charSequenceConsumerRecord37.toString();
        long long42 = charSequenceConsumerRecord37.timestamp();
        org.apache.kafka.common.header.Headers headers43 = charSequenceConsumerRecord37.headers();
        org.apache.kafka.common.record.TimestampType timestampType44 = charSequenceConsumerRecord37.timestampType();
        java.util.Optional<java.lang.Integer> intOptional45 = charSequenceConsumerRecord37.leaderEpoch();
        org.apache.storm.topology.IComponent iComponent46 = null;
        org.apache.kafka.common.record.TimestampType timestampType51 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType51, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long58 = charSequenceConsumerRecord57.checksum();
        int int59 = charSequenceConsumerRecord57.partition();
        long long60 = charSequenceConsumerRecord57.timestamp();
        java.lang.String str61 = charSequenceConsumerRecord57.toString();
        org.apache.kafka.common.header.Headers headers62 = charSequenceConsumerRecord57.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent> intOptionalConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent>("hi!", (int) ' ', (long) (byte) -1, (long) (-1), timestampType23, (java.lang.Long) 100L, (int) 'a', (-1), intOptional45, iComponent46, headers62);
        org.apache.storm.topology.IRichSpout iRichSpout68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.storm.topology.IRichSpout> strComparableConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.storm.topology.IRichSpout>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", (int) (byte) 0, (long) 10, (long) (-1), timestampType23, (long) 0, (int) (short) 10, (int) (byte) 1, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", iRichSpout68);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", (int) (byte) 100, 100L, (long) (short) 100, timestampType23, (long) 'a', (int) ' ', (-1), (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", 52, 0L, (long) 97, timestampType23, (long) (byte) -1, (int) ' ', 10, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        long long82 = charSequenceConsumerRecord81.timestamp();
        long long83 = charSequenceConsumerRecord81.checksum();
        long long84 = charSequenceConsumerRecord81.checksum();
        int int85 = charSequenceConsumerRecord81.serializedKeySize();
        long long86 = charSequenceConsumerRecord81.checksum();
        java.lang.CharSequence charSequence87 = charSequenceConsumerRecord81.key();
        org.apache.kafka.common.record.TimestampType timestampType88 = charSequenceConsumerRecord81.timestampType();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + (-1L) + "'", long38 == (-1L));
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + 10 + "'", int39 == 10);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertEquals("'" + str41 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str41, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long42 + "' != '" + (-1L) + "'", long42 == (-1L));
        org.junit.Assert.assertNotNull(headers43);
        org.junit.Assert.assertNull(timestampType44);
        org.junit.Assert.assertNotNull(intOptional45);
        org.junit.Assert.assertTrue("'" + long58 + "' != '" + (-1L) + "'", long58 == (-1L));
        org.junit.Assert.assertTrue("'" + int59 + "' != '" + 10 + "'", int59 == 10);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str61, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers62);
        org.junit.Assert.assertTrue("'" + long82 + "' != '" + 97L + "'", long82 == 97L);
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + (-1L) + "'", long83 == (-1L));
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + (-1L) + "'", long84 == (-1L));
        org.junit.Assert.assertTrue("'" + int85 + "' != '" + 32 + "'", int85 == 32);
        org.junit.Assert.assertTrue("'" + long86 + "' != '" + (-1L) + "'", long86 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence87 + "' != '" + "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})" + "'", charSequence87, "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
        org.junit.Assert.assertTrue("'" + timestampType88 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType88.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test2217() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2217");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        org.apache.kafka.common.header.Headers headers17 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertNotNull(headers17);
    }

    @Test
    public void test2218() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2218");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams6 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig7 = strKafkaSpout0.kafkaSpoutConfig;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet8 = strKafkaSpout0.emitted;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setAcked(topicPartition9, (long) (byte) 1);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutStreams6);
        org.junit.Assert.assertNull(strKafkaSpoutConfig7);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet8);
    }

    @Test
    public void test2219() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2219");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer4;
        boolean boolean6 = strKafkaSpout0.initialized;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
// flaky:             org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
    }

    @Test
    public void test2220() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2220");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer9 = strKafkaSpout0.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer10;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet12 = strKafkaSpout0.emitted;
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertNull(timer9);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet12);
    }

    @Test
    public void test2221() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2221");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType13 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray17 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList18 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean19 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList18, kafkaSpoutMessageIdArray17);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractCollection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.Comparable<java.lang.String>> kafkaSpoutMessageIdCollectionConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractCollection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.Comparable<java.lang.String>>("KafkaSpout{acked=null, emitted=null}", (-1), (long) (short) -1, (long) 10, timestampType13, (long) 1, (int) 'a', (-1), (java.util.AbstractCollection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList18, (java.lang.Comparable<java.lang.String>) "KafkaSpout{acked=null, emitted=null}");
        org.apache.kafka.common.record.TimestampType timestampType26 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType26, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long33 = charSequenceConsumerRecord32.checksum();
        int int34 = charSequenceConsumerRecord32.partition();
        long long35 = charSequenceConsumerRecord32.timestamp();
        long long36 = charSequenceConsumerRecord32.offset();
        int int37 = charSequenceConsumerRecord32.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType38 = charSequenceConsumerRecord32.timestampType();
        int int39 = charSequenceConsumerRecord32.partition();
        org.apache.kafka.common.header.Headers headers40 = charSequenceConsumerRecord32.headers();
        java.util.Optional<java.lang.Integer> intOptional41 = charSequenceConsumerRecord32.leaderEpoch();
        org.apache.kafka.common.header.Headers headers42 = charSequenceConsumerRecord32.headers();
        org.apache.kafka.common.record.TimestampType timestampType47 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType47, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        java.lang.String str54 = charSequenceConsumerRecord53.topic();
        java.lang.String str55 = charSequenceConsumerRecord53.topic();
        int int56 = charSequenceConsumerRecord53.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional57 = charSequenceConsumerRecord53.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.util.RandomAccess> strConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.util.RandomAccess>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", (int) (short) 100, 10L, (long) 35, timestampType4, (java.lang.Long) 32L, (int) (byte) 0, (int) '4', "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", (java.util.RandomAccess) kafkaSpoutMessageIdList18, headers42, intOptional57);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray17);
        org.junit.Assert.assertTrue("'" + boolean19 + "' != '" + false + "'", boolean19 == false);
        org.junit.Assert.assertTrue("'" + long33 + "' != '" + (-1L) + "'", long33 == (-1L));
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + 10 + "'", int34 == 10);
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + (-1L) + "'", long35 == (-1L));
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + 0L + "'", long36 == 0L);
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + 52 + "'", int37 == 52);
        org.junit.Assert.assertNull(timestampType38);
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + 10 + "'", int39 == 10);
        org.junit.Assert.assertNotNull(headers40);
        org.junit.Assert.assertNotNull(intOptional41);
        org.junit.Assert.assertNotNull(headers42);
        org.junit.Assert.assertEquals("'" + str54 + "' != '" + "hi!" + "'", str54, "hi!");
        org.junit.Assert.assertEquals("'" + str55 + "' != '" + "hi!" + "'", str55, "hi!");
        org.junit.Assert.assertTrue("'" + int56 + "' != '" + 10 + "'", int56 == 10);
        org.junit.Assert.assertNotNull(intOptional57);
    }

    @Test
    public void test2222() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2222");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        boolean boolean4 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams5 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords6 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords6);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertNull(kafkaSpoutStreams5);
    }

    @Test
    public void test2223() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2223");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = offsetComparator7.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator7.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator13.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator20 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator20;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = kafkaSpoutMessageIdComparator15.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator15.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator7.thenComparing(kafkaSpoutMessageIdComparator24);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator7.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator31 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator31;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator31.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = kafkaSpoutMessageIdComparator26.thenComparing(kafkaSpoutMessageIdComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = kafkaSpoutMessageIdComparator34.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator37 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator38 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator38;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator40 = offsetComparator38.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = offsetComparator37.thenComparing(kafkaSpoutMessageIdComparator40);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator42 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator42;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = offsetComparator42.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator49 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator49;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator49);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator52 = kafkaSpoutMessageIdComparator44.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator49);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator53 = offsetComparator37.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator49);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator54 = offsetComparator49.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator55 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator55;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator57 = offsetComparator55.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator62 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator62;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator62);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator65 = kafkaSpoutMessageIdComparator57.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator62);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator66 = offsetComparator62.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator67 = kafkaSpoutMessageIdComparator54.thenComparing(kafkaSpoutMessageIdComparator66);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator66;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator69 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator69;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator71 = offsetComparator69.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator76 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator76;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator76);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator79 = kafkaSpoutMessageIdComparator71.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator76);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator80 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator80;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator82 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator83 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator83;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator85 = offsetComparator83.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator86 = offsetComparator82.thenComparing(kafkaSpoutMessageIdComparator85);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator87 = offsetComparator80.thenComparing(kafkaSpoutMessageIdComparator86);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator88 = offsetComparator76.thenComparing(kafkaSpoutMessageIdComparator87);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator89 = kafkaSpoutMessageIdComparator88.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator90 = kafkaSpoutMessageIdComparator66.thenComparing(kafkaSpoutMessageIdComparator88);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator91 = kafkaSpoutMessageIdComparator36.thenComparing(kafkaSpoutMessageIdComparator88);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator40);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator52);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator53);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator54);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator57);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator65);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator66);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator67);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator71);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator79);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator85);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator86);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator87);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator88);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator89);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator90);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator91);
    }

    @Test
    public void test2224() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2224");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService5 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = strKafkaSpout0.firstPollOffsetStrategy;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Map<java.lang.String, java.lang.Object> strMap8 = strKafkaSpout0.getComponentConfiguration();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertNull(firstPollOffsetStrategy7);
    }

    @Test
    public void test2225() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2225");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str16 = charSequenceConsumerRecord10.value();
        java.lang.String str17 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 52 + "'", int14 == 52);
        org.junit.Assert.assertNull(timestampType15);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "hi!" + "'", str16, "hi!");
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertNull(timestampType18);
    }

    @Test
    public void test2226() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2226");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        java.lang.String str13 = charSequenceConsumerRecord10.topic();
        int int14 = charSequenceConsumerRecord10.partition();
        long long15 = charSequenceConsumerRecord10.offset();
        java.lang.String str16 = charSequenceConsumerRecord10.value();
        java.lang.Class<?> wildcardClass17 = charSequenceConsumerRecord10.getClass();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 0L + "'", long15 == 0L);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "hi!" + "'", str16, "hi!");
        org.junit.Assert.assertNotNull(wildcardClass17);
    }

    @Test
    public void test2227() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2227");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService5 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService5;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(strKafkaConsumer4);
    }

    @Test
    public void test2228() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2228");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator10;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
    }

    @Test
    public void test2229() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2229");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> kafkaSpoutMessageIdSetKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> kafkaSpoutMessageIdSetKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>(kafkaSpoutMessageIdSetKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test2230() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2230");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector8 = null;
        strKafkaSpout0.collector = spoutOutputCollector8;
        boolean boolean10 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig11;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
    }

    @Test
    public void test2231() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2231");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.common.TopicPartition topicPartition12 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection13 = strKafkaSpout0.toArrayList(topicPartition12);
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor14 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor14;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder16 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder16;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer18 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer18);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertNotNull(topicPartitionCollection13);
    }

    @Test
    public void test2232() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2232");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", 0, 10L, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "hi!");
        java.lang.String str6 = charSequenceConsumerRecord5.value();
        int int7 = charSequenceConsumerRecord5.serializedKeySize();
        java.lang.String str8 = charSequenceConsumerRecord5.topic();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "hi!" + "'", str6, "hi!");
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})" + "'", str8, "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
    }

    @Test
    public void test2233() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2233");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        boolean boolean5 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = strKafkaSpout0.collector;
        org.apache.kafka.common.record.TimestampType timestampType11 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType11, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long18 = charSequenceConsumerRecord17.offset();
        int int19 = charSequenceConsumerRecord17.serializedValueSize();
        org.apache.kafka.common.header.Headers headers20 = charSequenceConsumerRecord17.headers();
        int int21 = charSequenceConsumerRecord17.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType22 = charSequenceConsumerRecord17.timestampType();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.ack((java.lang.Object) charSequenceConsumerRecord17);
            org.junit.Assert.fail("Expected exception of type java.lang.ClassCastException; message: org.apache.kafka.clients.consumer.ConsumerRecord cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId");
        } catch (java.lang.ClassCastException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertNull(spoutOutputCollector6);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 52 + "'", int21 == 52);
        org.junit.Assert.assertNull(timestampType22);
    }

    @Test
    public void test2234() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2234");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor5 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor5;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
    }

    @Test
    public void test2235() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2235");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator14 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator14;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator14.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = offsetComparator13.thenComparing(kafkaSpoutMessageIdComparator16);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = offsetComparator11.thenComparing(kafkaSpoutMessageIdComparator17);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = offsetComparator7.thenComparing(kafkaSpoutMessageIdComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = kafkaSpoutMessageIdComparator18.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator21 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator21;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = offsetComparator21.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator28 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator28;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator28);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = kafkaSpoutMessageIdComparator23.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator28);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = offsetComparator28.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator33 = kafkaSpoutMessageIdComparator18.thenComparing(kafkaSpoutMessageIdComparator32);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator33;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = kafkaSpoutMessageIdComparator33.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator36 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = offsetComparator36.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = offsetComparator36.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = kafkaSpoutMessageIdComparator35.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator36);
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId40 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId41 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int42 = offsetComparator36.compare(kafkaSpoutMessageId40, kafkaSpoutMessageId41);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator33);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
    }

    @Test
    public void test2236() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2236");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer1 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy2 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams3 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams3;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder5 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder5;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = strKafkaSpout0.kafkaConsumer;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet8 = strKafkaSpout0.emitted;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.Class<?> wildcardClass9 = kafkaSpoutMessageIdSet8.getClass();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(timer1);
        org.junit.Assert.assertNull(firstPollOffsetStrategy2);
        org.junit.Assert.assertNull(strKafkaConsumer7);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet8);
    }

    @Test
    public void test2237() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2237");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout3 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout3.maxRetries = (byte) -1;
        int int6 = strKafkaSpout3.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout3.waitingToEmit = strConsumerRecordItor7;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout3.toArrayList(topicPartition9);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = strKafkaSpout3.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType16 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout20 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout20.maxRetries = (byte) -1;
        int int23 = strKafkaSpout20.maxRetries;
        strKafkaSpout20.numUncommittedOffsets = '#';
        strKafkaSpout20.initialized = true;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet28 = strKafkaSpout20.emitted;
        org.apache.kafka.common.record.TimestampType timestampType36 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType36, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int43 = charSequenceConsumerRecord42.serializedValueSize();
        java.lang.CharSequence charSequence44 = charSequenceConsumerRecord42.key();
        org.apache.kafka.common.header.Headers headers45 = charSequenceConsumerRecord42.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray46 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList47 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean48 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47, kafkaSpoutMessageIdArray46);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers45, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47);
        org.apache.kafka.common.record.TimestampType timestampType54 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType54, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int61 = charSequenceConsumerRecord60.serializedValueSize();
        java.lang.CharSequence charSequence62 = charSequenceConsumerRecord60.key();
        org.apache.kafka.common.header.Headers headers63 = charSequenceConsumerRecord60.headers();
        org.apache.kafka.common.record.TimestampType timestampType68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType68, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long75 = charSequenceConsumerRecord74.offset();
        int int76 = charSequenceConsumerRecord74.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional77 = charSequenceConsumerRecord74.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> objConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) '4', (long) (short) 0, (long) 100, timestampType16, (java.lang.Long) 1L, (int) (short) 0, 0, (java.lang.Object) kafkaSpoutMessageIdSet28, (java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47, headers63, intOptional77);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.common.header.Headers> iSpoutConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.common.header.Headers>("KafkaSpout{acked=null, emitted=null}", (int) '#', (long) 1, (org.apache.storm.spout.ISpout) strKafkaSpout3, headers63);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer80 = strKafkaSpout3.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService81 = strKafkaSpout3.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder82 = strKafkaSpout3.tuplesBuilder;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord83 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean84 = strKafkaSpout3.emitTupleIfNotEmitted(strConsumerRecord83);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(strKafkaConsumer11);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet28);
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + (-1) + "'", int43 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence44 + "' != '" + "" + "'", charSequence44, "");
        org.junit.Assert.assertNotNull(headers45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray46);
        org.junit.Assert.assertTrue("'" + boolean48 + "' != '" + false + "'", boolean48 == false);
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + (-1) + "'", int61 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence62 + "' != '" + "" + "'", charSequence62, "");
        org.junit.Assert.assertNotNull(headers63);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + 0L + "'", long75 == 0L);
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + (-1) + "'", int76 == (-1));
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertNull(timer80);
        org.junit.Assert.assertNull(kafkaSpoutRetryService81);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder82);
    }

    @Test
    public void test2238() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2238");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams9 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        boolean boolean11 = strKafkaSpout0.waitingToEmit();
        int int12 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy13 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer14 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer14;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.activate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
        org.junit.Assert.assertNull(kafkaSpoutStreams9);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNull(firstPollOffsetStrategy13);
    }

    @Test
    public void test2239() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2239");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        boolean boolean6 = strKafkaSpout0.waitingToEmit();
        org.apache.kafka.common.TopicPartition topicPartition7 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection8 = strKafkaSpout0.toArrayList(topicPartition7);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService9;
        long long11 = strKafkaSpout0.numUncommittedOffsets;
        java.lang.String str12 = strKafkaSpout0.toString();
        boolean boolean13 = strKafkaSpout0.initialized;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection8);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 35L + "'", long11 == 35L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str12, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + boolean13 + "' != '" + false + "'", boolean13 == false);
    }

    @Test
    public void test2240() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2240");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> timestampTypeEnumKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> timestampTypeEnumKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Enum<org.apache.kafka.common.record.TimestampType>, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>(timestampTypeEnumKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test2241() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2241");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = strKafkaSpout0.emitted;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.doSeekRetriableTopicPartitions();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet5);
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
    }

    @Test
    public void test2242() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2242");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        long long7 = charSequenceConsumerRecord5.timestamp();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        java.lang.String str9 = charSequenceConsumerRecord5.toString();
        int int10 = charSequenceConsumerRecord5.serializedValueSize();
        long long11 = charSequenceConsumerRecord5.timestamp();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str9, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
    }

    @Test
    public void test2243() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2243");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.timestamp();
        long long19 = charSequenceConsumerRecord10.offset();
        int int20 = charSequenceConsumerRecord10.partition();
        java.util.Optional<java.lang.Integer> intOptional21 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 10 + "'", int20 == 10);
        org.junit.Assert.assertNotNull(intOptional21);
    }

    @Test
    public void test2244() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2244");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = strKafkaSpout0.firstPollOffsetStrategy;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer9 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer9;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = strKafkaSpout0.collector;
        long long12 = strKafkaSpout0.numUncommittedOffsets;
        java.lang.String str13 = strKafkaSpout0.toString();
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords14 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords14);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 0 + "'", int8 == 0);
        org.junit.Assert.assertNull(spoutOutputCollector11);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 0L + "'", long12 == 0L);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str13, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test2245() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2245");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        long long8 = strKafkaSpout0.numUncommittedOffsets;
        java.lang.String str9 = strKafkaSpout0.toString();
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        boolean boolean12 = strKafkaSpout0.waitingToEmit();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.doSeekRetriableTopicPartitions();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 0L + "'", long8 == 0L);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str9, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + false + "'", boolean12 == false);
    }

    @Test
    public void test2246() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2246");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = strKafkaSpout0.tuplesBuilder;
        java.lang.String str8 = strKafkaSpout0.toString();
        strKafkaSpout0.maxRetries = ' ';
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean12 = strKafkaSpout0.poll();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
    }

    @Test
    public void test2247() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2247");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator1 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator1;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator3 = offsetComparator1.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator4 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator3);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator5 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator5;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator5.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator12 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator12;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = kafkaSpoutMessageIdComparator7.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator0.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator12);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator17 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator17;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = offsetComparator17.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator17;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator21 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator21;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = offsetComparator21.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = offsetComparator17.thenComparing(kafkaSpoutMessageIdComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = kafkaSpoutMessageIdComparator23.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator26 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = offsetComparator26.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator33 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator33;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator33);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = kafkaSpoutMessageIdComparator28.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator33);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator37 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator37;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = offsetComparator37.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator44 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator44;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator44);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator47 = kafkaSpoutMessageIdComparator39.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator44);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator48 = kafkaSpoutMessageIdComparator28.thenComparing(kafkaSpoutMessageIdComparator47);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator49 = kafkaSpoutMessageIdComparator48.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator50 = kafkaSpoutMessageIdComparator23.thenComparing(kafkaSpoutMessageIdComparator48);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator50;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator52 = offsetComparator12.thenComparing(kafkaSpoutMessageIdComparator50);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator53 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator54 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator54;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator56 = offsetComparator54.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator61 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator61;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator61);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator64 = kafkaSpoutMessageIdComparator56.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator61);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator65 = offsetComparator53.thenComparing(kafkaSpoutMessageIdComparator64);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator66 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator66;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator68 = offsetComparator66.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator73 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator73;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator73);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator76 = kafkaSpoutMessageIdComparator68.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator73);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator77 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator77;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator79 = offsetComparator77.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator84 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator84;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator84);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator87 = kafkaSpoutMessageIdComparator79.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator84);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator88 = kafkaSpoutMessageIdComparator68.thenComparing(kafkaSpoutMessageIdComparator87);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator89 = kafkaSpoutMessageIdComparator65.thenComparing(kafkaSpoutMessageIdComparator88);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator90 = kafkaSpoutMessageIdComparator88.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator91 = kafkaSpoutMessageIdComparator88.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator92 = kafkaSpoutMessageIdComparator50.thenComparing(kafkaSpoutMessageIdComparator91);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator93 = null;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator94 = kafkaSpoutMessageIdComparator91.thenComparing(kafkaSpoutMessageIdComparator93);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator3);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator4);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator47);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator48);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator49);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator50);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator52);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator56);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator64);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator65);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator68);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator76);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator79);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator87);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator88);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator89);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator90);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator91);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator92);
    }

    @Test
    public void test2248() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2248");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Map<java.lang.String, java.lang.Object> strMap11 = strKafkaSpout0.getComponentConfiguration();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
    }

    @Test
    public void test2249() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2249");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        strKafkaSpout0.maxRetries = (short) 100;
        org.apache.kafka.common.TopicPartition topicPartition11 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection12 = strKafkaSpout0.toArrayList(topicPartition11);
        boolean boolean13 = strKafkaSpout0.initialized;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNotNull(topicPartitionCollection12);
        org.junit.Assert.assertTrue("'" + boolean13 + "' != '" + false + "'", boolean13 == false);
    }

    @Test
    public void test2250() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2250");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        strKafkaSpout0.maxRetries = (short) 0;
        strKafkaSpout0.maxRetries = (short) -1;
        java.lang.String str7 = strKafkaSpout0.toString();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strConsumerRecordItor8);
    }

    @Test
    public void test2251() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2251");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.timestamp();
        long long16 = charSequenceConsumerRecord10.offset();
        long long17 = charSequenceConsumerRecord10.offset();
        long long18 = charSequenceConsumerRecord10.checksum();
        java.lang.String str19 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test2252() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2252");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout19 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout19.maxRetries = (byte) -1;
        int int22 = strKafkaSpout19.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor23 = null;
        strKafkaSpout19.waitingToEmit = strConsumerRecordItor23;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer25 = strKafkaSpout19.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer26 = strKafkaSpout19.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType32, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long39 = charSequenceConsumerRecord38.offset();
        long long40 = charSequenceConsumerRecord38.checksum();
        int int41 = charSequenceConsumerRecord38.serializedKeySize();
        org.apache.kafka.common.header.Headers headers42 = charSequenceConsumerRecord38.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType15, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout19, (java.lang.CharSequence) "hi!", headers42);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 1, 0L, (long) (byte) 0, timestampType15, (long) ' ', (int) (short) -1, (int) (byte) 10, (java.lang.CharSequence) "", "");
        java.lang.CharSequence charSequence50 = charSequenceConsumerRecord49.key();
        java.lang.String str51 = charSequenceConsumerRecord49.value();
        java.util.Optional<java.lang.Integer> intOptional52 = charSequenceConsumerRecord49.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType53 = charSequenceConsumerRecord49.timestampType();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertNull(timer25);
        org.junit.Assert.assertNull(strKafkaConsumer26);
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + 0L + "'", long39 == 0L);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + 52 + "'", int41 == 52);
        org.junit.Assert.assertNotNull(headers42);
        org.junit.Assert.assertEquals("'" + charSequence50 + "' != '" + "" + "'", charSequence50, "");
        org.junit.Assert.assertEquals("'" + str51 + "' != '" + "" + "'", str51, "");
        org.junit.Assert.assertNotNull(intOptional52);
        org.junit.Assert.assertTrue("'" + timestampType53 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType53.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test2253() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2253");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, java.lang.reflect.Type> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.reflect.Type> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, java.lang.reflect.Type>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test2254() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2254");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType4, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        long long11 = charSequenceConsumerRecord10.timestamp();
        long long12 = charSequenceConsumerRecord10.timestamp();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 35L + "'", long11 == 35L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 35L + "'", long12 == 35L);
    }

    @Test
    public void test2255() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2255");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout10 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout10.maxRetries = (byte) -1;
        int int13 = strKafkaSpout10.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray14 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet15 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean16 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet15, kafkaSpoutMessageIdArray14);
        strKafkaSpout10.emitted = kafkaSpoutMessageIdSet15;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet15;
        strKafkaSpout0.initialized = false;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig21 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig22 = strKafkaSpout0.kafkaSpoutConfig;
        boolean boolean23 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout24 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor25 = null;
        strKafkaSpout24.waitingToEmit = strConsumerRecordItor25;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer27 = null;
        strKafkaSpout24.kafkaConsumer = strKafkaConsumer27;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy29 = null;
        strKafkaSpout24.firstPollOffsetStrategy = firstPollOffsetStrategy29;
        java.lang.String str31 = strKafkaSpout24.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder32 = strKafkaSpout24.tuplesBuilder;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer33 = strKafkaSpout24.kafkaConsumer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer34 = strKafkaSpout24.kafkaConsumer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector35 = null;
        strKafkaSpout24.collector = spoutOutputCollector35;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.ack((java.lang.Object) spoutOutputCollector35);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(spoutOutputCollector9);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray14);
        org.junit.Assert.assertTrue("'" + boolean16 + "' != '" + false + "'", boolean16 == false);
        org.junit.Assert.assertNull(strKafkaSpoutConfig21);
        org.junit.Assert.assertNull(strKafkaSpoutConfig22);
        org.junit.Assert.assertTrue("'" + boolean23 + "' != '" + false + "'", boolean23 == false);
        org.junit.Assert.assertEquals("'" + str31 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str31, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder32);
        org.junit.Assert.assertNull(strKafkaConsumer33);
        org.junit.Assert.assertNull(strKafkaConsumer34);
    }

    @Test
    public void test2256() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2256");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout11 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = strKafkaSpout11.kafkaSpoutStreams;
        strKafkaSpout11.consumerAutoCommitMode = false;
        java.lang.String str15 = strKafkaSpout11.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout16 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout16.maxRetries = (byte) -1;
        int int19 = strKafkaSpout16.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray20 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet21 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean22 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, kafkaSpoutMessageIdArray20);
        strKafkaSpout16.emitted = kafkaSpoutMessageIdSet21;
        strKafkaSpout11.emitted = kafkaSpoutMessageIdSet21;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout25 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout25.maxRetries = (byte) -1;
        int int28 = strKafkaSpout25.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor29 = null;
        strKafkaSpout25.waitingToEmit = strConsumerRecordItor29;
        org.apache.kafka.common.TopicPartition topicPartition31 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection32 = strKafkaSpout25.toArrayList(topicPartition31);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout25.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector34 = strKafkaSpout25.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout35.maxRetries = (byte) -1;
        int int38 = strKafkaSpout35.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray39 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet40 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean41 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40, kafkaSpoutMessageIdArray39);
        strKafkaSpout35.emitted = kafkaSpoutMessageIdSet40;
        strKafkaSpout25.emitted = kafkaSpoutMessageIdSet40;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType7, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet40;
        long long46 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout47 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout47.maxRetries = (byte) -1;
        int int50 = strKafkaSpout47.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor51 = null;
        strKafkaSpout47.waitingToEmit = strConsumerRecordItor51;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig53 = null;
        strKafkaSpout47.kafkaSpoutConfig = strKafkaSpoutConfig53;
        int int55 = strKafkaSpout47.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy56 = null;
        strKafkaSpout47.firstPollOffsetStrategy = firstPollOffsetStrategy56;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet58 = strKafkaSpout47.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray59 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet60 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean61 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet60, kafkaSpoutMessageIdArray59);
        strKafkaSpout47.emitted = kafkaSpoutMessageIdSet60;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer63 = null;
        strKafkaSpout47.kafkaConsumer = strKafkaConsumer63;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector65 = null;
        strKafkaSpout47.collector = spoutOutputCollector65;
        int int67 = strKafkaSpout47.maxRetries;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet68 = strKafkaSpout47.emitted;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet68;
        org.apache.kafka.common.TopicPartition topicPartition70 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setAcked(topicPartition70, 1L);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(strKafkaSpoutConfig2);
        org.junit.Assert.assertNull(kafkaSpoutStreams12);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray20);
        org.junit.Assert.assertTrue("'" + boolean22 + "' != '" + false + "'", boolean22 == false);
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + (-1) + "'", int28 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection32);
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(spoutOutputCollector34);
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + (-1) + "'", int38 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray39);
        org.junit.Assert.assertTrue("'" + boolean41 + "' != '" + false + "'", boolean41 == false);
        org.junit.Assert.assertTrue("'" + long46 + "' != '" + 0L + "'", long46 == 0L);
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + (-1) + "'", int50 == (-1));
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + (-1) + "'", int55 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet58);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray59);
        org.junit.Assert.assertTrue("'" + boolean61 + "' != '" + false + "'", boolean61 == false);
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + (-1) + "'", int67 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdSet68);
    }

    @Test
    public void test2257() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2257");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer12 = strKafkaSpout0.kafkaConsumer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer13 = strKafkaSpout0.kafkaConsumer;
        strKafkaSpout0.maxRetries = (byte) 100;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertNull(strKafkaConsumer12);
        org.junit.Assert.assertNull(strKafkaConsumer13);
    }

    @Test
    public void test2258() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2258");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        long long7 = charSequenceConsumerRecord5.timestamp();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        java.lang.String str9 = charSequenceConsumerRecord5.toString();
        org.apache.kafka.common.header.Headers headers10 = charSequenceConsumerRecord5.headers();
        java.lang.String str11 = charSequenceConsumerRecord5.topic();
        long long12 = charSequenceConsumerRecord5.timestamp();
        int int13 = charSequenceConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional14 = charSequenceConsumerRecord5.leaderEpoch();
        int int15 = charSequenceConsumerRecord5.partition();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str9, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertNotNull(intOptional14);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 100 + "'", int15 == 100);
    }

    @Test
    public void test2259() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2259");
        org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> charSequenceConsumerRecordKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>();
    }

    @Test
    public void test2260() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2260");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams6 = strKafkaSpout0.kafkaSpoutStreams;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutStreams6);
    }

    @Test
    public void test2261() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2261");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = strKafkaSpout0.collector;
        strKafkaSpout0.maxRetries = (short) 0;
        java.lang.Class<?> wildcardClass12 = strKafkaSpout0.getClass();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(spoutOutputCollector9);
        org.junit.Assert.assertNotNull(wildcardClass12);
    }

    @Test
    public void test2262() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2262");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        long long12 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.checksum();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        java.lang.String str17 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
    }

    @Test
    public void test2263() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2263");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType4, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        long long11 = charSequenceConsumerRecord10.checksum();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        int int13 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 10L + "'", long11 == 10L);
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence12, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
    }

    @Test
    public void test2264() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2264");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType17 = null;
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int34 = charSequenceConsumerRecord33.serializedValueSize();
        java.lang.CharSequence charSequence35 = charSequenceConsumerRecord33.key();
        org.apache.kafka.common.header.Headers headers36 = charSequenceConsumerRecord33.headers();
        java.util.Optional<java.lang.Integer> intOptional37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType17, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers36, intOptional37);
        org.apache.kafka.common.record.TimestampType timestampType46 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType46, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int53 = charSequenceConsumerRecord52.serializedValueSize();
        java.lang.CharSequence charSequence54 = charSequenceConsumerRecord52.key();
        org.apache.kafka.common.header.Headers headers55 = charSequenceConsumerRecord52.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray56 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList57 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean58 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57, kafkaSpoutMessageIdArray56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers55, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headersConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("", (int) '#', 1L, headers36, kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType4, (java.lang.Long) (-1L), (int) (short) 100, 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}", headers36);
        long long62 = charSequenceConsumerRecord61.checksum();
        long long63 = charSequenceConsumerRecord61.checksum();
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + (-1) + "'", int34 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence35 + "' != '" + "" + "'", charSequence35, "");
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + (-1) + "'", int53 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence54 + "' != '" + "" + "'", charSequence54, "");
        org.junit.Assert.assertNotNull(headers55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray56);
        org.junit.Assert.assertTrue("'" + boolean58 + "' != '" + false + "'", boolean58 == false);
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + (-1L) + "'", long62 == (-1L));
        org.junit.Assert.assertTrue("'" + long63 + "' != '" + (-1L) + "'", long63 == (-1L));
    }

    @Test
    public void test2265() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2265");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator4 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator4;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator6 = offsetComparator4.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator6);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator8 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator9 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator10 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator10;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator10.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator9.thenComparing(kafkaSpoutMessageIdComparator12);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator14 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator14;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator14.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator21 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator21;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator21);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator16.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator21);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator9.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator21);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator21.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator27 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator27;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = offsetComparator27.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator34 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator34;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = kafkaSpoutMessageIdComparator29.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = offsetComparator34.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = kafkaSpoutMessageIdComparator26.thenComparing(kafkaSpoutMessageIdComparator38);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator40 = kafkaSpoutMessageIdComparator8.thenComparing(kafkaSpoutMessageIdComparator26);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator41 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator41;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator43 = offsetComparator41.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator48 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator48;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator48);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator51 = kafkaSpoutMessageIdComparator43.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator48);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator52 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator52;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator54 = offsetComparator52.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator59 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator59;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator59);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator62 = kafkaSpoutMessageIdComparator54.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator59);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator63 = kafkaSpoutMessageIdComparator43.thenComparing(kafkaSpoutMessageIdComparator62);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator64 = kafkaSpoutMessageIdComparator62.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator65 = kafkaSpoutMessageIdComparator8.thenComparing(kafkaSpoutMessageIdComparator62);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator8;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator6);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator8);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator40);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator43);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator51);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator54);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator62);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator63);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator64);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator65);
    }

    @Test
    public void test2266() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2266");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.timestamp();
        long long16 = charSequenceConsumerRecord10.offset();
        long long17 = charSequenceConsumerRecord10.offset();
        long long18 = charSequenceConsumerRecord10.offset();
        int int19 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
    }

    @Test
    public void test2267() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2267");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType4, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str13 = charSequenceConsumerRecord10.toString();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        int int15 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 35L + "'", long11 == 35L);
        org.junit.Assert.assertNull(timestampType12);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", str13, "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 1 + "'", int15 == 1);
    }

    @Test
    public void test2268() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2268");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        int int19 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.header.Headers headers20 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType21 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str22 = charSequenceConsumerRecord10.value();
        int int23 = charSequenceConsumerRecord10.serializedKeySize();
        int int24 = charSequenceConsumerRecord10.serializedValueSize();
        long long25 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers26 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertNull(timestampType21);
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "hi!" + "'", str22, "hi!");
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 52 + "'", int23 == 52);
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + (-1L) + "'", long25 == (-1L));
        org.junit.Assert.assertNotNull(headers26);
    }

    @Test
    public void test2269() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2269");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams4;
        boolean boolean6 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy7;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + 0 + "'", int3 == 0);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
    }

    @Test
    public void test2270() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2270");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers12 = charSequenceConsumerRecord10.headers();
        int int13 = charSequenceConsumerRecord10.serializedKeySize();
        int int14 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.String str15 = charSequenceConsumerRecord10.topic();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 52 + "'", int13 == 52);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "" + "'", str15, "");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
    }

    @Test
    public void test2271() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2271");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector2 = null;
        strKafkaSpout0.collector = spoutOutputCollector2;
        strKafkaSpout0.initialized = true;
        java.lang.Class<?> wildcardClass6 = strKafkaSpout0.getClass();
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNotNull(wildcardClass6);
    }

    @Test
    public void test2272() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2272");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams6 = strKafkaSpout0.kafkaSpoutStreams;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy8 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy8;
        boolean boolean10 = strKafkaSpout0.waitingToEmit();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.commitOffsetsForAckedTuples();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
    }

    @Test
    public void test2273() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2273");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) 100, 1L, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=[]}");
        java.lang.CharSequence charSequence6 = charSequenceConsumerRecord5.key();
        long long7 = charSequenceConsumerRecord5.offset();
        java.lang.String str8 = charSequenceConsumerRecord5.topic();
        java.lang.CharSequence charSequence9 = charSequenceConsumerRecord5.key();
        org.junit.Assert.assertEquals("'" + charSequence6 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence6, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + 1L + "'", long7 == 1L);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertEquals("'" + charSequence9 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence9, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test2274() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2274");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        java.lang.String str17 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.header.Headers headers18 = charSequenceConsumerRecord10.headers();
        int int19 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType20 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str21 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertNotNull(headers18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 52 + "'", int19 == 52);
        org.junit.Assert.assertNull(timestampType20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "" + "'", str21, "");
    }

    @Test
    public void test2275() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2275");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 97, (long) (short) 1, (long) '4', timestampType4, (long) (byte) 10, (int) (byte) 1, (int) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, null = 1, serialized key size = 32, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )");
        java.util.Optional<java.lang.Integer> intOptional11 = charSequenceConsumerRecord10.leaderEpoch();
        int int12 = charSequenceConsumerRecord10.partition();
        int int13 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertNotNull(intOptional11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 97 + "'", int12 == 97);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 1 + "'", int13 == 1);
    }

    @Test
    public void test2276() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2276");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = null;
        strKafkaSpout0.collector = spoutOutputCollector12;
        int int14 = strKafkaSpout0.maxRetries;
        long long15 = strKafkaSpout0.numUncommittedOffsets;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.deactivate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 0L + "'", long15 == 0L);
    }

    @Test
    public void test2277() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2277");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType17 = null;
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int34 = charSequenceConsumerRecord33.serializedValueSize();
        java.lang.CharSequence charSequence35 = charSequenceConsumerRecord33.key();
        org.apache.kafka.common.header.Headers headers36 = charSequenceConsumerRecord33.headers();
        java.util.Optional<java.lang.Integer> intOptional37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType17, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers36, intOptional37);
        org.apache.kafka.common.record.TimestampType timestampType46 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType46, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int53 = charSequenceConsumerRecord52.serializedValueSize();
        java.lang.CharSequence charSequence54 = charSequenceConsumerRecord52.key();
        org.apache.kafka.common.header.Headers headers55 = charSequenceConsumerRecord52.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray56 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList57 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean58 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57, kafkaSpoutMessageIdArray56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers55, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headersConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("", (int) '#', 1L, headers36, kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType4, (java.lang.Long) (-1L), (int) (short) 100, 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}", headers36);
        long long62 = charSequenceConsumerRecord61.checksum();
        long long63 = charSequenceConsumerRecord61.timestamp();
        long long64 = charSequenceConsumerRecord61.timestamp();
        long long65 = charSequenceConsumerRecord61.timestamp();
        long long66 = charSequenceConsumerRecord61.offset();
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + (-1) + "'", int34 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence35 + "' != '" + "" + "'", charSequence35, "");
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + (-1) + "'", int53 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence54 + "' != '" + "" + "'", charSequence54, "");
        org.junit.Assert.assertNotNull(headers55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray56);
        org.junit.Assert.assertTrue("'" + boolean58 + "' != '" + false + "'", boolean58 == false);
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + (-1L) + "'", long62 == (-1L));
        org.junit.Assert.assertTrue("'" + long63 + "' != '" + 0L + "'", long63 == 0L);
        org.junit.Assert.assertTrue("'" + long64 + "' != '" + 0L + "'", long64 == 0L);
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + 0L + "'", long65 == 0L);
        org.junit.Assert.assertTrue("'" + long66 + "' != '" + 1L + "'", long66 == 1L);
    }

    @Test
    public void test2278() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2278");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        java.lang.String str14 = charSequenceConsumerRecord10.value();
        int int15 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
    }

    @Test
    public void test2279() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2279");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 10, 1L, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=[]}");
        long long6 = charSequenceConsumerRecord5.checksum();
        java.lang.String str7 = charSequenceConsumerRecord5.toString();
        java.lang.CharSequence charSequence8 = charSequenceConsumerRecord5.key();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})" + "'", str7, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})");
        org.junit.Assert.assertEquals("'" + charSequence8 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence8, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test2280() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2280");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str21 = charSequenceConsumerRecord10.topic();
        long long22 = charSequenceConsumerRecord10.timestamp();
        long long23 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "" + "'", str21, "");
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
        org.junit.Assert.assertTrue("'" + long23 + "' != '" + 0L + "'", long23 == 0L);
    }

    @Test
    public void test2281() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2281");
        org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.reflect.Type> intOptionalKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.lang.reflect.Type>();
    }

    @Test
    public void test2282() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2282");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        long long7 = charSequenceConsumerRecord5.timestamp();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        java.lang.String str9 = charSequenceConsumerRecord5.toString();
        org.apache.kafka.common.header.Headers headers10 = charSequenceConsumerRecord5.headers();
        java.lang.String str11 = charSequenceConsumerRecord5.topic();
        java.lang.String str12 = charSequenceConsumerRecord5.toString();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord5.headers();
        java.lang.String str14 = charSequenceConsumerRecord5.topic();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str9, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str12, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
    }

    @Test
    public void test2283() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2283");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        boolean boolean8 = strKafkaSpout0.waitingToEmit();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.activate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
    }

    @Test
    public void test2284() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2284");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        int int21 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 10 + "'", int21 == 10);
    }

    @Test
    public void test2285() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2285");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.String str16 = charSequenceConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional17 = charSequenceConsumerRecord10.leaderEpoch();
        long long18 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(intOptional17);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
    }

    @Test
    public void test2286() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2286");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        java.lang.String str13 = charSequenceConsumerRecord10.toString();
        long long14 = charSequenceConsumerRecord10.checksum();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        long long16 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
    }

    @Test
    public void test2287() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2287");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 10, 1L, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=[]}");
        long long10 = charSequenceConsumerRecord9.checksum();
        org.apache.kafka.common.record.TimestampType timestampType11 = charSequenceConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType19, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int26 = charSequenceConsumerRecord25.serializedValueSize();
        int int27 = charSequenceConsumerRecord25.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType32, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long39 = charSequenceConsumerRecord38.checksum();
        int int40 = charSequenceConsumerRecord38.partition();
        java.lang.String str41 = charSequenceConsumerRecord38.value();
        int int42 = charSequenceConsumerRecord38.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional43 = charSequenceConsumerRecord38.leaderEpoch();
        long long44 = charSequenceConsumerRecord38.timestamp();
        java.util.Optional<java.lang.Integer> intOptional45 = charSequenceConsumerRecord38.leaderEpoch();
        int int46 = charSequenceConsumerRecord38.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional47 = charSequenceConsumerRecord38.leaderEpoch();
        java.lang.Class<?> wildcardClass48 = charSequenceConsumerRecord38.getClass();
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType53, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long60 = charSequenceConsumerRecord59.checksum();
        int int61 = charSequenceConsumerRecord59.partition();
        java.lang.String str62 = charSequenceConsumerRecord59.value();
        int int63 = charSequenceConsumerRecord59.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional64 = charSequenceConsumerRecord59.leaderEpoch();
        org.apache.kafka.common.header.Headers headers65 = charSequenceConsumerRecord59.headers();
        org.apache.kafka.common.record.TimestampType timestampType70 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) ' ', (long) (byte) 100, (long) (byte) -1, timestampType70, (long) (byte) -1, (int) (byte) 10, 10, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long77 = charSequenceConsumerRecord76.timestamp();
        java.lang.String str78 = charSequenceConsumerRecord76.toString();
        long long79 = charSequenceConsumerRecord76.offset();
        java.lang.String str80 = charSequenceConsumerRecord76.value();
        java.util.Optional<java.lang.Integer> intOptional81 = charSequenceConsumerRecord76.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>, java.lang.reflect.Type> charSequenceConsumerRecordConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>, java.lang.reflect.Type>("hi!", 0, (long) (short) 100, 0L, timestampType11, (java.lang.Long) (-1L), 0, (int) (short) 1, charSequenceConsumerRecord25, (java.lang.reflect.Type) wildcardClass48, headers65, intOptional81);
        org.apache.kafka.common.header.Headers headers83 = charSequenceConsumerRecord25.headers();
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int26 + "' != '" + (-1) + "'", int26 == (-1));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + 52 + "'", int27 == 52);
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + (-1L) + "'", long39 == (-1L));
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + 10 + "'", int40 == 10);
        org.junit.Assert.assertEquals("'" + str41 + "' != '" + "hi!" + "'", str41, "hi!");
        org.junit.Assert.assertTrue("'" + int42 + "' != '" + 52 + "'", int42 == 52);
        org.junit.Assert.assertNotNull(intOptional43);
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + (-1L) + "'", long44 == (-1L));
        org.junit.Assert.assertNotNull(intOptional45);
        org.junit.Assert.assertTrue("'" + int46 + "' != '" + (-1) + "'", int46 == (-1));
        org.junit.Assert.assertNotNull(intOptional47);
        org.junit.Assert.assertNotNull(wildcardClass48);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + 10 + "'", int61 == 10);
        org.junit.Assert.assertEquals("'" + str62 + "' != '" + "hi!" + "'", str62, "hi!");
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 52 + "'", int63 == 52);
        org.junit.Assert.assertNotNull(intOptional64);
        org.junit.Assert.assertNotNull(headers65);
        org.junit.Assert.assertTrue("'" + long77 + "' != '" + (-1L) + "'", long77 == (-1L));
        org.junit.Assert.assertEquals("'" + str78 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str78, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + long79 + "' != '" + 100L + "'", long79 == 100L);
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str80, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(intOptional81);
        org.junit.Assert.assertNotNull(headers83);
    }

    @Test
    public void test2288() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2288");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout27 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout27.maxRetries = (byte) -1;
        int int30 = strKafkaSpout27.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor31 = null;
        strKafkaSpout27.waitingToEmit = strConsumerRecordItor31;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout27.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer34 = strKafkaSpout27.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType40, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long47 = charSequenceConsumerRecord46.offset();
        long long48 = charSequenceConsumerRecord46.checksum();
        int int49 = charSequenceConsumerRecord46.serializedKeySize();
        org.apache.kafka.common.header.Headers headers50 = charSequenceConsumerRecord46.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType23, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout27, (java.lang.CharSequence) "hi!", headers50);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 1, 0L, (long) (byte) 0, timestampType23, (long) ' ', (int) (short) -1, (int) (byte) 10, (java.lang.CharSequence) "", "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) -1, (long) ' ', (long) (short) 0, timestampType23, (long) (short) 1, (int) (byte) 10, (int) '#', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        org.apache.kafka.common.record.TimestampType timestampType73 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType73, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        java.lang.String str80 = charSequenceConsumerRecord79.topic();
        org.apache.kafka.common.header.Headers headers81 = charSequenceConsumerRecord79.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 0, (long) 52, (long) (byte) -1, timestampType23, (java.lang.Long) 1L, (int) (short) 0, (-1), (java.lang.CharSequence) "hi!", "hi!", headers81);
        long long83 = charSequenceConsumerRecord82.timestamp();
        long long84 = charSequenceConsumerRecord82.checksum();
        java.util.Optional<java.lang.Integer> intOptional85 = charSequenceConsumerRecord82.leaderEpoch();
        int int86 = charSequenceConsumerRecord82.serializedValueSize();
        java.lang.String str87 = charSequenceConsumerRecord82.toString();
        java.lang.String str88 = charSequenceConsumerRecord82.topic();
        int int89 = charSequenceConsumerRecord82.partition();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(strKafkaConsumer34);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 0L + "'", long47 == 0L);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 52 + "'", int49 == 52);
        org.junit.Assert.assertNotNull(headers50);
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "hi!" + "'", str80, "hi!");
        org.junit.Assert.assertNotNull(headers81);
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + (-1L) + "'", long83 == (-1L));
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + 1L + "'", long84 == 1L);
        org.junit.Assert.assertNotNull(intOptional85);
        org.junit.Assert.assertTrue("'" + int86 + "' != '" + (-1) + "'", int86 == (-1));
        org.junit.Assert.assertEquals("'" + str87 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)" + "'", str87, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)");
        org.junit.Assert.assertEquals("'" + str88 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str88, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + int89 + "' != '" + 0 + "'", int89 == 0);
    }

    @Test
    public void test2289() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2289");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        int int12 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder13;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService15 = strKafkaSpout0.retryService;
        boolean boolean16 = strKafkaSpout0.consumerAutoCommitMode;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet17 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder18 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder18;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService15);
        org.junit.Assert.assertTrue("'" + boolean16 + "' != '" + false + "'", boolean16 == false);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet17);
    }

    @Test
    public void test2290() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2290");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str10 = strKafkaSpout0.getNamedTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
    }

    @Test
    public void test2291() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2291");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.emit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
    }

    @Test
    public void test2292() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2292");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        boolean boolean7 = strKafkaSpout0.initialized;
        strKafkaSpout0.consumerAutoCommitMode = true;
        boolean boolean10 = strKafkaSpout0.commit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor11 = strKafkaSpout0.waitingToEmit;
        org.apache.kafka.common.TopicPartition topicPartition12 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection13 = strKafkaSpout0.toArrayList(topicPartition12);
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig14 = strKafkaSpout0.kafkaSpoutConfig;
        boolean boolean15 = strKafkaSpout0.waitingToEmit();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.deactivate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor11);
        org.junit.Assert.assertNotNull(topicPartitionCollection13);
        org.junit.Assert.assertNull(strKafkaSpoutConfig14);
        org.junit.Assert.assertTrue("'" + boolean15 + "' != '" + false + "'", boolean15 == false);
    }

    @Test
    public void test2293() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2293");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str26 = charSequenceConsumerRecord25.topic();
        org.apache.kafka.common.record.TimestampType timestampType27 = charSequenceConsumerRecord25.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout31 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout31.maxRetries = (byte) -1;
        int int34 = strKafkaSpout31.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor35 = null;
        strKafkaSpout31.waitingToEmit = strConsumerRecordItor35;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer37 = strKafkaSpout31.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer38 = strKafkaSpout31.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType44 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType44, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long51 = charSequenceConsumerRecord50.offset();
        long long52 = charSequenceConsumerRecord50.checksum();
        int int53 = charSequenceConsumerRecord50.serializedKeySize();
        org.apache.kafka.common.header.Headers headers54 = charSequenceConsumerRecord50.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType27, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout31, (java.lang.CharSequence) "hi!", headers54);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 1, 0L, (long) (byte) 0, timestampType27, (long) ' ', (int) (short) -1, (int) (byte) 10, (java.lang.CharSequence) "", "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) -1, (long) ' ', (long) (short) 0, timestampType27, (long) (short) 1, (int) (byte) 10, (int) '#', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", (int) (short) 0, 1L, 0L, timestampType27, (long) 10, 1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 35, (long) 100, (long) (short) 10, timestampType27, (long) ' ', (int) 'a', (int) (short) 1, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)", "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
        int int80 = charSequenceConsumerRecord79.partition();
        java.lang.CharSequence charSequence81 = charSequenceConsumerRecord79.key();
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "" + "'", str26, "");
        org.junit.Assert.assertTrue("'" + timestampType27 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType27.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + (-1) + "'", int34 == (-1));
        org.junit.Assert.assertNull(timer37);
        org.junit.Assert.assertNull(strKafkaConsumer38);
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + 0L + "'", long51 == 0L);
        org.junit.Assert.assertTrue("'" + long52 + "' != '" + (-1L) + "'", long52 == (-1L));
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + 52 + "'", int53 == 52);
        org.junit.Assert.assertNotNull(headers54);
        org.junit.Assert.assertTrue("'" + int80 + "' != '" + 35 + "'", int80 == 35);
        org.junit.Assert.assertEquals("'" + charSequence81 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)" + "'", charSequence81, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)");
    }

    @Test
    public void test2294() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2294");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long10 = charSequenceConsumerRecord9.checksum();
        long long11 = charSequenceConsumerRecord9.timestamp();
        org.apache.kafka.common.header.Headers headers12 = charSequenceConsumerRecord9.headers();
        java.lang.String str13 = charSequenceConsumerRecord9.toString();
        org.apache.kafka.common.header.Headers headers14 = charSequenceConsumerRecord9.headers();
        java.lang.String str15 = charSequenceConsumerRecord9.topic();
        long long16 = charSequenceConsumerRecord9.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str33 = charSequenceConsumerRecord32.topic();
        org.apache.kafka.common.record.TimestampType timestampType34 = charSequenceConsumerRecord32.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType42 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType42, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long49 = charSequenceConsumerRecord48.checksum();
        int int50 = charSequenceConsumerRecord48.partition();
        long long51 = charSequenceConsumerRecord48.timestamp();
        java.lang.String str52 = charSequenceConsumerRecord48.toString();
        long long53 = charSequenceConsumerRecord48.timestamp();
        org.apache.kafka.common.header.Headers headers54 = charSequenceConsumerRecord48.headers();
        org.apache.kafka.common.record.TimestampType timestampType55 = charSequenceConsumerRecord48.timestampType();
        java.util.Optional<java.lang.Integer> intOptional56 = charSequenceConsumerRecord48.leaderEpoch();
        org.apache.storm.topology.IComponent iComponent57 = null;
        org.apache.kafka.common.record.TimestampType timestampType62 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType62, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long69 = charSequenceConsumerRecord68.checksum();
        int int70 = charSequenceConsumerRecord68.partition();
        long long71 = charSequenceConsumerRecord68.timestamp();
        java.lang.String str72 = charSequenceConsumerRecord68.toString();
        org.apache.kafka.common.header.Headers headers73 = charSequenceConsumerRecord68.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent> intOptionalConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent>("hi!", (int) ' ', (long) (byte) -1, (long) (-1), timestampType34, (java.lang.Long) 100L, (int) 'a', (-1), intOptional56, iComponent57, headers73);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 52, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 100, (long) 52, 10L, timestampType17, (java.lang.Long) 32L, (int) (byte) 1, 32, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 0, leaderEpoch = null, offset = -1, null = 100, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", headers73);
        long long76 = charSequenceConsumerRecord75.checksum();
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str13, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "" + "'", str15, "");
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType17 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType17.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "" + "'", str33, "");
        org.junit.Assert.assertTrue("'" + timestampType34 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType34.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long49 + "' != '" + (-1L) + "'", long49 == (-1L));
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + 10 + "'", int50 == 10);
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + (-1L) + "'", long51 == (-1L));
        org.junit.Assert.assertEquals("'" + str52 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str52, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long53 + "' != '" + (-1L) + "'", long53 == (-1L));
        org.junit.Assert.assertNotNull(headers54);
        org.junit.Assert.assertNull(timestampType55);
        org.junit.Assert.assertNotNull(intOptional56);
        org.junit.Assert.assertTrue("'" + long69 + "' != '" + (-1L) + "'", long69 == (-1L));
        org.junit.Assert.assertTrue("'" + int70 + "' != '" + 10 + "'", int70 == 10);
        org.junit.Assert.assertTrue("'" + long71 + "' != '" + (-1L) + "'", long71 == (-1L));
        org.junit.Assert.assertEquals("'" + str72 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str72, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers73);
        org.junit.Assert.assertTrue("'" + long76 + "' != '" + 32L + "'", long76 == 32L);
    }

    @Test
    public void test2295() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2295");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        strKafkaSpout0.numUncommittedOffsets = (byte) -1;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams5 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig7 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.common.TopicPartition topicPartition8 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection9 = strKafkaSpout0.toArrayList(topicPartition8);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = strKafkaSpout0.retryService;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean11 = strKafkaSpout0.commit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(strKafkaSpoutConfig7);
        org.junit.Assert.assertNotNull(topicPartitionCollection9);
        org.junit.Assert.assertNull(kafkaSpoutRetryService10);
    }

    @Test
    public void test2296() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2296");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.CharSequence, org.apache.storm.topology.base.BaseRichSpout> charSequenceKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, org.apache.storm.topology.base.BaseRichSpout> charSequenceKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.CharSequence, org.apache.storm.topology.base.BaseRichSpout>(charSequenceKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test2297() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2297");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", (int) (short) 100, 52L, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
    }

    @Test
    public void test2298() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2298");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer9 = strKafkaSpout0.kafkaConsumer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor10 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor10;
        strKafkaSpout0.numUncommittedOffsets = (short) 100;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer9);
    }

    @Test
    public void test2299() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2299");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.initialized = false;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer5 = strKafkaSpout0.kafkaConsumer;
        java.util.Map map6 = null;
        org.apache.storm.task.TopologyContext topologyContext7 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector8 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map6, topologyContext7, spoutOutputCollector8);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertNull(strKafkaConsumer5);
    }

    @Test
    public void test2300() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2300");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer4;
        strKafkaSpout0.maxRetries = 0;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.deactivate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
    }

    @Test
    public void test2301() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2301");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        boolean boolean7 = strKafkaSpout0.initialized;
        strKafkaSpout0.consumerAutoCommitMode = true;
        boolean boolean10 = strKafkaSpout0.commit();
        strKafkaSpout0.maxRetries = '4';
        strKafkaSpout0.numUncommittedOffsets = (short) 0;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig15 = strKafkaSpout0.kafkaSpoutConfig;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet16 = strKafkaSpout0.emitted;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNull(strKafkaSpoutConfig15);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet16);
    }

    @Test
    public void test2302() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2302");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        boolean boolean4 = strKafkaSpout0.waitingToEmit();
        strKafkaSpout0.initialized = false;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy7;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str9 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
    }

    @Test
    public void test2303() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2303");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        boolean boolean2 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig3 = strKafkaSpout0.kafkaSpoutConfig;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = strKafkaSpout0.waitingToEmit;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = strKafkaSpout0.emitted;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertTrue("'" + boolean2 + "' != '" + false + "'", boolean2 == false);
        org.junit.Assert.assertNull(strKafkaSpoutConfig3);
        org.junit.Assert.assertNull(strConsumerRecordItor4);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet5);
    }

    @Test
    public void test2304() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2304");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = offsetComparator7.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = kafkaSpoutMessageIdComparator11.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = kafkaSpoutMessageIdComparator11.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator14;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
    }

    @Test
    public void test2305() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2305");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout3 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout3.maxRetries = (byte) -1;
        int int6 = strKafkaSpout3.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout3.waitingToEmit = strConsumerRecordItor7;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout3.toArrayList(topicPartition9);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = strKafkaSpout3.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType16 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout20 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout20.maxRetries = (byte) -1;
        int int23 = strKafkaSpout20.maxRetries;
        strKafkaSpout20.numUncommittedOffsets = '#';
        strKafkaSpout20.initialized = true;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet28 = strKafkaSpout20.emitted;
        org.apache.kafka.common.record.TimestampType timestampType36 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType36, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int43 = charSequenceConsumerRecord42.serializedValueSize();
        java.lang.CharSequence charSequence44 = charSequenceConsumerRecord42.key();
        org.apache.kafka.common.header.Headers headers45 = charSequenceConsumerRecord42.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray46 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList47 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean48 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47, kafkaSpoutMessageIdArray46);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers45, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47);
        org.apache.kafka.common.record.TimestampType timestampType54 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType54, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int61 = charSequenceConsumerRecord60.serializedValueSize();
        java.lang.CharSequence charSequence62 = charSequenceConsumerRecord60.key();
        org.apache.kafka.common.header.Headers headers63 = charSequenceConsumerRecord60.headers();
        org.apache.kafka.common.record.TimestampType timestampType68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType68, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long75 = charSequenceConsumerRecord74.offset();
        int int76 = charSequenceConsumerRecord74.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional77 = charSequenceConsumerRecord74.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> objConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) '4', (long) (short) 0, (long) 100, timestampType16, (java.lang.Long) 1L, (int) (short) 0, 0, (java.lang.Object) kafkaSpoutMessageIdSet28, (java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47, headers63, intOptional77);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.common.header.Headers> iSpoutConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.common.header.Headers>("KafkaSpout{acked=null, emitted=null}", (int) '#', (long) 1, (org.apache.storm.spout.ISpout) strKafkaSpout3, headers63);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService80 = null;
        strKafkaSpout3.retryService = kafkaSpoutRetryService80;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords82 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout3.setWaitingToEmit(strConsumerRecords82);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(strKafkaConsumer11);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet28);
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + (-1) + "'", int43 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence44 + "' != '" + "" + "'", charSequence44, "");
        org.junit.Assert.assertNotNull(headers45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray46);
        org.junit.Assert.assertTrue("'" + boolean48 + "' != '" + false + "'", boolean48 == false);
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + (-1) + "'", int61 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence62 + "' != '" + "" + "'", charSequence62, "");
        org.junit.Assert.assertNotNull(headers63);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + 0L + "'", long75 == 0L);
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + (-1) + "'", int76 == (-1));
        org.junit.Assert.assertNotNull(intOptional77);
    }

    @Test
    public void test2306() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2306");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType23, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long30 = charSequenceConsumerRecord29.checksum();
        int int31 = charSequenceConsumerRecord29.partition();
        java.lang.String str32 = charSequenceConsumerRecord29.value();
        int int33 = charSequenceConsumerRecord29.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional34 = charSequenceConsumerRecord29.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet36 = strKafkaSpout35.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor37 = null;
        strKafkaSpout35.waitingToEmit = strConsumerRecordItor37;
        boolean boolean39 = strKafkaSpout35.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig40 = null;
        strKafkaSpout35.kafkaSpoutConfig = strKafkaSpoutConfig40;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy42 = strKafkaSpout35.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType15, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord29, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout35);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType53, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int60 = charSequenceConsumerRecord59.serializedValueSize();
        java.lang.CharSequence charSequence61 = charSequenceConsumerRecord59.key();
        org.apache.kafka.common.header.Headers headers62 = charSequenceConsumerRecord59.headers();
        int int63 = charSequenceConsumerRecord59.partition();
        int int64 = charSequenceConsumerRecord59.partition();
        org.apache.kafka.common.header.Headers headers65 = charSequenceConsumerRecord59.headers();
        org.apache.kafka.common.record.TimestampType timestampType70 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType70, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int77 = charSequenceConsumerRecord76.serializedValueSize();
        long long78 = charSequenceConsumerRecord76.checksum();
        java.util.Optional<java.lang.Integer> intOptional79 = charSequenceConsumerRecord76.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", (int) (short) 0, (long) (short) 10, (long) 1, timestampType15, (java.lang.Long) 100L, (int) (byte) -1, 52, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", headers65, intOptional79);
        java.lang.Class<?> wildcardClass81 = timestampType15.getClass();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 10 + "'", int31 == 10);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "hi!" + "'", str32, "hi!");
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + 52 + "'", int33 == 52);
        org.junit.Assert.assertNotNull(intOptional34);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet36);
        org.junit.Assert.assertTrue("'" + boolean39 + "' != '" + false + "'", boolean39 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy42);
        org.junit.Assert.assertTrue("'" + int60 + "' != '" + (-1) + "'", int60 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence61 + "' != '" + "" + "'", charSequence61, "");
        org.junit.Assert.assertNotNull(headers62);
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 10 + "'", int63 == 10);
        org.junit.Assert.assertTrue("'" + int64 + "' != '" + 10 + "'", int64 == 10);
        org.junit.Assert.assertNotNull(headers65);
        org.junit.Assert.assertTrue("'" + int77 + "' != '" + (-1) + "'", int77 == (-1));
        org.junit.Assert.assertTrue("'" + long78 + "' != '" + (-1L) + "'", long78 == (-1L));
        org.junit.Assert.assertNotNull(intOptional79);
        org.junit.Assert.assertNotNull(wildcardClass81);
    }

    @Test
    public void test2307() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2307");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet8 = null;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet8;
        java.lang.String str10 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder11 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder11;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Map<java.lang.String, java.lang.Object> strMap13 = strKafkaSpout0.getComponentConfiguration();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str10, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test2308() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2308");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        strKafkaSpout0.maxRetries = (byte) 10;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord8 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean9 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord8);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
    }

    @Test
    public void test2309() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2309");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        long long19 = charSequenceConsumerRecord10.offset();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        long long21 = charSequenceConsumerRecord10.offset();
        org.apache.kafka.common.record.TimestampType timestampType22 = charSequenceConsumerRecord10.timestampType();
        long long23 = charSequenceConsumerRecord10.checksum();
        long long24 = charSequenceConsumerRecord10.timestamp();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 0L + "'", long21 == 0L);
        org.junit.Assert.assertNull(timestampType22);
        org.junit.Assert.assertTrue("'" + long23 + "' != '" + (-1L) + "'", long23 == (-1L));
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + (-1L) + "'", long24 == (-1L));
    }

    @Test
    public void test2310() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2310");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder16 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder16;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet18 = strKafkaSpout0.emitted;
        strKafkaSpout0.maxRetries = (short) 0;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdSet18);
    }

    @Test
    public void test2311() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2311");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        long long8 = strKafkaSpout0.numUncommittedOffsets;
        strKafkaSpout0.numUncommittedOffsets = (-1L);
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams11 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.common.TopicPartition topicPartition12 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection13 = strKafkaSpout0.toArrayList(topicPartition12);
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector14 = strKafkaSpout0.collector;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.emit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 0L + "'", long8 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutStreams11);
        org.junit.Assert.assertNotNull(topicPartitionCollection13);
        org.junit.Assert.assertNull(spoutOutputCollector14);
    }

    @Test
    public void test2312() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2312");
        org.apache.storm.kafka.spout.KafkaSpout<java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>> kafkaSpoutMessageIdCollectionKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.Enum<org.apache.kafka.common.record.TimestampType>>();
    }

    @Test
    public void test2313() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2313");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout19 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout19.maxRetries = (byte) -1;
        int int22 = strKafkaSpout19.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor23 = null;
        strKafkaSpout19.waitingToEmit = strConsumerRecordItor23;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer25 = strKafkaSpout19.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer26 = strKafkaSpout19.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType32, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long39 = charSequenceConsumerRecord38.offset();
        long long40 = charSequenceConsumerRecord38.checksum();
        int int41 = charSequenceConsumerRecord38.serializedKeySize();
        org.apache.kafka.common.header.Headers headers42 = charSequenceConsumerRecord38.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType15, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout19, (java.lang.CharSequence) "hi!", headers42);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType53, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long60 = charSequenceConsumerRecord59.checksum();
        int int61 = charSequenceConsumerRecord59.partition();
        long long62 = charSequenceConsumerRecord59.offset();
        org.apache.kafka.common.header.Headers headers63 = charSequenceConsumerRecord59.headers();
        org.apache.kafka.common.record.TimestampType timestampType68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType68, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long75 = charSequenceConsumerRecord74.offset();
        int int76 = charSequenceConsumerRecord74.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional77 = charSequenceConsumerRecord74.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) 10, 10L, 0L, timestampType15, (java.lang.Long) 35L, (int) (byte) 0, (-1), (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers63, intOptional77);
        java.util.Optional<java.lang.Integer> intOptional79 = charSequenceConsumerRecord78.leaderEpoch();
        java.lang.String str80 = charSequenceConsumerRecord78.toString();
        org.apache.kafka.common.record.TimestampType timestampType81 = charSequenceConsumerRecord78.timestampType();
        java.lang.Class<?> wildcardClass82 = timestampType81.getClass();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertNull(timer25);
        org.junit.Assert.assertNull(strKafkaConsumer26);
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + 0L + "'", long39 == 0L);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + 52 + "'", int41 == 52);
        org.junit.Assert.assertNotNull(headers42);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + 10 + "'", int61 == 10);
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + 0L + "'", long62 == 0L);
        org.junit.Assert.assertNotNull(headers63);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + 0L + "'", long75 == 0L);
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + (-1) + "'", int76 == (-1));
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertNotNull(intOptional79);
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str80, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + timestampType81 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType81.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass82);
    }

    @Test
    public void test2314() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2314");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams3 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams7;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Map<java.lang.String, java.lang.Object> strMap9 = strKafkaSpout0.getComponentConfiguration();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test2315() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2315");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        java.lang.String str8 = strKafkaSpout0.toString();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor9 = strKafkaSpout0.waitingToEmit;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords10 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords10);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strConsumerRecordItor9);
    }

    @Test
    public void test2316() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2316");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer9 = strKafkaSpout0.commitTimer;
        boolean boolean10 = strKafkaSpout0.waitingToEmit();
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.initialized = true;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean15 = strKafkaSpout0.commit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertNull(timer9);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
    }

    @Test
    public void test2317() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2317");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams11 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer12 = strKafkaSpout0.kafkaConsumer;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(kafkaSpoutStreams11);
        org.junit.Assert.assertNull(strKafkaConsumer12);
    }

    @Test
    public void test2318() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2318");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        java.util.Optional<java.lang.Integer> intOptional15 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        int int17 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.String str18 = charSequenceConsumerRecord10.toString();
        org.apache.kafka.common.record.TimestampType timestampType19 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str20 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 52 + "'", int17 == 52);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str18, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNull(timestampType19);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "" + "'", str20, "");
    }

    @Test
    public void test2319() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2319");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition8 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection9 = strKafkaSpout0.toArrayList(topicPartition8);
        boolean boolean10 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition11 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection12 = strKafkaSpout0.toArrayList(topicPartition11);
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection9);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection12);
    }

    @Test
    public void test2320() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2320");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer9 = strKafkaSpout0.kafkaConsumer;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setAcked(topicPartition10, 35L);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertNull(strKafkaConsumer9);
    }

    @Test
    public void test2321() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2321");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str18 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
    }

    @Test
    public void test2322() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2322");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers12 = charSequenceConsumerRecord10.headers();
        int int13 = charSequenceConsumerRecord10.serializedKeySize();
        int int14 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.String str15 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 52 + "'", int13 == 52);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "" + "'", str15, "");
        org.junit.Assert.assertNull(timestampType16);
    }

    @Test
    public void test2323() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2323");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>, java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> charSequenceConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>, java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> charSequenceConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>, java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>(charSequenceConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test2324() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2324");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        int int19 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.header.Headers headers20 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType21 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str22 = charSequenceConsumerRecord10.value();
        int int23 = charSequenceConsumerRecord10.serializedKeySize();
        int int24 = charSequenceConsumerRecord10.serializedValueSize();
        long long25 = charSequenceConsumerRecord10.timestamp();
        int int26 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertNull(timestampType21);
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "hi!" + "'", str22, "hi!");
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 52 + "'", int23 == 52);
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + (-1L) + "'", long25 == (-1L));
        org.junit.Assert.assertTrue("'" + int26 + "' != '" + 10 + "'", int26 == 10);
    }

    @Test
    public void test2325() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2325");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy3 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout4 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout4.maxRetries = (byte) -1;
        int int7 = strKafkaSpout4.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray8 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet9 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean10 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet9, kafkaSpoutMessageIdArray8);
        strKafkaSpout4.emitted = kafkaSpoutMessageIdSet9;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet9;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams13 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams13;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str15 = strKafkaSpout0.getNamedTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(firstPollOffsetStrategy3);
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray8);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
    }

    @Test
    public void test2326() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2326");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.reflect.AnnotatedElement> kafkaSpoutMessageIdSetKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.reflect.AnnotatedElement> kafkaSpoutMessageIdSetKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.reflect.AnnotatedElement>(kafkaSpoutMessageIdSetKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test2327() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2327");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str18 = charSequenceConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = charSequenceConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long34 = charSequenceConsumerRecord33.checksum();
        int int35 = charSequenceConsumerRecord33.partition();
        long long36 = charSequenceConsumerRecord33.timestamp();
        java.lang.String str37 = charSequenceConsumerRecord33.toString();
        long long38 = charSequenceConsumerRecord33.timestamp();
        org.apache.kafka.common.header.Headers headers39 = charSequenceConsumerRecord33.headers();
        org.apache.kafka.common.record.TimestampType timestampType40 = charSequenceConsumerRecord33.timestampType();
        java.util.Optional<java.lang.Integer> intOptional41 = charSequenceConsumerRecord33.leaderEpoch();
        org.apache.storm.topology.IComponent iComponent42 = null;
        org.apache.kafka.common.record.TimestampType timestampType47 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType47, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long54 = charSequenceConsumerRecord53.checksum();
        int int55 = charSequenceConsumerRecord53.partition();
        long long56 = charSequenceConsumerRecord53.timestamp();
        java.lang.String str57 = charSequenceConsumerRecord53.toString();
        org.apache.kafka.common.header.Headers headers58 = charSequenceConsumerRecord53.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent> intOptionalConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent>("hi!", (int) ' ', (long) (byte) -1, (long) (-1), timestampType19, (java.lang.Long) 100L, (int) 'a', (-1), intOptional41, iComponent42, headers58);
        org.apache.storm.topology.IRichSpout iRichSpout64 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.storm.topology.IRichSpout> strComparableConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.storm.topology.IRichSpout>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", (int) (byte) 0, (long) 10, (long) (-1), timestampType19, (long) 0, (int) (short) 10, (int) (byte) 1, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", iRichSpout64);
        org.apache.kafka.common.header.Headers headers71 = null;
        org.apache.kafka.common.record.TimestampType timestampType76 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) ' ', (long) (byte) 100, (long) (byte) -1, timestampType76, (long) (byte) -1, (int) (byte) 10, 10, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long83 = charSequenceConsumerRecord82.timestamp();
        java.lang.CharSequence charSequence84 = charSequenceConsumerRecord82.key();
        org.apache.kafka.common.header.Headers headers85 = charSequenceConsumerRecord82.headers();
        java.util.Optional<java.lang.Integer> intOptional86 = charSequenceConsumerRecord82.leaderEpoch();
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = 35, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)", (int) (byte) 0, (long) '#', (long) (short) 0, timestampType19, (java.lang.Long) 10L, 10, 1, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", headers71, intOptional86);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertTrue("'" + int35 + "' != '" + 10 + "'", int35 == 10);
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + (-1L) + "'", long36 == (-1L));
        org.junit.Assert.assertEquals("'" + str37 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str37, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + (-1L) + "'", long38 == (-1L));
        org.junit.Assert.assertNotNull(headers39);
        org.junit.Assert.assertNull(timestampType40);
        org.junit.Assert.assertNotNull(intOptional41);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + (-1L) + "'", long54 == (-1L));
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + 10 + "'", int55 == 10);
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + (-1L) + "'", long56 == (-1L));
        org.junit.Assert.assertEquals("'" + str57 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str57, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers58);
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + (-1L) + "'", long83 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence84 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", charSequence84, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNotNull(headers85);
        org.junit.Assert.assertNotNull(intOptional86);
    }

    @Test
    public void test2328() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2328");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        int int18 = charSequenceConsumerRecord10.partition();
        java.lang.Class<?> wildcardClass19 = charSequenceConsumerRecord10.getClass();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 10 + "'", int18 == 10);
        org.junit.Assert.assertNotNull(wildcardClass19);
    }

    @Test
    public void test2329() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2329");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout19 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout19.maxRetries = (byte) -1;
        int int22 = strKafkaSpout19.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor23 = null;
        strKafkaSpout19.waitingToEmit = strConsumerRecordItor23;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer25 = strKafkaSpout19.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer26 = strKafkaSpout19.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType32, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long39 = charSequenceConsumerRecord38.offset();
        long long40 = charSequenceConsumerRecord38.checksum();
        int int41 = charSequenceConsumerRecord38.serializedKeySize();
        org.apache.kafka.common.header.Headers headers42 = charSequenceConsumerRecord38.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType15, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout19, (java.lang.CharSequence) "hi!", headers42);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType53, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long60 = charSequenceConsumerRecord59.checksum();
        int int61 = charSequenceConsumerRecord59.partition();
        long long62 = charSequenceConsumerRecord59.offset();
        org.apache.kafka.common.header.Headers headers63 = charSequenceConsumerRecord59.headers();
        org.apache.kafka.common.record.TimestampType timestampType68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType68, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long75 = charSequenceConsumerRecord74.offset();
        int int76 = charSequenceConsumerRecord74.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional77 = charSequenceConsumerRecord74.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) 10, 10L, 0L, timestampType15, (java.lang.Long) 35L, (int) (byte) 0, (-1), (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers63, intOptional77);
        java.util.Optional<java.lang.Integer> intOptional79 = charSequenceConsumerRecord78.leaderEpoch();
        java.lang.String str80 = charSequenceConsumerRecord78.toString();
        org.apache.kafka.common.record.TimestampType timestampType81 = charSequenceConsumerRecord78.timestampType();
        long long82 = charSequenceConsumerRecord78.checksum();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertNull(timer25);
        org.junit.Assert.assertNull(strKafkaConsumer26);
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + 0L + "'", long39 == 0L);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + 52 + "'", int41 == 52);
        org.junit.Assert.assertNotNull(headers42);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + 10 + "'", int61 == 10);
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + 0L + "'", long62 == 0L);
        org.junit.Assert.assertNotNull(headers63);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + 0L + "'", long75 == 0L);
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + (-1) + "'", int76 == (-1));
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertNotNull(intOptional79);
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str80, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + timestampType81 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType81.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long82 + "' != '" + 35L + "'", long82 == 35L);
    }

    @Test
    public void test2330() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2330");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        long long8 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = strKafkaSpout0.firstPollOffsetStrategy;
        java.lang.Class<?> wildcardClass10 = strKafkaSpout0.getClass();
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 0L + "'", long8 == 0L);
        org.junit.Assert.assertNull(firstPollOffsetStrategy9);
        org.junit.Assert.assertNotNull(wildcardClass10);
    }

    @Test
    public void test2331() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2331");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder2 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams3 = strKafkaSpout0.kafkaSpoutStreams;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords5 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords5);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder2);
        org.junit.Assert.assertNull(kafkaSpoutStreams3);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
    }

    @Test
    public void test2332() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2332");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = 35, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)", (int) (byte) 10, (long) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, null = 1, serialized key size = 32, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )");
        long long6 = charSequenceConsumerRecord5.timestamp();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
    }

    @Test
    public void test2333() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2333");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.Iterable<org.apache.kafka.common.header.Header>> kafkaSpoutMessageIdListKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.Iterable<org.apache.kafka.common.header.Header>> kafkaSpoutMessageIdListKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.Iterable<org.apache.kafka.common.header.Header>>(kafkaSpoutMessageIdListKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test2334() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2334");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService10;
        java.lang.Class<?> wildcardClass12 = strKafkaSpout0.getClass();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(wildcardClass12);
    }

    @Test
    public void test2335() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2335");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType13 = charSequenceConsumerRecord10.timestampType();
        int int14 = charSequenceConsumerRecord10.partition();
        int int15 = charSequenceConsumerRecord10.serializedValueSize();
        long long16 = charSequenceConsumerRecord10.checksum();
        java.lang.String str17 = charSequenceConsumerRecord10.value();
        int int18 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNull(timestampType13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 52 + "'", int18 == 52);
    }

    @Test
    public void test2336() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2336");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long10 = charSequenceConsumerRecord9.checksum();
        long long11 = charSequenceConsumerRecord9.timestamp();
        org.apache.kafka.common.header.Headers headers12 = charSequenceConsumerRecord9.headers();
        org.apache.kafka.common.record.TimestampType timestampType13 = charSequenceConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.CharSequence charSequence33 = charSequenceConsumerRecord32.key();
        long long34 = charSequenceConsumerRecord32.timestamp();
        java.lang.Class<?> wildcardClass35 = charSequenceConsumerRecord32.getClass();
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType40, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long47 = charSequenceConsumerRecord46.checksum();
        int int48 = charSequenceConsumerRecord46.partition();
        long long49 = charSequenceConsumerRecord46.timestamp();
        java.lang.String str50 = charSequenceConsumerRecord46.toString();
        org.apache.kafka.common.header.Headers headers51 = charSequenceConsumerRecord46.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, org.apache.kafka.common.header.Headers> genericDeclarationConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, org.apache.kafka.common.header.Headers>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)", 100, 100L, (long) 10, timestampType23, (long) 52, 97, (-1), (java.lang.reflect.GenericDeclaration) wildcardClass35, headers51);
        org.apache.kafka.common.record.TimestampType timestampType57 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType57, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int64 = charSequenceConsumerRecord63.serializedValueSize();
        java.lang.CharSequence charSequence65 = charSequenceConsumerRecord63.key();
        org.apache.kafka.common.header.Headers headers66 = charSequenceConsumerRecord63.headers();
        int int67 = charSequenceConsumerRecord63.partition();
        int int68 = charSequenceConsumerRecord63.partition();
        java.lang.String str69 = charSequenceConsumerRecord63.toString();
        java.util.Optional<java.lang.Integer> intOptional70 = charSequenceConsumerRecord63.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) 0, (long) (short) 0, (long) (-1), timestampType13, (java.lang.Long) 100L, (int) '#', (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", headers51, intOptional70);
        java.lang.Class<?> wildcardClass72 = headers51.getClass();
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertTrue("'" + timestampType13 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType13.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + charSequence33 + "' != '" + "" + "'", charSequence33, "");
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass35);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + (-1L) + "'", long47 == (-1L));
        org.junit.Assert.assertTrue("'" + int48 + "' != '" + 10 + "'", int48 == 10);
        org.junit.Assert.assertTrue("'" + long49 + "' != '" + (-1L) + "'", long49 == (-1L));
        org.junit.Assert.assertEquals("'" + str50 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str50, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers51);
        org.junit.Assert.assertTrue("'" + int64 + "' != '" + (-1) + "'", int64 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence65 + "' != '" + "" + "'", charSequence65, "");
        org.junit.Assert.assertNotNull(headers66);
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + 10 + "'", int67 == 10);
        org.junit.Assert.assertTrue("'" + int68 + "' != '" + 10 + "'", int68 == 10);
        org.junit.Assert.assertEquals("'" + str69 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str69, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(intOptional70);
        org.junit.Assert.assertNotNull(wildcardClass72);
    }

    @Test
    public void test2337() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2337");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str30 = charSequenceConsumerRecord29.topic();
        org.apache.kafka.common.record.TimestampType timestampType31 = charSequenceConsumerRecord29.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout35.maxRetries = (byte) -1;
        int int38 = strKafkaSpout35.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor39 = null;
        strKafkaSpout35.waitingToEmit = strConsumerRecordItor39;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer41 = strKafkaSpout35.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer42 = strKafkaSpout35.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType48 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType48, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long55 = charSequenceConsumerRecord54.offset();
        long long56 = charSequenceConsumerRecord54.checksum();
        int int57 = charSequenceConsumerRecord54.serializedKeySize();
        org.apache.kafka.common.header.Headers headers58 = charSequenceConsumerRecord54.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType31, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout35, (java.lang.CharSequence) "hi!", headers58);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 1, 0L, (long) (byte) 0, timestampType31, (long) ' ', (int) (short) -1, (int) (byte) 10, (java.lang.CharSequence) "", "");
        org.apache.kafka.common.record.TimestampType timestampType75 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType75, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int82 = charSequenceConsumerRecord81.serializedValueSize();
        java.lang.CharSequence charSequence83 = charSequenceConsumerRecord81.key();
        org.apache.kafka.common.header.Headers headers84 = charSequenceConsumerRecord81.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", 0, (long) 97, (long) (-1), timestampType31, (java.lang.Long) 10L, (int) (byte) 10, (int) (short) 10, (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers84);
        long long86 = charSequenceConsumerRecord85.offset();
        long long87 = charSequenceConsumerRecord85.offset();
        java.lang.String str88 = charSequenceConsumerRecord85.topic();
        org.apache.kafka.common.header.Headers headers89 = charSequenceConsumerRecord85.headers();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.ack((java.lang.Object) headers89);
            org.junit.Assert.fail("Expected exception of type java.lang.ClassCastException; message: org.apache.kafka.common.header.internals.RecordHeaders cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId");
        } catch (java.lang.ClassCastException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertEquals("'" + str30 + "' != '" + "" + "'", str30, "");
        org.junit.Assert.assertTrue("'" + timestampType31 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType31.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + (-1) + "'", int38 == (-1));
        org.junit.Assert.assertNull(timer41);
        org.junit.Assert.assertNull(strKafkaConsumer42);
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + 0L + "'", long55 == 0L);
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + (-1L) + "'", long56 == (-1L));
        org.junit.Assert.assertTrue("'" + int57 + "' != '" + 52 + "'", int57 == 52);
        org.junit.Assert.assertNotNull(headers58);
        org.junit.Assert.assertTrue("'" + int82 + "' != '" + (-1) + "'", int82 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence83 + "' != '" + "" + "'", charSequence83, "");
        org.junit.Assert.assertNotNull(headers84);
        org.junit.Assert.assertTrue("'" + long86 + "' != '" + 97L + "'", long86 == 97L);
        org.junit.Assert.assertTrue("'" + long87 + "' != '" + 97L + "'", long87 == 97L);
        org.junit.Assert.assertEquals("'" + str88 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str88, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNotNull(headers89);
    }

    @Test
    public void test2338() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2338");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        boolean boolean11 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor12 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor12;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService14 = strKafkaSpout0.retryService;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
// flaky:             org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(kafkaSpoutRetryService14);
    }

    @Test
    public void test2339() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2339");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.CharSequence charSequence6 = charSequenceConsumerRecord5.key();
        org.apache.kafka.common.header.Headers headers7 = charSequenceConsumerRecord5.headers();
        org.apache.kafka.common.record.TimestampType timestampType8 = charSequenceConsumerRecord5.timestampType();
        org.apache.kafka.common.header.Headers headers9 = charSequenceConsumerRecord5.headers();
        org.junit.Assert.assertEquals("'" + charSequence6 + "' != '" + "" + "'", charSequence6, "");
        org.junit.Assert.assertNotNull(headers7);
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers9);
    }

    @Test
    public void test2340() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2340");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer12 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector13 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy14 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer15 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer15);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertNull(strKafkaConsumer12);
        org.junit.Assert.assertNull(spoutOutputCollector13);
        org.junit.Assert.assertNull(firstPollOffsetStrategy14);
    }

    @Test
    public void test2341() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2341");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout27 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout27.maxRetries = (byte) -1;
        int int30 = strKafkaSpout27.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor31 = null;
        strKafkaSpout27.waitingToEmit = strConsumerRecordItor31;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout27.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer34 = strKafkaSpout27.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType40, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long47 = charSequenceConsumerRecord46.offset();
        long long48 = charSequenceConsumerRecord46.checksum();
        int int49 = charSequenceConsumerRecord46.serializedKeySize();
        org.apache.kafka.common.header.Headers headers50 = charSequenceConsumerRecord46.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType23, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout27, (java.lang.CharSequence) "hi!", headers50);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 1, 0L, (long) (byte) 0, timestampType23, (long) ' ', (int) (short) -1, (int) (byte) 10, (java.lang.CharSequence) "", "");
        java.lang.CharSequence charSequence58 = charSequenceConsumerRecord57.key();
        java.lang.String str59 = charSequenceConsumerRecord57.value();
        org.apache.kafka.common.record.TimestampType timestampType60 = charSequenceConsumerRecord57.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord66 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 10, (long) (short) 100, (long) (byte) 0, timestampType60, (long) ' ', (int) (short) 1, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", 10, (long) 52, (long) (short) 0, timestampType60, (long) (short) 10, (int) '4', 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        long long73 = charSequenceConsumerRecord72.timestamp();
        int int74 = charSequenceConsumerRecord72.serializedValueSize();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(strKafkaConsumer34);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 0L + "'", long47 == 0L);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 52 + "'", int49 == 52);
        org.junit.Assert.assertNotNull(headers50);
        org.junit.Assert.assertEquals("'" + charSequence58 + "' != '" + "" + "'", charSequence58, "");
        org.junit.Assert.assertEquals("'" + str59 + "' != '" + "" + "'", str59, "");
        org.junit.Assert.assertTrue("'" + timestampType60 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType60.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long73 + "' != '" + 0L + "'", long73 == 0L);
        org.junit.Assert.assertTrue("'" + int74 + "' != '" + 0 + "'", int74 == 0);
    }

    @Test
    public void test2342() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2342");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer11 = strKafkaSpout0.commitTimer;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.doSeekRetriableTopicPartitions();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(timer11);
    }

    @Test
    public void test2343() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2343");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) 100, (long) 0, (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        int int7 = charSequenceConsumerRecord5.partition();
        long long8 = charSequenceConsumerRecord5.checksum();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + (-1L) + "'", long8 == (-1L));
    }

    @Test
    public void test2344() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2344");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator3 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator3;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator5 = offsetComparator3.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator10 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator10;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator10);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = kafkaSpoutMessageIdComparator5.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator10);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = offsetComparator10.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator10.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator16 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator16;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = offsetComparator16.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator23;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = kafkaSpoutMessageIdComparator18.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = kafkaSpoutMessageIdComparator18.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = offsetComparator10.thenComparing(kafkaSpoutMessageIdComparator27);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = offsetComparator10.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = offsetComparator10.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator30);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId34 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId35 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int36 = offsetComparator0.compare(kafkaSpoutMessageId34, kafkaSpoutMessageId35);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator5);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
    }

    @Test
    public void test2345() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2345");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        strKafkaSpout0.numUncommittedOffsets = (byte) -1;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams5 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig7 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.common.TopicPartition topicPartition8 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection9 = strKafkaSpout0.toArrayList(topicPartition8);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = strKafkaSpout0.retryService;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = strKafkaSpout0.collector;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(strKafkaSpoutConfig7);
        org.junit.Assert.assertNotNull(topicPartitionCollection9);
        org.junit.Assert.assertNull(kafkaSpoutRetryService10);
        org.junit.Assert.assertNull(spoutOutputCollector11);
    }

    @Test
    public void test2346() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2346");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams4;
        boolean boolean6 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.kafka.common.TopicPartition topicPartition8 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection9 = strKafkaSpout0.toArrayList(topicPartition8);
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + 0 + "'", int3 == 0);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy7);
        org.junit.Assert.assertNotNull(topicPartitionCollection9);
    }

    @Test
    public void test2347() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2347");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        strKafkaSpout0.initialized = true;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder10 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder10;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords13 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords13);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutStreams12);
    }

    @Test
    public void test2348() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2348");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType23, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long30 = charSequenceConsumerRecord29.checksum();
        int int31 = charSequenceConsumerRecord29.partition();
        java.lang.String str32 = charSequenceConsumerRecord29.value();
        int int33 = charSequenceConsumerRecord29.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional34 = charSequenceConsumerRecord29.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet36 = strKafkaSpout35.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor37 = null;
        strKafkaSpout35.waitingToEmit = strConsumerRecordItor37;
        boolean boolean39 = strKafkaSpout35.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig40 = null;
        strKafkaSpout35.kafkaSpoutConfig = strKafkaSpoutConfig40;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy42 = strKafkaSpout35.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType15, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord29, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout35);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType53, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long60 = charSequenceConsumerRecord59.checksum();
        int int61 = charSequenceConsumerRecord59.partition();
        java.lang.String str62 = charSequenceConsumerRecord59.value();
        int int63 = charSequenceConsumerRecord59.serializedKeySize();
        org.apache.kafka.common.header.Headers headers64 = charSequenceConsumerRecord59.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str71 = charSequenceConsumerRecord70.topic();
        java.util.Optional<java.lang.Integer> intOptional72 = charSequenceConsumerRecord70.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 0, (long) (short) 10, (long) (-1), timestampType15, (java.lang.Long) 35L, 10, (int) (short) 10, (java.lang.CharSequence) "", "KafkaSpout{acked=null, emitted=null}", headers64, intOptional72);
        long long74 = charSequenceConsumerRecord73.timestamp();
        int int75 = charSequenceConsumerRecord73.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional76 = charSequenceConsumerRecord73.leaderEpoch();
        java.lang.String str77 = charSequenceConsumerRecord73.value();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 10 + "'", int31 == 10);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "hi!" + "'", str32, "hi!");
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + 52 + "'", int33 == 52);
        org.junit.Assert.assertNotNull(intOptional34);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet36);
        org.junit.Assert.assertTrue("'" + boolean39 + "' != '" + false + "'", boolean39 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy42);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + 10 + "'", int61 == 10);
        org.junit.Assert.assertEquals("'" + str62 + "' != '" + "hi!" + "'", str62, "hi!");
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 52 + "'", int63 == 52);
        org.junit.Assert.assertNotNull(headers64);
        org.junit.Assert.assertEquals("'" + str71 + "' != '" + "" + "'", str71, "");
        org.junit.Assert.assertNotNull(intOptional72);
        org.junit.Assert.assertTrue("'" + long74 + "' != '" + (-1L) + "'", long74 == (-1L));
        org.junit.Assert.assertTrue("'" + int75 + "' != '" + 10 + "'", int75 == 10);
        org.junit.Assert.assertNotNull(intOptional76);
        org.junit.Assert.assertEquals("'" + str77 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str77, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test2349() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2349");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", (int) (short) 0, (long) 32, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, null = 1, serialized key size = 32, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})");
    }

    @Test
    public void test2350() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2350");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams6 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.initialized = true;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService9;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams11 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams11;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams6);
    }

    @Test
    public void test2351() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2351");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        int int8 = strKafkaSpout0.maxRetries;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean9 = strKafkaSpout0.poll();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
    }

    @Test
    public void test2352() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2352");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        long long7 = charSequenceConsumerRecord5.timestamp();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        java.lang.String str9 = charSequenceConsumerRecord5.toString();
        org.apache.kafka.common.header.Headers headers10 = charSequenceConsumerRecord5.headers();
        java.lang.String str11 = charSequenceConsumerRecord5.topic();
        java.lang.String str12 = charSequenceConsumerRecord5.toString();
        java.lang.String str13 = charSequenceConsumerRecord5.value();
        int int14 = charSequenceConsumerRecord5.partition();
        long long15 = charSequenceConsumerRecord5.timestamp();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str9, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str12, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 100 + "'", int14 == 100);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
    }

    @Test
    public void test2353() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2353");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer10 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy11 = strKafkaSpout0.firstPollOffsetStrategy;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean12 = strKafkaSpout0.commit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(spoutOutputCollector9);
        org.junit.Assert.assertNull(timer10);
        org.junit.Assert.assertNull(firstPollOffsetStrategy11);
    }

    @Test
    public void test2354() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2354");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer10 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy11 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = strKafkaSpout0.kafkaSpoutStreams;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str13 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(spoutOutputCollector9);
        org.junit.Assert.assertNull(timer10);
        org.junit.Assert.assertNull(firstPollOffsetStrategy11);
        org.junit.Assert.assertNull(kafkaSpoutStreams12);
    }

    @Test
    public void test2355() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2355");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService8;
        long long10 = strKafkaSpout0.numUncommittedOffsets;
        boolean boolean11 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer12 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder13;
        java.lang.String str15 = strKafkaSpout0.toString();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 0L + "'", long10 == 0L);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(timer12);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test2356() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2356");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.io.Serializable, java.io.Serializable> serializableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.io.Serializable> serializableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, java.io.Serializable>(serializableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test2357() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2357");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = strKafkaSpout0.kafkaConsumer;
        int int12 = strKafkaSpout0.maxRetries;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector13 = null;
        strKafkaSpout0.collector = spoutOutputCollector13;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
    }

    @Test
    public void test2358() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2358");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        boolean boolean7 = strKafkaSpout0.initialized;
        strKafkaSpout0.consumerAutoCommitMode = true;
        boolean boolean10 = strKafkaSpout0.commit();
        strKafkaSpout0.maxRetries = '4';
        strKafkaSpout0.numUncommittedOffsets = (short) 0;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords15 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords15);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
    }

    @Test
    public void test2359() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2359");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams7;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = strKafkaSpout0.retryService;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.emit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(kafkaSpoutRetryService9);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
    }

    @Test
    public void test2360() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2360");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer10 = strKafkaSpout0.commitTimer;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(spoutOutputCollector9);
        org.junit.Assert.assertNull(timer10);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
    }

    @Test
    public void test2361() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2361");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str10 = charSequenceConsumerRecord9.topic();
        org.apache.kafka.common.record.TimestampType timestampType11 = charSequenceConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType19, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long26 = charSequenceConsumerRecord25.checksum();
        int int27 = charSequenceConsumerRecord25.partition();
        java.lang.String str28 = charSequenceConsumerRecord25.value();
        int int29 = charSequenceConsumerRecord25.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional30 = charSequenceConsumerRecord25.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout31 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet32 = strKafkaSpout31.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor33 = null;
        strKafkaSpout31.waitingToEmit = strConsumerRecordItor33;
        boolean boolean35 = strKafkaSpout31.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig36 = null;
        strKafkaSpout31.kafkaSpoutConfig = strKafkaSpoutConfig36;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy38 = strKafkaSpout31.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType11, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord25, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout31);
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy40 = null;
        strKafkaSpout31.firstPollOffsetStrategy = firstPollOffsetStrategy40;
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "" + "'", str10, "");
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + (-1L) + "'", long26 == (-1L));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + 10 + "'", int27 == 10);
        org.junit.Assert.assertEquals("'" + str28 + "' != '" + "hi!" + "'", str28, "hi!");
        org.junit.Assert.assertTrue("'" + int29 + "' != '" + 52 + "'", int29 == 52);
        org.junit.Assert.assertNotNull(intOptional30);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet32);
        org.junit.Assert.assertTrue("'" + boolean35 + "' != '" + false + "'", boolean35 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy38);
    }

    @Test
    public void test2362() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2362");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder2 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder2;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy4 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy4;
        boolean boolean6 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy8 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy8;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords10 = strKafkaSpout0.pollKafkaBroker();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNull(kafkaSpoutStreams7);
    }

    @Test
    public void test2363() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2363");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator1 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator1;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator3 = offsetComparator1.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator4 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator3);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator5 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator5;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator5.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator12 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator12;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = kafkaSpoutMessageIdComparator7.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator0.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = offsetComparator12.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = offsetComparator18.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator25 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator25;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator25);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = kafkaSpoutMessageIdComparator20.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator25);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = offsetComparator25.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = kafkaSpoutMessageIdComparator17.thenComparing(kafkaSpoutMessageIdComparator29);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = kafkaSpoutMessageIdComparator17.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator32 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator32;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator32.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator39 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator39;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator39);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator42 = kafkaSpoutMessageIdComparator34.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator39);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator43 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator43;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator45 = offsetComparator43.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator50 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator50;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator50);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator53 = kafkaSpoutMessageIdComparator45.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator50);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator54 = kafkaSpoutMessageIdComparator34.thenComparing(kafkaSpoutMessageIdComparator53);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator55 = kafkaSpoutMessageIdComparator53.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator56 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator56;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator58 = offsetComparator56.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator63 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator63;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator63);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator66 = kafkaSpoutMessageIdComparator58.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator63);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator67 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator67;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator69 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator70 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator70;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator72 = offsetComparator70.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator73 = offsetComparator69.thenComparing(kafkaSpoutMessageIdComparator72);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator74 = offsetComparator67.thenComparing(kafkaSpoutMessageIdComparator73);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator75 = offsetComparator63.thenComparing(kafkaSpoutMessageIdComparator74);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator76 = kafkaSpoutMessageIdComparator55.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator63);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator77 = kafkaSpoutMessageIdComparator17.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator63);
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId78 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId79 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int80 = offsetComparator63.compare(kafkaSpoutMessageId78, kafkaSpoutMessageId79);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator3);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator4);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator42);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator53);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator54);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator58);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator66);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator72);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator73);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator74);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator75);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator76);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator77);
    }

    @Test
    public void test2364() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2364");
        org.apache.kafka.common.record.TimestampType timestampType8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType8, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long15 = charSequenceConsumerRecord14.checksum();
        int int16 = charSequenceConsumerRecord14.partition();
        long long17 = charSequenceConsumerRecord14.timestamp();
        long long18 = charSequenceConsumerRecord14.offset();
        int int19 = charSequenceConsumerRecord14.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType20 = charSequenceConsumerRecord14.timestampType();
        int int21 = charSequenceConsumerRecord14.partition();
        long long22 = charSequenceConsumerRecord14.checksum();
        java.util.Optional<java.lang.Integer> intOptional23 = charSequenceConsumerRecord14.leaderEpoch();
        org.apache.kafka.common.header.Headers headers24 = charSequenceConsumerRecord14.headers();
        java.lang.String str25 = charSequenceConsumerRecord14.value();
        java.lang.String str26 = charSequenceConsumerRecord14.value();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>> strComparableConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", (int) (byte) 10, 32L, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", charSequenceConsumerRecord14);
        long long28 = charSequenceConsumerRecord14.checksum();
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 52 + "'", int19 == 52);
        org.junit.Assert.assertNull(timestampType20);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 10 + "'", int21 == 10);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
        org.junit.Assert.assertNotNull(intOptional23);
        org.junit.Assert.assertNotNull(headers24);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "hi!" + "'", str25, "hi!");
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "hi!" + "'", str26, "hi!");
        org.junit.Assert.assertTrue("'" + long28 + "' != '" + (-1L) + "'", long28 == (-1L));
    }

    @Test
    public void test2365() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2365");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        int int12 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder13;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str15 = strKafkaSpout0.getNamedTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
    }

    @Test
    public void test2366() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2366");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor6 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor6;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder9;
        boolean boolean11 = strKafkaSpout0.initialized;
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
    }

    @Test
    public void test2367() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2367");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.HashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.io.Serializable> kafkaSpoutMessageIdSetKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.HashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.io.Serializable> kafkaSpoutMessageIdSetKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.HashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.io.Serializable>(kafkaSpoutMessageIdSetKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test2368() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2368");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer9 = strKafkaSpout0.commitTimer;
        boolean boolean10 = strKafkaSpout0.waitingToEmit();
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder12 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder12;
        boolean boolean14 = strKafkaSpout0.consumerAutoCommitMode;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertNull(timer9);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNull(strKafkaConsumer11);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
    }

    @Test
    public void test2369() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2369");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        java.lang.String str13 = charSequenceConsumerRecord10.toString();
        org.apache.kafka.common.header.Headers headers14 = charSequenceConsumerRecord10.headers();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers14);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
    }

    @Test
    public void test2370() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2370");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.initialized = false;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector10 = strKafkaSpout0.collector;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService13 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService13;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(spoutOutputCollector10);
    }

    @Test
    public void test2371() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2371");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) 100, 1L, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=[]}");
        int int6 = charSequenceConsumerRecord5.serializedValueSize();
        long long7 = charSequenceConsumerRecord5.checksum();
        java.lang.String str8 = charSequenceConsumerRecord5.topic();
        long long9 = charSequenceConsumerRecord5.offset();
        int int10 = charSequenceConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 1L + "'", long9 == 1L);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
    }

    @Test
    public void test2372() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2372");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams6 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig7 = strKafkaSpout0.kafkaSpoutConfig;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet8 = strKafkaSpout0.emitted;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord9 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean10 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord9);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutStreams6);
        org.junit.Assert.assertNull(strKafkaSpoutConfig7);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet8);
    }

    @Test
    public void test2373() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2373");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector10 = strKafkaSpout0.collector;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str11 = strKafkaSpout0.getNamedTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder9);
        org.junit.Assert.assertNull(spoutOutputCollector10);
    }

    @Test
    public void test2374() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2374");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 1, 1L, (long) (byte) 10, timestampType4, (long) '#', (int) (byte) 100, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        java.lang.String str11 = charSequenceConsumerRecord10.value();
        java.lang.String str12 = charSequenceConsumerRecord10.topic();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        java.lang.String str15 = charSequenceConsumerRecord10.toString();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str12, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )" + "'", str14, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )");
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )" + "'", str15, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )");
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNull(timestampType17);
    }

    @Test
    public void test2375() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2375");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout27 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout27.maxRetries = (byte) -1;
        int int30 = strKafkaSpout27.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor31 = null;
        strKafkaSpout27.waitingToEmit = strConsumerRecordItor31;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout27.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer34 = strKafkaSpout27.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType40, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long47 = charSequenceConsumerRecord46.offset();
        long long48 = charSequenceConsumerRecord46.checksum();
        int int49 = charSequenceConsumerRecord46.serializedKeySize();
        org.apache.kafka.common.header.Headers headers50 = charSequenceConsumerRecord46.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType23, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout27, (java.lang.CharSequence) "hi!", headers50);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 1, 0L, (long) (byte) 0, timestampType23, (long) ' ', (int) (short) -1, (int) (byte) 10, (java.lang.CharSequence) "", "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) -1, (long) ' ', (long) (short) 0, timestampType23, (long) (short) 1, (int) (byte) 10, (int) '#', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        org.apache.kafka.common.record.TimestampType timestampType73 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType73, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        java.lang.String str80 = charSequenceConsumerRecord79.topic();
        org.apache.kafka.common.header.Headers headers81 = charSequenceConsumerRecord79.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 0, (long) 52, (long) (byte) -1, timestampType23, (java.lang.Long) 1L, (int) (short) 0, (-1), (java.lang.CharSequence) "hi!", "hi!", headers81);
        long long83 = charSequenceConsumerRecord82.timestamp();
        long long84 = charSequenceConsumerRecord82.checksum();
        java.util.Optional<java.lang.Integer> intOptional85 = charSequenceConsumerRecord82.leaderEpoch();
        int int86 = charSequenceConsumerRecord82.serializedValueSize();
        long long87 = charSequenceConsumerRecord82.offset();
        int int88 = charSequenceConsumerRecord82.serializedValueSize();
        java.lang.CharSequence charSequence89 = charSequenceConsumerRecord82.key();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(strKafkaConsumer34);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 0L + "'", long47 == 0L);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 52 + "'", int49 == 52);
        org.junit.Assert.assertNotNull(headers50);
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "hi!" + "'", str80, "hi!");
        org.junit.Assert.assertNotNull(headers81);
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + (-1L) + "'", long83 == (-1L));
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + 1L + "'", long84 == 1L);
        org.junit.Assert.assertNotNull(intOptional85);
        org.junit.Assert.assertTrue("'" + int86 + "' != '" + (-1) + "'", int86 == (-1));
        org.junit.Assert.assertTrue("'" + long87 + "' != '" + 52L + "'", long87 == 52L);
        org.junit.Assert.assertTrue("'" + int88 + "' != '" + (-1) + "'", int88 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence89 + "' != '" + "hi!" + "'", charSequence89, "hi!");
    }

    @Test
    public void test2376() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2376");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        int int8 = strKafkaSpout0.maxRetries;
        boolean boolean9 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout10 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout10.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor13 = strKafkaSpout10.waitingToEmit;
        boolean boolean14 = strKafkaSpout10.waitingToEmit();
        strKafkaSpout10.initialized = false;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy17 = null;
        strKafkaSpout10.firstPollOffsetStrategy = firstPollOffsetStrategy17;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.ack((java.lang.Object) firstPollOffsetStrategy17);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertTrue("'" + boolean9 + "' != '" + false + "'", boolean9 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor13);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
    }

    @Test
    public void test2377() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2377");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        java.lang.String str4 = strKafkaSpout0.toString();
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector5 = null;
        strKafkaSpout0.collector = spoutOutputCollector5;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer7 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer7);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertEquals("'" + str4 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str4, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test2378() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2378");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator3 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator4 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator4;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator6 = offsetComparator4.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator3.thenComparing(kafkaSpoutMessageIdComparator6);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator8 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator8;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = offsetComparator8.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator15 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator15;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator15);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = kafkaSpoutMessageIdComparator10.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator15);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = offsetComparator3.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator15);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator19;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = kafkaSpoutMessageIdComparator19.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator22 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator23;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator23.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator30 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator30;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator30);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator33 = kafkaSpoutMessageIdComparator25.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator30);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator22.thenComparing(kafkaSpoutMessageIdComparator33);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = kafkaSpoutMessageIdComparator19.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator22);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout36 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout36.maxRetries = (byte) -1;
        int int39 = strKafkaSpout36.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor40 = null;
        strKafkaSpout36.waitingToEmit = strConsumerRecordItor40;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig42 = null;
        strKafkaSpout36.kafkaSpoutConfig = strKafkaSpoutConfig42;
        int int44 = strKafkaSpout36.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy45 = null;
        strKafkaSpout36.firstPollOffsetStrategy = firstPollOffsetStrategy45;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig47 = strKafkaSpout36.kafkaSpoutConfig;
        int int48 = strKafkaSpout36.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder49 = null;
        strKafkaSpout36.tuplesBuilder = strKafkaSpoutTuplesBuilder49;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService51 = strKafkaSpout36.retryService;
        boolean boolean52 = strKafkaSpout36.consumerAutoCommitMode;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet53 = strKafkaSpout36.emitted;
        boolean boolean54 = strKafkaSpout36.waitingToEmit();
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector55 = strKafkaSpout36.collector;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder56 = strKafkaSpout36.tuplesBuilder;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, org.apache.storm.topology.IComponent> kafkaSpoutMessageIdComparatorConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, org.apache.storm.topology.IComponent>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) -1, (long) 100, (java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator22, (org.apache.storm.topology.IComponent) strKafkaSpout36);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator58 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator58;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator60 = offsetComparator58.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator65 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator65;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator65);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator68 = kafkaSpoutMessageIdComparator60.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator65);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator69 = offsetComparator65.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator70 = offsetComparator65.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator71 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator71;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator73 = offsetComparator71.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator78 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator78;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator78);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator81 = kafkaSpoutMessageIdComparator73.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator78);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator82 = kafkaSpoutMessageIdComparator73.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator83 = offsetComparator65.thenComparing(kafkaSpoutMessageIdComparator82);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator84 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator85 = offsetComparator84.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator86 = kafkaSpoutMessageIdComparator83.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator84);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator87 = offsetComparator22.thenComparing(kafkaSpoutMessageIdComparator86);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator6);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator33);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + (-1) + "'", int39 == (-1));
        org.junit.Assert.assertTrue("'" + int44 + "' != '" + (-1) + "'", int44 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig47);
        org.junit.Assert.assertTrue("'" + int48 + "' != '" + (-1) + "'", int48 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService51);
        org.junit.Assert.assertTrue("'" + boolean52 + "' != '" + false + "'", boolean52 == false);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet53);
        org.junit.Assert.assertTrue("'" + boolean54 + "' != '" + false + "'", boolean54 == false);
        org.junit.Assert.assertNull(spoutOutputCollector55);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder56);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator60);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator68);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator69);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator70);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator73);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator81);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator82);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator83);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator85);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator86);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator87);
    }

    @Test
    public void test2379() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2379");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.header.Headers headers21 = charSequenceConsumerRecord10.headers();
        java.lang.String str22 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertNotNull(headers21);
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
    }

    @Test
    public void test2380() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2380");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        java.lang.String str4 = strKafkaSpout0.toString();
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer7;
        java.lang.String str9 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout10 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout10.maxRetries = (byte) -1;
        int int13 = strKafkaSpout10.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor14 = null;
        strKafkaSpout10.waitingToEmit = strConsumerRecordItor14;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig16 = null;
        strKafkaSpout10.kafkaSpoutConfig = strKafkaSpoutConfig16;
        int int18 = strKafkaSpout10.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy19 = null;
        strKafkaSpout10.firstPollOffsetStrategy = firstPollOffsetStrategy19;
        boolean boolean21 = strKafkaSpout10.consumerAutoCommitMode;
        boolean boolean22 = strKafkaSpout10.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor23 = strKafkaSpout10.waitingToEmit;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector24 = null;
        strKafkaSpout10.collector = spoutOutputCollector24;
        boolean boolean26 = strKafkaSpout10.initialized;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor27 = strKafkaSpout10.waitingToEmit;
        int int28 = strKafkaSpout10.maxRetries;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.fail((java.lang.Object) int28);
            org.junit.Assert.fail("Expected exception of type java.lang.ClassCastException; message: java.lang.Integer cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId");
        } catch (java.lang.ClassCastException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertEquals("'" + str4 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str4, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str9, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + (-1) + "'", int18 == (-1));
        org.junit.Assert.assertTrue("'" + boolean21 + "' != '" + false + "'", boolean21 == false);
        org.junit.Assert.assertTrue("'" + boolean22 + "' != '" + false + "'", boolean22 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor23);
        org.junit.Assert.assertTrue("'" + boolean26 + "' != '" + false + "'", boolean26 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor27);
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + (-1) + "'", int28 == (-1));
    }

    @Test
    public void test2381() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2381");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord7 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean8 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord7);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer4);
        org.junit.Assert.assertNull(strKafkaSpoutConfig5);
        org.junit.Assert.assertNull(timer6);
    }

    @Test
    public void test2382() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2382");
        org.apache.storm.kafka.spout.KafkaSpout<java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.reflect.AnnotatedElement> kafkaSpoutMessageIdSetKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.reflect.AnnotatedElement>();
    }

    @Test
    public void test2383() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2383");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        int int12 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder13;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService15 = strKafkaSpout0.retryService;
        boolean boolean16 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector17 = strKafkaSpout0.collector;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean18 = strKafkaSpout0.poll();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService15);
        org.junit.Assert.assertTrue("'" + boolean16 + "' != '" + false + "'", boolean16 == false);
        org.junit.Assert.assertNull(spoutOutputCollector17);
    }

    @Test
    public void test2384() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2384");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = strKafkaSpout0.firstPollOffsetStrategy;
        int int8 = strKafkaSpout0.maxRetries;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str9 = strKafkaSpout0.getNamedTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 0 + "'", int8 == 0);
    }

    @Test
    public void test2385() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2385");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        java.lang.String str18 = charSequenceConsumerRecord10.topic();
        long long19 = charSequenceConsumerRecord10.offset();
        java.lang.CharSequence charSequence20 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType21 = charSequenceConsumerRecord10.timestampType();
        java.util.Optional<java.lang.Integer> intOptional22 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertEquals("'" + charSequence20 + "' != '" + "" + "'", charSequence20, "");
        org.junit.Assert.assertNull(timestampType21);
        org.junit.Assert.assertNotNull(intOptional22);
    }

    @Test
    public void test2386() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2386");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        long long20 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 0L + "'", long20 == 0L);
    }

    @Test
    public void test2387() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2387");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService8;
        long long10 = strKafkaSpout0.numUncommittedOffsets;
        boolean boolean11 = strKafkaSpout0.consumerAutoCommitMode;
        java.lang.String str12 = strKafkaSpout0.toString();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.deactivate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 0L + "'", long10 == 0L);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str12, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test2388() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2388");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str6 = charSequenceConsumerRecord5.topic();
        java.util.Optional<java.lang.Integer> intOptional7 = charSequenceConsumerRecord5.leaderEpoch();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        int int9 = charSequenceConsumerRecord5.serializedKeySize();
        int int10 = charSequenceConsumerRecord5.serializedKeySize();
        int int11 = charSequenceConsumerRecord5.serializedValueSize();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "" + "'", str6, "");
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
    }

    @Test
    public void test2389() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2389");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
    }

    @Test
    public void test2390() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2390");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence17 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence18 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType20 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str21 = charSequenceConsumerRecord10.toString();
        java.lang.CharSequence charSequence22 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertEquals("'" + charSequence17 + "' != '" + "" + "'", charSequence17, "");
        org.junit.Assert.assertEquals("'" + charSequence18 + "' != '" + "" + "'", charSequence18, "");
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertNull(timestampType20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str21, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + charSequence22 + "' != '" + "" + "'", charSequence22, "");
    }

    @Test
    public void test2391() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2391");
        org.apache.kafka.common.record.TimestampType timestampType8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType8, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord14.timestampType();
        long long16 = charSequenceConsumerRecord14.offset();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.Object> strComparableConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.Object>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) -1, 10L, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", (java.lang.Object) charSequenceConsumerRecord14);
        java.lang.CharSequence charSequence18 = charSequenceConsumerRecord14.key();
        java.lang.String str19 = charSequenceConsumerRecord14.toString();
        org.junit.Assert.assertNull(timestampType15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertEquals("'" + charSequence18 + "' != '" + "" + "'", charSequence18, "");
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test2392() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2392");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService1 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = strKafkaSpout0.kafkaConsumer;
        org.junit.Assert.assertNull(strKafkaConsumer3);
    }

    @Test
    public void test2393() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2393");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.String str16 = charSequenceConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional17 = charSequenceConsumerRecord10.leaderEpoch();
        int int18 = charSequenceConsumerRecord10.partition();
        int int19 = charSequenceConsumerRecord10.partition();
        java.lang.String str20 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(intOptional17);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 10 + "'", int18 == 10);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test2394() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2394");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        boolean boolean4 = strKafkaSpout0.waitingToEmit();
        java.lang.String str5 = strKafkaSpout0.toString();
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertEquals("'" + str5 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str5, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test2395() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2395");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long18 = charSequenceConsumerRecord17.checksum();
        long long19 = charSequenceConsumerRecord17.timestamp();
        org.apache.kafka.common.header.Headers headers20 = charSequenceConsumerRecord17.headers();
        java.lang.String str21 = charSequenceConsumerRecord17.toString();
        org.apache.kafka.common.header.Headers headers22 = charSequenceConsumerRecord17.headers();
        java.lang.String str23 = charSequenceConsumerRecord17.topic();
        long long24 = charSequenceConsumerRecord17.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType25 = charSequenceConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (byte) 1, (long) 100, timestampType25, (long) 1, 35, (int) (byte) 10, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.apache.kafka.common.record.TimestampType timestampType41 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType41, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long48 = charSequenceConsumerRecord47.checksum();
        int int49 = charSequenceConsumerRecord47.partition();
        long long50 = charSequenceConsumerRecord47.timestamp();
        long long51 = charSequenceConsumerRecord47.offset();
        java.lang.String str52 = charSequenceConsumerRecord47.toString();
        java.lang.String str53 = charSequenceConsumerRecord47.topic();
        org.apache.kafka.common.header.Headers headers54 = charSequenceConsumerRecord47.headers();
        org.apache.kafka.common.record.TimestampType timestampType59 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType59, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long66 = charSequenceConsumerRecord65.checksum();
        int int67 = charSequenceConsumerRecord65.partition();
        long long68 = charSequenceConsumerRecord65.timestamp();
        java.lang.String str69 = charSequenceConsumerRecord65.toString();
        long long70 = charSequenceConsumerRecord65.timestamp();
        long long71 = charSequenceConsumerRecord65.offset();
        long long72 = charSequenceConsumerRecord65.offset();
        org.apache.kafka.common.header.Headers headers73 = charSequenceConsumerRecord65.headers();
        int int74 = charSequenceConsumerRecord65.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional75 = charSequenceConsumerRecord65.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", 32, 52L, (long) 32, timestampType25, (java.lang.Long) 10L, (int) (byte) 1, 1, (java.lang.CharSequence) "", "", headers54, intOptional75);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str88 = charSequenceConsumerRecord87.topic();
        java.util.Optional<java.lang.Integer> intOptional89 = charSequenceConsumerRecord87.leaderEpoch();
        org.apache.kafka.common.header.Headers headers90 = charSequenceConsumerRecord87.headers();
        org.apache.kafka.common.header.Headers headers91 = charSequenceConsumerRecord87.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord92 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", 97, (long) (byte) 10, 97L, timestampType25, (java.lang.Long) 35L, 32, (int) '4', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)", headers91);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str21, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers22);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "" + "'", str23, "");
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + (-1L) + "'", long24 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType25 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType25.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 10 + "'", int49 == 10);
        org.junit.Assert.assertTrue("'" + long50 + "' != '" + (-1L) + "'", long50 == (-1L));
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + 0L + "'", long51 == 0L);
        org.junit.Assert.assertEquals("'" + str52 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str52, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "" + "'", str53, "");
        org.junit.Assert.assertNotNull(headers54);
        org.junit.Assert.assertTrue("'" + long66 + "' != '" + (-1L) + "'", long66 == (-1L));
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + 10 + "'", int67 == 10);
        org.junit.Assert.assertTrue("'" + long68 + "' != '" + (-1L) + "'", long68 == (-1L));
        org.junit.Assert.assertEquals("'" + str69 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str69, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long70 + "' != '" + (-1L) + "'", long70 == (-1L));
        org.junit.Assert.assertTrue("'" + long71 + "' != '" + 0L + "'", long71 == 0L);
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + 0L + "'", long72 == 0L);
        org.junit.Assert.assertNotNull(headers73);
        org.junit.Assert.assertTrue("'" + int74 + "' != '" + (-1) + "'", int74 == (-1));
        org.junit.Assert.assertNotNull(intOptional75);
        org.junit.Assert.assertEquals("'" + str88 + "' != '" + "" + "'", str88, "");
        org.junit.Assert.assertNotNull(intOptional89);
        org.junit.Assert.assertNotNull(headers90);
        org.junit.Assert.assertNotNull(headers91);
    }

    @Test
    public void test2396() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2396");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder16 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder16;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet18 = strKafkaSpout0.emitted;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.deactivate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdSet18);
    }

    @Test
    public void test2397() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2397");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        long long14 = charSequenceConsumerRecord10.offset();
        long long15 = charSequenceConsumerRecord10.timestamp();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
    }

    @Test
    public void test2398() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2398");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams11 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams11;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
    }

    @Test
    public void test2399() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2399");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) '4', (long) (byte) 1, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = 35, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)");
        java.lang.CharSequence charSequence6 = charSequenceConsumerRecord5.key();
        int int7 = charSequenceConsumerRecord5.partition();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        org.junit.Assert.assertEquals("'" + charSequence6 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = 35, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)" + "'", charSequence6, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = 35, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)");
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 52 + "'", int7 == 52);
        org.junit.Assert.assertNotNull(headers8);
    }

    @Test
    public void test2400() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2400");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        java.lang.String str4 = strKafkaSpout0.toString();
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector5 = null;
        strKafkaSpout0.collector = spoutOutputCollector5;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.activate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertEquals("'" + str4 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str4, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strConsumerRecordItor7);
    }

    @Test
    public void test2401() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2401");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = null;
        strKafkaSpout0.collector = spoutOutputCollector12;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService14 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService14;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService16 = strKafkaSpout0.retryService;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertNull(kafkaSpoutRetryService16);
    }

    @Test
    public void test2402() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2402");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        int int16 = charSequenceConsumerRecord10.partition();
        long long17 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
    }

    @Test
    public void test2403() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2403");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 52, (-1L), (java.lang.CharSequence) "hi!", "hi!");
        int int6 = charSequenceConsumerRecord5.serializedValueSize();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
    }

    @Test
    public void test2404() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2404");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService8;
        boolean boolean10 = strKafkaSpout0.initialized;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
    }

    @Test
    public void test2405() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2405");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.common.TopicPartition topicPartition12 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection13 = strKafkaSpout0.toArrayList(topicPartition12);
        org.apache.kafka.common.TopicPartition topicPartition14 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection15 = strKafkaSpout0.toArrayList(topicPartition14);
        java.util.Map map16 = null;
        org.apache.storm.task.TopologyContext topologyContext17 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector18 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map16, topologyContext17, spoutOutputCollector18);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertNotNull(topicPartitionCollection13);
        org.junit.Assert.assertNotNull(topicPartitionCollection15);
    }

    @Test
    public void test2406() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2406");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) ' ', (long) (byte) 100, (long) (byte) -1, timestampType4, (long) (byte) -1, (int) (byte) 10, 10, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long11 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str12 = charSequenceConsumerRecord10.toString();
        org.apache.kafka.common.record.TimestampType timestampType13 = charSequenceConsumerRecord10.timestampType();
        java.lang.CharSequence charSequence14 = charSequenceConsumerRecord10.key();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        int int16 = charSequenceConsumerRecord10.partition();
        long long17 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str12, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNull(timestampType13);
        org.junit.Assert.assertEquals("'" + charSequence14 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", charSequence14, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 32 + "'", int16 == 32);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
    }

    @Test
    public void test2407() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2407");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType17 = null;
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int34 = charSequenceConsumerRecord33.serializedValueSize();
        java.lang.CharSequence charSequence35 = charSequenceConsumerRecord33.key();
        org.apache.kafka.common.header.Headers headers36 = charSequenceConsumerRecord33.headers();
        java.util.Optional<java.lang.Integer> intOptional37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType17, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers36, intOptional37);
        org.apache.kafka.common.record.TimestampType timestampType46 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType46, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int53 = charSequenceConsumerRecord52.serializedValueSize();
        java.lang.CharSequence charSequence54 = charSequenceConsumerRecord52.key();
        org.apache.kafka.common.header.Headers headers55 = charSequenceConsumerRecord52.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray56 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList57 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean58 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57, kafkaSpoutMessageIdArray56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers55, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headersConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("", (int) '#', 1L, headers36, kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType4, (java.lang.Long) (-1L), (int) (short) 100, 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}", headers36);
        long long62 = charSequenceConsumerRecord61.checksum();
        long long63 = charSequenceConsumerRecord61.timestamp();
        long long64 = charSequenceConsumerRecord61.timestamp();
        long long65 = charSequenceConsumerRecord61.checksum();
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + (-1) + "'", int34 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence35 + "' != '" + "" + "'", charSequence35, "");
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + (-1) + "'", int53 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence54 + "' != '" + "" + "'", charSequence54, "");
        org.junit.Assert.assertNotNull(headers55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray56);
        org.junit.Assert.assertTrue("'" + boolean58 + "' != '" + false + "'", boolean58 == false);
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + (-1L) + "'", long62 == (-1L));
        org.junit.Assert.assertTrue("'" + long63 + "' != '" + 0L + "'", long63 == 0L);
        org.junit.Assert.assertTrue("'" + long64 + "' != '" + 0L + "'", long64 == 0L);
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + (-1L) + "'", long65 == (-1L));
    }

    @Test
    public void test2408() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2408");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType4, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord10.timestampType();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str15 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 35L + "'", long11 == 35L);
        org.junit.Assert.assertNull(timestampType12);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", str15, "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
    }

    @Test
    public void test2409() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2409");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=[]}", (int) (byte) 0, 52L, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
    }

    @Test
    public void test2410() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2410");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy8 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = null;
        strKafkaSpout0.collector = spoutOutputCollector9;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
// flaky:             org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertNull(firstPollOffsetStrategy8);
    }

    @Test
    public void test2411() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2411");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = strKafkaSpout0.kafkaConsumer;
        strKafkaSpout0.maxRetries = (byte) 100;
        boolean boolean7 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor11 = strKafkaSpout0.waitingToEmit;
        java.util.Map map12 = null;
        org.apache.storm.task.TopologyContext topologyContext13 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector14 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map12, topologyContext13, spoutOutputCollector14);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer4);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
        org.junit.Assert.assertNull(strConsumerRecordItor11);
    }

    @Test
    public void test2412() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2412");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder7;
        int int9 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy10 = strKafkaSpout0.firstPollOffsetStrategy;
        java.util.Map map11 = null;
        org.apache.storm.task.TopologyContext topologyContext12 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector13 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map11, topologyContext12, spoutOutputCollector13);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + 0 + "'", int9 == 0);
        org.junit.Assert.assertNull(firstPollOffsetStrategy10);
    }

    @Test
    public void test2413() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2413");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.CharSequence charSequence6 = charSequenceConsumerRecord5.key();
        java.util.Optional<java.lang.Integer> intOptional7 = charSequenceConsumerRecord5.leaderEpoch();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        int int9 = charSequenceConsumerRecord5.serializedValueSize();
        org.junit.Assert.assertEquals("'" + charSequence6 + "' != '" + "" + "'", charSequence6, "");
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
    }

    @Test
    public void test2414() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2414");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.initialized = false;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor5 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.consumerAutoCommitMode = true;
        strKafkaSpout0.maxRetries = '4';
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertNull(strConsumerRecordItor5);
    }

    @Test
    public void test2415() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2415");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder7;
        int int9 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy10 = strKafkaSpout0.firstPollOffsetStrategy;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str11 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + 0 + "'", int9 == 0);
        org.junit.Assert.assertNull(firstPollOffsetStrategy10);
    }

    @Test
    public void test2416() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2416");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.common.TopicPartition topicPartition16 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection17 = strKafkaSpout0.toArrayList(topicPartition16);
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection17);
    }

    @Test
    public void test2417() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2417");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout7 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = strKafkaSpout7.kafkaSpoutStreams;
        strKafkaSpout7.consumerAutoCommitMode = false;
        java.lang.String str11 = strKafkaSpout7.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout12 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout12.maxRetries = (byte) -1;
        int int15 = strKafkaSpout12.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray16 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet17 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean18 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet17, kafkaSpoutMessageIdArray16);
        strKafkaSpout12.emitted = kafkaSpoutMessageIdSet17;
        strKafkaSpout7.emitted = kafkaSpoutMessageIdSet17;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet17;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str22 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(kafkaSpoutStreams8);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str11, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray16);
        org.junit.Assert.assertTrue("'" + boolean18 + "' != '" + false + "'", boolean18 == false);
    }

    @Test
    public void test2418() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2418");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy3 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy4 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams6 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector7 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder8;
        org.junit.Assert.assertNull(firstPollOffsetStrategy3);
        org.junit.Assert.assertNull(firstPollOffsetStrategy4);
        org.junit.Assert.assertNull(firstPollOffsetStrategy5);
        org.junit.Assert.assertNull(kafkaSpoutStreams6);
        org.junit.Assert.assertNull(spoutOutputCollector7);
    }

    @Test
    public void test2419() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2419");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.CharSequence charSequence10 = charSequenceConsumerRecord9.key();
        org.apache.kafka.common.header.Headers headers11 = charSequenceConsumerRecord9.headers();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, null = 1, serialized key size = 32, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", 35, (long) 0, (long) (short) 0, timestampType12, (long) (-1), 0, 35, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=[]}", "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        java.lang.String str19 = charSequenceConsumerRecord18.topic();
        org.junit.Assert.assertEquals("'" + charSequence10 + "' != '" + "" + "'", charSequence10, "");
        org.junit.Assert.assertNotNull(headers11);
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, null = 1, serialized key size = 32, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )" + "'", str19, "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, null = 1, serialized key size = 32, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )");
    }

    @Test
    public void test2420() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2420");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer12 = strKafkaSpout0.kafkaConsumer;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord13 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean14 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord13);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertNull(strKafkaConsumer12);
    }

    @Test
    public void test2421() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2421");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        java.util.Optional<java.lang.Integer> intOptional17 = charSequenceConsumerRecord10.leaderEpoch();
        int int18 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertNotNull(intOptional17);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 10 + "'", int18 == 10);
    }

    @Test
    public void test2422() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2422");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        int int20 = charSequenceConsumerRecord10.serializedKeySize();
        int int21 = charSequenceConsumerRecord10.serializedValueSize();
        int int22 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.header.Headers headers23 = charSequenceConsumerRecord10.headers();
        long long24 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 52 + "'", int20 == 52);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 52 + "'", int22 == 52);
        org.junit.Assert.assertNotNull(headers23);
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 0L + "'", long24 == 0L);
    }

    @Test
    public void test2423() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2423");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        java.lang.String str16 = charSequenceConsumerRecord10.toString();
        long long17 = charSequenceConsumerRecord10.checksum();
        java.lang.String str18 = charSequenceConsumerRecord10.topic();
        java.lang.Class<?> wildcardClass19 = charSequenceConsumerRecord10.getClass();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertNotNull(wildcardClass19);
    }

    @Test
    public void test2424() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2424");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        strKafkaSpout0.initialized = true;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService8;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = strKafkaSpout0.retryService;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService10);
    }

    @Test
    public void test2425() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2425");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator10 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator12 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator12;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = offsetComparator12.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator19 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator19;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator19);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = kafkaSpoutMessageIdComparator14.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator19);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = offsetComparator11.thenComparing(kafkaSpoutMessageIdComparator22);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator22.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator10.thenComparing(kafkaSpoutMessageIdComparator22);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = kafkaSpoutMessageIdComparator22.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = kafkaSpoutMessageIdComparator22.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator28 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator29 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator29;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = offsetComparator29.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = offsetComparator28.thenComparing(kafkaSpoutMessageIdComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator33 = kafkaSpoutMessageIdComparator22.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator28);
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.fail((java.lang.Object) offsetComparator28);
            org.junit.Assert.fail("Expected exception of type java.lang.ClassCastException; message: org.apache.storm.kafka.spout.KafkaSpout$OffsetComparator cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId");
        } catch (java.lang.ClassCastException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator33);
    }

    @Test
    public void test2426() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2426");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        boolean boolean5 = strKafkaSpout0.waitingToEmit();
        long long6 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder7;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        org.apache.kafka.common.record.TimestampType timestampType15 = null;
        org.apache.kafka.common.record.TimestampType timestampType25 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType25, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long32 = charSequenceConsumerRecord31.checksum();
        int int33 = charSequenceConsumerRecord31.partition();
        long long34 = charSequenceConsumerRecord31.offset();
        org.apache.kafka.common.header.Headers headers35 = charSequenceConsumerRecord31.headers();
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType40, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long47 = charSequenceConsumerRecord46.checksum();
        int int48 = charSequenceConsumerRecord46.partition();
        long long49 = charSequenceConsumerRecord46.timestamp();
        long long50 = charSequenceConsumerRecord46.offset();
        int int51 = charSequenceConsumerRecord46.partition();
        java.lang.CharSequence charSequence52 = charSequenceConsumerRecord46.key();
        org.apache.kafka.common.record.TimestampType timestampType53 = charSequenceConsumerRecord46.timestampType();
        java.util.Optional<java.lang.Integer> intOptional54 = charSequenceConsumerRecord46.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.Comparable<java.lang.String>> strComparableConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 1, (long) 'a', (long) (-1), timestampType15, (java.lang.Long) (-1L), 0, (int) '#', (java.lang.Comparable<java.lang.String>) "hi!", (java.lang.Comparable<java.lang.String>) "", headers35, intOptional54);
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.ack((java.lang.Object) intOptional54);
            org.junit.Assert.fail("Expected exception of type java.lang.ClassCastException; message: java.util.Optional cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId");
        } catch (java.lang.ClassCastException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + 0L + "'", long6 == 0L);
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertTrue("'" + long32 + "' != '" + (-1L) + "'", long32 == (-1L));
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + 10 + "'", int33 == 10);
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + 0L + "'", long34 == 0L);
        org.junit.Assert.assertNotNull(headers35);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + (-1L) + "'", long47 == (-1L));
        org.junit.Assert.assertTrue("'" + int48 + "' != '" + 10 + "'", int48 == 10);
        org.junit.Assert.assertTrue("'" + long49 + "' != '" + (-1L) + "'", long49 == (-1L));
        org.junit.Assert.assertTrue("'" + long50 + "' != '" + 0L + "'", long50 == 0L);
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 10 + "'", int51 == 10);
        org.junit.Assert.assertEquals("'" + charSequence52 + "' != '" + "" + "'", charSequence52, "");
        org.junit.Assert.assertNull(timestampType53);
        org.junit.Assert.assertNotNull(intOptional54);
    }

    @Test
    public void test2427() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2427");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = null;
        strKafkaSpout0.collector = spoutOutputCollector12;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer14 = strKafkaSpout0.commitTimer;
        boolean boolean15 = strKafkaSpout0.initialized;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertNull(timer14);
        org.junit.Assert.assertTrue("'" + boolean15 + "' != '" + false + "'", boolean15 == false);
    }

    @Test
    public void test2428() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2428");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig5;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector7 = strKafkaSpout0.collector;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout16 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams17 = strKafkaSpout16.kafkaSpoutStreams;
        strKafkaSpout16.consumerAutoCommitMode = false;
        java.lang.String str20 = strKafkaSpout16.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout21 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout21.maxRetries = (byte) -1;
        int int24 = strKafkaSpout21.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray25 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet26 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean27 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet26, kafkaSpoutMessageIdArray25);
        strKafkaSpout21.emitted = kafkaSpoutMessageIdSet26;
        strKafkaSpout16.emitted = kafkaSpoutMessageIdSet26;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout30 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout30.maxRetries = (byte) -1;
        int int33 = strKafkaSpout30.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor34 = null;
        strKafkaSpout30.waitingToEmit = strConsumerRecordItor34;
        org.apache.kafka.common.TopicPartition topicPartition36 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection37 = strKafkaSpout30.toArrayList(topicPartition36);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer38 = strKafkaSpout30.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector39 = strKafkaSpout30.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout40 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout40.maxRetries = (byte) -1;
        int int43 = strKafkaSpout40.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray44 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet45 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean46 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet45, kafkaSpoutMessageIdArray44);
        strKafkaSpout40.emitted = kafkaSpoutMessageIdSet45;
        strKafkaSpout30.emitted = kafkaSpoutMessageIdSet45;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType12, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet26, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet45);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet45;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy51 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy51;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord53 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean54 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord53);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertNull(spoutOutputCollector7);
        org.junit.Assert.assertNull(kafkaSpoutStreams17);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str20, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray25);
        org.junit.Assert.assertTrue("'" + boolean27 + "' != '" + false + "'", boolean27 == false);
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + (-1) + "'", int33 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection37);
        org.junit.Assert.assertNull(timer38);
        org.junit.Assert.assertNull(spoutOutputCollector39);
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + (-1) + "'", int43 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray44);
        org.junit.Assert.assertTrue("'" + boolean46 + "' != '" + false + "'", boolean46 == false);
    }

    @Test
    public void test2429() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2429");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = strKafkaSpout0.tuplesBuilder;
        boolean boolean10 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout11 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout11.maxRetries = (byte) -1;
        int int14 = strKafkaSpout11.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor15 = null;
        strKafkaSpout11.waitingToEmit = strConsumerRecordItor15;
        org.apache.kafka.common.TopicPartition topicPartition17 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection18 = strKafkaSpout11.toArrayList(topicPartition17);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer19 = strKafkaSpout11.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService20 = strKafkaSpout11.retryService;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.ack((java.lang.Object) kafkaSpoutRetryService20);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder9);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection18);
        org.junit.Assert.assertNull(strKafkaConsumer19);
        org.junit.Assert.assertNull(kafkaSpoutRetryService20);
    }

    @Test
    public void test2430() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2430");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition8 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection9 = strKafkaSpout0.toArrayList(topicPartition8);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer10;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer12 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer12;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig14 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig14;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy16 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord17 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean18 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord17);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection9);
        org.junit.Assert.assertNull(firstPollOffsetStrategy16);
    }

    @Test
    public void test2431() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2431");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams7;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig10 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig10;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
// flaky:             org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(kafkaSpoutRetryService9);
    }

    @Test
    public void test2432() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2432");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer16;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector18 = null;
        strKafkaSpout0.collector = spoutOutputCollector18;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor20 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor20;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService22 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService22;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor24 = strKafkaSpout0.waitingToEmit;
        org.apache.kafka.common.TopicPartition topicPartition25 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection26 = strKafkaSpout0.toArrayList(topicPartition25);
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor27 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer28 = strKafkaSpout0.commitTimer;
        long long29 = strKafkaSpout0.numUncommittedOffsets;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor24);
        org.junit.Assert.assertNotNull(topicPartitionCollection26);
        org.junit.Assert.assertNull(strConsumerRecordItor27);
        org.junit.Assert.assertNull(timer28);
        org.junit.Assert.assertTrue("'" + long29 + "' != '" + 0L + "'", long29 == 0L);
    }

    @Test
    public void test2433() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2433");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType4, (long) (short) -1, (int) (byte) 1, (int) (short) -1, (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str11 = charSequenceConsumerRecord10.topic();
        java.util.Optional<java.lang.Integer> intOptional12 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType13 = charSequenceConsumerRecord10.timestampType();
        int int14 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "hi!" + "'", str11, "hi!");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNull(timestampType13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
    }

    @Test
    public void test2434() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2434");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str10 = charSequenceConsumerRecord9.topic();
        org.apache.kafka.common.record.TimestampType timestampType11 = charSequenceConsumerRecord9.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout15 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout15.maxRetries = (byte) -1;
        int int18 = strKafkaSpout15.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor19 = null;
        strKafkaSpout15.waitingToEmit = strConsumerRecordItor19;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer21 = strKafkaSpout15.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer22 = strKafkaSpout15.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType28 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType28, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long35 = charSequenceConsumerRecord34.offset();
        long long36 = charSequenceConsumerRecord34.checksum();
        int int37 = charSequenceConsumerRecord34.serializedKeySize();
        org.apache.kafka.common.header.Headers headers38 = charSequenceConsumerRecord34.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType11, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout15, (java.lang.CharSequence) "hi!", headers38);
        strKafkaSpout15.initialized = false;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout15.doSeekRetriableTopicPartitions();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "" + "'", str10, "");
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + (-1) + "'", int18 == (-1));
        org.junit.Assert.assertNull(timer21);
        org.junit.Assert.assertNull(strKafkaConsumer22);
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + 0L + "'", long35 == 0L);
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + (-1L) + "'", long36 == (-1L));
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + 52 + "'", int37 == 52);
        org.junit.Assert.assertNotNull(headers38);
    }

    @Test
    public void test2435() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2435");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams7;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = strKafkaSpout0.retryService;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        strKafkaSpout0.maxRetries = (-1);
        long long13 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector14 = strKafkaSpout0.collector;
        java.util.Map map15 = null;
        org.apache.storm.task.TopologyContext topologyContext16 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector17 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map15, topologyContext16, spoutOutputCollector17);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(kafkaSpoutRetryService9);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 35L + "'", long13 == 35L);
        org.junit.Assert.assertNull(spoutOutputCollector14);
    }

    @Test
    public void test2436() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2436");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
    }

    @Test
    public void test2437() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2437");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy4 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy4;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord6 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean7 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord6);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
    }

    @Test
    public void test2438() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2438");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (byte) 0, (long) (byte) -1, (long) (short) 100, timestampType4, (long) (short) 1, (int) (byte) 1, (int) (short) 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        long long11 = charSequenceConsumerRecord10.offset();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord10.timestampType();
        int int13 = charSequenceConsumerRecord10.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional14 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.Class<?> wildcardClass15 = intOptional14.getClass();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNull(timestampType12);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 1 + "'", int13 == 1);
        org.junit.Assert.assertNotNull(intOptional14);
        org.junit.Assert.assertNotNull(wildcardClass15);
    }

    @Test
    public void test2439() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2439");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) '#', 0L, timestampType4, (long) 0, (int) (byte) -1, (int) (short) 10, (java.lang.CharSequence) "", "hi!");
        java.util.Optional<java.lang.Integer> intOptional11 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertNotNull(intOptional11);
    }

    @Test
    public void test2440() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2440");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.timestamp();
        long long16 = charSequenceConsumerRecord10.offset();
        long long17 = charSequenceConsumerRecord10.offset();
        int int18 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        int int20 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.Class<?> wildcardClass21 = charSequenceConsumerRecord10.getClass();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 52 + "'", int18 == 52);
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 52 + "'", int20 == 52);
        org.junit.Assert.assertNotNull(wildcardClass21);
    }

    @Test
    public void test2441() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2441");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional15 = charSequenceConsumerRecord10.leaderEpoch();
        long long16 = charSequenceConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional17 = charSequenceConsumerRecord10.leaderEpoch();
        int int18 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.Class<?> wildcardClass20 = intOptional19.getClass();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 52 + "'", int14 == 52);
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertNotNull(intOptional17);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + (-1) + "'", int18 == (-1));
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertNotNull(wildcardClass20);
    }

    @Test
    public void test2442() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2442");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.header.Headers headers18 = charSequenceConsumerRecord10.headers();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType20 = charSequenceConsumerRecord10.timestampType();
        long long21 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNotNull(headers18);
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertNull(timestampType20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
    }

    @Test
    public void test2443() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2443");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = strKafkaSpout0.kafkaConsumer;
        java.lang.String str8 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService9;
        boolean boolean11 = strKafkaSpout0.initialized;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor12 = strKafkaSpout0.waitingToEmit;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertNull(strKafkaConsumer7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor12);
    }

    @Test
    public void test2444() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2444");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig8 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer9 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig10 = strKafkaSpout0.kafkaSpoutConfig;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(strKafkaSpoutConfig8);
        org.junit.Assert.assertNull(strKafkaConsumer9);
        org.junit.Assert.assertNull(strKafkaSpoutConfig10);
    }

    @Test
    public void test2445() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2445");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        int int8 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor9 = strKafkaSpout0.waitingToEmit;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet10 = strKafkaSpout0.emitted;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = strKafkaSpout0.collector;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords12 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords12);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strConsumerRecordItor9);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet10);
        org.junit.Assert.assertNull(spoutOutputCollector11);
    }

    @Test
    public void test2446() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2446");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor6 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor6;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams9 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams9;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService11 = strKafkaSpout0.retryService;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str12 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
        org.junit.Assert.assertNull(kafkaSpoutRetryService11);
    }

    @Test
    public void test2447() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2447");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        java.lang.String str8 = strKafkaSpout0.toString();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor9 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams12;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy14 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.kafka.common.record.TimestampType timestampType19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType19, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long26 = charSequenceConsumerRecord25.checksum();
        int int27 = charSequenceConsumerRecord25.partition();
        long long28 = charSequenceConsumerRecord25.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType29 = charSequenceConsumerRecord25.timestampType();
        int int30 = charSequenceConsumerRecord25.serializedKeySize();
        org.apache.kafka.common.header.Headers headers31 = charSequenceConsumerRecord25.headers();
        java.lang.CharSequence charSequence32 = charSequenceConsumerRecord25.key();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.fail((java.lang.Object) charSequenceConsumerRecord25);
            org.junit.Assert.fail("Expected exception of type java.lang.ClassCastException; message: org.apache.kafka.clients.consumer.ConsumerRecord cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId");
        } catch (java.lang.ClassCastException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strConsumerRecordItor9);
        org.junit.Assert.assertNull(firstPollOffsetStrategy14);
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + (-1L) + "'", long26 == (-1L));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + 10 + "'", int27 == 10);
        org.junit.Assert.assertTrue("'" + long28 + "' != '" + (-1L) + "'", long28 == (-1L));
        org.junit.Assert.assertNull(timestampType29);
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + 52 + "'", int30 == 52);
        org.junit.Assert.assertNotNull(headers31);
        org.junit.Assert.assertEquals("'" + charSequence32 + "' != '" + "" + "'", charSequence32, "");
    }

    @Test
    public void test2448() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2448");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator4 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator4;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord6 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator4);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator4.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator8 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator9 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator9;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = offsetComparator9.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator8.thenComparing(kafkaSpoutMessageIdComparator11);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator13.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator13.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = kafkaSpoutMessageIdComparator11.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator13);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator17;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = offsetComparator4.thenComparing(kafkaSpoutMessageIdComparator17);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator17;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = kafkaSpoutMessageIdComparator17.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = kafkaSpoutMessageIdComparator21.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
    }

    @Test
    public void test2449() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2449");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = strKafkaSpout0.tuplesBuilder;
        java.lang.String str8 = strKafkaSpout0.toString();
        strKafkaSpout0.maxRetries = ' ';
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.emit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
    }

    @Test
    public void test2450() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2450");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet4 = strKafkaSpout0.emitted;
        org.apache.kafka.common.TopicPartition topicPartition5 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection6 = strKafkaSpout0.toArrayList(topicPartition5);
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str7 = strKafkaSpout0.getNamedTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + 0 + "'", int3 == 0);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet4);
        org.junit.Assert.assertNotNull(topicPartitionCollection6);
    }

    @Test
    public void test2451() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2451");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = kafkaSpoutMessageIdComparator13.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator18);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator22 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator22;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = offsetComparator22.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator29 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator29;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator29);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = kafkaSpoutMessageIdComparator24.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator29);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator33 = kafkaSpoutMessageIdComparator13.thenComparing(kafkaSpoutMessageIdComparator32);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator7.thenComparing(kafkaSpoutMessageIdComparator33);
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId35 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId36 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int37 = offsetComparator7.compare(kafkaSpoutMessageId35, kafkaSpoutMessageId36);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator33);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
    }

    @Test
    public void test2452() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2452");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer6 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer6;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector8 = strKafkaSpout0.collector;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.activate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(spoutOutputCollector8);
    }

    @Test
    public void test2453() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2453");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        long long16 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
    }

    @Test
    public void test2454() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2454");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        long long8 = strKafkaSpout0.numUncommittedOffsets;
        strKafkaSpout0.numUncommittedOffsets = (-1L);
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams11 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.common.TopicPartition topicPartition12 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection13 = strKafkaSpout0.toArrayList(topicPartition12);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService14 = strKafkaSpout0.retryService;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 0L + "'", long8 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutStreams11);
        org.junit.Assert.assertNotNull(topicPartitionCollection13);
        org.junit.Assert.assertNull(kafkaSpoutRetryService14);
    }

    @Test
    public void test2455() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2455");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer1 = strKafkaSpout0.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer2 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer2;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean4 = strKafkaSpout0.poll();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(timer1);
    }

    @Test
    public void test2456() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2456");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 35, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)))", 32, (long) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "KafkaSpout{acked=null, emitted=[]}");
    }

    @Test
    public void test2457() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2457");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = strKafkaSpout0.kafkaConsumer;
        strKafkaSpout0.maxRetries = (byte) 100;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor7;
        long long9 = strKafkaSpout0.numUncommittedOffsets;
        int int10 = strKafkaSpout0.maxRetries;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer11 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer11);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer4);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 0L + "'", long9 == 0L);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 100 + "'", int10 == 100);
    }

    @Test
    public void test2458() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2458");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray6 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet7 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean8 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet7, kafkaSpoutMessageIdArray6);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet7;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer10 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService11 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService11;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = strKafkaSpout0.tuplesBuilder;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer14 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer14;
        java.lang.Class<?> wildcardClass16 = strKafkaSpout0.getClass();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray6);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
        org.junit.Assert.assertNull(timer10);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder13);
        org.junit.Assert.assertNotNull(wildcardClass16);
    }

    @Test
    public void test2459() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2459");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord10.timestampType();
        long long16 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertNull(timestampType15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
    }

    @Test
    public void test2460() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2460");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer8 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer8;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams10;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords12 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords12);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
    }

    @Test
    public void test2461() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2461");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder2 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams3 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        org.apache.kafka.common.TopicPartition topicPartition8 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setAcked(topicPartition8, (long) 52);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder2);
        org.junit.Assert.assertNull(kafkaSpoutStreams3);
    }

    @Test
    public void test2462() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2462");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator5 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator5;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator5.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator12 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator12;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = kafkaSpoutMessageIdComparator7.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator12);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator16 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator16;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = offsetComparator16.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator23;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = kafkaSpoutMessageIdComparator18.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = kafkaSpoutMessageIdComparator7.thenComparing(kafkaSpoutMessageIdComparator26);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = kafkaSpoutMessageIdComparator27.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = kafkaSpoutMessageIdComparator27.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator27);
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId31 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId32 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int33 = offsetComparator0.compare(kafkaSpoutMessageId31, kafkaSpoutMessageId32);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
    }

    @Test
    public void test2463() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2463");
        org.apache.storm.kafka.spout.KafkaSpout<java.util.RandomAccess, java.lang.reflect.GenericDeclaration> randomAccessKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.RandomAccess, java.lang.reflect.GenericDeclaration>();
    }

    @Test
    public void test2464() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2464");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        long long18 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        int int20 = charSequenceConsumerRecord10.partition();
        long long21 = charSequenceConsumerRecord10.checksum();
        int int22 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 10 + "'", int20 == 10);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 10 + "'", int22 == 10);
    }

    @Test
    public void test2465() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2465");
        org.apache.storm.kafka.spout.KafkaSpout<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.Cloneable> kafkaSpoutMessageIdSetKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.Cloneable>();
    }

    @Test
    public void test2466() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2466");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder12 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder12;
        boolean boolean14 = strKafkaSpout0.initialized;
        java.lang.String str15 = strKafkaSpout0.toString();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.deactivate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test2467() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2467");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService1 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService1;
        long long3 = strKafkaSpout0.numUncommittedOffsets;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = strKafkaSpout0.waitingToEmit;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = strKafkaSpout0.emitted;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig8 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = null;
        strKafkaSpout0.collector = spoutOutputCollector9;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.activate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long3 + "' != '" + 0L + "'", long3 == 0L);
        org.junit.Assert.assertNull(strConsumerRecordItor4);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet5);
        org.junit.Assert.assertNull(strKafkaSpoutConfig8);
    }

    @Test
    public void test2468() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2468");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.numUncommittedOffsets = (byte) 1;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
    }

    @Test
    public void test2469() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2469");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.common.TopicPartition topicPartition12 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection13 = strKafkaSpout0.toArrayList(topicPartition12);
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor14 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor14;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder16 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder16;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str18 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertNotNull(topicPartitionCollection13);
    }

    @Test
    public void test2470() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2470");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) 'a', (long) (byte) 1, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
    }

    @Test
    public void test2471() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2471");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout19 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout19.maxRetries = (byte) -1;
        int int22 = strKafkaSpout19.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor23 = null;
        strKafkaSpout19.waitingToEmit = strConsumerRecordItor23;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer25 = strKafkaSpout19.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer26 = strKafkaSpout19.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType32, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long39 = charSequenceConsumerRecord38.offset();
        long long40 = charSequenceConsumerRecord38.checksum();
        int int41 = charSequenceConsumerRecord38.serializedKeySize();
        org.apache.kafka.common.header.Headers headers42 = charSequenceConsumerRecord38.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType15, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout19, (java.lang.CharSequence) "hi!", headers42);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 1, 0L, (long) (byte) 0, timestampType15, (long) ' ', (int) (short) -1, (int) (byte) 10, (java.lang.CharSequence) "", "");
        java.lang.CharSequence charSequence50 = charSequenceConsumerRecord49.key();
        org.apache.kafka.common.record.TimestampType timestampType51 = charSequenceConsumerRecord49.timestampType();
        int int52 = charSequenceConsumerRecord49.partition();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertNull(timer25);
        org.junit.Assert.assertNull(strKafkaConsumer26);
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + 0L + "'", long39 == 0L);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + 52 + "'", int41 == 52);
        org.junit.Assert.assertNotNull(headers42);
        org.junit.Assert.assertEquals("'" + charSequence50 + "' != '" + "" + "'", charSequence50, "");
        org.junit.Assert.assertTrue("'" + timestampType51 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType51.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int52 + "' != '" + 1 + "'", int52 == 1);
    }

    @Test
    public void test2472() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2472");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.numUncommittedOffsets = (byte) 1;
        strKafkaSpout0.initialized = false;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet14 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService15 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService15;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy17 = strKafkaSpout0.firstPollOffsetStrategy;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet14);
        org.junit.Assert.assertNull(firstPollOffsetStrategy17);
    }

    @Test
    public void test2473() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2473");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy6 = strKafkaSpout0.firstPollOffsetStrategy;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean7 = strKafkaSpout0.poll();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(firstPollOffsetStrategy6);
    }

    @Test
    public void test2474() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2474");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig8 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService9;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertNull(strKafkaConsumer7);
        org.junit.Assert.assertNull(strKafkaSpoutConfig8);
    }

    @Test
    public void test2475() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2475");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str18 = charSequenceConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = charSequenceConsumerRecord17.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout23 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout23.maxRetries = (byte) -1;
        int int26 = strKafkaSpout23.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor27 = null;
        strKafkaSpout23.waitingToEmit = strConsumerRecordItor27;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer29 = strKafkaSpout23.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer30 = strKafkaSpout23.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType36 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType36, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long43 = charSequenceConsumerRecord42.offset();
        long long44 = charSequenceConsumerRecord42.checksum();
        int int45 = charSequenceConsumerRecord42.serializedKeySize();
        org.apache.kafka.common.header.Headers headers46 = charSequenceConsumerRecord42.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType19, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout23, (java.lang.CharSequence) "hi!", headers46);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 1, 0L, (long) (byte) 0, timestampType19, (long) ' ', (int) (short) -1, (int) (byte) 10, (java.lang.CharSequence) "", "");
        org.apache.kafka.common.record.TimestampType timestampType63 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType63, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int70 = charSequenceConsumerRecord69.serializedValueSize();
        java.lang.CharSequence charSequence71 = charSequenceConsumerRecord69.key();
        org.apache.kafka.common.header.Headers headers72 = charSequenceConsumerRecord69.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", 0, (long) 97, (long) (-1), timestampType19, (java.lang.Long) 10L, (int) (byte) 10, (int) (short) 10, (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers72);
        long long74 = charSequenceConsumerRecord73.offset();
        java.util.Optional<java.lang.Integer> intOptional75 = charSequenceConsumerRecord73.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional76 = charSequenceConsumerRecord73.leaderEpoch();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int26 + "' != '" + (-1) + "'", int26 == (-1));
        org.junit.Assert.assertNull(timer29);
        org.junit.Assert.assertNull(strKafkaConsumer30);
        org.junit.Assert.assertTrue("'" + long43 + "' != '" + 0L + "'", long43 == 0L);
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + (-1L) + "'", long44 == (-1L));
        org.junit.Assert.assertTrue("'" + int45 + "' != '" + 52 + "'", int45 == 52);
        org.junit.Assert.assertNotNull(headers46);
        org.junit.Assert.assertTrue("'" + int70 + "' != '" + (-1) + "'", int70 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence71 + "' != '" + "" + "'", charSequence71, "");
        org.junit.Assert.assertNotNull(headers72);
        org.junit.Assert.assertTrue("'" + long74 + "' != '" + 97L + "'", long74 == 97L);
        org.junit.Assert.assertNotNull(intOptional75);
        org.junit.Assert.assertNotNull(intOptional76);
    }

    @Test
    public void test2476() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2476");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor11 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer14 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer14;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.activate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertNull(strConsumerRecordItor11);
    }

    @Test
    public void test2477() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2477");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.header.Headers headers18 = charSequenceConsumerRecord10.headers();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str20 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNotNull(headers18);
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
    }

    @Test
    public void test2478() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2478");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        java.util.Optional<java.lang.Integer> intOptional18 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        int int20 = charSequenceConsumerRecord10.partition();
        int int21 = charSequenceConsumerRecord10.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType22 = charSequenceConsumerRecord10.timestampType();
        long long23 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertNotNull(intOptional18);
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 10 + "'", int20 == 10);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertNull(timestampType22);
        org.junit.Assert.assertTrue("'" + long23 + "' != '" + (-1L) + "'", long23 == (-1L));
    }

    @Test
    public void test2479() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2479");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer11 = strKafkaSpout0.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer12 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer12;
        strKafkaSpout0.maxRetries = (byte) -1;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean16 = strKafkaSpout0.commit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(timer11);
    }

    @Test
    public void test2480() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2480");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str18 = charSequenceConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = charSequenceConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long34 = charSequenceConsumerRecord33.checksum();
        int int35 = charSequenceConsumerRecord33.partition();
        long long36 = charSequenceConsumerRecord33.timestamp();
        java.lang.String str37 = charSequenceConsumerRecord33.toString();
        long long38 = charSequenceConsumerRecord33.timestamp();
        org.apache.kafka.common.header.Headers headers39 = charSequenceConsumerRecord33.headers();
        org.apache.kafka.common.record.TimestampType timestampType40 = charSequenceConsumerRecord33.timestampType();
        java.util.Optional<java.lang.Integer> intOptional41 = charSequenceConsumerRecord33.leaderEpoch();
        org.apache.storm.topology.IComponent iComponent42 = null;
        org.apache.kafka.common.record.TimestampType timestampType47 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType47, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long54 = charSequenceConsumerRecord53.checksum();
        int int55 = charSequenceConsumerRecord53.partition();
        long long56 = charSequenceConsumerRecord53.timestamp();
        java.lang.String str57 = charSequenceConsumerRecord53.toString();
        org.apache.kafka.common.header.Headers headers58 = charSequenceConsumerRecord53.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent> intOptionalConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent>("hi!", (int) ' ', (long) (byte) -1, (long) (-1), timestampType19, (java.lang.Long) 100L, (int) 'a', (-1), intOptional41, iComponent42, headers58);
        org.apache.storm.topology.IRichSpout iRichSpout64 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.storm.topology.IRichSpout> strComparableConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.storm.topology.IRichSpout>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", (int) (byte) 0, (long) 10, (long) (-1), timestampType19, (long) 0, (int) (short) 10, (int) (byte) 1, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", iRichSpout64);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (short) 100, 0L, (long) (short) 1, timestampType19, 0L, (int) (byte) 0, (int) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        long long72 = charSequenceConsumerRecord71.checksum();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertTrue("'" + int35 + "' != '" + 10 + "'", int35 == 10);
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + (-1L) + "'", long36 == (-1L));
        org.junit.Assert.assertEquals("'" + str37 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str37, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + (-1L) + "'", long38 == (-1L));
        org.junit.Assert.assertNotNull(headers39);
        org.junit.Assert.assertNull(timestampType40);
        org.junit.Assert.assertNotNull(intOptional41);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + (-1L) + "'", long54 == (-1L));
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + 10 + "'", int55 == 10);
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + (-1L) + "'", long56 == (-1L));
        org.junit.Assert.assertEquals("'" + str57 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str57, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers58);
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + 0L + "'", long72 == 0L);
    }

    @Test
    public void test2481() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2481");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder2 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder2;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
    }

    @Test
    public void test2482() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2482");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional15 = charSequenceConsumerRecord10.leaderEpoch();
        long long16 = charSequenceConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional17 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str18 = charSequenceConsumerRecord10.toString();
        int int19 = charSequenceConsumerRecord10.partition();
        int int20 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 52 + "'", int14 == 52);
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertNotNull(intOptional17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str18, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 52 + "'", int20 == 52);
    }

    @Test
    public void test2483() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2483");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout3 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout3.maxRetries = (byte) -1;
        int int6 = strKafkaSpout3.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout3.waitingToEmit = strConsumerRecordItor7;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout3.toArrayList(topicPartition9);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = strKafkaSpout3.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType16 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout20 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout20.maxRetries = (byte) -1;
        int int23 = strKafkaSpout20.maxRetries;
        strKafkaSpout20.numUncommittedOffsets = '#';
        strKafkaSpout20.initialized = true;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet28 = strKafkaSpout20.emitted;
        org.apache.kafka.common.record.TimestampType timestampType36 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType36, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int43 = charSequenceConsumerRecord42.serializedValueSize();
        java.lang.CharSequence charSequence44 = charSequenceConsumerRecord42.key();
        org.apache.kafka.common.header.Headers headers45 = charSequenceConsumerRecord42.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray46 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList47 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean48 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47, kafkaSpoutMessageIdArray46);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers45, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47);
        org.apache.kafka.common.record.TimestampType timestampType54 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType54, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int61 = charSequenceConsumerRecord60.serializedValueSize();
        java.lang.CharSequence charSequence62 = charSequenceConsumerRecord60.key();
        org.apache.kafka.common.header.Headers headers63 = charSequenceConsumerRecord60.headers();
        org.apache.kafka.common.record.TimestampType timestampType68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType68, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long75 = charSequenceConsumerRecord74.offset();
        int int76 = charSequenceConsumerRecord74.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional77 = charSequenceConsumerRecord74.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> objConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) '4', (long) (short) 0, (long) 100, timestampType16, (java.lang.Long) 1L, (int) (short) 0, 0, (java.lang.Object) kafkaSpoutMessageIdSet28, (java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47, headers63, intOptional77);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.common.header.Headers> iSpoutConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.common.header.Headers>("KafkaSpout{acked=null, emitted=null}", (int) '#', (long) 1, (org.apache.storm.spout.ISpout) strKafkaSpout3, headers63);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer80 = strKafkaSpout3.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder81 = strKafkaSpout3.tuplesBuilder;
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(strKafkaConsumer11);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet28);
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + (-1) + "'", int43 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence44 + "' != '" + "" + "'", charSequence44, "");
        org.junit.Assert.assertNotNull(headers45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray46);
        org.junit.Assert.assertTrue("'" + boolean48 + "' != '" + false + "'", boolean48 == false);
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + (-1) + "'", int61 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence62 + "' != '" + "" + "'", charSequence62, "");
        org.junit.Assert.assertNotNull(headers63);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + 0L + "'", long75 == 0L);
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + (-1) + "'", int76 == (-1));
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertNull(timer80);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder81);
    }

    @Test
    public void test2484() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2484");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        boolean boolean5 = strKafkaSpout0.waitingToEmit();
        long long6 = strKafkaSpout0.numUncommittedOffsets;
        boolean boolean7 = strKafkaSpout0.consumerAutoCommitMode;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + 0L + "'", long6 == 0L);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
    }

    @Test
    public void test2485() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2485");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        strKafkaSpout0.maxRetries = (byte) 1;
        int int10 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord11 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean12 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord11);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 1 + "'", int10 == 1);
    }

    @Test
    public void test2486() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2486");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
    }

    @Test
    public void test2487() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2487");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout27 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout27.maxRetries = (byte) -1;
        int int30 = strKafkaSpout27.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor31 = null;
        strKafkaSpout27.waitingToEmit = strConsumerRecordItor31;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout27.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer34 = strKafkaSpout27.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType40, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long47 = charSequenceConsumerRecord46.offset();
        long long48 = charSequenceConsumerRecord46.checksum();
        int int49 = charSequenceConsumerRecord46.serializedKeySize();
        org.apache.kafka.common.header.Headers headers50 = charSequenceConsumerRecord46.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType23, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout27, (java.lang.CharSequence) "hi!", headers50);
        org.apache.kafka.common.record.TimestampType timestampType61 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType61, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long68 = charSequenceConsumerRecord67.checksum();
        int int69 = charSequenceConsumerRecord67.partition();
        long long70 = charSequenceConsumerRecord67.offset();
        org.apache.kafka.common.header.Headers headers71 = charSequenceConsumerRecord67.headers();
        org.apache.kafka.common.record.TimestampType timestampType76 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType76, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long83 = charSequenceConsumerRecord82.offset();
        int int84 = charSequenceConsumerRecord82.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional85 = charSequenceConsumerRecord82.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) 10, 10L, 0L, timestampType23, (java.lang.Long) 35L, (int) (byte) 0, (-1), (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers71, intOptional85);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord92 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 10, (long) (short) 0, (long) (-1), timestampType23, (long) ' ', 32, (int) (byte) 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 35, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)))", "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = 35, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (byte) 10, 97L, 10L, timestampType23, (long) (byte) 10, 100, 97, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = hi!, partition = 0, leaderEpoch = null, offset = -1, null = 100, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )");
        java.lang.String str99 = charSequenceConsumerRecord98.value();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(strKafkaConsumer34);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 0L + "'", long47 == 0L);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 52 + "'", int49 == 52);
        org.junit.Assert.assertNotNull(headers50);
        org.junit.Assert.assertTrue("'" + long68 + "' != '" + (-1L) + "'", long68 == (-1L));
        org.junit.Assert.assertTrue("'" + int69 + "' != '" + 10 + "'", int69 == 10);
        org.junit.Assert.assertTrue("'" + long70 + "' != '" + 0L + "'", long70 == 0L);
        org.junit.Assert.assertNotNull(headers71);
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + 0L + "'", long83 == 0L);
        org.junit.Assert.assertTrue("'" + int84 + "' != '" + (-1) + "'", int84 == (-1));
        org.junit.Assert.assertNotNull(intOptional85);
        org.junit.Assert.assertEquals("'" + str99 + "' != '" + "ConsumerRecord(topic = hi!, partition = 0, leaderEpoch = null, offset = -1, null = 100, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )" + "'", str99, "ConsumerRecord(topic = hi!, partition = 0, leaderEpoch = null, offset = -1, null = 100, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )");
    }

    @Test
    public void test2488() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2488");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        int int21 = charSequenceConsumerRecord10.serializedValueSize();
        long long22 = charSequenceConsumerRecord10.checksum();
        long long23 = charSequenceConsumerRecord10.timestamp();
        int int24 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
        org.junit.Assert.assertTrue("'" + long23 + "' != '" + (-1L) + "'", long23 == (-1L));
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
    }

    @Test
    public void test2489() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2489");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer9 = strKafkaSpout0.kafkaConsumer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor10 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor10;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams12;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer14 = strKafkaSpout0.commitTimer;
        java.util.Map map15 = null;
        org.apache.storm.task.TopologyContext topologyContext16 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector17 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map15, topologyContext16, spoutOutputCollector17);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertNull(strKafkaConsumer9);
        org.junit.Assert.assertNull(timer14);
    }

    @Test
    public void test2490() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2490");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        strKafkaSpout0.numUncommittedOffsets = (byte) -1;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
    }

    @Test
    public void test2491() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2491");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer5 = strKafkaSpout0.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer6 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer6;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(strConsumerRecordItor4);
        org.junit.Assert.assertNull(timer5);
    }

    @Test
    public void test2492() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2492");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        long long16 = charSequenceConsumerRecord10.offset();
        java.lang.CharSequence charSequence17 = charSequenceConsumerRecord10.key();
        java.util.Optional<java.lang.Integer> intOptional18 = charSequenceConsumerRecord10.leaderEpoch();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType20 = charSequenceConsumerRecord10.timestampType();
        int int21 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertEquals("'" + charSequence17 + "' != '" + "" + "'", charSequence17, "");
        org.junit.Assert.assertNotNull(intOptional18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNull(timestampType20);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 10 + "'", int21 == 10);
    }

    @Test
    public void test2493() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2493");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        long long7 = charSequenceConsumerRecord5.timestamp();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        java.lang.String str9 = charSequenceConsumerRecord5.toString();
        org.apache.kafka.common.header.Headers headers10 = charSequenceConsumerRecord5.headers();
        java.lang.String str11 = charSequenceConsumerRecord5.topic();
        java.lang.String str12 = charSequenceConsumerRecord5.toString();
        int int13 = charSequenceConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str9, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str12, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
    }

    @Test
    public void test2494() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2494");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator7.reversed();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId13 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId14 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int15 = offsetComparator7.compare(kafkaSpoutMessageId13, kafkaSpoutMessageId14);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
    }

    @Test
    public void test2495() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2495");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.offset();
        int int19 = charSequenceConsumerRecord10.partition();
        int int20 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.String str21 = charSequenceConsumerRecord10.topic();
        int int22 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.CharSequence charSequence23 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 52 + "'", int20 == 52);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "" + "'", str21, "");
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 52 + "'", int22 == 52);
        org.junit.Assert.assertEquals("'" + charSequence23 + "' != '" + "" + "'", charSequence23, "");
    }

    @Test
    public void test2496() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2496");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", (int) 'a', (long) (byte) -1, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        int int6 = charSequenceConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
    }

    @Test
    public void test2497() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2497");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout11 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = strKafkaSpout11.kafkaSpoutStreams;
        strKafkaSpout11.consumerAutoCommitMode = false;
        java.lang.String str15 = strKafkaSpout11.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout16 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout16.maxRetries = (byte) -1;
        int int19 = strKafkaSpout16.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray20 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet21 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean22 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, kafkaSpoutMessageIdArray20);
        strKafkaSpout16.emitted = kafkaSpoutMessageIdSet21;
        strKafkaSpout11.emitted = kafkaSpoutMessageIdSet21;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout25 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout25.maxRetries = (byte) -1;
        int int28 = strKafkaSpout25.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor29 = null;
        strKafkaSpout25.waitingToEmit = strConsumerRecordItor29;
        org.apache.kafka.common.TopicPartition topicPartition31 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection32 = strKafkaSpout25.toArrayList(topicPartition31);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout25.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector34 = strKafkaSpout25.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout35.maxRetries = (byte) -1;
        int int38 = strKafkaSpout35.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray39 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet40 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean41 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40, kafkaSpoutMessageIdArray39);
        strKafkaSpout35.emitted = kafkaSpoutMessageIdSet40;
        strKafkaSpout25.emitted = kafkaSpoutMessageIdSet40;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType7, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet40;
        long long46 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout47 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout47.maxRetries = (byte) -1;
        int int50 = strKafkaSpout47.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor51 = null;
        strKafkaSpout47.waitingToEmit = strConsumerRecordItor51;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig53 = null;
        strKafkaSpout47.kafkaSpoutConfig = strKafkaSpoutConfig53;
        int int55 = strKafkaSpout47.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy56 = null;
        strKafkaSpout47.firstPollOffsetStrategy = firstPollOffsetStrategy56;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet58 = strKafkaSpout47.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray59 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet60 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean61 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet60, kafkaSpoutMessageIdArray59);
        strKafkaSpout47.emitted = kafkaSpoutMessageIdSet60;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer63 = null;
        strKafkaSpout47.kafkaConsumer = strKafkaConsumer63;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector65 = null;
        strKafkaSpout47.collector = spoutOutputCollector65;
        int int67 = strKafkaSpout47.maxRetries;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet68 = strKafkaSpout47.emitted;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet68;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.commitOffsetsForAckedTuples();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(strKafkaSpoutConfig2);
        org.junit.Assert.assertNull(kafkaSpoutStreams12);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray20);
        org.junit.Assert.assertTrue("'" + boolean22 + "' != '" + false + "'", boolean22 == false);
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + (-1) + "'", int28 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection32);
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(spoutOutputCollector34);
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + (-1) + "'", int38 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray39);
        org.junit.Assert.assertTrue("'" + boolean41 + "' != '" + false + "'", boolean41 == false);
        org.junit.Assert.assertTrue("'" + long46 + "' != '" + 0L + "'", long46 == 0L);
        org.junit.Assert.assertTrue("'" + int50 + "' != '" + (-1) + "'", int50 == (-1));
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + (-1) + "'", int55 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet58);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray59);
        org.junit.Assert.assertTrue("'" + boolean61 + "' != '" + false + "'", boolean61 == false);
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + (-1) + "'", int67 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdSet68);
    }

    @Test
    public void test2498() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2498");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition8 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection9 = strKafkaSpout0.toArrayList(topicPartition8);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer10;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor12 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor12;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService14 = strKafkaSpout0.retryService;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection9);
        org.junit.Assert.assertNull(kafkaSpoutRetryService14);
    }

    @Test
    public void test2499() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2499");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 1, 1L, (long) (byte) 10, timestampType4, (long) '#', (int) (byte) 100, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        java.lang.String str11 = charSequenceConsumerRecord10.value();
        java.lang.String str12 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        long long14 = charSequenceConsumerRecord10.checksum();
        long long15 = charSequenceConsumerRecord10.checksum();
        long long16 = charSequenceConsumerRecord10.timestamp();
        long long17 = charSequenceConsumerRecord10.timestamp();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str12, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 35L + "'", long14 == 35L);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 35L + "'", long15 == 35L);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 10L + "'", long16 == 10L);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 10L + "'", long17 == 10L);
    }

    @Test
    public void test2500() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest4.test2500");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        boolean boolean4 = strKafkaSpout0.waitingToEmit();
        strKafkaSpout0.initialized = false;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer7;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams9 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams9;
        org.apache.kafka.common.TopicPartition topicPartition11 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setAcked(topicPartition11, (long) 10);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
    }
}
