import org.junit.FixMethodOrder;
import org.junit.Test;
import org.junit.runners.MethodSorters;

@FixMethodOrder(MethodSorters.NAME_ASCENDING)
public class RegressionTest13 {

    public static boolean debug = false;

    @Test
    public void test6501() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6501");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        int int12 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder13;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService15 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams16 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector17 = null;
        strKafkaSpout0.collector = spoutOutputCollector17;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService15);
        org.junit.Assert.assertNull(kafkaSpoutStreams16);
    }

    @Test
    public void test6502() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6502");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertNull(timestampType15);
    }

    @Test
    public void test6503() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6503");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        boolean boolean7 = strKafkaSpout0.initialized;
        strKafkaSpout0.maxRetries = (byte) 10;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService10;
        int int12 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService13 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer14 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy15 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy15;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertNull(kafkaSpoutRetryService13);
        org.junit.Assert.assertNull(timer14);
    }

    @Test
    public void test6504() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6504");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout11 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = strKafkaSpout11.kafkaSpoutStreams;
        strKafkaSpout11.consumerAutoCommitMode = false;
        java.lang.String str15 = strKafkaSpout11.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout16 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout16.maxRetries = (byte) -1;
        int int19 = strKafkaSpout16.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray20 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet21 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean22 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, kafkaSpoutMessageIdArray20);
        strKafkaSpout16.emitted = kafkaSpoutMessageIdSet21;
        strKafkaSpout11.emitted = kafkaSpoutMessageIdSet21;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout25 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout25.maxRetries = (byte) -1;
        int int28 = strKafkaSpout25.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor29 = null;
        strKafkaSpout25.waitingToEmit = strConsumerRecordItor29;
        org.apache.kafka.common.TopicPartition topicPartition31 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection32 = strKafkaSpout25.toArrayList(topicPartition31);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout25.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector34 = strKafkaSpout25.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout35.maxRetries = (byte) -1;
        int int38 = strKafkaSpout35.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray39 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet40 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean41 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40, kafkaSpoutMessageIdArray39);
        strKafkaSpout35.emitted = kafkaSpoutMessageIdSet40;
        strKafkaSpout25.emitted = kafkaSpoutMessageIdSet40;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType7, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet40;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector46 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer47 = strKafkaSpout0.commitTimer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor48 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor48;
        java.lang.String str50 = strKafkaSpout0.toString();
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer51 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer51;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(strKafkaSpoutConfig2);
        org.junit.Assert.assertNull(kafkaSpoutStreams12);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray20);
        org.junit.Assert.assertTrue("'" + boolean22 + "' != '" + false + "'", boolean22 == false);
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + (-1) + "'", int28 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection32);
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(spoutOutputCollector34);
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + (-1) + "'", int38 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray39);
        org.junit.Assert.assertTrue("'" + boolean41 + "' != '" + false + "'", boolean41 == false);
        org.junit.Assert.assertNull(spoutOutputCollector46);
        org.junit.Assert.assertNull(timer47);
        org.junit.Assert.assertEquals("'" + str50 + "' != '" + "KafkaSpout{acked=null, emitted=[]}" + "'", str50, "KafkaSpout{acked=null, emitted=[]}");
    }

    @Test
    public void test6505() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6505");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams3 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = strKafkaSpout0.kafkaSpoutStreams;
        int int8 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor9 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy11 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy11;
        org.junit.Assert.assertNull(kafkaSpoutStreams7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
    }

    @Test
    public void test6506() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6506");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        int int8 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor9 = strKafkaSpout0.waitingToEmit;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setAcked(topicPartition10, (long) (byte) 1);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strConsumerRecordItor9);
    }

    @Test
    public void test6507() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6507");
        org.apache.storm.kafka.spout.KafkaSpout kafkaSpout0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.RandomAccess, java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>.Timer timer1 = kafkaSpout0.new Timer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: reflection call to org.apache.storm.kafka.spout.KafkaSpout$Timer with null for superclass argument");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test6508() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6508");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType17 = null;
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int34 = charSequenceConsumerRecord33.serializedValueSize();
        java.lang.CharSequence charSequence35 = charSequenceConsumerRecord33.key();
        org.apache.kafka.common.header.Headers headers36 = charSequenceConsumerRecord33.headers();
        java.util.Optional<java.lang.Integer> intOptional37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType17, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers36, intOptional37);
        org.apache.kafka.common.record.TimestampType timestampType46 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType46, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int53 = charSequenceConsumerRecord52.serializedValueSize();
        java.lang.CharSequence charSequence54 = charSequenceConsumerRecord52.key();
        org.apache.kafka.common.header.Headers headers55 = charSequenceConsumerRecord52.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray56 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList57 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean58 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57, kafkaSpoutMessageIdArray56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers55, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headersConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("", (int) '#', 1L, headers36, kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType4, (java.lang.Long) (-1L), (int) (short) 100, 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}", headers36);
        long long62 = charSequenceConsumerRecord61.checksum();
        long long63 = charSequenceConsumerRecord61.timestamp();
        long long64 = charSequenceConsumerRecord61.timestamp();
        long long65 = charSequenceConsumerRecord61.offset();
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + (-1) + "'", int34 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence35 + "' != '" + "" + "'", charSequence35, "");
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + (-1) + "'", int53 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence54 + "' != '" + "" + "'", charSequence54, "");
        org.junit.Assert.assertNotNull(headers55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray56);
        org.junit.Assert.assertTrue("'" + boolean58 + "' != '" + false + "'", boolean58 == false);
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + (-1L) + "'", long62 == (-1L));
        org.junit.Assert.assertTrue("'" + long63 + "' != '" + 0L + "'", long63 == 0L);
        org.junit.Assert.assertTrue("'" + long64 + "' != '" + 0L + "'", long64 == 0L);
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + 1L + "'", long65 == 1L);
    }

    @Test
    public void test6509() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6509");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        boolean boolean8 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = strKafkaSpout0.retryService;
        java.lang.String str10 = strKafkaSpout0.toString();
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
        org.junit.Assert.assertNull(kafkaSpoutRetryService9);
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str10, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test6510() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6510");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer9 = strKafkaSpout0.kafkaConsumer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor10 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor10;
        boolean boolean12 = strKafkaSpout0.initialized;
        java.lang.String str13 = strKafkaSpout0.toString();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor14 = strKafkaSpout0.waitingToEmit;
        int int15 = strKafkaSpout0.maxRetries;
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertNull(strKafkaConsumer9);
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + false + "'", boolean12 == false);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str13, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strConsumerRecordItor14);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 0 + "'", int15 == 0);
    }

    @Test
    public void test6511() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6511");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) ' ', (long) (byte) 100, (long) (byte) -1, timestampType4, (long) (byte) -1, (int) (byte) 10, 10, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        org.apache.kafka.common.header.Headers headers12 = charSequenceConsumerRecord10.headers();
        java.lang.CharSequence charSequence13 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 10 + "'", int11 == 10);
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertEquals("'" + charSequence13 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", charSequence13, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test6512() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6512");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        java.lang.String str13 = charSequenceConsumerRecord10.topic();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        long long16 = charSequenceConsumerRecord10.checksum();
        int int17 = charSequenceConsumerRecord10.serializedValueSize();
        int int18 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + (-1) + "'", int17 == (-1));
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 52 + "'", int18 == 52);
    }

    @Test
    public void test6513() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6513");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer9 = strKafkaSpout0.commitTimer;
        boolean boolean10 = strKafkaSpout0.waitingToEmit();
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder12 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder12;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig14 = strKafkaSpout0.kafkaSpoutConfig;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor15 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService16 = strKafkaSpout0.retryService;
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertNull(timer9);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNull(strKafkaConsumer11);
        org.junit.Assert.assertNull(strKafkaSpoutConfig14);
        org.junit.Assert.assertNull(strConsumerRecordItor15);
        org.junit.Assert.assertNull(kafkaSpoutRetryService16);
    }

    @Test
    public void test6514() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6514");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor10 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor10;
        org.apache.kafka.common.TopicPartition topicPartition12 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection13 = strKafkaSpout0.toArrayList(topicPartition12);
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer14 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer14);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection13);
    }

    @Test
    public void test6515() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6515");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = offsetComparator11.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator7.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator11);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator16 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator17 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = offsetComparator18.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = offsetComparator17.thenComparing(kafkaSpoutMessageIdComparator20);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator22 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator22;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = offsetComparator22.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator22.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = kafkaSpoutMessageIdComparator20.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator22);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = offsetComparator16.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator22);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator28 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator28;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = offsetComparator28.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator35 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator35;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator35);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = kafkaSpoutMessageIdComparator30.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator35);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator39 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator39;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = offsetComparator39.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator46 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator46;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator46);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator49 = kafkaSpoutMessageIdComparator41.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator46);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator50 = kafkaSpoutMessageIdComparator30.thenComparing(kafkaSpoutMessageIdComparator49);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator51 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator51;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator53 = offsetComparator51.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator54 = offsetComparator51.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator55 = kafkaSpoutMessageIdComparator49.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator51);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator56 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator56;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator58 = offsetComparator56.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator56;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator60 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator60;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator62 = offsetComparator60.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator63 = offsetComparator56.thenComparing(kafkaSpoutMessageIdComparator62);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator64 = kafkaSpoutMessageIdComparator62.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator65 = kafkaSpoutMessageIdComparator49.thenComparing(kafkaSpoutMessageIdComparator62);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator66 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator67 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator67;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator69 = offsetComparator67.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator70 = offsetComparator66.thenComparing(kafkaSpoutMessageIdComparator69);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator71 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator71;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator73 = offsetComparator71.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator78 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator78;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator78);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator81 = kafkaSpoutMessageIdComparator73.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator78);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator82 = kafkaSpoutMessageIdComparator73.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator83 = kafkaSpoutMessageIdComparator70.thenComparing(kafkaSpoutMessageIdComparator82);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator84 = kafkaSpoutMessageIdComparator49.thenComparing(kafkaSpoutMessageIdComparator83);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator85 = offsetComparator16.thenComparing(kafkaSpoutMessageIdComparator83);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator86 = offsetComparator7.thenComparing(kafkaSpoutMessageIdComparator85);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator49);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator50);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator53);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator54);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator58);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator62);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator63);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator64);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator65);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator69);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator70);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator73);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator81);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator82);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator83);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator84);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator85);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator86);
    }

    @Test
    public void test6516() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6516");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.timestamp();
        long long16 = charSequenceConsumerRecord10.offset();
        long long17 = charSequenceConsumerRecord10.offset();
        int int18 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        int int20 = charSequenceConsumerRecord10.serializedKeySize();
        long long21 = charSequenceConsumerRecord10.checksum();
        long long22 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str23 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 52 + "'", int18 == 52);
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 52 + "'", int20 == 52);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str23, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test6517() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6517");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator2 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator3 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator3;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator5 = offsetComparator3.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator6 = offsetComparator2.thenComparing(kafkaSpoutMessageIdComparator5);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator6);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator8 = offsetComparator0.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator9 = offsetComparator0.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId11 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId12 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int13 = offsetComparator0.compare(kafkaSpoutMessageId11, kafkaSpoutMessageId12);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator5);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator6);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator8);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator9);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
    }

    @Test
    public void test6518() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6518");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str18 = charSequenceConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = charSequenceConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long34 = charSequenceConsumerRecord33.checksum();
        int int35 = charSequenceConsumerRecord33.partition();
        long long36 = charSequenceConsumerRecord33.timestamp();
        java.lang.String str37 = charSequenceConsumerRecord33.toString();
        long long38 = charSequenceConsumerRecord33.timestamp();
        org.apache.kafka.common.header.Headers headers39 = charSequenceConsumerRecord33.headers();
        org.apache.kafka.common.record.TimestampType timestampType40 = charSequenceConsumerRecord33.timestampType();
        java.util.Optional<java.lang.Integer> intOptional41 = charSequenceConsumerRecord33.leaderEpoch();
        org.apache.storm.topology.IComponent iComponent42 = null;
        org.apache.kafka.common.record.TimestampType timestampType47 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType47, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long54 = charSequenceConsumerRecord53.checksum();
        int int55 = charSequenceConsumerRecord53.partition();
        long long56 = charSequenceConsumerRecord53.timestamp();
        java.lang.String str57 = charSequenceConsumerRecord53.toString();
        org.apache.kafka.common.header.Headers headers58 = charSequenceConsumerRecord53.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent> intOptionalConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent>("hi!", (int) ' ', (long) (byte) -1, (long) (-1), timestampType19, (java.lang.Long) 100L, (int) 'a', (-1), intOptional41, iComponent42, headers58);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", (int) ' ', (long) (short) 10, (long) '4', timestampType19, (long) (short) 1, 97, 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )");
        java.lang.CharSequence charSequence69 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 97, (long) 1, 0L, timestampType19, (long) (short) -1, (int) (byte) 100, (int) (short) 1, charSequence69, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        int int72 = charSequenceConsumerRecord71.serializedKeySize();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertTrue("'" + int35 + "' != '" + 10 + "'", int35 == 10);
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + (-1L) + "'", long36 == (-1L));
        org.junit.Assert.assertEquals("'" + str37 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str37, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + (-1L) + "'", long38 == (-1L));
        org.junit.Assert.assertNotNull(headers39);
        org.junit.Assert.assertNull(timestampType40);
        org.junit.Assert.assertNotNull(intOptional41);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + (-1L) + "'", long54 == (-1L));
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + 10 + "'", int55 == 10);
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + (-1L) + "'", long56 == (-1L));
        org.junit.Assert.assertEquals("'" + str57 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str57, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers58);
        org.junit.Assert.assertTrue("'" + int72 + "' != '" + 100 + "'", int72 == 100);
    }

    @Test
    public void test6519() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6519");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = kafkaSpoutMessageIdComparator13.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = kafkaSpoutMessageIdComparator2.thenComparing(kafkaSpoutMessageIdComparator21);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = kafkaSpoutMessageIdComparator21.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator24 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator24;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator24.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator31 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator31;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = kafkaSpoutMessageIdComparator26.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator31);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator35 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator35;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator37 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator38 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator38;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator40 = offsetComparator38.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = offsetComparator37.thenComparing(kafkaSpoutMessageIdComparator40);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator42 = offsetComparator35.thenComparing(kafkaSpoutMessageIdComparator41);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator43 = offsetComparator31.thenComparing(kafkaSpoutMessageIdComparator42);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = kafkaSpoutMessageIdComparator23.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator45 = kafkaSpoutMessageIdComparator23.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator23;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator40);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator42);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator43);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator45);
    }

    @Test
    public void test6520() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6520");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.String str15 = charSequenceConsumerRecord10.topic();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        java.util.Optional<java.lang.Integer> intOptional17 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "" + "'", str15, "");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertNotNull(intOptional17);
    }

    @Test
    public void test6521() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6521");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        java.lang.String str18 = charSequenceConsumerRecord10.topic();
        long long19 = charSequenceConsumerRecord10.offset();
        java.lang.CharSequence charSequence20 = charSequenceConsumerRecord10.key();
        long long21 = charSequenceConsumerRecord10.checksum();
        long long22 = charSequenceConsumerRecord10.timestamp();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertEquals("'" + charSequence20 + "' != '" + "" + "'", charSequence20, "");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
    }

    @Test
    public void test6522() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6522");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedValueSize();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord10.headers();
        long long17 = charSequenceConsumerRecord10.offset();
        long long18 = charSequenceConsumerRecord10.timestamp();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
    }

    @Test
    public void test6523() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6523");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer6 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector7 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig8 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = strKafkaSpout0.tuplesBuilder;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet10 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor11 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig12 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig12;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.emit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer6);
        org.junit.Assert.assertNull(spoutOutputCollector7);
        org.junit.Assert.assertNull(strKafkaSpoutConfig8);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder9);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet10);
        org.junit.Assert.assertNull(strConsumerRecordItor11);
    }

    @Test
    public void test6524() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6524");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        boolean boolean8 = strKafkaSpout0.initialized;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
    }

    @Test
    public void test6525() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6525");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator1 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator1;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator3 = offsetComparator1.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator4 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator3);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator5 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator5;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator5.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator12 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator12;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = kafkaSpoutMessageIdComparator7.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator0.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = offsetComparator12.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = offsetComparator18.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator25 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator25;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator25);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = kafkaSpoutMessageIdComparator20.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator25);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = offsetComparator25.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = kafkaSpoutMessageIdComparator17.thenComparing(kafkaSpoutMessageIdComparator29);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = kafkaSpoutMessageIdComparator17.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = kafkaSpoutMessageIdComparator17.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator3);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator4);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
    }

    @Test
    public void test6526() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6526");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams9 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        boolean boolean11 = strKafkaSpout0.waitingToEmit();
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer12 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector13 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig14 = strKafkaSpout0.kafkaSpoutConfig;
        int int15 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor16 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor16;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
        org.junit.Assert.assertNull(kafkaSpoutStreams9);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(strKafkaConsumer12);
        org.junit.Assert.assertNull(spoutOutputCollector13);
        org.junit.Assert.assertNull(strKafkaSpoutConfig14);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
    }

    @Test
    public void test6527() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6527");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor6 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor6;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams9 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams9;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService11 = strKafkaSpout0.retryService;
        java.util.Map map12 = null;
        org.apache.storm.task.TopologyContext topologyContext13 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector14 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map12, topologyContext13, spoutOutputCollector14);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
        org.junit.Assert.assertNull(kafkaSpoutRetryService11);
    }

    @Test
    public void test6528() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6528");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.offset();
        long long19 = charSequenceConsumerRecord10.checksum();
        int int20 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.header.Headers headers21 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 10 + "'", int20 == 10);
        org.junit.Assert.assertNotNull(headers21);
    }

    @Test
    public void test6529() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6529");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = strKafkaSpout0.firstPollOffsetStrategy;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer9 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer9;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = strKafkaSpout0.collector;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord12 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean13 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord12);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 0 + "'", int8 == 0);
        org.junit.Assert.assertNull(spoutOutputCollector11);
    }

    @Test
    public void test6530() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6530");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer11 = strKafkaSpout0.commitTimer;
        java.lang.String str12 = strKafkaSpout0.toString();
        boolean boolean13 = strKafkaSpout0.waitingToEmit();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(timer11);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str12, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + boolean13 + "' != '" + false + "'", boolean13 == false);
    }

    @Test
    public void test6531() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6531");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.util.Optional<java.lang.Integer> intOptional16 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str17 = charSequenceConsumerRecord10.value();
        java.lang.String str18 = charSequenceConsumerRecord10.topic();
        java.lang.String str19 = charSequenceConsumerRecord10.topic();
        java.lang.String str20 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "" + "'", str19, "");
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
    }

    @Test
    public void test6532() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6532");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        long long8 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords10 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords10);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 0L + "'", long8 == 0L);
        org.junit.Assert.assertNull(firstPollOffsetStrategy9);
    }

    @Test
    public void test6533() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6533");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        int int20 = charSequenceConsumerRecord10.serializedKeySize();
        int int21 = charSequenceConsumerRecord10.serializedValueSize();
        int int22 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord10.timestampType();
        java.lang.CharSequence charSequence24 = charSequenceConsumerRecord10.key();
        int int25 = charSequenceConsumerRecord10.serializedValueSize();
        org.apache.kafka.common.header.Headers headers26 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 52 + "'", int20 == 52);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 52 + "'", int22 == 52);
        org.junit.Assert.assertNull(timestampType23);
        org.junit.Assert.assertEquals("'" + charSequence24 + "' != '" + "" + "'", charSequence24, "");
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + (-1) + "'", int25 == (-1));
        org.junit.Assert.assertNotNull(headers26);
    }

    @Test
    public void test6534() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6534");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder2 = strKafkaSpout0.tuplesBuilder;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService4 = strKafkaSpout0.retryService;
        java.lang.String str5 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = strKafkaSpout0.kafkaSpoutConfig;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder2);
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + 0 + "'", int3 == 0);
        org.junit.Assert.assertNull(kafkaSpoutRetryService4);
        org.junit.Assert.assertEquals("'" + str5 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str5, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutConfig6);
    }

    @Test
    public void test6535() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6535");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.initialized = true;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer10;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService12 = strKafkaSpout0.retryService;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService12);
    }

    @Test
    public void test6536() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6536");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer16;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector18 = null;
        strKafkaSpout0.collector = spoutOutputCollector18;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor20 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor20;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService22 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService22;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor24 = strKafkaSpout0.waitingToEmit;
        org.apache.kafka.common.TopicPartition topicPartition25 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection26 = strKafkaSpout0.toArrayList(topicPartition25);
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor27 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer28 = strKafkaSpout0.commitTimer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor29 = strKafkaSpout0.waitingToEmit;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor24);
        org.junit.Assert.assertNotNull(topicPartitionCollection26);
        org.junit.Assert.assertNull(strConsumerRecordItor27);
        org.junit.Assert.assertNull(timer28);
        org.junit.Assert.assertNull(strConsumerRecordItor29);
    }

    @Test
    public void test6537() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6537");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str17 = charSequenceConsumerRecord10.topic();
        java.lang.String str18 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str18, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test6538() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6538");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long18 = charSequenceConsumerRecord17.checksum();
        long long19 = charSequenceConsumerRecord17.timestamp();
        org.apache.kafka.common.header.Headers headers20 = charSequenceConsumerRecord17.headers();
        java.lang.String str21 = charSequenceConsumerRecord17.toString();
        org.apache.kafka.common.header.Headers headers22 = charSequenceConsumerRecord17.headers();
        java.lang.String str23 = charSequenceConsumerRecord17.topic();
        long long24 = charSequenceConsumerRecord17.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType25 = charSequenceConsumerRecord17.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (byte) 1, (long) 100, timestampType25, (long) 1, 35, (int) (byte) 10, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.apache.kafka.common.record.TimestampType timestampType41 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType41, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long48 = charSequenceConsumerRecord47.checksum();
        int int49 = charSequenceConsumerRecord47.partition();
        long long50 = charSequenceConsumerRecord47.timestamp();
        long long51 = charSequenceConsumerRecord47.offset();
        java.lang.String str52 = charSequenceConsumerRecord47.toString();
        java.lang.String str53 = charSequenceConsumerRecord47.topic();
        org.apache.kafka.common.header.Headers headers54 = charSequenceConsumerRecord47.headers();
        org.apache.kafka.common.record.TimestampType timestampType59 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType59, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long66 = charSequenceConsumerRecord65.checksum();
        int int67 = charSequenceConsumerRecord65.partition();
        long long68 = charSequenceConsumerRecord65.timestamp();
        java.lang.String str69 = charSequenceConsumerRecord65.toString();
        long long70 = charSequenceConsumerRecord65.timestamp();
        long long71 = charSequenceConsumerRecord65.offset();
        long long72 = charSequenceConsumerRecord65.offset();
        org.apache.kafka.common.header.Headers headers73 = charSequenceConsumerRecord65.headers();
        int int74 = charSequenceConsumerRecord65.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional75 = charSequenceConsumerRecord65.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", 32, 52L, (long) 32, timestampType25, (java.lang.Long) 10L, (int) (byte) 1, 1, (java.lang.CharSequence) "", "", headers54, intOptional75);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", (int) 'a', (long) 10, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        java.lang.CharSequence charSequence88 = charSequenceConsumerRecord87.key();
        org.apache.kafka.common.header.Headers headers89 = charSequenceConsumerRecord87.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord90 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 1, (long) (short) 0, (long) (short) 10, timestampType25, (java.lang.Long) 97L, (int) (short) -1, (int) '#', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)", headers89);
        java.lang.String str91 = charSequenceConsumerRecord90.value();
        int int92 = charSequenceConsumerRecord90.serializedValueSize();
        int int93 = charSequenceConsumerRecord90.partition();
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str21, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers22);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "" + "'", str23, "");
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + (-1L) + "'", long24 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType25 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType25.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 10 + "'", int49 == 10);
        org.junit.Assert.assertTrue("'" + long50 + "' != '" + (-1L) + "'", long50 == (-1L));
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + 0L + "'", long51 == 0L);
        org.junit.Assert.assertEquals("'" + str52 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str52, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "" + "'", str53, "");
        org.junit.Assert.assertNotNull(headers54);
        org.junit.Assert.assertTrue("'" + long66 + "' != '" + (-1L) + "'", long66 == (-1L));
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + 10 + "'", int67 == 10);
        org.junit.Assert.assertTrue("'" + long68 + "' != '" + (-1L) + "'", long68 == (-1L));
        org.junit.Assert.assertEquals("'" + str69 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str69, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long70 + "' != '" + (-1L) + "'", long70 == (-1L));
        org.junit.Assert.assertTrue("'" + long71 + "' != '" + 0L + "'", long71 == 0L);
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + 0L + "'", long72 == 0L);
        org.junit.Assert.assertNotNull(headers73);
        org.junit.Assert.assertTrue("'" + int74 + "' != '" + (-1) + "'", int74 == (-1));
        org.junit.Assert.assertNotNull(intOptional75);
        org.junit.Assert.assertEquals("'" + charSequence88 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", charSequence88, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNotNull(headers89);
        org.junit.Assert.assertEquals("'" + str91 + "' != '" + "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)" + "'", str91, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)");
        org.junit.Assert.assertTrue("'" + int92 + "' != '" + 35 + "'", int92 == 35);
        org.junit.Assert.assertTrue("'" + int93 + "' != '" + 1 + "'", int93 == 1);
    }

    @Test
    public void test6539() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6539");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str18 = charSequenceConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = charSequenceConsumerRecord17.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout23 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout23.maxRetries = (byte) -1;
        int int26 = strKafkaSpout23.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor27 = null;
        strKafkaSpout23.waitingToEmit = strConsumerRecordItor27;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer29 = strKafkaSpout23.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer30 = strKafkaSpout23.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType36 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType36, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long43 = charSequenceConsumerRecord42.offset();
        long long44 = charSequenceConsumerRecord42.checksum();
        int int45 = charSequenceConsumerRecord42.serializedKeySize();
        org.apache.kafka.common.header.Headers headers46 = charSequenceConsumerRecord42.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType19, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout23, (java.lang.CharSequence) "hi!", headers46);
        org.apache.kafka.common.record.TimestampType timestampType57 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType57, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long64 = charSequenceConsumerRecord63.checksum();
        int int65 = charSequenceConsumerRecord63.partition();
        long long66 = charSequenceConsumerRecord63.offset();
        org.apache.kafka.common.header.Headers headers67 = charSequenceConsumerRecord63.headers();
        org.apache.kafka.common.record.TimestampType timestampType72 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType72, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long79 = charSequenceConsumerRecord78.offset();
        int int80 = charSequenceConsumerRecord78.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional81 = charSequenceConsumerRecord78.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) 10, 10L, 0L, timestampType19, (java.lang.Long) 35L, (int) (byte) 0, (-1), (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers67, intOptional81);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", 32, (long) (short) -1, (long) (byte) 10, timestampType19, (long) ' ', 35, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        int int89 = charSequenceConsumerRecord88.partition();
        long long90 = charSequenceConsumerRecord88.offset();
        java.util.Optional<java.lang.Integer> intOptional91 = charSequenceConsumerRecord88.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional92 = charSequenceConsumerRecord88.leaderEpoch();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int26 + "' != '" + (-1) + "'", int26 == (-1));
        org.junit.Assert.assertNull(timer29);
        org.junit.Assert.assertNull(strKafkaConsumer30);
        org.junit.Assert.assertTrue("'" + long43 + "' != '" + 0L + "'", long43 == 0L);
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + (-1L) + "'", long44 == (-1L));
        org.junit.Assert.assertTrue("'" + int45 + "' != '" + 52 + "'", int45 == 52);
        org.junit.Assert.assertNotNull(headers46);
        org.junit.Assert.assertTrue("'" + long64 + "' != '" + (-1L) + "'", long64 == (-1L));
        org.junit.Assert.assertTrue("'" + int65 + "' != '" + 10 + "'", int65 == 10);
        org.junit.Assert.assertTrue("'" + long66 + "' != '" + 0L + "'", long66 == 0L);
        org.junit.Assert.assertNotNull(headers67);
        org.junit.Assert.assertTrue("'" + long79 + "' != '" + 0L + "'", long79 == 0L);
        org.junit.Assert.assertTrue("'" + int80 + "' != '" + (-1) + "'", int80 == (-1));
        org.junit.Assert.assertNotNull(intOptional81);
        org.junit.Assert.assertTrue("'" + int89 + "' != '" + 32 + "'", int89 == 32);
        org.junit.Assert.assertTrue("'" + long90 + "' != '" + (-1L) + "'", long90 == (-1L));
        org.junit.Assert.assertNotNull(intOptional91);
        org.junit.Assert.assertNotNull(intOptional92);
    }

    @Test
    public void test6540() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6540");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = 97, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = )", (int) (byte) 1, (long) 0, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 0, null = 97, serialized key size = 32, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, null = 1, serialized key size = 32, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )");
        java.lang.String str6 = charSequenceConsumerRecord5.topic();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = 97, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = )" + "'", str6, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = 97, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = )");
    }

    @Test
    public void test6541() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6541");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType17 = null;
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int34 = charSequenceConsumerRecord33.serializedValueSize();
        java.lang.CharSequence charSequence35 = charSequenceConsumerRecord33.key();
        org.apache.kafka.common.header.Headers headers36 = charSequenceConsumerRecord33.headers();
        java.util.Optional<java.lang.Integer> intOptional37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType17, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers36, intOptional37);
        org.apache.kafka.common.record.TimestampType timestampType46 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType46, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int53 = charSequenceConsumerRecord52.serializedValueSize();
        java.lang.CharSequence charSequence54 = charSequenceConsumerRecord52.key();
        org.apache.kafka.common.header.Headers headers55 = charSequenceConsumerRecord52.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray56 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList57 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean58 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57, kafkaSpoutMessageIdArray56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers55, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headersConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("", (int) '#', 1L, headers36, kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType4, (java.lang.Long) (-1L), (int) (short) 100, 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}", headers36);
        java.lang.String str62 = charSequenceConsumerRecord61.toString();
        java.util.Optional<java.lang.Integer> intOptional63 = charSequenceConsumerRecord61.leaderEpoch();
        int int64 = charSequenceConsumerRecord61.serializedValueSize();
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + (-1) + "'", int34 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence35 + "' != '" + "" + "'", charSequence35, "");
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + (-1) + "'", int53 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence54 + "' != '" + "" + "'", charSequence54, "");
        org.junit.Assert.assertNotNull(headers55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray56);
        org.junit.Assert.assertTrue("'" + boolean58 + "' != '" + false + "'", boolean58 == false);
        org.junit.Assert.assertEquals("'" + str62 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", str62, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.junit.Assert.assertNotNull(intOptional63);
        org.junit.Assert.assertTrue("'" + int64 + "' != '" + 1 + "'", int64 == 1);
    }

    @Test
    public void test6542() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6542");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService5 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor10 = strKafkaSpout0.waitingToEmit;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertNull(firstPollOffsetStrategy7);
        org.junit.Assert.assertNull(strConsumerRecordItor10);
    }

    @Test
    public void test6543() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6543");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        java.lang.String str18 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = charSequenceConsumerRecord10.timestampType();
        long long20 = charSequenceConsumerRecord10.checksum();
        int int21 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.String str22 = charSequenceConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional23 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertNull(timestampType19);
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str22, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(intOptional23);
    }

    @Test
    public void test6544() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6544");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        strKafkaSpout0.initialized = true;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet8 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer9 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy11 = strKafkaSpout0.firstPollOffsetStrategy;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet12 = strKafkaSpout0.emitted;
        boolean boolean13 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams14 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams14;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords16 = strKafkaSpout0.pollKafkaBroker();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet8);
        org.junit.Assert.assertNull(timer9);
        org.junit.Assert.assertNull(kafkaSpoutStreams10);
        org.junit.Assert.assertNull(firstPollOffsetStrategy11);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet12);
        org.junit.Assert.assertTrue("'" + boolean13 + "' != '" + true + "'", boolean13 == true);
    }

    @Test
    public void test6545() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6545");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) ' ', (long) (byte) 100, (long) (byte) -1, timestampType4, (long) (byte) -1, (int) (byte) 10, 10, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long11 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str12 = charSequenceConsumerRecord10.toString();
        org.apache.kafka.common.record.TimestampType timestampType13 = charSequenceConsumerRecord10.timestampType();
        int int14 = charSequenceConsumerRecord10.partition();
        int int15 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str12, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNull(timestampType13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 32 + "'", int14 == 32);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 32 + "'", int15 == 32);
    }

    @Test
    public void test6546() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6546");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy8 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer11 = strKafkaSpout0.commitTimer;
        java.util.Map map12 = null;
        org.apache.storm.task.TopologyContext topologyContext13 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector14 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map12, topologyContext13, spoutOutputCollector14);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertNull(firstPollOffsetStrategy8);
        org.junit.Assert.assertNull(timer11);
    }

    @Test
    public void test6547() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6547");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder2 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams3 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer6 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer6;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
// flaky:             org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder2);
        org.junit.Assert.assertNull(kafkaSpoutStreams3);
    }

    @Test
    public void test6548() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6548");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.numUncommittedOffsets = (byte) 1;
        strKafkaSpout0.initialized = false;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet14 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService15 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService15;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder17 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder17;
        strKafkaSpout0.maxRetries = (short) 10;
        int int21 = strKafkaSpout0.maxRetries;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet14);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 10 + "'", int21 == 10);
    }

    @Test
    public void test6549() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6549");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}))", 35, (long) (byte) 10, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = 35, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
    }

    @Test
    public void test6550() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6550");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = kafkaSpoutMessageIdComparator13.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = kafkaSpoutMessageIdComparator2.thenComparing(kafkaSpoutMessageIdComparator21);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = kafkaSpoutMessageIdComparator22.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator23.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator25 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator26 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator27 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator27;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = offsetComparator27.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = offsetComparator26.thenComparing(kafkaSpoutMessageIdComparator29);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator31 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator31;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator33 = offsetComparator31.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator31.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = kafkaSpoutMessageIdComparator29.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = offsetComparator25.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = kafkaSpoutMessageIdComparator36.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator38 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator39 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator39;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = offsetComparator39.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator46 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator46;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator46);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator49 = kafkaSpoutMessageIdComparator41.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator46);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator50 = offsetComparator38.thenComparing(kafkaSpoutMessageIdComparator49);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator51 = offsetComparator38.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator52 = kafkaSpoutMessageIdComparator37.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator38);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator53 = kafkaSpoutMessageIdComparator24.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator33);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator49);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator50);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator51);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator52);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator53);
    }

    @Test
    public void test6551() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6551");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) -1, (long) (-1), (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        int int6 = charSequenceConsumerRecord5.partition();
        int int7 = charSequenceConsumerRecord5.partition();
        java.lang.String str8 = charSequenceConsumerRecord5.topic();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test6552() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6552");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder12 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder12;
        boolean boolean14 = strKafkaSpout0.initialized;
        java.lang.String str15 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService16 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService16;
        int int18 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor19 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService20 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService20;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet22 = strKafkaSpout0.emitted;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + (-1) + "'", int18 == (-1));
        org.junit.Assert.assertNull(strConsumerRecordItor19);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet22);
    }

    @Test
    public void test6553() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6553");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout11 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = strKafkaSpout11.kafkaSpoutStreams;
        strKafkaSpout11.consumerAutoCommitMode = false;
        java.lang.String str15 = strKafkaSpout11.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout16 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout16.maxRetries = (byte) -1;
        int int19 = strKafkaSpout16.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray20 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet21 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean22 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, kafkaSpoutMessageIdArray20);
        strKafkaSpout16.emitted = kafkaSpoutMessageIdSet21;
        strKafkaSpout11.emitted = kafkaSpoutMessageIdSet21;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout25 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout25.maxRetries = (byte) -1;
        int int28 = strKafkaSpout25.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor29 = null;
        strKafkaSpout25.waitingToEmit = strConsumerRecordItor29;
        org.apache.kafka.common.TopicPartition topicPartition31 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection32 = strKafkaSpout25.toArrayList(topicPartition31);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout25.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector34 = strKafkaSpout25.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout35.maxRetries = (byte) -1;
        int int38 = strKafkaSpout35.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray39 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet40 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean41 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40, kafkaSpoutMessageIdArray39);
        strKafkaSpout35.emitted = kafkaSpoutMessageIdSet40;
        strKafkaSpout25.emitted = kafkaSpoutMessageIdSet40;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType7, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet40;
        long long46 = strKafkaSpout0.numUncommittedOffsets;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor47 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.initialized = true;
        java.lang.String str50 = strKafkaSpout0.toString();
        boolean boolean51 = strKafkaSpout0.waitingToEmit();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord52 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean53 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord52);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(strKafkaSpoutConfig2);
        org.junit.Assert.assertNull(kafkaSpoutStreams12);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray20);
        org.junit.Assert.assertTrue("'" + boolean22 + "' != '" + false + "'", boolean22 == false);
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + (-1) + "'", int28 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection32);
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(spoutOutputCollector34);
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + (-1) + "'", int38 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray39);
        org.junit.Assert.assertTrue("'" + boolean41 + "' != '" + false + "'", boolean41 == false);
        org.junit.Assert.assertTrue("'" + long46 + "' != '" + 0L + "'", long46 == 0L);
        org.junit.Assert.assertNull(strConsumerRecordItor47);
        org.junit.Assert.assertEquals("'" + str50 + "' != '" + "KafkaSpout{acked=null, emitted=[]}" + "'", str50, "KafkaSpout{acked=null, emitted=[]}");
        org.junit.Assert.assertTrue("'" + boolean51 + "' != '" + false + "'", boolean51 == false);
    }

    @Test
    public void test6554() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6554");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType31 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType31, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long38 = charSequenceConsumerRecord37.checksum();
        int int39 = charSequenceConsumerRecord37.partition();
        long long40 = charSequenceConsumerRecord37.timestamp();
        java.lang.String str41 = charSequenceConsumerRecord37.toString();
        long long42 = charSequenceConsumerRecord37.timestamp();
        org.apache.kafka.common.header.Headers headers43 = charSequenceConsumerRecord37.headers();
        org.apache.kafka.common.record.TimestampType timestampType44 = charSequenceConsumerRecord37.timestampType();
        java.util.Optional<java.lang.Integer> intOptional45 = charSequenceConsumerRecord37.leaderEpoch();
        org.apache.storm.topology.IComponent iComponent46 = null;
        org.apache.kafka.common.record.TimestampType timestampType51 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType51, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long58 = charSequenceConsumerRecord57.checksum();
        int int59 = charSequenceConsumerRecord57.partition();
        long long60 = charSequenceConsumerRecord57.timestamp();
        java.lang.String str61 = charSequenceConsumerRecord57.toString();
        org.apache.kafka.common.header.Headers headers62 = charSequenceConsumerRecord57.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent> intOptionalConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent>("hi!", (int) ' ', (long) (byte) -1, (long) (-1), timestampType23, (java.lang.Long) 100L, (int) 'a', (-1), intOptional45, iComponent46, headers62);
        org.apache.storm.topology.IRichSpout iRichSpout68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.storm.topology.IRichSpout> strComparableConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.storm.topology.IRichSpout>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", (int) (byte) 0, (long) 10, (long) (-1), timestampType23, (long) 0, (int) (short) 10, (int) (byte) 1, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", iRichSpout68);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", (int) (byte) 100, 100L, (long) (short) 100, timestampType23, (long) 'a', (int) ' ', (-1), (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        java.lang.CharSequence charSequence79 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 52, (-1L), (java.lang.CharSequence) "hi!", "hi!");
        long long87 = charSequenceConsumerRecord86.checksum();
        org.apache.kafka.common.header.Headers headers88 = charSequenceConsumerRecord86.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord89 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (byte) 10, (long) 100, (long) '4', timestampType23, (java.lang.Long) 100L, 52, 0, charSequence79, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = 97, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = )", headers88);
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + (-1L) + "'", long38 == (-1L));
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + 10 + "'", int39 == 10);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertEquals("'" + str41 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str41, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long42 + "' != '" + (-1L) + "'", long42 == (-1L));
        org.junit.Assert.assertNotNull(headers43);
        org.junit.Assert.assertNull(timestampType44);
        org.junit.Assert.assertNotNull(intOptional45);
        org.junit.Assert.assertTrue("'" + long58 + "' != '" + (-1L) + "'", long58 == (-1L));
        org.junit.Assert.assertTrue("'" + int59 + "' != '" + 10 + "'", int59 == 10);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str61, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers62);
        org.junit.Assert.assertTrue("'" + long87 + "' != '" + (-1L) + "'", long87 == (-1L));
        org.junit.Assert.assertNotNull(headers88);
    }

    @Test
    public void test6555() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6555");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        boolean boolean11 = strKafkaSpout0.consumerAutoCommitMode;
        boolean boolean12 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor13 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = (byte) 1;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet16 = strKafkaSpout0.emitted;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + false + "'", boolean12 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor13);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet16);
    }

    @Test
    public void test6556() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6556");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 10, 1L, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=[]}");
        long long6 = charSequenceConsumerRecord5.checksum();
        java.lang.CharSequence charSequence7 = charSequenceConsumerRecord5.key();
        org.apache.kafka.common.record.TimestampType timestampType8 = charSequenceConsumerRecord5.timestampType();
        java.util.Optional<java.lang.Integer> intOptional9 = charSequenceConsumerRecord5.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence7 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence7, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(intOptional9);
    }

    @Test
    public void test6557() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6557");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout3 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout3.maxRetries = (byte) -1;
        int int6 = strKafkaSpout3.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout3.waitingToEmit = strConsumerRecordItor7;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout3.toArrayList(topicPartition9);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = strKafkaSpout3.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType16 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout20 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout20.maxRetries = (byte) -1;
        int int23 = strKafkaSpout20.maxRetries;
        strKafkaSpout20.numUncommittedOffsets = '#';
        strKafkaSpout20.initialized = true;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet28 = strKafkaSpout20.emitted;
        org.apache.kafka.common.record.TimestampType timestampType36 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType36, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int43 = charSequenceConsumerRecord42.serializedValueSize();
        java.lang.CharSequence charSequence44 = charSequenceConsumerRecord42.key();
        org.apache.kafka.common.header.Headers headers45 = charSequenceConsumerRecord42.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray46 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList47 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean48 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47, kafkaSpoutMessageIdArray46);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers45, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47);
        org.apache.kafka.common.record.TimestampType timestampType54 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType54, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int61 = charSequenceConsumerRecord60.serializedValueSize();
        java.lang.CharSequence charSequence62 = charSequenceConsumerRecord60.key();
        org.apache.kafka.common.header.Headers headers63 = charSequenceConsumerRecord60.headers();
        org.apache.kafka.common.record.TimestampType timestampType68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType68, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long75 = charSequenceConsumerRecord74.offset();
        int int76 = charSequenceConsumerRecord74.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional77 = charSequenceConsumerRecord74.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> objConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) '4', (long) (short) 0, (long) 100, timestampType16, (java.lang.Long) 1L, (int) (short) 0, 0, (java.lang.Object) kafkaSpoutMessageIdSet28, (java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47, headers63, intOptional77);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.common.header.Headers> iSpoutConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.common.header.Headers>("KafkaSpout{acked=null, emitted=null}", (int) '#', (long) 1, (org.apache.storm.spout.ISpout) strKafkaSpout3, headers63);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService80 = null;
        strKafkaSpout3.retryService = kafkaSpoutRetryService80;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy82 = null;
        strKafkaSpout3.firstPollOffsetStrategy = firstPollOffsetStrategy82;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer84 = strKafkaSpout3.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder85 = strKafkaSpout3.tuplesBuilder;
        boolean boolean86 = strKafkaSpout3.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams87 = null;
        strKafkaSpout3.kafkaSpoutStreams = kafkaSpoutStreams87;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer89 = strKafkaSpout3.commitTimer;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean90 = strKafkaSpout3.commit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(strKafkaConsumer11);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet28);
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + (-1) + "'", int43 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence44 + "' != '" + "" + "'", charSequence44, "");
        org.junit.Assert.assertNotNull(headers45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray46);
        org.junit.Assert.assertTrue("'" + boolean48 + "' != '" + false + "'", boolean48 == false);
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + (-1) + "'", int61 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence62 + "' != '" + "" + "'", charSequence62, "");
        org.junit.Assert.assertNotNull(headers63);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + 0L + "'", long75 == 0L);
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + (-1) + "'", int76 == (-1));
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertNull(timer84);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder85);
        org.junit.Assert.assertTrue("'" + boolean86 + "' != '" + false + "'", boolean86 == false);
        org.junit.Assert.assertNull(timer89);
    }

    @Test
    public void test6558() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6558");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = offsetComparator7.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator7.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator13.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator20 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator20;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = kafkaSpoutMessageIdComparator15.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator15.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator7.thenComparing(kafkaSpoutMessageIdComparator24);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator7.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator31 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator31;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator31.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = kafkaSpoutMessageIdComparator26.thenComparing(kafkaSpoutMessageIdComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = kafkaSpoutMessageIdComparator34.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = kafkaSpoutMessageIdComparator34.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator37;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
    }

    @Test
    public void test6559() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6559");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator1 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator1;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator3 = offsetComparator1.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator8 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator8;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator8);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = kafkaSpoutMessageIdComparator3.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator8);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator11);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator3);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
    }

    @Test
    public void test6560() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6560");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) '#', 10L, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)", "ConsumerRecord(topic = , partition = 52, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test6561() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6561");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer10 = strKafkaSpout0.commitTimer;
        org.apache.kafka.common.TopicPartition topicPartition11 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection12 = strKafkaSpout0.toArrayList(topicPartition11);
        strKafkaSpout0.initialized = false;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer15 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout16 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean17 = strKafkaSpout16.waitingToEmit();
        strKafkaSpout16.maxRetries = 1;
        boolean boolean20 = strKafkaSpout16.consumerAutoCommitMode;
        boolean boolean21 = strKafkaSpout16.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService22 = null;
        strKafkaSpout16.retryService = kafkaSpoutRetryService22;
        strKafkaSpout16.numUncommittedOffsets = (-1L);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout26 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout26.maxRetries = (short) 0;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy29 = strKafkaSpout26.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout30 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout30.maxRetries = (byte) -1;
        int int33 = strKafkaSpout30.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray34 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet35 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean36 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet35, kafkaSpoutMessageIdArray34);
        strKafkaSpout30.emitted = kafkaSpoutMessageIdSet35;
        strKafkaSpout26.emitted = kafkaSpoutMessageIdSet35;
        strKafkaSpout16.emitted = kafkaSpoutMessageIdSet35;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService40 = strKafkaSpout16.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy41 = strKafkaSpout16.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService42 = null;
        strKafkaSpout16.retryService = kafkaSpoutRetryService42;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.fail((java.lang.Object) strKafkaSpout16);
            org.junit.Assert.fail("Expected exception of type java.lang.ClassCastException; message: org.apache.storm.kafka.spout.KafkaSpout cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId");
        } catch (java.lang.ClassCastException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(spoutOutputCollector9);
        org.junit.Assert.assertNull(timer10);
        org.junit.Assert.assertNotNull(topicPartitionCollection12);
        org.junit.Assert.assertNull(strKafkaConsumer15);
        org.junit.Assert.assertTrue("'" + boolean17 + "' != '" + false + "'", boolean17 == false);
        org.junit.Assert.assertTrue("'" + boolean20 + "' != '" + false + "'", boolean20 == false);
        org.junit.Assert.assertTrue("'" + boolean21 + "' != '" + false + "'", boolean21 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy29);
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + (-1) + "'", int33 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray34);
        org.junit.Assert.assertTrue("'" + boolean36 + "' != '" + false + "'", boolean36 == false);
        org.junit.Assert.assertNull(kafkaSpoutRetryService40);
        org.junit.Assert.assertNull(firstPollOffsetStrategy41);
    }

    @Test
    public void test6562() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6562");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) 100, (long) 0, (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        int int7 = charSequenceConsumerRecord5.partition();
        int int8 = charSequenceConsumerRecord5.partition();
        java.lang.String str9 = charSequenceConsumerRecord5.topic();
        java.util.Optional<java.lang.Integer> intOptional10 = charSequenceConsumerRecord5.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 100 + "'", int8 == 100);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str9, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(intOptional10);
    }

    @Test
    public void test6563() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6563");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.offset();
        java.lang.CharSequence charSequence14 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertEquals("'" + charSequence14 + "' != '" + "" + "'", charSequence14, "");
    }

    @Test
    public void test6564() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6564");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
    }

    @Test
    public void test6565() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6565");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        java.lang.String str17 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.header.Headers headers18 = charSequenceConsumerRecord10.headers();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertNotNull(headers18);
        org.junit.Assert.assertNotNull(intOptional19);
    }

    @Test
    public void test6566() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6566");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) 100, (long) 0, (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.apache.kafka.common.record.TimestampType timestampType6 = charSequenceConsumerRecord5.timestampType();
        org.apache.kafka.common.header.Headers headers7 = charSequenceConsumerRecord5.headers();
        long long8 = charSequenceConsumerRecord5.offset();
        java.util.Optional<java.lang.Integer> intOptional9 = charSequenceConsumerRecord5.leaderEpoch();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers7);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 0L + "'", long8 == 0L);
        org.junit.Assert.assertNotNull(intOptional9);
    }

    @Test
    public void test6567() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6567");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        java.lang.CharSequence charSequence18 = charSequenceConsumerRecord10.key();
        java.lang.String str19 = charSequenceConsumerRecord10.toString();
        long long20 = charSequenceConsumerRecord10.offset();
        long long21 = charSequenceConsumerRecord10.checksum();
        long long22 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertEquals("'" + charSequence18 + "' != '" + "" + "'", charSequence18, "");
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 0L + "'", long20 == 0L);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 0L + "'", long22 == 0L);
    }

    @Test
    public void test6568() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6568");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        int int13 = charSequenceConsumerRecord10.partition();
        java.lang.String str14 = charSequenceConsumerRecord10.topic();
        long long15 = charSequenceConsumerRecord10.timestamp();
        long long16 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
    }

    @Test
    public void test6569() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6569");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        int int20 = charSequenceConsumerRecord10.serializedKeySize();
        long long21 = charSequenceConsumerRecord10.timestamp();
        int int22 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.header.Headers headers23 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 52 + "'", int20 == 52);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 52 + "'", int22 == 52);
        org.junit.Assert.assertNotNull(headers23);
    }

    @Test
    public void test6570() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6570");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams6 = strKafkaSpout0.kafkaSpoutStreams;
        boolean boolean7 = strKafkaSpout0.waitingToEmit();
        int int8 = strKafkaSpout0.maxRetries;
        boolean boolean9 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder10 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder10;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Map<java.lang.String, java.lang.Object> strMap12 = strKafkaSpout0.getComponentConfiguration();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + 0 + "'", int3 == 0);
        org.junit.Assert.assertNull(kafkaSpoutStreams6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 0 + "'", int8 == 0);
        org.junit.Assert.assertTrue("'" + boolean9 + "' != '" + false + "'", boolean9 == false);
    }

    @Test
    public void test6571() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6571");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig3 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService7 = strKafkaSpout0.retryService;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer8 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer8;
        boolean boolean10 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor11 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor11;
        org.junit.Assert.assertNull(kafkaSpoutRetryService7);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
    }

    @Test
    public void test6572() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6572");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder2 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder2;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
    }

    @Test
    public void test6573() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6573");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = strKafkaSpout0.kafkaConsumer;
        strKafkaSpout0.maxRetries = (byte) 100;
        boolean boolean7 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = 0;
        boolean boolean11 = strKafkaSpout0.initialized;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer4);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
    }

    @Test
    public void test6574() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6574");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType13 = charSequenceConsumerRecord10.timestampType();
        int int14 = charSequenceConsumerRecord10.partition();
        int int15 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional16 = charSequenceConsumerRecord10.leaderEpoch();
        int int17 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNull(timestampType13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
    }

    @Test
    public void test6575() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6575");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        int int12 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder13;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService15 = strKafkaSpout0.retryService;
        boolean boolean16 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector17 = strKafkaSpout0.collector;
        boolean boolean18 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy19 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy19;
        strKafkaSpout0.maxRetries = 10;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService15);
        org.junit.Assert.assertTrue("'" + boolean16 + "' != '" + false + "'", boolean16 == false);
        org.junit.Assert.assertNull(spoutOutputCollector17);
        org.junit.Assert.assertTrue("'" + boolean18 + "' != '" + false + "'", boolean18 == false);
    }

    @Test
    public void test6576() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6576");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        int int12 = strKafkaSpout0.maxRetries;
        long long13 = strKafkaSpout0.numUncommittedOffsets;
        java.lang.String str14 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams15 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams15;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor17 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor17;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig19 = strKafkaSpout0.kafkaSpoutConfig;
        java.lang.Class<?> wildcardClass20 = strKafkaSpout0.getClass();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str14, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutConfig19);
        org.junit.Assert.assertNotNull(wildcardClass20);
    }

    @Test
    public void test6577() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6577");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)", (int) (byte) 10, (long) (byte) -1, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
    }

    @Test
    public void test6578() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6578");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder6 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder6;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords9 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords9);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutStreams8);
    }

    @Test
    public void test6579() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6579");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = strKafkaSpout0.tuplesBuilder;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor10 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = ' ';
        boolean boolean13 = strKafkaSpout0.waitingToEmit();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder9);
        org.junit.Assert.assertNull(strConsumerRecordItor10);
        org.junit.Assert.assertTrue("'" + boolean13 + "' != '" + false + "'", boolean13 == false);
    }

    @Test
    public void test6580() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6580");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder2 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams3 = strKafkaSpout0.kafkaSpoutStreams;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService6;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer8 = strKafkaSpout0.kafkaConsumer;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder2);
        org.junit.Assert.assertNull(kafkaSpoutStreams3);
        org.junit.Assert.assertNull(strKafkaConsumer8);
    }

    @Test
    public void test6581() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6581");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, 10L, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        java.lang.String str6 = charSequenceConsumerRecord5.topic();
        org.apache.kafka.common.header.Headers headers7 = charSequenceConsumerRecord5.headers();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str6, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers7);
    }

    @Test
    public void test6582() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6582");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.offset();
        java.lang.String str16 = charSequenceConsumerRecord10.toString();
        int int17 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 0L + "'", long15 == 0L);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 52 + "'", int17 == 52);
    }

    @Test
    public void test6583() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6583");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.initialized = false;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector10 = strKafkaSpout0.collector;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams13 = strKafkaSpout0.kafkaSpoutStreams;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(spoutOutputCollector10);
        org.junit.Assert.assertNull(kafkaSpoutStreams13);
    }

    @Test
    public void test6584() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6584");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer6 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder7;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig9 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig9;
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer6);
    }

    @Test
    public void test6585() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6585");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer5 = strKafkaSpout0.commitTimer;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        long long8 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams9 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams9;
        int int11 = strKafkaSpout0.maxRetries;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(strConsumerRecordItor4);
        org.junit.Assert.assertNull(timer5);
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 0L + "'", long8 == 0L);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 0 + "'", int11 == 0);
    }

    @Test
    public void test6586() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6586");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator1 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator1;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator3 = offsetComparator1.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator8 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator8;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator8);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = kafkaSpoutMessageIdComparator3.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator8);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator11);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator13.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator20 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator20;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = kafkaSpoutMessageIdComparator15.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator20);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator24 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator24;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator24.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator31 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator31;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = kafkaSpoutMessageIdComparator26.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = kafkaSpoutMessageIdComparator15.thenComparing(kafkaSpoutMessageIdComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = kafkaSpoutMessageIdComparator12.thenComparing(kafkaSpoutMessageIdComparator35);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator37 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator37;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = offsetComparator37.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator37;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator41 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator41;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator43 = offsetComparator41.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = offsetComparator37.thenComparing(kafkaSpoutMessageIdComparator43);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator45 = kafkaSpoutMessageIdComparator12.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator37);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator37;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator3);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator43);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator45);
    }

    @Test
    public void test6587() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6587");
        java.lang.CharSequence charSequence3 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) '4', (long) 100, charSequence3, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.apache.kafka.common.header.Headers headers6 = charSequenceConsumerRecord5.headers();
        org.junit.Assert.assertNotNull(headers6);
    }

    @Test
    public void test6588() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6588");
        org.apache.storm.kafka.spout.KafkaSpout kafkaSpout0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>>.KafkaSpoutConsumerRebalanceListener kafkaSpoutConsumerRebalanceListener1 = kafkaSpout0.new KafkaSpoutConsumerRebalanceListener();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: reflection call to org.apache.storm.kafka.spout.KafkaSpout$KafkaSpoutConsumerRebalanceListener with null for superclass argument");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test6589() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6589");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator3 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator3;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator5 = offsetComparator3.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator10 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator10;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator10);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = kafkaSpoutMessageIdComparator5.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator10);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = offsetComparator10.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator10.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator16 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator16;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = offsetComparator16.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator23;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = kafkaSpoutMessageIdComparator18.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = kafkaSpoutMessageIdComparator18.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = offsetComparator10.thenComparing(kafkaSpoutMessageIdComparator27);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = offsetComparator10.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = offsetComparator10.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator30);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator32 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator33 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator33;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = offsetComparator33.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator40 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator40;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator40);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator43 = kafkaSpoutMessageIdComparator35.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator40);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator44 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator44;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator46 = offsetComparator44.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator47 = offsetComparator44.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator48 = offsetComparator40.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator44);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator49 = offsetComparator32.thenComparing(kafkaSpoutMessageIdComparator48);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator50 = kafkaSpoutMessageIdComparator30.thenComparing(kafkaSpoutMessageIdComparator49);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator30;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator5);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator43);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator46);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator47);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator48);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator49);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator50);
    }

    @Test
    public void test6590() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6590");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) ' ', (long) (byte) 100, (long) (byte) -1, timestampType4, (long) (byte) -1, (int) (byte) 10, 10, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long11 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str12 = charSequenceConsumerRecord10.toString();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional15 = charSequenceConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional16 = charSequenceConsumerRecord10.leaderEpoch();
        long long17 = charSequenceConsumerRecord10.checksum();
        java.lang.CharSequence charSequence18 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str12, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence18 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", charSequence18, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test6591() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6591");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        int int13 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        int int15 = charSequenceConsumerRecord10.serializedValueSize();
        int int16 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        int int18 = charSequenceConsumerRecord10.serializedValueSize();
        int int19 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 52 + "'", int13 == 52);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + (-1) + "'", int18 == (-1));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
    }

    @Test
    public void test6592() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6592");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (byte) 1, (long) 52, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=[]}", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
    }

    @Test
    public void test6593() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6593");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 1, 1L, (long) (byte) 10, timestampType4, (long) '#', (int) (byte) 100, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str13 = charSequenceConsumerRecord10.toString();
        java.lang.Class<?> wildcardClass14 = charSequenceConsumerRecord10.getClass();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 10L + "'", long11 == 10L);
        org.junit.Assert.assertNull(timestampType12);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )" + "'", str13, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )");
        org.junit.Assert.assertNotNull(wildcardClass14);
    }

    @Test
    public void test6594() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6594");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = 35, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)", (int) (short) -1, (long) (short) 10, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
        java.lang.String str6 = charSequenceConsumerRecord5.topic();
        java.lang.CharSequence charSequence7 = charSequenceConsumerRecord5.key();
        java.lang.String str8 = charSequenceConsumerRecord5.topic();
        int int9 = charSequenceConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = 35, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)" + "'", str6, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = 35, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)");
        org.junit.Assert.assertEquals("'" + charSequence7 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", charSequence7, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = 35, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)" + "'", str8, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = 35, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)");
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
    }

    @Test
    public void test6595() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6595");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        int int12 = strKafkaSpout0.maxRetries;
        long long13 = strKafkaSpout0.numUncommittedOffsets;
        java.lang.String str14 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams15 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams15;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor17 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor17;
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType23, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long30 = charSequenceConsumerRecord29.checksum();
        int int31 = charSequenceConsumerRecord29.partition();
        long long32 = charSequenceConsumerRecord29.timestamp();
        long long33 = charSequenceConsumerRecord29.offset();
        int int34 = charSequenceConsumerRecord29.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType35 = charSequenceConsumerRecord29.timestampType();
        int int36 = charSequenceConsumerRecord29.partition();
        long long37 = charSequenceConsumerRecord29.offset();
        int int38 = charSequenceConsumerRecord29.partition();
        int int39 = charSequenceConsumerRecord29.serializedKeySize();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.ack((java.lang.Object) int39);
            org.junit.Assert.fail("Expected exception of type java.lang.ClassCastException; message: java.lang.Integer cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId");
        } catch (java.lang.ClassCastException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str14, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 10 + "'", int31 == 10);
        org.junit.Assert.assertTrue("'" + long32 + "' != '" + (-1L) + "'", long32 == (-1L));
        org.junit.Assert.assertTrue("'" + long33 + "' != '" + 0L + "'", long33 == 0L);
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + 52 + "'", int34 == 52);
        org.junit.Assert.assertNull(timestampType35);
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + 10 + "'", int36 == 10);
        org.junit.Assert.assertTrue("'" + long37 + "' != '" + 0L + "'", long37 == 0L);
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + 10 + "'", int38 == 10);
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + 52 + "'", int39 == 52);
    }

    @Test
    public void test6596() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6596");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        int int9 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.maxRetries = (byte) 100;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams13 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer15 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer15;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertNull(spoutOutputCollector12);
    }

    @Test
    public void test6597() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6597");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.timestamp();
        long long19 = charSequenceConsumerRecord10.offset();
        int int20 = charSequenceConsumerRecord10.partition();
        java.lang.String str21 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.record.TimestampType timestampType22 = charSequenceConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 10 + "'", int20 == 10);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "" + "'", str21, "");
        org.junit.Assert.assertNull(timestampType22);
    }

    @Test
    public void test6598() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6598");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) '4', (long) 'a', (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "");
        org.apache.kafka.common.record.TimestampType timestampType10 = charSequenceConsumerRecord9.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout14 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams15 = strKafkaSpout14.kafkaSpoutStreams;
        strKafkaSpout14.consumerAutoCommitMode = false;
        strKafkaSpout14.maxRetries = (byte) -1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer20 = null;
        strKafkaSpout14.kafkaConsumer = strKafkaConsumer20;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector22 = strKafkaSpout14.collector;
        strKafkaSpout14.maxRetries = 97;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService25 = strKafkaSpout14.retryService;
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, java.lang.Comparable<java.lang.String>> iSpoutConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}))", 52, (long) 0, (long) 32, timestampType10, (long) 100, (-1), 52, (org.apache.storm.spout.ISpout) strKafkaSpout14, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer28 = strKafkaSpout14.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig29 = null;
        strKafkaSpout14.kafkaSpoutConfig = strKafkaSpoutConfig29;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords31 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout14.setWaitingToEmit(strConsumerRecords31);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNull(kafkaSpoutStreams15);
        org.junit.Assert.assertNull(spoutOutputCollector22);
        org.junit.Assert.assertNull(kafkaSpoutRetryService25);
        org.junit.Assert.assertNull(timer28);
    }

    @Test
    public void test6599() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6599");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.offset();
        int int19 = charSequenceConsumerRecord10.partition();
        int int20 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.String str21 = charSequenceConsumerRecord10.topic();
        int int22 = charSequenceConsumerRecord10.serializedKeySize();
        long long23 = charSequenceConsumerRecord10.timestamp();
        int int24 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 52 + "'", int20 == 52);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "" + "'", str21, "");
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 52 + "'", int22 == 52);
        org.junit.Assert.assertTrue("'" + long23 + "' != '" + (-1L) + "'", long23 == (-1L));
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + 10 + "'", int24 == 10);
    }

    @Test
    public void test6600() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6600");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout11 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = strKafkaSpout11.kafkaSpoutStreams;
        strKafkaSpout11.consumerAutoCommitMode = false;
        java.lang.String str15 = strKafkaSpout11.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout16 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout16.maxRetries = (byte) -1;
        int int19 = strKafkaSpout16.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray20 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet21 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean22 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, kafkaSpoutMessageIdArray20);
        strKafkaSpout16.emitted = kafkaSpoutMessageIdSet21;
        strKafkaSpout11.emitted = kafkaSpoutMessageIdSet21;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout25 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout25.maxRetries = (byte) -1;
        int int28 = strKafkaSpout25.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor29 = null;
        strKafkaSpout25.waitingToEmit = strConsumerRecordItor29;
        org.apache.kafka.common.TopicPartition topicPartition31 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection32 = strKafkaSpout25.toArrayList(topicPartition31);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout25.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector34 = strKafkaSpout25.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout35.maxRetries = (byte) -1;
        int int38 = strKafkaSpout35.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray39 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet40 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean41 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40, kafkaSpoutMessageIdArray39);
        strKafkaSpout35.emitted = kafkaSpoutMessageIdSet40;
        strKafkaSpout25.emitted = kafkaSpoutMessageIdSet40;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType7, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet40;
        strKafkaSpout0.maxRetries = '4';
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet48 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor49 = strKafkaSpout0.waitingToEmit;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(strKafkaSpoutConfig2);
        org.junit.Assert.assertNull(kafkaSpoutStreams12);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray20);
        org.junit.Assert.assertTrue("'" + boolean22 + "' != '" + false + "'", boolean22 == false);
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + (-1) + "'", int28 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection32);
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(spoutOutputCollector34);
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + (-1) + "'", int38 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray39);
        org.junit.Assert.assertTrue("'" + boolean41 + "' != '" + false + "'", boolean41 == false);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdSet48);
        org.junit.Assert.assertNull(strConsumerRecordItor49);
    }

    @Test
    public void test6601() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6601");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer10 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy11 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.initialized = false;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector15 = null;
        strKafkaSpout0.collector = spoutOutputCollector15;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig17 = strKafkaSpout0.kafkaSpoutConfig;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(spoutOutputCollector9);
        org.junit.Assert.assertNull(timer10);
        org.junit.Assert.assertNull(firstPollOffsetStrategy11);
        org.junit.Assert.assertNull(kafkaSpoutStreams12);
        org.junit.Assert.assertNull(strKafkaSpoutConfig17);
    }

    @Test
    public void test6602() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6602");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator14 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator14;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator14.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = offsetComparator13.thenComparing(kafkaSpoutMessageIdComparator16);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = offsetComparator11.thenComparing(kafkaSpoutMessageIdComparator17);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = offsetComparator7.thenComparing(kafkaSpoutMessageIdComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = kafkaSpoutMessageIdComparator19.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator21 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator21;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = offsetComparator21.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator28 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator28;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator28);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = kafkaSpoutMessageIdComparator23.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator28);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = offsetComparator28.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator33 = kafkaSpoutMessageIdComparator32.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = kafkaSpoutMessageIdComparator20.thenComparing(kafkaSpoutMessageIdComparator32);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator34;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = kafkaSpoutMessageIdComparator34.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = kafkaSpoutMessageIdComparator36.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator33);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
    }

    @Test
    public void test6603() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6603");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        int int18 = charSequenceConsumerRecord10.partition();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str20 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 10 + "'", int18 == 10);
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "" + "'", str20, "");
    }

    @Test
    public void test6604() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6604");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = strKafkaSpout0.firstPollOffsetStrategy;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer9 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer9;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = strKafkaSpout0.collector;
        long long12 = strKafkaSpout0.numUncommittedOffsets;
        java.lang.String str13 = strKafkaSpout0.toString();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.activate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 0 + "'", int8 == 0);
        org.junit.Assert.assertNull(spoutOutputCollector11);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 0L + "'", long12 == 0L);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str13, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test6605() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6605");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer8 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder10 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder10;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = strKafkaSpout0.collector;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor13 = strKafkaSpout0.waitingToEmit;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer8);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder9);
        org.junit.Assert.assertNull(spoutOutputCollector12);
        org.junit.Assert.assertNull(strConsumerRecordItor13);
    }

    @Test
    public void test6606() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6606");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 1, 1L, (long) (byte) 10, timestampType4, (long) '#', (int) (byte) 100, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        int int11 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.header.Headers headers12 = charSequenceConsumerRecord10.headers();
        long long13 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 1 + "'", int11 == 1);
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 35L + "'", long13 == 35L);
    }

    @Test
    public void test6607() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6607");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet4 = strKafkaSpout0.emitted;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy6 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy6;
        boolean boolean8 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = strKafkaSpout0.retryService;
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
        org.junit.Assert.assertNull(kafkaSpoutRetryService9);
    }

    @Test
    public void test6608() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6608");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = ' ';
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig10 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig10;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer12 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService13 = strKafkaSpout0.retryService;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertNull(timer12);
        org.junit.Assert.assertNull(kafkaSpoutRetryService13);
    }

    @Test
    public void test6609() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6609");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType14, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long21 = charSequenceConsumerRecord20.checksum();
        int int22 = charSequenceConsumerRecord20.partition();
        long long23 = charSequenceConsumerRecord20.timestamp();
        long long24 = charSequenceConsumerRecord20.offset();
        int int25 = charSequenceConsumerRecord20.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType26 = charSequenceConsumerRecord20.timestampType();
        int int27 = charSequenceConsumerRecord20.partition();
        long long28 = charSequenceConsumerRecord20.checksum();
        int int29 = charSequenceConsumerRecord20.partition();
        org.apache.kafka.common.header.Headers headers30 = charSequenceConsumerRecord20.headers();
        org.apache.kafka.common.record.TimestampType timestampType35 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType35, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long42 = charSequenceConsumerRecord41.checksum();
        java.util.Optional<java.lang.Integer> intOptional43 = charSequenceConsumerRecord41.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = 35, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)", 0, (long) (-1), (long) (byte) 0, timestampType4, (java.lang.Long) 32L, (int) (short) -1, (int) (short) 10, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "", headers30, intOptional43);
        long long45 = charSequenceConsumerRecord44.checksum();
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 10 + "'", int22 == 10);
        org.junit.Assert.assertTrue("'" + long23 + "' != '" + (-1L) + "'", long23 == (-1L));
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 0L + "'", long24 == 0L);
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + 52 + "'", int25 == 52);
        org.junit.Assert.assertNull(timestampType26);
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + 10 + "'", int27 == 10);
        org.junit.Assert.assertTrue("'" + long28 + "' != '" + (-1L) + "'", long28 == (-1L));
        org.junit.Assert.assertTrue("'" + int29 + "' != '" + 10 + "'", int29 == 10);
        org.junit.Assert.assertNotNull(headers30);
        org.junit.Assert.assertTrue("'" + long42 + "' != '" + (-1L) + "'", long42 == (-1L));
        org.junit.Assert.assertNotNull(intOptional43);
        org.junit.Assert.assertTrue("'" + long45 + "' != '" + 32L + "'", long45 == 32L);
    }

    @Test
    public void test6610() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6610");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str19 = charSequenceConsumerRecord10.value();
        java.lang.String str20 = charSequenceConsumerRecord10.value();
        long long21 = charSequenceConsumerRecord10.offset();
        int int22 = charSequenceConsumerRecord10.serializedKeySize();
        long long23 = charSequenceConsumerRecord10.timestamp();
        int int24 = charSequenceConsumerRecord10.serializedValueSize();
        long long25 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 0L + "'", long21 == 0L);
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 52 + "'", int22 == 52);
        org.junit.Assert.assertTrue("'" + long23 + "' != '" + (-1L) + "'", long23 == (-1L));
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + 0L + "'", long25 == 0L);
    }

    @Test
    public void test6611() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6611");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", (int) '4', (long) 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})");
    }

    @Test
    public void test6612() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6612");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional21 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str22 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertNotNull(intOptional21);
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "hi!" + "'", str22, "hi!");
    }

    @Test
    public void test6613() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6613");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService6;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder8;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy10 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy10;
        boolean boolean12 = strKafkaSpout0.waitingToEmit();
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str13 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + false + "'", boolean12 == false);
    }

    @Test
    public void test6614() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6614");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        strKafkaSpout0.maxRetries = (short) 0;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
    }

    @Test
    public void test6615() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6615");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        java.util.Optional<java.lang.Integer> intOptional16 = charSequenceConsumerRecord10.leaderEpoch();
        long long17 = charSequenceConsumerRecord10.offset();
        long long18 = charSequenceConsumerRecord10.checksum();
        int int19 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 52 + "'", int19 == 52);
    }

    @Test
    public void test6616() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6616");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        boolean boolean6 = strKafkaSpout0.waitingToEmit();
        org.apache.kafka.common.TopicPartition topicPartition7 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection8 = strKafkaSpout0.toArrayList(topicPartition7);
        boolean boolean9 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams10;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams12;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor14 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor14;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer16 = strKafkaSpout0.commitTimer;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection8);
        org.junit.Assert.assertTrue("'" + boolean9 + "' != '" + false + "'", boolean9 == false);
        org.junit.Assert.assertNull(timer16);
    }

    @Test
    public void test6617() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6617");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) -1, (long) (-1), (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        java.lang.CharSequence charSequence6 = charSequenceConsumerRecord5.key();
        int int7 = charSequenceConsumerRecord5.serializedValueSize();
        java.lang.CharSequence charSequence8 = charSequenceConsumerRecord5.key();
        org.junit.Assert.assertEquals("'" + charSequence6 + "' != '" + "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", charSequence6, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence8 + "' != '" + "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", charSequence8, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
    }

    @Test
    public void test6618() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6618");
        org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, org.apache.storm.topology.base.BaseRichSpout> serializableKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.io.Serializable, org.apache.storm.topology.base.BaseRichSpout>();
    }

    @Test
    public void test6619() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6619");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy11 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy11;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig13 = strKafkaSpout0.kafkaSpoutConfig;
        int int14 = strKafkaSpout0.maxRetries;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector15 = strKafkaSpout0.collector;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(strKafkaSpoutConfig13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertNull(spoutOutputCollector15);
    }

    @Test
    public void test6620() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6620");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        java.lang.String str4 = strKafkaSpout0.toString();
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer7;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = strKafkaSpout0.retryService;
        boolean boolean11 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer12 = strKafkaSpout0.kafkaConsumer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor13 = strKafkaSpout0.waitingToEmit;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertEquals("'" + str4 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str4, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(firstPollOffsetStrategy9);
        org.junit.Assert.assertNull(kafkaSpoutRetryService10);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + true + "'", boolean11 == true);
        org.junit.Assert.assertNull(strKafkaConsumer12);
        org.junit.Assert.assertNull(strConsumerRecordItor13);
    }

    @Test
    public void test6621() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6621");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer10;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder12 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder12;
        int int14 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer15 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder16 = strKafkaSpout0.tuplesBuilder;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 0 + "'", int14 == 0);
        org.junit.Assert.assertNull(strKafkaConsumer15);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder16);
    }

    @Test
    public void test6622() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6622");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.offset();
        int int19 = charSequenceConsumerRecord10.partition();
        int int20 = charSequenceConsumerRecord10.serializedKeySize();
        int int21 = charSequenceConsumerRecord10.serializedKeySize();
        long long22 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 52 + "'", int20 == 52);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 52 + "'", int21 == 52);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
        org.junit.Assert.assertNull(timestampType23);
    }

    @Test
    public void test6623() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6623");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator3 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator3;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator5 = offsetComparator3.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator10 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator10;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator10);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = kafkaSpoutMessageIdComparator5.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator10);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator14 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator14;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator14.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator21 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator21;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator21);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator16.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator21);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = kafkaSpoutMessageIdComparator5.thenComparing(kafkaSpoutMessageIdComparator24);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator26 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = offsetComparator26.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = offsetComparator26.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = kafkaSpoutMessageIdComparator24.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator26);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator, java.lang.Comparable<java.lang.String>> offsetComparatorConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, 1L, offsetComparator26, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = offsetComparator26.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = offsetComparator26.reversed();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId38 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId39 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int40 = offsetComparator26.compare(kafkaSpoutMessageId38, kafkaSpoutMessageId39);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator5);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
    }

    @Test
    public void test6624() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6624");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.header.Headers headers20 = charSequenceConsumerRecord10.headers();
        java.lang.String str21 = charSequenceConsumerRecord10.value();
        int int22 = charSequenceConsumerRecord10.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional23 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.header.Headers headers24 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "hi!" + "'", str21, "hi!");
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 52 + "'", int22 == 52);
        org.junit.Assert.assertNotNull(intOptional23);
        org.junit.Assert.assertNotNull(headers24);
    }

    @Test
    public void test6625() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6625");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str19 = charSequenceConsumerRecord10.value();
        java.lang.CharSequence charSequence20 = charSequenceConsumerRecord10.key();
        long long21 = charSequenceConsumerRecord10.checksum();
        org.apache.kafka.common.record.TimestampType timestampType22 = charSequenceConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
        org.junit.Assert.assertEquals("'" + charSequence20 + "' != '" + "" + "'", charSequence20, "");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertNull(timestampType22);
    }

    @Test
    public void test6626() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6626");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str19 = charSequenceConsumerRecord10.value();
        java.lang.String str20 = charSequenceConsumerRecord10.value();
        java.lang.String str21 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.record.TimestampType timestampType22 = charSequenceConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "" + "'", str21, "");
        org.junit.Assert.assertNull(timestampType22);
    }

    @Test
    public void test6627() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6627");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = ' ';
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy10 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy10;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.activate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
    }

    @Test
    public void test6628() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6628");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator1 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator1;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator3 = offsetComparator1.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator4 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator3);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator5 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator5;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator5.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator12 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator12;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = kafkaSpoutMessageIdComparator7.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = kafkaSpoutMessageIdComparator7.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = kafkaSpoutMessageIdComparator4.thenComparing(kafkaSpoutMessageIdComparator16);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = offsetComparator18.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator25 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator25;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator25);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = kafkaSpoutMessageIdComparator20.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator25);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator29 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator29;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator31 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator32 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator32;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator32.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = offsetComparator31.thenComparing(kafkaSpoutMessageIdComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = offsetComparator29.thenComparing(kafkaSpoutMessageIdComparator35);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = offsetComparator25.thenComparing(kafkaSpoutMessageIdComparator36);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator38 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator39 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator39;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = offsetComparator39.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator42 = offsetComparator38.thenComparing(kafkaSpoutMessageIdComparator41);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator43 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator43;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator45 = offsetComparator43.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator50 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator50;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator50);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator53 = kafkaSpoutMessageIdComparator45.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator50);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator54 = offsetComparator38.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator50);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator54;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator56 = kafkaSpoutMessageIdComparator54.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator57 = kafkaSpoutMessageIdComparator37.thenComparing(kafkaSpoutMessageIdComparator54);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator58 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator58;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator60 = offsetComparator58.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator65 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator65;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator65);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator68 = kafkaSpoutMessageIdComparator60.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator65);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator69 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator69;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator71 = offsetComparator69.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator76 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator76;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator76);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator79 = kafkaSpoutMessageIdComparator71.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator76);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator80 = kafkaSpoutMessageIdComparator60.thenComparing(kafkaSpoutMessageIdComparator79);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator81 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator81;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator83 = offsetComparator81.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator84 = offsetComparator81.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator85 = kafkaSpoutMessageIdComparator79.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator81);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator86 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator86;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator88 = offsetComparator86.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator86;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator90 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator90;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator92 = offsetComparator90.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator93 = offsetComparator86.thenComparing(kafkaSpoutMessageIdComparator92);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator94 = kafkaSpoutMessageIdComparator92.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator95 = kafkaSpoutMessageIdComparator79.thenComparing(kafkaSpoutMessageIdComparator92);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator92;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator97 = kafkaSpoutMessageIdComparator37.thenComparing(kafkaSpoutMessageIdComparator92);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator98 = kafkaSpoutMessageIdComparator16.thenComparing(kafkaSpoutMessageIdComparator97);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator99 = kafkaSpoutMessageIdComparator98.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator3);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator4);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator42);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator53);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator54);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator56);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator57);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator60);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator68);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator71);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator79);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator80);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator83);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator84);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator85);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator88);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator92);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator93);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator94);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator95);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator97);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator98);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator99);
    }

    @Test
    public void test6629() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6629");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer9 = strKafkaSpout0.kafkaConsumer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor10 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor10;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams12;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer14 = strKafkaSpout0.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector15 = null;
        strKafkaSpout0.collector = spoutOutputCollector15;
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertNull(strKafkaConsumer9);
        org.junit.Assert.assertNull(timer14);
    }

    @Test
    public void test6630() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6630");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 0, leaderEpoch = null, offset = -1, null = 100, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", 32, (long) 0, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 97, leaderEpoch = null, offset = 100, NoTimestampType = 97, serialized key size = 97, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=[]}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.apache.kafka.common.header.Headers headers6 = charSequenceConsumerRecord5.headers();
        org.junit.Assert.assertNotNull(headers6);
    }

    @Test
    public void test6631() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6631");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str19 = charSequenceConsumerRecord10.toString();
        java.lang.String str20 = charSequenceConsumerRecord10.topic();
        int int21 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional22 = charSequenceConsumerRecord10.leaderEpoch();
        int int23 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "" + "'", str20, "");
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertNotNull(intOptional22);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
    }

    @Test
    public void test6632() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6632");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer1 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy2 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams3 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams3;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder5 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder5;
        boolean boolean7 = strKafkaSpout0.waitingToEmit();
        java.lang.String str8 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams9 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams9;
        org.junit.Assert.assertNull(timer1);
        org.junit.Assert.assertNull(firstPollOffsetStrategy2);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test6633() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6633");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        java.lang.String str8 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer9 = strKafkaSpout0.commitTimer;
        int int10 = strKafkaSpout0.maxRetries;
        boolean boolean11 = strKafkaSpout0.consumerAutoCommitMode;
        boolean boolean12 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition13 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection14 = strKafkaSpout0.toArrayList(topicPartition13);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(timer9);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 0 + "'", int10 == 0);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + false + "'", boolean12 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection14);
    }

    @Test
    public void test6634() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6634");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        long long8 = strKafkaSpout0.numUncommittedOffsets;
        strKafkaSpout0.numUncommittedOffsets = (-1L);
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams11 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService12 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService12;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet14 = strKafkaSpout0.emitted;
        int int15 = strKafkaSpout0.maxRetries;
        java.lang.Class<?> wildcardClass16 = strKafkaSpout0.getClass();
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 0L + "'", long8 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutStreams11);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet14);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 0 + "'", int15 == 0);
        org.junit.Assert.assertNotNull(wildcardClass16);
    }

    @Test
    public void test6635() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6635");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        int int11 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig12 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy13 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy13;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 0 + "'", int11 == 0);
        org.junit.Assert.assertNull(strKafkaSpoutConfig12);
    }

    @Test
    public void test6636() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6636");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator, java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> offsetComparatorKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator, java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> offsetComparatorKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator, java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>(offsetComparatorKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test6637() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6637");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType13 = charSequenceConsumerRecord10.timestampType();
        int int14 = charSequenceConsumerRecord10.partition();
        int int15 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str18 = charSequenceConsumerRecord10.topic();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        int int20 = charSequenceConsumerRecord10.serializedKeySize();
        long long21 = charSequenceConsumerRecord10.checksum();
        java.lang.String str22 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNull(timestampType13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 52 + "'", int20 == 52);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "hi!" + "'", str22, "hi!");
    }

    @Test
    public void test6638() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6638");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str26 = charSequenceConsumerRecord25.topic();
        org.apache.kafka.common.record.TimestampType timestampType27 = charSequenceConsumerRecord25.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout31 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout31.maxRetries = (byte) -1;
        int int34 = strKafkaSpout31.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor35 = null;
        strKafkaSpout31.waitingToEmit = strConsumerRecordItor35;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer37 = strKafkaSpout31.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer38 = strKafkaSpout31.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType44 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType44, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long51 = charSequenceConsumerRecord50.offset();
        long long52 = charSequenceConsumerRecord50.checksum();
        int int53 = charSequenceConsumerRecord50.serializedKeySize();
        org.apache.kafka.common.header.Headers headers54 = charSequenceConsumerRecord50.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType27, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout31, (java.lang.CharSequence) "hi!", headers54);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 1, 0L, (long) (byte) 0, timestampType27, (long) ' ', (int) (short) -1, (int) (byte) 10, (java.lang.CharSequence) "", "");
        java.lang.CharSequence charSequence62 = charSequenceConsumerRecord61.key();
        java.lang.String str63 = charSequenceConsumerRecord61.value();
        org.apache.kafka.common.record.TimestampType timestampType64 = charSequenceConsumerRecord61.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 10, (long) (short) 100, (long) (byte) 0, timestampType64, (long) ' ', (int) (short) 1, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", 10, (long) 52, (long) (short) 0, timestampType64, (long) (short) 10, (int) '4', 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.apache.kafka.common.record.TimestampType timestampType77 = charSequenceConsumerRecord76.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", 0, (long) 97, (long) (byte) 10, timestampType77, (long) 0, (int) (byte) 1, (int) '#', (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})");
        int int84 = charSequenceConsumerRecord83.serializedValueSize();
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "" + "'", str26, "");
        org.junit.Assert.assertTrue("'" + timestampType27 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType27.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + (-1) + "'", int34 == (-1));
        org.junit.Assert.assertNull(timer37);
        org.junit.Assert.assertNull(strKafkaConsumer38);
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + 0L + "'", long51 == 0L);
        org.junit.Assert.assertTrue("'" + long52 + "' != '" + (-1L) + "'", long52 == (-1L));
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + 52 + "'", int53 == 52);
        org.junit.Assert.assertNotNull(headers54);
        org.junit.Assert.assertEquals("'" + charSequence62 + "' != '" + "" + "'", charSequence62, "");
        org.junit.Assert.assertEquals("'" + str63 + "' != '" + "" + "'", str63, "");
        org.junit.Assert.assertTrue("'" + timestampType64 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType64.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType77 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType77.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int84 + "' != '" + 35 + "'", int84 == 35);
    }

    @Test
    public void test6639() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6639");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        long long15 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        java.lang.String str17 = charSequenceConsumerRecord10.value();
        java.lang.String str18 = charSequenceConsumerRecord10.topic();
        java.lang.String str19 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
    }

    @Test
    public void test6640() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6640");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator2 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator3 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator3;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator5 = offsetComparator3.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator6 = offsetComparator2.thenComparing(kafkaSpoutMessageIdComparator5);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator6);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator8 = offsetComparator0.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator9 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator10 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator10;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator10.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator17 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator17;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator17);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = kafkaSpoutMessageIdComparator12.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator17);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = offsetComparator17.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = offsetComparator17.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator22;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator24 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator24;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator24.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator31 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator31;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = kafkaSpoutMessageIdComparator26.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = kafkaSpoutMessageIdComparator26.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator36 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator37 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator37;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = offsetComparator37.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator44 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator44;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator44);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator47 = kafkaSpoutMessageIdComparator39.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator44);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator48 = offsetComparator36.thenComparing(kafkaSpoutMessageIdComparator47);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator49 = kafkaSpoutMessageIdComparator35.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator36);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator49;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator51 = kafkaSpoutMessageIdComparator22.thenComparing(kafkaSpoutMessageIdComparator49);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator52 = kafkaSpoutMessageIdComparator49.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator53 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator49);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId55 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId56 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int57 = offsetComparator0.compare(kafkaSpoutMessageId55, kafkaSpoutMessageId56);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator5);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator6);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator8);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator9);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator47);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator48);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator49);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator51);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator52);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator53);
    }

    @Test
    public void test6641() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6641");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        java.lang.String str13 = charSequenceConsumerRecord10.topic();
        int int14 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        int int16 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + (-1) + "'", int16 == (-1));
    }

    @Test
    public void test6642() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6642");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.emit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer10);
    }

    @Test
    public void test6643() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6643");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.String str16 = charSequenceConsumerRecord10.value();
        java.lang.String str17 = charSequenceConsumerRecord10.value();
        java.util.Optional<java.lang.Integer> intOptional18 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str19 = charSequenceConsumerRecord10.toString();
        long long20 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "hi!" + "'", str16, "hi!");
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertNotNull(intOptional18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 0L + "'", long20 == 0L);
    }

    @Test
    public void test6644() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6644");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator14 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator14;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator14.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = offsetComparator13.thenComparing(kafkaSpoutMessageIdComparator16);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = offsetComparator11.thenComparing(kafkaSpoutMessageIdComparator17);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = offsetComparator7.thenComparing(kafkaSpoutMessageIdComparator18);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator20 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator20;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = offsetComparator20.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator27 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator27;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator27);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = kafkaSpoutMessageIdComparator22.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator27);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = offsetComparator27.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = offsetComparator27.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator33 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator33;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = offsetComparator33.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator40 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator40;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator40);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator43 = kafkaSpoutMessageIdComparator35.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator40);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = kafkaSpoutMessageIdComparator35.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator45 = offsetComparator27.thenComparing(kafkaSpoutMessageIdComparator44);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator46 = kafkaSpoutMessageIdComparator44.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator47 = kafkaSpoutMessageIdComparator19.thenComparing(kafkaSpoutMessageIdComparator46);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator48 = kafkaSpoutMessageIdComparator19.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator43);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator46);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator47);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator48);
    }

    @Test
    public void test6645() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6645");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = strKafkaSpout0.tuplesBuilder;
        strKafkaSpout0.numUncommittedOffsets = 1L;
        strKafkaSpout0.maxRetries = 52;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder7);
    }

    @Test
    public void test6646() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6646");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        strKafkaSpout0.maxRetries = (short) 0;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = strKafkaSpout0.kafkaSpoutStreams;
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutStreams8);
    }

    @Test
    public void test6647() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6647");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        boolean boolean10 = strKafkaSpout0.consumerAutoCommitMode;
        boolean boolean11 = strKafkaSpout0.waitingToEmit();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.emit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
    }

    @Test
    public void test6648() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6648");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig5;
        strKafkaSpout0.maxRetries = (short) 0;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = strKafkaSpout0.tuplesBuilder;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder9);
    }

    @Test
    public void test6649() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6649");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str10 = charSequenceConsumerRecord9.topic();
        org.apache.kafka.common.record.TimestampType timestampType11 = charSequenceConsumerRecord9.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout15 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout15.maxRetries = (byte) -1;
        int int18 = strKafkaSpout15.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor19 = null;
        strKafkaSpout15.waitingToEmit = strConsumerRecordItor19;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer21 = strKafkaSpout15.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer22 = strKafkaSpout15.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType28 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType28, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long35 = charSequenceConsumerRecord34.offset();
        long long36 = charSequenceConsumerRecord34.checksum();
        int int37 = charSequenceConsumerRecord34.serializedKeySize();
        org.apache.kafka.common.header.Headers headers38 = charSequenceConsumerRecord34.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType11, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout15, (java.lang.CharSequence) "hi!", headers38);
        strKafkaSpout15.initialized = false;
        strKafkaSpout15.numUncommittedOffsets = 100L;
        java.lang.String str44 = strKafkaSpout15.toString();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService45 = strKafkaSpout15.retryService;
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "" + "'", str10, "");
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + (-1) + "'", int18 == (-1));
        org.junit.Assert.assertNull(timer21);
        org.junit.Assert.assertNull(strKafkaConsumer22);
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + 0L + "'", long35 == 0L);
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + (-1L) + "'", long36 == (-1L));
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + 52 + "'", int37 == 52);
        org.junit.Assert.assertNotNull(headers38);
        org.junit.Assert.assertEquals("'" + str44 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str44, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(kafkaSpoutRetryService45);
    }

    @Test
    public void test6650() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6650");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer16;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector18 = null;
        strKafkaSpout0.collector = spoutOutputCollector18;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout20 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout20.maxRetries = (byte) -1;
        int int23 = strKafkaSpout20.maxRetries;
        strKafkaSpout20.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray26 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet27 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean28 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet27, kafkaSpoutMessageIdArray26);
        strKafkaSpout20.emitted = kafkaSpoutMessageIdSet27;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet27;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean31 = strKafkaSpout0.poll();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray26);
        org.junit.Assert.assertTrue("'" + boolean28 + "' != '" + false + "'", boolean28 == false);
    }

    @Test
    public void test6651() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6651");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence17 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence18 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType20 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str21 = charSequenceConsumerRecord10.toString();
        int int22 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertEquals("'" + charSequence17 + "' != '" + "" + "'", charSequence17, "");
        org.junit.Assert.assertEquals("'" + charSequence18 + "' != '" + "" + "'", charSequence18, "");
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertNull(timestampType20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str21, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 10 + "'", int22 == 10);
    }

    @Test
    public void test6652() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6652");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        int int20 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType21 = charSequenceConsumerRecord10.timestampType();
        java.util.Optional<java.lang.Integer> intOptional22 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str23 = charSequenceConsumerRecord10.value();
        java.lang.String str24 = charSequenceConsumerRecord10.topic();
        java.lang.String str25 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 10 + "'", int20 == 10);
        org.junit.Assert.assertNull(timestampType21);
        org.junit.Assert.assertNotNull(intOptional22);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "hi!" + "'", str23, "hi!");
        org.junit.Assert.assertEquals("'" + str24 + "' != '" + "" + "'", str24, "");
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "hi!" + "'", str25, "hi!");
    }

    @Test
    public void test6653() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6653");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType4, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        java.lang.String str11 = charSequenceConsumerRecord10.topic();
        long long12 = charSequenceConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "hi!" + "'", str11, "hi!");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 35L + "'", long12 == 35L);
        org.junit.Assert.assertNotNull(intOptional13);
    }

    @Test
    public void test6654() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6654");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.initialized = false;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer5 = strKafkaSpout0.kafkaConsumer;
        long long6 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer7 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer7);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertNull(strKafkaConsumer5);
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + 0L + "'", long6 == 0L);
    }

    @Test
    public void test6655() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6655");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 10, 1L, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=[]}");
        long long6 = charSequenceConsumerRecord5.checksum();
        java.lang.CharSequence charSequence7 = charSequenceConsumerRecord5.key();
        org.apache.kafka.common.record.TimestampType timestampType8 = charSequenceConsumerRecord5.timestampType();
        java.lang.CharSequence charSequence9 = charSequenceConsumerRecord5.key();
        java.lang.Class<?> wildcardClass10 = charSequence9.getClass();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence7 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence7, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + charSequence9 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence9, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(wildcardClass10);
    }

    @Test
    public void test6656() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6656");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector2 = null;
        strKafkaSpout0.collector = spoutOutputCollector2;
        org.apache.kafka.common.TopicPartition topicPartition4 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection5 = strKafkaSpout0.toArrayList(topicPartition4);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNotNull(topicPartitionCollection5);
    }

    @Test
    public void test6657() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6657");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        long long12 = charSequenceConsumerRecord10.checksum();
        int int13 = charSequenceConsumerRecord10.serializedValueSize();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 52 + "'", int14 == 52);
    }

    @Test
    public void test6658() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6658");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        long long16 = charSequenceConsumerRecord10.offset();
        long long17 = charSequenceConsumerRecord10.checksum();
        long long18 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        long long20 = charSequenceConsumerRecord10.checksum();
        long long21 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 0L + "'", long21 == 0L);
    }

    @Test
    public void test6659() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6659");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig17 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig17;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams19 = strKafkaSpout0.kafkaSpoutStreams;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertNull(strKafkaConsumer16);
        org.junit.Assert.assertNull(kafkaSpoutStreams19);
    }

    @Test
    public void test6660() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6660");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 1, 1L, (long) (byte) 10, timestampType4, (long) '#', (int) (byte) 100, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str13 = charSequenceConsumerRecord10.toString();
        int int14 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 10L + "'", long11 == 10L);
        org.junit.Assert.assertNull(timestampType12);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )" + "'", str13, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
    }

    @Test
    public void test6661() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6661");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        long long6 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = strKafkaSpout0.tuplesBuilder;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.deactivate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + 0L + "'", long6 == 0L);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder7);
    }

    @Test
    public void test6662() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6662");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams9 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        int int11 = strKafkaSpout0.maxRetries;
        boolean boolean12 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer13 = strKafkaSpout0.kafkaConsumer;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
        org.junit.Assert.assertNull(kafkaSpoutStreams9);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + false + "'", boolean12 == false);
        org.junit.Assert.assertNull(strKafkaConsumer13);
    }

    @Test
    public void test6663() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6663");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy3 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout4 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout4.maxRetries = (byte) -1;
        int int7 = strKafkaSpout4.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray8 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet9 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean10 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet9, kafkaSpoutMessageIdArray8);
        strKafkaSpout4.emitted = kafkaSpoutMessageIdSet9;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig13 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig13;
        strKafkaSpout0.initialized = true;
        java.lang.Class<?> wildcardClass17 = strKafkaSpout0.getClass();
        org.junit.Assert.assertNull(firstPollOffsetStrategy3);
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray8);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNotNull(wildcardClass17);
    }

    @Test
    public void test6664() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6664");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        java.lang.String str12 = charSequenceConsumerRecord10.topic();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.CharSequence charSequence14 = charSequenceConsumerRecord10.key();
        int int15 = charSequenceConsumerRecord10.serializedValueSize();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord10.headers();
        java.lang.CharSequence charSequence17 = charSequenceConsumerRecord10.key();
        long long18 = charSequenceConsumerRecord10.offset();
        java.lang.String str19 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "" + "'", str12, "");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence14 + "' != '" + "" + "'", charSequence14, "");
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertEquals("'" + charSequence17 + "' != '" + "" + "'", charSequence17, "");
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
    }

    @Test
    public void test6665() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6665");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType4, (long) (short) -1, (int) (byte) 1, (int) (short) -1, (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str11 = charSequenceConsumerRecord10.topic();
        java.util.Optional<java.lang.Integer> intOptional12 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType13 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str14 = charSequenceConsumerRecord10.value();
        long long15 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "hi!" + "'", str11, "hi!");
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertNull(timestampType13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
    }

    @Test
    public void test6666() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6666");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        boolean boolean9 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder12 = strKafkaSpout0.tuplesBuilder;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertTrue("'" + boolean9 + "' != '" + false + "'", boolean9 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder12);
    }

    @Test
    public void test6667() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6667");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        long long12 = charSequenceConsumerRecord10.checksum();
        int int13 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.header.Headers headers14 = charSequenceConsumerRecord10.headers();
        long long15 = charSequenceConsumerRecord10.checksum();
        int int16 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 52 + "'", int13 == 52);
        org.junit.Assert.assertNotNull(headers14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 52 + "'", int16 == 52);
    }

    @Test
    public void test6668() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6668");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout11 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = strKafkaSpout11.kafkaSpoutStreams;
        strKafkaSpout11.consumerAutoCommitMode = false;
        java.lang.String str15 = strKafkaSpout11.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout16 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout16.maxRetries = (byte) -1;
        int int19 = strKafkaSpout16.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray20 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet21 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean22 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, kafkaSpoutMessageIdArray20);
        strKafkaSpout16.emitted = kafkaSpoutMessageIdSet21;
        strKafkaSpout11.emitted = kafkaSpoutMessageIdSet21;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout25 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout25.maxRetries = (byte) -1;
        int int28 = strKafkaSpout25.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor29 = null;
        strKafkaSpout25.waitingToEmit = strConsumerRecordItor29;
        org.apache.kafka.common.TopicPartition topicPartition31 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection32 = strKafkaSpout25.toArrayList(topicPartition31);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout25.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector34 = strKafkaSpout25.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout35.maxRetries = (byte) -1;
        int int38 = strKafkaSpout35.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray39 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet40 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean41 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40, kafkaSpoutMessageIdArray39);
        strKafkaSpout35.emitted = kafkaSpoutMessageIdSet40;
        strKafkaSpout25.emitted = kafkaSpoutMessageIdSet40;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType7, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet40;
        strKafkaSpout0.maxRetries = '4';
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet48 = strKafkaSpout0.emitted;
        java.lang.Class<?> wildcardClass49 = kafkaSpoutMessageIdSet48.getClass();
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(strKafkaSpoutConfig2);
        org.junit.Assert.assertNull(kafkaSpoutStreams12);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray20);
        org.junit.Assert.assertTrue("'" + boolean22 + "' != '" + false + "'", boolean22 == false);
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + (-1) + "'", int28 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection32);
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(spoutOutputCollector34);
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + (-1) + "'", int38 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray39);
        org.junit.Assert.assertTrue("'" + boolean41 + "' != '" + false + "'", boolean41 == false);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdSet48);
        org.junit.Assert.assertNotNull(wildcardClass49);
    }

    @Test
    public void test6669() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6669");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer5 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy7;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setAcked(topicPartition9, (long) 100);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
    }

    @Test
    public void test6670() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6670");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", 10, 100L, (long) 10, timestampType4, (-1L), (int) (short) 10, (int) (byte) 100, (java.lang.CharSequence) "", "KafkaSpout{acked=null, emitted=null}");
        java.lang.String str11 = charSequenceConsumerRecord10.value();
        long long12 = charSequenceConsumerRecord10.checksum();
        org.apache.kafka.common.record.TimestampType timestampType13 = charSequenceConsumerRecord10.timestampType();
        int int14 = charSequenceConsumerRecord10.partition();
        long long15 = charSequenceConsumerRecord10.offset();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        java.lang.String str17 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str11, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertNull(timestampType13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 100L + "'", long15 == 100L);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str16, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str17, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test6671() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6671");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        java.lang.String str4 = strKafkaSpout0.toString();
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer7;
        java.lang.String str9 = strKafkaSpout0.toString();
        boolean boolean10 = strKafkaSpout0.initialized;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        strKafkaSpout0.maxRetries = (byte) 100;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer14 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer14;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder16 = strKafkaSpout0.tuplesBuilder;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.doSeekRetriableTopicPartitions();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertEquals("'" + str4 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str4, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str9, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder16);
    }

    @Test
    public void test6672() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6672");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        java.lang.String str11 = charSequenceConsumerRecord10.toString();
        java.lang.String str12 = charSequenceConsumerRecord10.topic();
        long long13 = charSequenceConsumerRecord10.checksum();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.String str15 = charSequenceConsumerRecord10.topic();
        long long16 = charSequenceConsumerRecord10.timestamp();
        int int17 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "" + "'", str12, "");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "" + "'", str15, "");
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + (-1) + "'", int17 == (-1));
    }

    @Test
    public void test6673() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6673");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator1 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator2 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator2;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator4 = offsetComparator2.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator9 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator9;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord11 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator9);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = kafkaSpoutMessageIdComparator4.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator9);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator1.thenComparing(kafkaSpoutMessageIdComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = kafkaSpoutMessageIdComparator12.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator12);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator16 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator16;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = offsetComparator16.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator23;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = kafkaSpoutMessageIdComparator18.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator23);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator27 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator27;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = offsetComparator27.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator34 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator34;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = kafkaSpoutMessageIdComparator29.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = kafkaSpoutMessageIdComparator18.thenComparing(kafkaSpoutMessageIdComparator37);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator38);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator40 = offsetComparator0.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = kafkaSpoutMessageIdComparator40.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator4);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator40);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
    }

    @Test
    public void test6674() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6674");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.Comparable<java.lang.String>> strComparableKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Comparable<java.lang.String>, java.lang.Comparable<java.lang.String>>();
    }

    @Test
    public void test6675() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6675");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = strKafkaSpout0.kafkaConsumer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor5 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor5;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig8 = strKafkaSpout0.kafkaSpoutConfig;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.activate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer4);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder7);
        org.junit.Assert.assertNull(strKafkaSpoutConfig8);
    }

    @Test
    public void test6676() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6676");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        org.apache.kafka.common.TopicPartition topicPartition3 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection4 = strKafkaSpout0.toArrayList(topicPartition3);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService5 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig7 = strKafkaSpout0.kafkaSpoutConfig;
        org.junit.Assert.assertNotNull(topicPartitionCollection4);
        org.junit.Assert.assertNull(strKafkaSpoutConfig7);
    }

    @Test
    public void test6677() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6677");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Optional<java.lang.Integer>, java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> intOptionalKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> intOptionalKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Optional<java.lang.Integer>, java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>(intOptionalKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test6678() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6678");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", (int) (short) 1, (long) 'a', (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )");
        org.apache.kafka.common.header.Headers headers6 = charSequenceConsumerRecord5.headers();
        int int7 = charSequenceConsumerRecord5.partition();
        java.lang.CharSequence charSequence8 = charSequenceConsumerRecord5.key();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 1 + "'", int7 == 1);
        org.junit.Assert.assertEquals("'" + charSequence8 + "' != '" + "hi!" + "'", charSequence8, "hi!");
    }

    @Test
    public void test6679() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6679");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        java.lang.String str11 = charSequenceConsumerRecord10.toString();
        java.lang.String str12 = charSequenceConsumerRecord10.topic();
        java.lang.CharSequence charSequence13 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "" + "'", str12, "");
        org.junit.Assert.assertEquals("'" + charSequence13 + "' != '" + "" + "'", charSequence13, "");
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
    }

    @Test
    public void test6680() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6680");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence17 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers18 = charSequenceConsumerRecord10.headers();
        int int19 = charSequenceConsumerRecord10.partition();
        java.lang.String str20 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.header.Headers headers21 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertEquals("'" + charSequence17 + "' != '" + "" + "'", charSequence17, "");
        org.junit.Assert.assertNotNull(headers18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertNotNull(headers21);
    }

    @Test
    public void test6681() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6681");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.util.Optional<java.lang.Integer> intOptional16 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str17 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.header.Headers headers18 = charSequenceConsumerRecord10.headers();
        long long19 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertNotNull(headers18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
    }

    @Test
    public void test6682() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6682");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str10 = charSequenceConsumerRecord9.topic();
        int int11 = charSequenceConsumerRecord9.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, null = 1, serialized key size = 32, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", (int) (short) 0, (long) 97, (long) (short) 1, timestampType12, (long) 1, (int) '4', (-1), (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 97, leaderEpoch = null, offset = 100, NoTimestampType = 97, serialized key size = 97, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=[]}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}))");
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "" + "'", str10, "");
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test6683() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6683");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer6 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService7 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService7;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet9 = strKafkaSpout0.emitted;
        long long10 = strKafkaSpout0.numUncommittedOffsets;
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer6);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet9);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 0L + "'", long10 == 0L);
    }

    @Test
    public void test6684() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6684");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.util.Optional<java.lang.Integer> intOptional16 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str17 = charSequenceConsumerRecord10.value();
        java.lang.String str18 = charSequenceConsumerRecord10.topic();
        long long19 = charSequenceConsumerRecord10.offset();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.header.Headers headers21 = charSequenceConsumerRecord10.headers();
        java.util.Optional<java.lang.Integer> intOptional22 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.CharSequence charSequence23 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertNotNull(headers21);
        org.junit.Assert.assertNotNull(intOptional22);
        org.junit.Assert.assertEquals("'" + charSequence23 + "' != '" + "" + "'", charSequence23, "");
    }

    @Test
    public void test6685() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6685");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer16;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor18 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer19 = strKafkaSpout0.commitTimer;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet20 = null;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet20;
        strKafkaSpout0.numUncommittedOffsets = 52L;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer24 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer24);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor18);
        org.junit.Assert.assertNull(timer19);
    }

    @Test
    public void test6686() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6686");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator3 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator3;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator5 = offsetComparator3.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator10 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator10;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator10);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = kafkaSpoutMessageIdComparator5.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator10);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator14 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator14;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator14.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator21 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator21;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator21);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator16.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator21);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = kafkaSpoutMessageIdComparator5.thenComparing(kafkaSpoutMessageIdComparator24);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator26 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = offsetComparator26.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = offsetComparator26.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = kafkaSpoutMessageIdComparator24.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator26);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator, java.lang.Comparable<java.lang.String>> offsetComparatorConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, 1L, offsetComparator26, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = offsetComparator26.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId38 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId39 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int40 = offsetComparator26.compare(kafkaSpoutMessageId38, kafkaSpoutMessageId39);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator5);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
    }

    @Test
    public void test6687() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6687");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", 100, (long) (byte) 100, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.CharSequence charSequence6 = charSequenceConsumerRecord5.key();
        org.apache.kafka.common.record.TimestampType timestampType7 = charSequenceConsumerRecord5.timestampType();
        int int8 = charSequenceConsumerRecord5.partition();
        long long9 = charSequenceConsumerRecord5.offset();
        org.junit.Assert.assertEquals("'" + charSequence6 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", charSequence6, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 100 + "'", int8 == 100);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 100L + "'", long9 == 100L);
    }

    @Test
    public void test6688() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6688");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        long long17 = charSequenceConsumerRecord10.checksum();
        long long18 = charSequenceConsumerRecord10.timestamp();
        int int19 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
    }

    @Test
    public void test6689() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6689");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = kafkaSpoutMessageIdComparator13.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = kafkaSpoutMessageIdComparator2.thenComparing(kafkaSpoutMessageIdComparator21);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator23;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator23.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator23.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = kafkaSpoutMessageIdComparator21.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator23);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator28 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator28;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = offsetComparator28.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator28;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator32 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator32;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator32.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = offsetComparator28.thenComparing(kafkaSpoutMessageIdComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = kafkaSpoutMessageIdComparator34.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = kafkaSpoutMessageIdComparator21.thenComparing(kafkaSpoutMessageIdComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = kafkaSpoutMessageIdComparator37.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = kafkaSpoutMessageIdComparator37.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
    }

    @Test
    public void test6690() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6690");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.util.AbstractList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> strKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.util.AbstractList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> strKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.util.AbstractList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>(strKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test6691() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6691");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = strKafkaSpout0.tuplesBuilder;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer8 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer8;
        strKafkaSpout0.numUncommittedOffsets = 1L;
        long long12 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector13 = strKafkaSpout0.collector;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder7);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 1L + "'", long12 == 1L);
        org.junit.Assert.assertNull(spoutOutputCollector13);
    }

    @Test
    public void test6692() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6692");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector8 = null;
        strKafkaSpout0.collector = spoutOutputCollector8;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig10 = strKafkaSpout0.kafkaSpoutConfig;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(strKafkaSpoutConfig10);
    }

    @Test
    public void test6693() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6693");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig12 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig12;
        strKafkaSpout0.maxRetries = (byte) 100;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
    }

    @Test
    public void test6694() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6694");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", 0, 10L, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "hi!");
        java.lang.String str6 = charSequenceConsumerRecord5.value();
        java.lang.String str7 = charSequenceConsumerRecord5.toString();
        java.lang.String str8 = charSequenceConsumerRecord5.topic();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "hi!" + "'", str6, "hi!");
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null}), partition = 0, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)" + "'", str7, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null}), partition = 0, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)");
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})" + "'", str8, "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
    }

    @Test
    public void test6695() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6695");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder9;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder11 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder11;
        boolean boolean13 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig14 = strKafkaSpout0.kafkaSpoutConfig;
        long long15 = strKafkaSpout0.numUncommittedOffsets;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str16 = strKafkaSpout0.getNamedTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertTrue("'" + boolean13 + "' != '" + false + "'", boolean13 == false);
        org.junit.Assert.assertNull(strKafkaSpoutConfig14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 0L + "'", long15 == 0L);
    }

    @Test
    public void test6696() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6696");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = strKafkaSpout0.kafkaConsumer;
        java.lang.String str8 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy13 = strKafkaSpout0.firstPollOffsetStrategy;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.deactivate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertNull(strKafkaConsumer7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(firstPollOffsetStrategy13);
    }

    @Test
    public void test6697() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6697");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator14 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator14;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator14.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = offsetComparator13.thenComparing(kafkaSpoutMessageIdComparator16);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = offsetComparator11.thenComparing(kafkaSpoutMessageIdComparator17);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = offsetComparator7.thenComparing(kafkaSpoutMessageIdComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = kafkaSpoutMessageIdComparator18.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator21 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator21;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = offsetComparator21.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator28 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator28;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator28);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = kafkaSpoutMessageIdComparator23.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator28);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = offsetComparator28.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator33 = kafkaSpoutMessageIdComparator18.thenComparing(kafkaSpoutMessageIdComparator32);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = kafkaSpoutMessageIdComparator32.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = kafkaSpoutMessageIdComparator32.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = kafkaSpoutMessageIdComparator32.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator37 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator37;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = offsetComparator37.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator44 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator44;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator44);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator47 = kafkaSpoutMessageIdComparator39.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator44);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator48 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator48;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator50 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator51 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator51;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator53 = offsetComparator51.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator54 = offsetComparator50.thenComparing(kafkaSpoutMessageIdComparator53);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator55 = offsetComparator48.thenComparing(kafkaSpoutMessageIdComparator54);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator56 = offsetComparator44.thenComparing(kafkaSpoutMessageIdComparator55);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator57 = kafkaSpoutMessageIdComparator56.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator58 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator58;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator60 = offsetComparator58.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator65 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator65;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator65);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator68 = kafkaSpoutMessageIdComparator60.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator65);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator69 = offsetComparator65.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator70 = offsetComparator65.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator71 = kafkaSpoutMessageIdComparator70.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator72 = kafkaSpoutMessageIdComparator56.thenComparing(kafkaSpoutMessageIdComparator70);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator73 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator74 = kafkaSpoutMessageIdComparator70.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator73);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator75 = kafkaSpoutMessageIdComparator32.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator73);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator33);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator47);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator53);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator54);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator56);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator57);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator60);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator68);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator69);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator70);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator71);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator72);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator74);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator75);
    }

    @Test
    public void test6698() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6698");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator1 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator2 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator2;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator4 = offsetComparator2.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator9 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator9;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord11 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator9);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = kafkaSpoutMessageIdComparator4.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator9);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator1.thenComparing(kafkaSpoutMessageIdComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = kafkaSpoutMessageIdComparator12.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = kafkaSpoutMessageIdComparator12.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator17 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator17;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = offsetComparator17.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator24 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator24;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator24);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = kafkaSpoutMessageIdComparator19.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator24);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = kafkaSpoutMessageIdComparator19.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator29 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator30 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator30;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = offsetComparator30.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator37 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator37;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator37);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator40 = kafkaSpoutMessageIdComparator32.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator37);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = offsetComparator29.thenComparing(kafkaSpoutMessageIdComparator40);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator42 = kafkaSpoutMessageIdComparator28.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator29);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator42;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = kafkaSpoutMessageIdComparator12.thenComparing(kafkaSpoutMessageIdComparator42);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator45 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator45;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator47 = offsetComparator45.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator45;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator49 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator49;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator51 = offsetComparator49.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator52 = offsetComparator45.thenComparing(kafkaSpoutMessageIdComparator51);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator53 = offsetComparator45.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator54 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator55 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator55;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator57 = offsetComparator55.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator58 = offsetComparator54.thenComparing(kafkaSpoutMessageIdComparator57);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator59 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator59;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator61 = offsetComparator59.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator66 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator66;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator66);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator69 = kafkaSpoutMessageIdComparator61.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator66);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator70 = offsetComparator54.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator66);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator71 = offsetComparator66.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator72 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator72;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator74 = offsetComparator72.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator79 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator79;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator79);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator82 = kafkaSpoutMessageIdComparator74.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator79);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator83 = offsetComparator79.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator84 = kafkaSpoutMessageIdComparator71.thenComparing(kafkaSpoutMessageIdComparator83);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator85 = kafkaSpoutMessageIdComparator53.thenComparing(kafkaSpoutMessageIdComparator71);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator86 = kafkaSpoutMessageIdComparator42.thenComparing(kafkaSpoutMessageIdComparator53);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator87 = kafkaSpoutMessageIdComparator42.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator88 = kafkaSpoutMessageIdComparator87.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator4);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator40);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator42);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator47);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator51);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator52);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator53);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator57);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator58);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator61);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator69);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator70);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator71);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator74);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator82);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator83);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator84);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator85);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator86);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator87);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator88);
    }

    @Test
    public void test6699() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6699");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str19 = charSequenceConsumerRecord10.value();
        java.lang.String str20 = charSequenceConsumerRecord10.value();
        java.lang.String str21 = charSequenceConsumerRecord10.topic();
        long long22 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "" + "'", str21, "");
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
    }

    @Test
    public void test6700() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6700");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService1 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService1;
        long long3 = strKafkaSpout0.numUncommittedOffsets;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = strKafkaSpout0.waitingToEmit;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = strKafkaSpout0.emitted;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig8 = strKafkaSpout0.kafkaSpoutConfig;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig11;
        org.junit.Assert.assertTrue("'" + long3 + "' != '" + 0L + "'", long3 == 0L);
        org.junit.Assert.assertNull(strConsumerRecordItor4);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet5);
        org.junit.Assert.assertNull(strKafkaSpoutConfig8);
    }

    @Test
    public void test6701() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6701");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)", (int) (byte) 1, 0L, (java.lang.CharSequence) "hi!", "");
        org.apache.kafka.common.header.Headers headers6 = charSequenceConsumerRecord5.headers();
        java.lang.String str7 = charSequenceConsumerRecord5.toString();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!), partition = 1, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = )" + "'", str7, "ConsumerRecord(topic = ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!), partition = 1, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = )");
    }

    @Test
    public void test6702() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6702");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer4 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer4);
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test6703() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6703");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = strKafkaSpout0.firstPollOffsetStrategy;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer9 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer9;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = strKafkaSpout0.collector;
        boolean boolean12 = strKafkaSpout0.waitingToEmit();
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.numUncommittedOffsets = (-1);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 0 + "'", int8 == 0);
        org.junit.Assert.assertNull(spoutOutputCollector11);
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + false + "'", boolean12 == false);
    }

    @Test
    public void test6704() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6704");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = strKafkaSpout0.waitingToEmit;
        org.apache.kafka.common.TopicPartition topicPartition5 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection6 = strKafkaSpout0.toArrayList(topicPartition5);
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet7 = strKafkaSpout0.emitted;
        strKafkaSpout0.initialized = false;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.deactivate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertNull(strConsumerRecordItor4);
        org.junit.Assert.assertNotNull(topicPartitionCollection6);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet7);
    }

    @Test
    public void test6705() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6705");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.common.TopicPartition topicPartition12 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection13 = strKafkaSpout0.toArrayList(topicPartition12);
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor14 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor14;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder16 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder16;
        strKafkaSpout0.initialized = true;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertNotNull(topicPartitionCollection13);
    }

    @Test
    public void test6706() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6706");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.String str16 = charSequenceConsumerRecord10.toString();
        java.lang.String str17 = charSequenceConsumerRecord10.value();
        long long18 = charSequenceConsumerRecord10.offset();
        java.lang.String str19 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
    }

    @Test
    public void test6707() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6707");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.CharSequence charSequence6 = charSequenceConsumerRecord5.key();
        java.util.Optional<java.lang.Integer> intOptional7 = charSequenceConsumerRecord5.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional8 = charSequenceConsumerRecord5.leaderEpoch();
        org.junit.Assert.assertEquals("'" + charSequence6 + "' != '" + "" + "'", charSequence6, "");
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertNotNull(intOptional8);
    }

    @Test
    public void test6708() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6708");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        strKafkaSpout0.maxRetries = 'a';
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
    }

    @Test
    public void test6709() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6709");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout3 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout3.maxRetries = (byte) -1;
        int int6 = strKafkaSpout3.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout3.waitingToEmit = strConsumerRecordItor7;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig9 = null;
        strKafkaSpout3.kafkaSpoutConfig = strKafkaSpoutConfig9;
        int int11 = strKafkaSpout3.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy12 = null;
        strKafkaSpout3.firstPollOffsetStrategy = firstPollOffsetStrategy12;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig14 = strKafkaSpout3.kafkaSpoutConfig;
        int int15 = strKafkaSpout3.maxRetries;
        boolean boolean16 = strKafkaSpout3.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder17 = strKafkaSpout3.tuplesBuilder;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord18 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>> iSpoutConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) 0, (long) 10, (org.apache.storm.spout.ISpout) strKafkaSpout3, charSequenceConsumerRecord18);
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig20 = strKafkaSpout3.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout21 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean22 = strKafkaSpout21.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder23 = null;
        strKafkaSpout21.tuplesBuilder = strKafkaSpoutTuplesBuilder23;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy25 = null;
        strKafkaSpout21.firstPollOffsetStrategy = firstPollOffsetStrategy25;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig27 = strKafkaSpout21.kafkaSpoutConfig;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor28 = null;
        strKafkaSpout21.waitingToEmit = strConsumerRecordItor28;
        org.apache.kafka.common.record.TimestampType timestampType34 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout38 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams39 = strKafkaSpout38.kafkaSpoutStreams;
        strKafkaSpout38.consumerAutoCommitMode = false;
        java.lang.String str42 = strKafkaSpout38.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout43 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout43.maxRetries = (byte) -1;
        int int46 = strKafkaSpout43.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray47 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet48 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean49 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet48, kafkaSpoutMessageIdArray47);
        strKafkaSpout43.emitted = kafkaSpoutMessageIdSet48;
        strKafkaSpout38.emitted = kafkaSpoutMessageIdSet48;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout52 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout52.maxRetries = (byte) -1;
        int int55 = strKafkaSpout52.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor56 = null;
        strKafkaSpout52.waitingToEmit = strConsumerRecordItor56;
        org.apache.kafka.common.TopicPartition topicPartition58 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection59 = strKafkaSpout52.toArrayList(topicPartition58);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer60 = strKafkaSpout52.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector61 = strKafkaSpout52.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout62 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout62.maxRetries = (byte) -1;
        int int65 = strKafkaSpout62.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray66 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet67 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean68 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet67, kafkaSpoutMessageIdArray66);
        strKafkaSpout62.emitted = kafkaSpoutMessageIdSet67;
        strKafkaSpout52.emitted = kafkaSpoutMessageIdSet67;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType34, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet48, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet67);
        strKafkaSpout21.emitted = kafkaSpoutMessageIdSet48;
        strKafkaSpout3.emitted = kafkaSpoutMessageIdSet48;
        boolean boolean74 = strKafkaSpout3.consumerAutoCommitMode;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer75 = strKafkaSpout3.kafkaConsumer;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Map<java.lang.String, java.lang.Object> strMap76 = strKafkaSpout3.getComponentConfiguration();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig14);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + boolean16 + "' != '" + false + "'", boolean16 == false);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder17);
        org.junit.Assert.assertNull(strKafkaSpoutConfig20);
        org.junit.Assert.assertTrue("'" + boolean22 + "' != '" + false + "'", boolean22 == false);
        org.junit.Assert.assertNull(strKafkaSpoutConfig27);
        org.junit.Assert.assertNull(kafkaSpoutStreams39);
        org.junit.Assert.assertEquals("'" + str42 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str42, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int46 + "' != '" + (-1) + "'", int46 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray47);
        org.junit.Assert.assertTrue("'" + boolean49 + "' != '" + false + "'", boolean49 == false);
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + (-1) + "'", int55 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection59);
        org.junit.Assert.assertNull(timer60);
        org.junit.Assert.assertNull(spoutOutputCollector61);
        org.junit.Assert.assertTrue("'" + int65 + "' != '" + (-1) + "'", int65 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray66);
        org.junit.Assert.assertTrue("'" + boolean68 + "' != '" + false + "'", boolean68 == false);
        org.junit.Assert.assertTrue("'" + boolean74 + "' != '" + false + "'", boolean74 == false);
        org.junit.Assert.assertNull(strKafkaConsumer75);
    }

    @Test
    public void test6710() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6710");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer16;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer18 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector19 = strKafkaSpout0.collector;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector20 = null;
        strKafkaSpout0.collector = spoutOutputCollector20;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService22 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService22;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertNull(strKafkaConsumer18);
        org.junit.Assert.assertNull(spoutOutputCollector19);
    }

    @Test
    public void test6711() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6711");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers12 = charSequenceConsumerRecord10.headers();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        java.lang.String str14 = charSequenceConsumerRecord10.topic();
        java.util.Optional<java.lang.Integer> intOptional15 = charSequenceConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional16 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str17 = charSequenceConsumerRecord10.toString();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str17, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNull(timestampType18);
    }

    @Test
    public void test6712() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6712");
        org.apache.kafka.common.record.TimestampType timestampType8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType8, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long15 = charSequenceConsumerRecord14.checksum();
        int int16 = charSequenceConsumerRecord14.partition();
        long long17 = charSequenceConsumerRecord14.timestamp();
        long long18 = charSequenceConsumerRecord14.offset();
        int int19 = charSequenceConsumerRecord14.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType20 = charSequenceConsumerRecord14.timestampType();
        int int21 = charSequenceConsumerRecord14.partition();
        long long22 = charSequenceConsumerRecord14.checksum();
        java.util.Optional<java.lang.Integer> intOptional23 = charSequenceConsumerRecord14.leaderEpoch();
        org.apache.kafka.common.header.Headers headers24 = charSequenceConsumerRecord14.headers();
        java.lang.String str25 = charSequenceConsumerRecord14.value();
        java.lang.String str26 = charSequenceConsumerRecord14.value();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>> strComparableConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", (int) (byte) 10, 32L, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", charSequenceConsumerRecord14);
        org.apache.kafka.common.header.Headers headers28 = charSequenceConsumerRecord14.headers();
        int int29 = charSequenceConsumerRecord14.partition();
        long long30 = charSequenceConsumerRecord14.timestamp();
        long long31 = charSequenceConsumerRecord14.offset();
        long long32 = charSequenceConsumerRecord14.checksum();
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 52 + "'", int19 == 52);
        org.junit.Assert.assertNull(timestampType20);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 10 + "'", int21 == 10);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
        org.junit.Assert.assertNotNull(intOptional23);
        org.junit.Assert.assertNotNull(headers24);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "hi!" + "'", str25, "hi!");
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "hi!" + "'", str26, "hi!");
        org.junit.Assert.assertNotNull(headers28);
        org.junit.Assert.assertTrue("'" + int29 + "' != '" + 10 + "'", int29 == 10);
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + long31 + "' != '" + 0L + "'", long31 == 0L);
        org.junit.Assert.assertTrue("'" + long32 + "' != '" + (-1L) + "'", long32 == (-1L));
    }

    @Test
    public void test6713() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6713");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        boolean boolean9 = strKafkaSpout0.consumerAutoCommitMode;
        java.lang.String str10 = strKafkaSpout0.toString();
        int int11 = strKafkaSpout0.maxRetries;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.doSeekRetriableTopicPartitions();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertTrue("'" + boolean9 + "' != '" + false + "'", boolean9 == false);
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str10, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 0 + "'", int11 == 0);
    }

    @Test
    public void test6714() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6714");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams7;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = strKafkaSpout0.retryService;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        strKafkaSpout0.maxRetries = (-1);
        org.apache.kafka.common.TopicPartition topicPartition13 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection14 = strKafkaSpout0.toArrayList(topicPartition13);
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords15 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords15);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(kafkaSpoutRetryService9);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertNotNull(topicPartitionCollection14);
    }

    @Test
    public void test6715() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6715");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer10 = strKafkaSpout0.commitTimer;
        org.apache.kafka.common.TopicPartition topicPartition11 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection12 = strKafkaSpout0.toArrayList(topicPartition11);
        strKafkaSpout0.numUncommittedOffsets = 100;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(spoutOutputCollector9);
        org.junit.Assert.assertNull(timer10);
        org.junit.Assert.assertNotNull(topicPartitionCollection12);
    }

    @Test
    public void test6716() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6716");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = 0;
        boolean boolean6 = strKafkaSpout0.consumerAutoCommitMode;
        boolean boolean7 = strKafkaSpout0.initialized;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        strKafkaSpout0.numUncommittedOffsets = (byte) -1;
        long long13 = strKafkaSpout0.numUncommittedOffsets;
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
    }

    @Test
    public void test6717() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6717");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer8 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder9;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor11 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor11;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig13 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer14 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer14;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector16 = strKafkaSpout0.collector;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor17 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor17;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(strKafkaConsumer8);
        org.junit.Assert.assertNull(strKafkaSpoutConfig13);
        org.junit.Assert.assertNull(spoutOutputCollector16);
    }

    @Test
    public void test6718() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6718");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        java.lang.String str8 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer9 = strKafkaSpout0.commitTimer;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean10 = strKafkaSpout0.poll();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(timer9);
    }

    @Test
    public void test6719() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6719");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.initialized = false;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = strKafkaSpout0.retryService;
        boolean boolean11 = strKafkaSpout0.waitingToEmit();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet12 = strKafkaSpout0.emitted;
        strKafkaSpout0.initialized = false;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutRetryService10);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet12);
    }

    @Test
    public void test6720() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6720");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str6 = charSequenceConsumerRecord5.topic();
        int int7 = charSequenceConsumerRecord5.serializedKeySize();
        java.lang.String str8 = charSequenceConsumerRecord5.toString();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "" + "'", str6, "");
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str8, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
    }

    @Test
    public void test6721() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6721");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout11 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = strKafkaSpout11.kafkaSpoutStreams;
        strKafkaSpout11.consumerAutoCommitMode = false;
        java.lang.String str15 = strKafkaSpout11.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout16 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout16.maxRetries = (byte) -1;
        int int19 = strKafkaSpout16.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray20 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet21 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean22 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, kafkaSpoutMessageIdArray20);
        strKafkaSpout16.emitted = kafkaSpoutMessageIdSet21;
        strKafkaSpout11.emitted = kafkaSpoutMessageIdSet21;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout25 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout25.maxRetries = (byte) -1;
        int int28 = strKafkaSpout25.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor29 = null;
        strKafkaSpout25.waitingToEmit = strConsumerRecordItor29;
        org.apache.kafka.common.TopicPartition topicPartition31 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection32 = strKafkaSpout25.toArrayList(topicPartition31);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout25.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector34 = strKafkaSpout25.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout35.maxRetries = (byte) -1;
        int int38 = strKafkaSpout35.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray39 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet40 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean41 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40, kafkaSpoutMessageIdArray39);
        strKafkaSpout35.emitted = kafkaSpoutMessageIdSet40;
        strKafkaSpout25.emitted = kafkaSpoutMessageIdSet40;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType7, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet40;
        long long46 = strKafkaSpout0.numUncommittedOffsets;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor47 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder48 = strKafkaSpout0.tuplesBuilder;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Map<java.lang.String, java.lang.Object> strMap49 = strKafkaSpout0.getComponentConfiguration();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(strKafkaSpoutConfig2);
        org.junit.Assert.assertNull(kafkaSpoutStreams12);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray20);
        org.junit.Assert.assertTrue("'" + boolean22 + "' != '" + false + "'", boolean22 == false);
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + (-1) + "'", int28 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection32);
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(spoutOutputCollector34);
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + (-1) + "'", int38 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray39);
        org.junit.Assert.assertTrue("'" + boolean41 + "' != '" + false + "'", boolean41 == false);
        org.junit.Assert.assertTrue("'" + long46 + "' != '" + 0L + "'", long46 == 0L);
        org.junit.Assert.assertNull(strConsumerRecordItor47);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder48);
    }

    @Test
    public void test6722() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6722");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        strKafkaSpout0.numUncommittedOffsets = 1L;
        boolean boolean4 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig5;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.emit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
    }

    @Test
    public void test6723() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6723");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = strKafkaSpout0.waitingToEmit;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor5 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertNull(strConsumerRecordItor4);
        org.junit.Assert.assertNull(strConsumerRecordItor5);
    }

    @Test
    public void test6724() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6724");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = kafkaSpoutMessageIdComparator13.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = kafkaSpoutMessageIdComparator2.thenComparing(kafkaSpoutMessageIdComparator21);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator23;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator23.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator23.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = kafkaSpoutMessageIdComparator21.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator23);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator28 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator28;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = offsetComparator28.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator28;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator32 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator32;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator32.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = offsetComparator28.thenComparing(kafkaSpoutMessageIdComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = kafkaSpoutMessageIdComparator34.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = kafkaSpoutMessageIdComparator21.thenComparing(kafkaSpoutMessageIdComparator34);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator38 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator39 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator39;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = offsetComparator39.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator42 = offsetComparator38.thenComparing(kafkaSpoutMessageIdComparator41);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator43 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator43;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator45 = offsetComparator43.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator50 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator50;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator50);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator53 = kafkaSpoutMessageIdComparator45.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator50);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator54 = kafkaSpoutMessageIdComparator45.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator55 = kafkaSpoutMessageIdComparator42.thenComparing(kafkaSpoutMessageIdComparator54);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator56 = kafkaSpoutMessageIdComparator21.thenComparing(kafkaSpoutMessageIdComparator55);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator55;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator42);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator53);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator54);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator56);
    }

    @Test
    public void test6725() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6725");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        boolean boolean10 = strKafkaSpout0.consumerAutoCommitMode;
        strKafkaSpout0.maxRetries = (short) 10;
        strKafkaSpout0.maxRetries = 35;
        strKafkaSpout0.numUncommittedOffsets = 1;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor17 = strKafkaSpout0.waitingToEmit;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords18 = strKafkaSpout0.pollKafkaBroker();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor17);
    }

    @Test
    public void test6726() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6726");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.initialized = false;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = strKafkaSpout0.retryService;
        boolean boolean11 = strKafkaSpout0.waitingToEmit();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet12 = strKafkaSpout0.emitted;
        strKafkaSpout0.initialized = false;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService15 = strKafkaSpout0.retryService;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutRetryService10);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet12);
        org.junit.Assert.assertNull(kafkaSpoutRetryService15);
    }

    @Test
    public void test6727() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6727");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy11 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy11;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig13 = strKafkaSpout0.kafkaSpoutConfig;
        strKafkaSpout0.numUncommittedOffsets = (byte) 1;
        boolean boolean16 = strKafkaSpout0.consumerAutoCommitMode;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(strKafkaSpoutConfig13);
        org.junit.Assert.assertTrue("'" + boolean16 + "' != '" + false + "'", boolean16 == false);
    }

    @Test
    public void test6728() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6728");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder9;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord11 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean12 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord11);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
    }

    @Test
    public void test6729() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6729");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig8 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig8;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor10 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor10;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Map<java.lang.String, java.lang.Object> strMap12 = strKafkaSpout0.getComponentConfiguration();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
    }

    @Test
    public void test6730() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6730");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str18 = charSequenceConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = charSequenceConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long34 = charSequenceConsumerRecord33.checksum();
        int int35 = charSequenceConsumerRecord33.partition();
        java.lang.String str36 = charSequenceConsumerRecord33.value();
        int int37 = charSequenceConsumerRecord33.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional38 = charSequenceConsumerRecord33.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout39 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet40 = strKafkaSpout39.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor41 = null;
        strKafkaSpout39.waitingToEmit = strConsumerRecordItor41;
        boolean boolean43 = strKafkaSpout39.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig44 = null;
        strKafkaSpout39.kafkaSpoutConfig = strKafkaSpoutConfig44;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy46 = strKafkaSpout39.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType19, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord33, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout39);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long59 = charSequenceConsumerRecord58.checksum();
        long long60 = charSequenceConsumerRecord58.timestamp();
        org.apache.kafka.common.header.Headers headers61 = charSequenceConsumerRecord58.headers();
        org.apache.kafka.common.record.TimestampType timestampType66 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType66, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long73 = charSequenceConsumerRecord72.offset();
        int int74 = charSequenceConsumerRecord72.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional75 = charSequenceConsumerRecord72.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType76 = charSequenceConsumerRecord72.timestampType();
        java.util.Optional<java.lang.Integer> intOptional77 = charSequenceConsumerRecord72.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 52, 0L, (-1L), timestampType19, (java.lang.Long) 35L, (int) (short) -1, 0, (java.lang.CharSequence) "", "hi!", headers61, intOptional77);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (byte) 100, (long) '#', (long) 0, timestampType19, (long) 'a', 52, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "hi!");
        java.util.Optional<java.lang.Integer> intOptional85 = charSequenceConsumerRecord84.leaderEpoch();
        long long86 = charSequenceConsumerRecord84.checksum();
        int int87 = charSequenceConsumerRecord84.partition();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertTrue("'" + int35 + "' != '" + 10 + "'", int35 == 10);
        org.junit.Assert.assertEquals("'" + str36 + "' != '" + "hi!" + "'", str36, "hi!");
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + 52 + "'", int37 == 52);
        org.junit.Assert.assertNotNull(intOptional38);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet40);
        org.junit.Assert.assertTrue("'" + boolean43 + "' != '" + false + "'", boolean43 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy46);
        org.junit.Assert.assertTrue("'" + long59 + "' != '" + (-1L) + "'", long59 == (-1L));
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertNotNull(headers61);
        org.junit.Assert.assertTrue("'" + long73 + "' != '" + 0L + "'", long73 == 0L);
        org.junit.Assert.assertTrue("'" + int74 + "' != '" + (-1) + "'", int74 == (-1));
        org.junit.Assert.assertNotNull(intOptional75);
        org.junit.Assert.assertNull(timestampType76);
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertNotNull(intOptional85);
        org.junit.Assert.assertTrue("'" + long86 + "' != '" + 97L + "'", long86 == 97L);
        org.junit.Assert.assertTrue("'" + int87 + "' != '" + 100 + "'", int87 == 100);
    }

    @Test
    public void test6731() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6731");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (-1), (long) ' ', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.util.Optional<java.lang.Integer> intOptional6 = charSequenceConsumerRecord5.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional7 = charSequenceConsumerRecord5.leaderEpoch();
        java.lang.CharSequence charSequence8 = charSequenceConsumerRecord5.key();
        long long9 = charSequenceConsumerRecord5.offset();
        java.lang.CharSequence charSequence10 = charSequenceConsumerRecord5.key();
        org.apache.kafka.common.record.TimestampType timestampType11 = charSequenceConsumerRecord5.timestampType();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord5.key();
        org.junit.Assert.assertNotNull(intOptional6);
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertEquals("'" + charSequence8 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence8, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 32L + "'", long9 == 32L);
        org.junit.Assert.assertEquals("'" + charSequence10 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence10, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence12, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test6732() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6732");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = strKafkaSpout0.collector;
        strKafkaSpout0.initialized = true;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = null;
        strKafkaSpout0.collector = spoutOutputCollector9;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams11 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams12;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(spoutOutputCollector6);
        org.junit.Assert.assertNull(kafkaSpoutStreams11);
    }

    @Test
    public void test6733() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6733");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = strKafkaSpout0.kafkaConsumer;
        strKafkaSpout0.maxRetries = (byte) 100;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor7;
        int int9 = strKafkaSpout0.maxRetries;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.activate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer4);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + 100 + "'", int9 == 100);
    }

    @Test
    public void test6734() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6734");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 10, 0L, (java.lang.CharSequence) "", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        long long6 = charSequenceConsumerRecord5.checksum();
        java.lang.String str7 = charSequenceConsumerRecord5.topic();
        java.lang.String str8 = charSequenceConsumerRecord5.toString();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str7, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}))" + "'", str8, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}))");
    }

    @Test
    public void test6735() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6735");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 1, 1L, (long) (byte) 10, timestampType4, (long) '#', (int) (byte) 100, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord10.timestampType();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional14 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 10L + "'", long11 == 10L);
        org.junit.Assert.assertNull(timestampType12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 10L + "'", long13 == 10L);
        org.junit.Assert.assertNotNull(intOptional14);
    }

    @Test
    public void test6736() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6736");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        long long12 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str14 = charSequenceConsumerRecord10.value();
        long long15 = charSequenceConsumerRecord10.timestamp();
        int int16 = charSequenceConsumerRecord10.serializedValueSize();
        int int17 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence18 = charSequenceConsumerRecord10.key();
        java.lang.String str19 = charSequenceConsumerRecord10.value();
        long long20 = charSequenceConsumerRecord10.offset();
        java.lang.String str21 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + (-1) + "'", int16 == (-1));
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertEquals("'" + charSequence18 + "' != '" + "" + "'", charSequence18, "");
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 0L + "'", long20 == 0L);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "hi!" + "'", str21, "hi!");
    }

    @Test
    public void test6737() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6737");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        java.lang.CharSequence charSequence17 = charSequenceConsumerRecord10.key();
        int int18 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertEquals("'" + charSequence17 + "' != '" + "" + "'", charSequence17, "");
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 52 + "'", int18 == 52);
        org.junit.Assert.assertNotNull(headers19);
    }

    @Test
    public void test6738() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6738");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = strKafkaSpout0.kafkaConsumer;
        int int12 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor13 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor13;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str15 = strKafkaSpout0.getNamedTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
    }

    @Test
    public void test6739() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6739");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        long long7 = charSequenceConsumerRecord5.timestamp();
        long long8 = charSequenceConsumerRecord5.timestamp();
        long long9 = charSequenceConsumerRecord5.timestamp();
        int int10 = charSequenceConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + (-1L) + "'", long8 == (-1L));
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
    }

    @Test
    public void test6740() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6740");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", 100, (long) '#', 100L, timestampType4, (long) 10, (int) '#', (int) (byte) 100, (java.lang.CharSequence) "", "");
        long long11 = charSequenceConsumerRecord10.timestamp();
        long long12 = charSequenceConsumerRecord10.offset();
        int int13 = charSequenceConsumerRecord10.serializedKeySize();
        int int14 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 100L + "'", long11 == 100L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 35L + "'", long12 == 35L);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 35 + "'", int13 == 35);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 100 + "'", int14 == 100);
    }

    @Test
    public void test6741() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6741");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        int int12 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy13 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy13;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
    }

    @Test
    public void test6742() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6742");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout27 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout27.maxRetries = (byte) -1;
        int int30 = strKafkaSpout27.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor31 = null;
        strKafkaSpout27.waitingToEmit = strConsumerRecordItor31;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout27.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer34 = strKafkaSpout27.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType40, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long47 = charSequenceConsumerRecord46.offset();
        long long48 = charSequenceConsumerRecord46.checksum();
        int int49 = charSequenceConsumerRecord46.serializedKeySize();
        org.apache.kafka.common.header.Headers headers50 = charSequenceConsumerRecord46.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType23, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout27, (java.lang.CharSequence) "hi!", headers50);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 1, 0L, (long) (byte) 0, timestampType23, (long) ' ', (int) (short) -1, (int) (byte) 10, (java.lang.CharSequence) "", "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) -1, (long) ' ', (long) (short) 0, timestampType23, (long) (short) 1, (int) (byte) 10, (int) '#', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        org.apache.kafka.common.record.TimestampType timestampType73 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType73, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        java.lang.String str80 = charSequenceConsumerRecord79.topic();
        org.apache.kafka.common.header.Headers headers81 = charSequenceConsumerRecord79.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 0, (long) 52, (long) (byte) -1, timestampType23, (java.lang.Long) 1L, (int) (short) 0, (-1), (java.lang.CharSequence) "hi!", "hi!", headers81);
        long long83 = charSequenceConsumerRecord82.timestamp();
        org.apache.kafka.common.header.Headers headers84 = charSequenceConsumerRecord82.headers();
        int int85 = charSequenceConsumerRecord82.partition();
        java.lang.String str86 = charSequenceConsumerRecord82.topic();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(strKafkaConsumer34);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 0L + "'", long47 == 0L);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 52 + "'", int49 == 52);
        org.junit.Assert.assertNotNull(headers50);
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "hi!" + "'", str80, "hi!");
        org.junit.Assert.assertNotNull(headers81);
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + (-1L) + "'", long83 == (-1L));
        org.junit.Assert.assertNotNull(headers84);
        org.junit.Assert.assertTrue("'" + int85 + "' != '" + 0 + "'", int85 == 0);
        org.junit.Assert.assertEquals("'" + str86 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str86, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
    }

    @Test
    public void test6743() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6743");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.header.Headers headers20 = charSequenceConsumerRecord10.headers();
        java.lang.String str21 = charSequenceConsumerRecord10.value();
        java.lang.String str22 = charSequenceConsumerRecord10.value();
        long long23 = charSequenceConsumerRecord10.timestamp();
        int int24 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "hi!" + "'", str21, "hi!");
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "hi!" + "'", str22, "hi!");
        org.junit.Assert.assertTrue("'" + long23 + "' != '" + (-1L) + "'", long23 == (-1L));
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
    }

    @Test
    public void test6744() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6744");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType14, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long21 = charSequenceConsumerRecord20.checksum();
        int int22 = charSequenceConsumerRecord20.partition();
        java.lang.String str23 = charSequenceConsumerRecord20.value();
        int int24 = charSequenceConsumerRecord20.serializedKeySize();
        org.apache.kafka.common.header.Headers headers25 = charSequenceConsumerRecord20.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 0, (long) 100, (long) (short) 1, timestampType4, (java.lang.Long) 0L, (int) ' ', (int) (short) 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "", headers25);
        long long27 = charSequenceConsumerRecord26.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType28 = charSequenceConsumerRecord26.timestampType();
        long long29 = charSequenceConsumerRecord26.timestamp();
        java.lang.String str30 = charSequenceConsumerRecord26.toString();
        java.lang.CharSequence charSequence31 = charSequenceConsumerRecord26.key();
        int int32 = charSequenceConsumerRecord26.partition();
        java.lang.String str33 = charSequenceConsumerRecord26.value();
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 10 + "'", int22 == 10);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "hi!" + "'", str23, "hi!");
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + 52 + "'", int24 == 52);
        org.junit.Assert.assertNotNull(headers25);
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + 1L + "'", long27 == 1L);
        org.junit.Assert.assertNull(timestampType28);
        org.junit.Assert.assertTrue("'" + long29 + "' != '" + 1L + "'", long29 == 1L);
        org.junit.Assert.assertEquals("'" + str30 + "' != '" + "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, null = 1, serialized key size = 32, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )" + "'", str30, "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, null = 1, serialized key size = 32, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )");
        org.junit.Assert.assertEquals("'" + charSequence31 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence31, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int32 + "' != '" + 0 + "'", int32 == 0);
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "" + "'", str33, "");
    }

    @Test
    public void test6745() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6745");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.numUncommittedOffsets = (byte) 1;
        strKafkaSpout0.initialized = false;
        strKafkaSpout0.maxRetries = (byte) 100;
        boolean boolean16 = strKafkaSpout0.consumerAutoCommitMode;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + boolean16 + "' != '" + false + "'", boolean16 == false);
    }

    @Test
    public void test6746() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6746");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        strKafkaSpout0.initialized = false;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig10 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords11 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords11);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNull(strKafkaSpoutConfig10);
    }

    @Test
    public void test6747() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6747");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 10, (long) '4', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
        java.lang.String str6 = charSequenceConsumerRecord5.toString();
        java.util.Optional<java.lang.Integer> intOptional7 = charSequenceConsumerRecord5.leaderEpoch();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]}), value = ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null}))" + "'", str6, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]}), value = ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null}))");
        org.junit.Assert.assertNotNull(intOptional7);
    }

    @Test
    public void test6748() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6748");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        int int12 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder13;
        strKafkaSpout0.numUncommittedOffsets = (short) 10;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor17 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor17;
        boolean boolean19 = strKafkaSpout0.consumerAutoCommitMode;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + boolean19 + "' != '" + false + "'", boolean19 == false);
    }

    @Test
    public void test6749() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6749");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.CharSequence charSequence6 = charSequenceConsumerRecord5.key();
        org.apache.kafka.common.header.Headers headers7 = charSequenceConsumerRecord5.headers();
        org.apache.kafka.common.record.TimestampType timestampType8 = charSequenceConsumerRecord5.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType9 = charSequenceConsumerRecord5.timestampType();
        long long10 = charSequenceConsumerRecord5.offset();
        org.junit.Assert.assertEquals("'" + charSequence6 + "' != '" + "" + "'", charSequence6, "");
        org.junit.Assert.assertNotNull(headers7);
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType9 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType9.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 10L + "'", long10 == 10L);
    }

    @Test
    public void test6750() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6750");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        long long8 = strKafkaSpout0.numUncommittedOffsets;
        strKafkaSpout0.numUncommittedOffsets = (-1L);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = strKafkaSpout0.kafkaConsumer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor12 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor12;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
// flaky:             org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 0L + "'", long8 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer11);
    }

    @Test
    public void test6751() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6751");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (-1), (long) ' ', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long14 = charSequenceConsumerRecord13.timestamp();
        java.lang.String str15 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord13.headers();
        long long17 = charSequenceConsumerRecord13.checksum();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = 35, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)", (int) ' ', 0L, (long) ' ', timestampType18, (long) (short) -1, (int) (short) 10, (int) (short) 0, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdCollection28 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.CharSequence> kafkaSpoutMessageIdCollectionConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.CharSequence>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 52, 0L, (long) 0, timestampType18, 35L, (-1), (int) (byte) -1, kafkaSpoutMessageIdCollection28, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test6752() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6752");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer16;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer18 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig19 = strKafkaSpout0.kafkaSpoutConfig;
        strKafkaSpout0.maxRetries = 0;
        org.apache.kafka.common.TopicPartition topicPartition22 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection23 = strKafkaSpout0.toArrayList(topicPartition22);
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertNull(strKafkaConsumer18);
        org.junit.Assert.assertNull(strKafkaSpoutConfig19);
        org.junit.Assert.assertNotNull(topicPartitionCollection23);
    }

    @Test
    public void test6753() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6753");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy6 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig7 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig7;
        int int9 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(firstPollOffsetStrategy6);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + 0 + "'", int9 == 0);
    }

    @Test
    public void test6754() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6754");
        org.apache.kafka.common.record.TimestampType timestampType8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType8, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long15 = charSequenceConsumerRecord14.checksum();
        int int16 = charSequenceConsumerRecord14.partition();
        long long17 = charSequenceConsumerRecord14.timestamp();
        long long18 = charSequenceConsumerRecord14.offset();
        int int19 = charSequenceConsumerRecord14.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType20 = charSequenceConsumerRecord14.timestampType();
        int int21 = charSequenceConsumerRecord14.partition();
        long long22 = charSequenceConsumerRecord14.checksum();
        java.util.Optional<java.lang.Integer> intOptional23 = charSequenceConsumerRecord14.leaderEpoch();
        org.apache.kafka.common.header.Headers headers24 = charSequenceConsumerRecord14.headers();
        java.lang.String str25 = charSequenceConsumerRecord14.value();
        java.lang.String str26 = charSequenceConsumerRecord14.value();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>> strComparableConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", (int) (byte) 10, 32L, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", charSequenceConsumerRecord14);
        org.apache.kafka.common.header.Headers headers28 = charSequenceConsumerRecord14.headers();
        long long29 = charSequenceConsumerRecord14.timestamp();
        long long30 = charSequenceConsumerRecord14.timestamp();
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 52 + "'", int19 == 52);
        org.junit.Assert.assertNull(timestampType20);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 10 + "'", int21 == 10);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
        org.junit.Assert.assertNotNull(intOptional23);
        org.junit.Assert.assertNotNull(headers24);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "hi!" + "'", str25, "hi!");
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "hi!" + "'", str26, "hi!");
        org.junit.Assert.assertNotNull(headers28);
        org.junit.Assert.assertTrue("'" + long29 + "' != '" + (-1L) + "'", long29 == (-1L));
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
    }

    @Test
    public void test6755() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6755");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService8;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean10 = strKafkaSpout0.poll();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
    }

    @Test
    public void test6756() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6756");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams7;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = strKafkaSpout0.retryService;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        strKafkaSpout0.maxRetries = (-1);
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig13 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy14 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy14;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(kafkaSpoutRetryService9);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertNull(strKafkaSpoutConfig13);
    }

    @Test
    public void test6757() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6757");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.initialized = false;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = null;
        strKafkaSpout0.collector = spoutOutputCollector12;
        boolean boolean14 = strKafkaSpout0.consumerAutoCommitMode;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
    }

    @Test
    public void test6758() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6758");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor6 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor6;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService8;
        java.lang.String str10 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer11 = strKafkaSpout0.commitTimer;
        boolean boolean12 = strKafkaSpout0.waitingToEmit();
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str10, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(timer11);
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + false + "'", boolean12 == false);
    }

    @Test
    public void test6759() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6759");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        long long20 = charSequenceConsumerRecord10.timestamp();
        long long21 = charSequenceConsumerRecord10.timestamp();
        java.lang.CharSequence charSequence22 = charSequenceConsumerRecord10.key();
        int int23 = charSequenceConsumerRecord10.partition();
        long long24 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence22 + "' != '" + "" + "'", charSequence22, "");
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 10 + "'", int23 == 10);
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + (-1L) + "'", long24 == (-1L));
    }

    @Test
    public void test6760() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6760");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        java.lang.String str18 = charSequenceConsumerRecord10.topic();
        int int19 = charSequenceConsumerRecord10.serializedKeySize();
        long long20 = charSequenceConsumerRecord10.offset();
        java.lang.String str21 = charSequenceConsumerRecord10.toString();
        java.lang.CharSequence charSequence22 = charSequenceConsumerRecord10.key();
        long long23 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 52 + "'", int19 == 52);
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 0L + "'", long20 == 0L);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str21, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + charSequence22 + "' != '" + "" + "'", charSequence22, "");
        org.junit.Assert.assertTrue("'" + long23 + "' != '" + 0L + "'", long23 == 0L);
    }

    @Test
    public void test6761() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6761");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        int int12 = strKafkaSpout0.maxRetries;
        long long13 = strKafkaSpout0.numUncommittedOffsets;
        java.lang.String str14 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams15 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams15;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor17 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor17;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig19 = strKafkaSpout0.kafkaSpoutConfig;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean20 = strKafkaSpout0.poll();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str14, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutConfig19);
    }

    @Test
    public void test6762() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6762");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig8 = strKafkaSpout0.kafkaSpoutConfig;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str9 = strKafkaSpout0.getNamedTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(strKafkaSpoutConfig8);
    }

    @Test
    public void test6763() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6763");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType4, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        java.lang.String str11 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.header.Headers headers12 = charSequenceConsumerRecord10.headers();
        java.lang.CharSequence charSequence13 = charSequenceConsumerRecord10.key();
        java.lang.String str14 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.header.Headers headers15 = charSequenceConsumerRecord10.headers();
        java.lang.String str16 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "hi!" + "'", str11, "hi!");
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertEquals("'" + charSequence13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertNotNull(headers15);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", str16, "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
    }

    @Test
    public void test6764() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6764");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) 100, (long) 0, (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        int int7 = charSequenceConsumerRecord5.partition();
        int int8 = charSequenceConsumerRecord5.partition();
        java.lang.String str9 = charSequenceConsumerRecord5.topic();
        long long10 = charSequenceConsumerRecord5.offset();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 100 + "'", int8 == 100);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str9, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 0L + "'", long10 == 0L);
    }

    @Test
    public void test6765() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6765");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor6 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor6;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService8;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector10 = strKafkaSpout0.collector;
        boolean boolean11 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = null;
        strKafkaSpout0.collector = spoutOutputCollector12;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(spoutOutputCollector10);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
    }

    @Test
    public void test6766() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6766");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord8 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 10, 1L, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=[]}");
        long long9 = charSequenceConsumerRecord8.checksum();
        java.lang.CharSequence charSequence10 = charSequenceConsumerRecord8.key();
        java.util.Optional<java.lang.Integer> intOptional11 = charSequenceConsumerRecord8.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.Comparable<java.lang.String>> intOptionalConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", (int) (byte) 1, (long) 1, intOptional11, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence10 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence10, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(intOptional11);
    }

    @Test
    public void test6767() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6767");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout11 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = strKafkaSpout11.kafkaSpoutStreams;
        strKafkaSpout11.consumerAutoCommitMode = false;
        java.lang.String str15 = strKafkaSpout11.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout16 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout16.maxRetries = (byte) -1;
        int int19 = strKafkaSpout16.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray20 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet21 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean22 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, kafkaSpoutMessageIdArray20);
        strKafkaSpout16.emitted = kafkaSpoutMessageIdSet21;
        strKafkaSpout11.emitted = kafkaSpoutMessageIdSet21;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout25 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout25.maxRetries = (byte) -1;
        int int28 = strKafkaSpout25.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor29 = null;
        strKafkaSpout25.waitingToEmit = strConsumerRecordItor29;
        org.apache.kafka.common.TopicPartition topicPartition31 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection32 = strKafkaSpout25.toArrayList(topicPartition31);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout25.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector34 = strKafkaSpout25.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout35.maxRetries = (byte) -1;
        int int38 = strKafkaSpout35.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray39 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet40 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean41 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40, kafkaSpoutMessageIdArray39);
        strKafkaSpout35.emitted = kafkaSpoutMessageIdSet40;
        strKafkaSpout25.emitted = kafkaSpoutMessageIdSet40;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType7, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet40;
        long long46 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService47 = strKafkaSpout0.retryService;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(strKafkaSpoutConfig2);
        org.junit.Assert.assertNull(kafkaSpoutStreams12);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray20);
        org.junit.Assert.assertTrue("'" + boolean22 + "' != '" + false + "'", boolean22 == false);
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + (-1) + "'", int28 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection32);
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(spoutOutputCollector34);
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + (-1) + "'", int38 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray39);
        org.junit.Assert.assertTrue("'" + boolean41 + "' != '" + false + "'", boolean41 == false);
        org.junit.Assert.assertTrue("'" + long46 + "' != '" + 0L + "'", long46 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutRetryService47);
    }

    @Test
    public void test6768() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6768");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 10, 1L, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=[]}");
        int int6 = charSequenceConsumerRecord5.partition();
        java.lang.String str7 = charSequenceConsumerRecord5.toString();
        java.lang.CharSequence charSequence8 = charSequenceConsumerRecord5.key();
        long long9 = charSequenceConsumerRecord5.timestamp();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + 10 + "'", int6 == 10);
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})" + "'", str7, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})");
        org.junit.Assert.assertEquals("'" + charSequence8 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence8, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
    }

    @Test
    public void test6769() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6769");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.toString();
        long long16 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str15, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
    }

    @Test
    public void test6770() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6770");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)", (int) '#', 97L, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
    }

    @Test
    public void test6771() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6771");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        int int12 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder13;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService15 = strKafkaSpout0.retryService;
        boolean boolean16 = strKafkaSpout0.consumerAutoCommitMode;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet17 = strKafkaSpout0.emitted;
        boolean boolean18 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector19 = strKafkaSpout0.collector;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str20 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService15);
        org.junit.Assert.assertTrue("'" + boolean16 + "' != '" + false + "'", boolean16 == false);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet17);
        org.junit.Assert.assertTrue("'" + boolean18 + "' != '" + false + "'", boolean18 == false);
        org.junit.Assert.assertNull(spoutOutputCollector19);
    }

    @Test
    public void test6772() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6772");
        org.apache.storm.kafka.spout.KafkaSpout<java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, org.apache.storm.kafka.spout.KafkaSpout<org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>, org.apache.storm.topology.base.BaseRichSpout>.KafkaSpoutConsumerRebalanceListener> kafkaSpoutMessageIdListKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, org.apache.storm.kafka.spout.KafkaSpout<org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>, org.apache.storm.topology.base.BaseRichSpout>.KafkaSpoutConsumerRebalanceListener>();
    }

    @Test
    public void test6773() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6773");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        boolean boolean11 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor12 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor12;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer14 = strKafkaSpout0.kafkaConsumer;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(strKafkaConsumer14);
    }

    @Test
    public void test6774() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6774");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 10, 1L, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=[]}");
        java.lang.String str6 = charSequenceConsumerRecord5.value();
        java.util.Optional<java.lang.Integer> intOptional7 = charSequenceConsumerRecord5.leaderEpoch();
        long long8 = charSequenceConsumerRecord5.offset();
        java.lang.String str9 = charSequenceConsumerRecord5.value();
        long long10 = charSequenceConsumerRecord5.timestamp();
        int int11 = charSequenceConsumerRecord5.partition();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "KafkaSpout{acked=null, emitted=[]}" + "'", str6, "KafkaSpout{acked=null, emitted=[]}");
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 1L + "'", long8 == 1L);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "KafkaSpout{acked=null, emitted=[]}" + "'", str9, "KafkaSpout{acked=null, emitted=[]}");
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 10 + "'", int11 == 10);
    }

    @Test
    public void test6775() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6775");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (byte) 0, (long) (byte) -1, (long) (short) 100, timestampType4, (long) (short) 1, (int) (byte) 1, (int) (short) 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        long long11 = charSequenceConsumerRecord10.offset();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str13 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNull(timestampType12);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertNull(timestampType14);
    }

    @Test
    public void test6776() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6776");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams3 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = strKafkaSpout0.firstPollOffsetStrategy;
        boolean boolean6 = strKafkaSpout0.consumerAutoCommitMode;
        org.junit.Assert.assertNull(firstPollOffsetStrategy5);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
    }

    @Test
    public void test6777() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6777");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor10 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor10;
        org.apache.kafka.common.TopicPartition topicPartition12 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection13 = strKafkaSpout0.toArrayList(topicPartition12);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer14 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer14;
        strKafkaSpout0.numUncommittedOffsets = 100;
        strKafkaSpout0.maxRetries = (byte) 100;
        long long20 = strKafkaSpout0.numUncommittedOffsets;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor21 = strKafkaSpout0.waitingToEmit;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection13);
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 100L + "'", long20 == 100L);
        org.junit.Assert.assertNull(strConsumerRecordItor21);
    }

    @Test
    public void test6778() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6778");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams9 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams10;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout12 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor13 = null;
        strKafkaSpout12.waitingToEmit = strConsumerRecordItor13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer15 = null;
        strKafkaSpout12.kafkaConsumer = strKafkaConsumer15;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy17 = null;
        strKafkaSpout12.firstPollOffsetStrategy = firstPollOffsetStrategy17;
        java.lang.String str19 = strKafkaSpout12.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder20 = strKafkaSpout12.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout21 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout21.maxRetries = (byte) -1;
        int int24 = strKafkaSpout21.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor25 = null;
        strKafkaSpout21.waitingToEmit = strConsumerRecordItor25;
        org.apache.kafka.common.TopicPartition topicPartition27 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection28 = strKafkaSpout21.toArrayList(topicPartition27);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer29 = strKafkaSpout21.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector30 = strKafkaSpout21.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout31 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout31.maxRetries = (byte) -1;
        int int34 = strKafkaSpout31.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray35 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet36 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean37 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet36, kafkaSpoutMessageIdArray35);
        strKafkaSpout31.emitted = kafkaSpoutMessageIdSet36;
        strKafkaSpout21.emitted = kafkaSpoutMessageIdSet36;
        strKafkaSpout12.emitted = kafkaSpoutMessageIdSet36;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet36;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.deactivate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(kafkaSpoutStreams9);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str19, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder20);
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection28);
        org.junit.Assert.assertNull(timer29);
        org.junit.Assert.assertNull(spoutOutputCollector30);
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + (-1) + "'", int34 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray35);
        org.junit.Assert.assertTrue("'" + boolean37 + "' != '" + false + "'", boolean37 == false);
    }

    @Test
    public void test6779() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6779");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy3 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy4 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = strKafkaSpout0.firstPollOffsetStrategy;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor6 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor6;
        strKafkaSpout0.numUncommittedOffsets = 32L;
        long long10 = strKafkaSpout0.numUncommittedOffsets;
        org.junit.Assert.assertNull(firstPollOffsetStrategy3);
        org.junit.Assert.assertNull(firstPollOffsetStrategy4);
        org.junit.Assert.assertNull(firstPollOffsetStrategy5);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 32L + "'", long10 == 32L);
    }

    @Test
    public void test6780() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6780");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        strKafkaSpout0.initialized = true;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder10 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder10;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.deactivate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
    }

    @Test
    public void test6781() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6781");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        long long8 = strKafkaSpout0.numUncommittedOffsets;
        strKafkaSpout0.numUncommittedOffsets = (-1L);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService12 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService12;
        long long14 = strKafkaSpout0.numUncommittedOffsets;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 0L + "'", long8 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer11);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
    }

    @Test
    public void test6782() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6782");
        org.apache.storm.kafka.spout.KafkaSpout kafkaSpout0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, org.apache.storm.kafka.spout.KafkaSpout<org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>, org.apache.storm.topology.base.BaseRichSpout>.KafkaSpoutConsumerRebalanceListener>.Timer timer1 = kafkaSpout0.new Timer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: reflection call to org.apache.storm.kafka.spout.KafkaSpout$Timer with null for superclass argument");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test6783() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6783");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        boolean boolean9 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector10 = strKafkaSpout0.collector;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords11 = strKafkaSpout0.pollKafkaBroker();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertTrue("'" + boolean9 + "' != '" + false + "'", boolean9 == false);
        org.junit.Assert.assertNull(spoutOutputCollector10);
    }

    @Test
    public void test6784() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6784");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder2 = strKafkaSpout0.tuplesBuilder;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService4 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService4;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder6 = strKafkaSpout0.tuplesBuilder;
        org.apache.kafka.common.TopicPartition topicPartition7 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection8 = strKafkaSpout0.toArrayList(topicPartition7);
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder2);
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + 0 + "'", int3 == 0);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder6);
        org.junit.Assert.assertNotNull(topicPartitionCollection8);
    }

    @Test
    public void test6785() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6785");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType13 = charSequenceConsumerRecord10.timestampType();
        int int14 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str16 = charSequenceConsumerRecord10.toString();
        long long17 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNull(timestampType13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertNull(timestampType15);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
    }

    @Test
    public void test6786() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6786");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams10;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy12 = strKafkaSpout0.firstPollOffsetStrategy;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder9);
        org.junit.Assert.assertNull(firstPollOffsetStrategy12);
    }

    @Test
    public void test6787() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6787");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        int int19 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.header.Headers headers20 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType21 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str22 = charSequenceConsumerRecord10.value();
        int int23 = charSequenceConsumerRecord10.serializedKeySize();
        int int24 = charSequenceConsumerRecord10.serializedValueSize();
        int int25 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.String str26 = charSequenceConsumerRecord10.toString();
        java.lang.String str27 = charSequenceConsumerRecord10.value();
        int int28 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertNull(timestampType21);
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "hi!" + "'", str22, "hi!");
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 52 + "'", int23 == 52);
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + (-1) + "'", int25 == (-1));
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str26, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str27 + "' != '" + "hi!" + "'", str27, "hi!");
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 52 + "'", int28 == 52);
    }

    @Test
    public void test6788() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6788");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) 0, 0L, (long) 97, timestampType4, (long) '4', (int) ' ', (int) (byte) 1, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        int int11 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        long long15 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 0 + "'", int11 == 0);
        org.junit.Assert.assertNull(timestampType12);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 0L + "'", long15 == 0L);
    }

    @Test
    public void test6789() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6789");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout27 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout27.maxRetries = (byte) -1;
        int int30 = strKafkaSpout27.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor31 = null;
        strKafkaSpout27.waitingToEmit = strConsumerRecordItor31;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout27.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer34 = strKafkaSpout27.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType40, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long47 = charSequenceConsumerRecord46.offset();
        long long48 = charSequenceConsumerRecord46.checksum();
        int int49 = charSequenceConsumerRecord46.serializedKeySize();
        org.apache.kafka.common.header.Headers headers50 = charSequenceConsumerRecord46.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType23, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout27, (java.lang.CharSequence) "hi!", headers50);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 1, 0L, (long) (byte) 0, timestampType23, (long) ' ', (int) (short) -1, (int) (byte) 10, (java.lang.CharSequence) "", "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) -1, (long) ' ', (long) (short) 0, timestampType23, (long) (short) 1, (int) (byte) 10, (int) '#', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        org.apache.kafka.common.header.Headers headers64 = charSequenceConsumerRecord63.headers();
        org.apache.kafka.common.header.Headers headers65 = charSequenceConsumerRecord63.headers();
        org.apache.kafka.common.record.TimestampType timestampType66 = charSequenceConsumerRecord63.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 100, (long) '4', 1L, timestampType66, 97L, 97, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
        org.apache.kafka.common.record.TimestampType timestampType73 = charSequenceConsumerRecord72.timestampType();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(strKafkaConsumer34);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 0L + "'", long47 == 0L);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 52 + "'", int49 == 52);
        org.junit.Assert.assertNotNull(headers50);
        org.junit.Assert.assertNotNull(headers64);
        org.junit.Assert.assertNotNull(headers65);
        org.junit.Assert.assertTrue("'" + timestampType66 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType66.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType73 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType73.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test6790() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6790");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator4 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator4;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord6 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator4);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator4.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator8 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator9 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator9;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = offsetComparator9.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator16 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator16;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator16);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = kafkaSpoutMessageIdComparator11.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator16);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = offsetComparator8.thenComparing(kafkaSpoutMessageIdComparator19);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = kafkaSpoutMessageIdComparator19.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator19;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = kafkaSpoutMessageIdComparator7.thenComparing(kafkaSpoutMessageIdComparator19);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator24 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator24;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator24.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator31 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator31;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = kafkaSpoutMessageIdComparator26.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator31);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator35 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator35;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = offsetComparator35.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = offsetComparator35.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = offsetComparator31.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator35);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator40 = kafkaSpoutMessageIdComparator39.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = kafkaSpoutMessageIdComparator40.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator42 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator42;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = offsetComparator42.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator49 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator49;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator49);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator52 = kafkaSpoutMessageIdComparator44.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator49);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator53 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator53;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator55 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator56 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator56;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator58 = offsetComparator56.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator59 = offsetComparator55.thenComparing(kafkaSpoutMessageIdComparator58);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator60 = offsetComparator53.thenComparing(kafkaSpoutMessageIdComparator59);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator61 = offsetComparator49.thenComparing(kafkaSpoutMessageIdComparator60);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator62 = kafkaSpoutMessageIdComparator40.thenComparing(kafkaSpoutMessageIdComparator60);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator63 = kafkaSpoutMessageIdComparator7.thenComparing(kafkaSpoutMessageIdComparator62);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator64 = kafkaSpoutMessageIdComparator7.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator40);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator52);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator58);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator59);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator60);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator61);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator62);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator63);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator64);
    }

    @Test
    public void test6791() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6791");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig8 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig8;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean10 = strKafkaSpout0.commit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
    }

    @Test
    public void test6792() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6792");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        boolean boolean5 = strKafkaSpout0.waitingToEmit();
        long long6 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder7;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig10 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig10;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor12 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor12;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord14 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean15 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord14);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + 0L + "'", long6 == 0L);
        org.junit.Assert.assertNull(firstPollOffsetStrategy9);
    }

    @Test
    public void test6793() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6793");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, 1L, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "");
        long long6 = charSequenceConsumerRecord5.offset();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + 1L + "'", long6 == 1L);
    }

    @Test
    public void test6794() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6794");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        java.lang.String str12 = charSequenceConsumerRecord10.value();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord10.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        org.apache.kafka.common.header.Headers headers17 = charSequenceConsumerRecord10.headers();
        java.lang.CharSequence charSequence18 = charSequenceConsumerRecord10.key();
        java.lang.String str19 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertNull(timestampType15);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertNotNull(headers17);
        org.junit.Assert.assertEquals("'" + charSequence18 + "' != '" + "" + "'", charSequence18, "");
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "" + "'", str19, "");
    }

    @Test
    public void test6795() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6795");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig4 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(timer6);
    }

    @Test
    public void test6796() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6796");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        int int15 = charSequenceConsumerRecord10.partition();
        long long16 = charSequenceConsumerRecord10.checksum();
        long long17 = charSequenceConsumerRecord10.offset();
        long long18 = charSequenceConsumerRecord10.offset();
        java.lang.CharSequence charSequence19 = charSequenceConsumerRecord10.key();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertEquals("'" + charSequence19 + "' != '" + "" + "'", charSequence19, "");
        org.junit.Assert.assertNotNull(intOptional20);
    }

    @Test
    public void test6797() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6797");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy3 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy4 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = strKafkaSpout0.firstPollOffsetStrategy;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor6 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor6;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet8 = strKafkaSpout0.emitted;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer9 = strKafkaSpout0.kafkaConsumer;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(firstPollOffsetStrategy3);
        org.junit.Assert.assertNull(firstPollOffsetStrategy4);
        org.junit.Assert.assertNull(firstPollOffsetStrategy5);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet8);
        org.junit.Assert.assertNull(strKafkaConsumer9);
    }

    @Test
    public void test6798() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6798");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        long long12 = charSequenceConsumerRecord10.checksum();
        int int13 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.String str14 = charSequenceConsumerRecord10.value();
        long long15 = charSequenceConsumerRecord10.checksum();
        long long16 = charSequenceConsumerRecord10.timestamp();
        int int17 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 52 + "'", int13 == 52);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 52 + "'", int17 == 52);
    }

    @Test
    public void test6799() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6799");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str6 = charSequenceConsumerRecord5.topic();
        java.util.Optional<java.lang.Integer> intOptional7 = charSequenceConsumerRecord5.leaderEpoch();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        int int9 = charSequenceConsumerRecord5.serializedKeySize();
        int int10 = charSequenceConsumerRecord5.serializedKeySize();
        long long11 = charSequenceConsumerRecord5.checksum();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord5.key();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "" + "'", str6, "");
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
    }

    @Test
    public void test6800() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6800");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = ' ';
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams10;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean12 = strKafkaSpout0.commit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
    }

    @Test
    public void test6801() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6801");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        boolean boolean7 = strKafkaSpout0.initialized;
        strKafkaSpout0.maxRetries = (byte) 10;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService10;
        int int12 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder13;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords15 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords15);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
    }

    @Test
    public void test6802() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6802");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Object, java.lang.Object> objKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.Object> objKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Object, java.lang.Object>(objKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test6803() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6803");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        java.lang.String str18 = charSequenceConsumerRecord10.topic();
        long long19 = charSequenceConsumerRecord10.checksum();
        java.lang.String str20 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str20, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test6804() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6804");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout3 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout3.maxRetries = (byte) -1;
        int int6 = strKafkaSpout3.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout3.waitingToEmit = strConsumerRecordItor7;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout3.toArrayList(topicPartition9);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = strKafkaSpout3.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType16 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout20 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout20.maxRetries = (byte) -1;
        int int23 = strKafkaSpout20.maxRetries;
        strKafkaSpout20.numUncommittedOffsets = '#';
        strKafkaSpout20.initialized = true;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet28 = strKafkaSpout20.emitted;
        org.apache.kafka.common.record.TimestampType timestampType36 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType36, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int43 = charSequenceConsumerRecord42.serializedValueSize();
        java.lang.CharSequence charSequence44 = charSequenceConsumerRecord42.key();
        org.apache.kafka.common.header.Headers headers45 = charSequenceConsumerRecord42.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray46 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList47 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean48 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47, kafkaSpoutMessageIdArray46);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers45, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47);
        org.apache.kafka.common.record.TimestampType timestampType54 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType54, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int61 = charSequenceConsumerRecord60.serializedValueSize();
        java.lang.CharSequence charSequence62 = charSequenceConsumerRecord60.key();
        org.apache.kafka.common.header.Headers headers63 = charSequenceConsumerRecord60.headers();
        org.apache.kafka.common.record.TimestampType timestampType68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType68, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long75 = charSequenceConsumerRecord74.offset();
        int int76 = charSequenceConsumerRecord74.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional77 = charSequenceConsumerRecord74.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> objConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) '4', (long) (short) 0, (long) 100, timestampType16, (java.lang.Long) 1L, (int) (short) 0, 0, (java.lang.Object) kafkaSpoutMessageIdSet28, (java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47, headers63, intOptional77);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.common.header.Headers> iSpoutConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.common.header.Headers>("KafkaSpout{acked=null, emitted=null}", (int) '#', (long) 1, (org.apache.storm.spout.ISpout) strKafkaSpout3, headers63);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService80 = null;
        strKafkaSpout3.retryService = kafkaSpoutRetryService80;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy82 = null;
        strKafkaSpout3.firstPollOffsetStrategy = firstPollOffsetStrategy82;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer84 = strKafkaSpout3.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder85 = strKafkaSpout3.tuplesBuilder;
        boolean boolean86 = strKafkaSpout3.initialized;
        int int87 = strKafkaSpout3.maxRetries;
        strKafkaSpout3.consumerAutoCommitMode = false;
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(strKafkaConsumer11);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet28);
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + (-1) + "'", int43 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence44 + "' != '" + "" + "'", charSequence44, "");
        org.junit.Assert.assertNotNull(headers45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray46);
        org.junit.Assert.assertTrue("'" + boolean48 + "' != '" + false + "'", boolean48 == false);
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + (-1) + "'", int61 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence62 + "' != '" + "" + "'", charSequence62, "");
        org.junit.Assert.assertNotNull(headers63);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + 0L + "'", long75 == 0L);
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + (-1) + "'", int76 == (-1));
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertNull(timer84);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder85);
        org.junit.Assert.assertTrue("'" + boolean86 + "' != '" + false + "'", boolean86 == false);
        org.junit.Assert.assertTrue("'" + int87 + "' != '" + (-1) + "'", int87 == (-1));
    }

    @Test
    public void test6805() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6805");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector3 = null;
        strKafkaSpout0.collector = spoutOutputCollector3;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = strKafkaSpout0.emitted;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(strKafkaSpoutConfig2);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet5);
    }

    @Test
    public void test6806() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6806");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        boolean boolean7 = strKafkaSpout0.initialized;
        strKafkaSpout0.consumerAutoCommitMode = true;
        boolean boolean10 = strKafkaSpout0.commit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor11 = strKafkaSpout0.waitingToEmit;
        org.apache.kafka.common.TopicPartition topicPartition12 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection13 = strKafkaSpout0.toArrayList(topicPartition12);
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig14 = strKafkaSpout0.kafkaSpoutConfig;
        boolean boolean15 = strKafkaSpout0.waitingToEmit();
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str16 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor11);
        org.junit.Assert.assertNotNull(topicPartitionCollection13);
        org.junit.Assert.assertNull(strKafkaSpoutConfig14);
        org.junit.Assert.assertTrue("'" + boolean15 + "' != '" + false + "'", boolean15 == false);
    }

    @Test
    public void test6807() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6807");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long14 = charSequenceConsumerRecord13.checksum();
        long long15 = charSequenceConsumerRecord13.timestamp();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord13.headers();
        java.lang.String str17 = charSequenceConsumerRecord13.toString();
        org.apache.kafka.common.header.Headers headers18 = charSequenceConsumerRecord13.headers();
        java.lang.String str19 = charSequenceConsumerRecord13.topic();
        long long20 = charSequenceConsumerRecord13.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType21 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType31 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType31, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long38 = charSequenceConsumerRecord37.checksum();
        int int39 = charSequenceConsumerRecord37.partition();
        long long40 = charSequenceConsumerRecord37.timestamp();
        long long41 = charSequenceConsumerRecord37.offset();
        java.lang.String str42 = charSequenceConsumerRecord37.value();
        java.lang.String str43 = charSequenceConsumerRecord37.topic();
        int int44 = charSequenceConsumerRecord37.partition();
        org.apache.kafka.common.record.TimestampType timestampType45 = charSequenceConsumerRecord37.timestampType();
        int int46 = charSequenceConsumerRecord37.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional47 = charSequenceConsumerRecord37.leaderEpoch();
        int int48 = charSequenceConsumerRecord37.serializedValueSize();
        org.apache.kafka.common.header.Headers headers49 = charSequenceConsumerRecord37.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 100, (long) (short) 1, 52L, timestampType21, (java.lang.Long) 52L, (int) (short) 10, (int) (byte) 1, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", "", headers49);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", (int) (byte) 0, 10L, (long) 32, timestampType21, (long) (byte) 10, (int) '4', 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        long long57 = charSequenceConsumerRecord56.offset();
        org.apache.kafka.common.header.Headers headers58 = charSequenceConsumerRecord56.headers();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str17, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "" + "'", str19, "");
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType21 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType21.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + (-1L) + "'", long38 == (-1L));
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + 10 + "'", int39 == 10);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertTrue("'" + long41 + "' != '" + 0L + "'", long41 == 0L);
        org.junit.Assert.assertEquals("'" + str42 + "' != '" + "hi!" + "'", str42, "hi!");
        org.junit.Assert.assertEquals("'" + str43 + "' != '" + "" + "'", str43, "");
        org.junit.Assert.assertTrue("'" + int44 + "' != '" + 10 + "'", int44 == 10);
        org.junit.Assert.assertNull(timestampType45);
        org.junit.Assert.assertTrue("'" + int46 + "' != '" + (-1) + "'", int46 == (-1));
        org.junit.Assert.assertNotNull(intOptional47);
        org.junit.Assert.assertTrue("'" + int48 + "' != '" + (-1) + "'", int48 == (-1));
        org.junit.Assert.assertNotNull(headers49);
        org.junit.Assert.assertTrue("'" + long57 + "' != '" + 10L + "'", long57 == 10L);
        org.junit.Assert.assertNotNull(headers58);
    }

    @Test
    public void test6808() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6808");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence17 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence18 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        long long20 = charSequenceConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers21 = charSequenceConsumerRecord10.headers();
        int int22 = charSequenceConsumerRecord10.serializedKeySize();
        int int23 = charSequenceConsumerRecord10.partition();
        java.util.Optional<java.lang.Integer> intOptional24 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType25 = charSequenceConsumerRecord10.timestampType();
        int int26 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertEquals("'" + charSequence17 + "' != '" + "" + "'", charSequence17, "");
        org.junit.Assert.assertEquals("'" + charSequence18 + "' != '" + "" + "'", charSequence18, "");
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 0L + "'", long20 == 0L);
        org.junit.Assert.assertNotNull(headers21);
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 52 + "'", int22 == 52);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 10 + "'", int23 == 10);
        org.junit.Assert.assertNotNull(intOptional24);
        org.junit.Assert.assertNull(timestampType25);
        org.junit.Assert.assertTrue("'" + int26 + "' != '" + 52 + "'", int26 == 52);
    }

    @Test
    public void test6809() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6809");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", 0, 10L, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "hi!");
        java.lang.String str6 = charSequenceConsumerRecord5.value();
        long long7 = charSequenceConsumerRecord5.offset();
        int int8 = charSequenceConsumerRecord5.serializedKeySize();
        long long9 = charSequenceConsumerRecord5.timestamp();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "hi!" + "'", str6, "hi!");
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + 10L + "'", long7 == 10L);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
    }

    @Test
    public void test6810() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6810");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.Cloneable, java.lang.Cloneable> cloneableKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Cloneable, java.lang.Cloneable>();
    }

    @Test
    public void test6811() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6811");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        int int21 = charSequenceConsumerRecord10.serializedValueSize();
        long long22 = charSequenceConsumerRecord10.checksum();
        int int23 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 10 + "'", int23 == 10);
    }

    @Test
    public void test6812() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6812");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer6 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer7 = strKafkaSpout0.commitTimer;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean8 = strKafkaSpout0.poll();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer6);
        org.junit.Assert.assertNull(timer7);
    }

    @Test
    public void test6813() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6813");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord10.timestampType();
        long long13 = charSequenceConsumerRecord10.offset();
        java.util.Optional<java.lang.Integer> intOptional14 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNull(timestampType12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertNotNull(intOptional14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
    }

    @Test
    public void test6814() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6814");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = ' ';
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig10 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig10;
        java.lang.String str12 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy13 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector14 = strKafkaSpout0.collector;
        int int15 = strKafkaSpout0.maxRetries;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str12, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(firstPollOffsetStrategy13);
        org.junit.Assert.assertNull(spoutOutputCollector14);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 32 + "'", int15 == 32);
    }

    @Test
    public void test6815() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6815");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout27 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout27.maxRetries = (byte) -1;
        int int30 = strKafkaSpout27.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor31 = null;
        strKafkaSpout27.waitingToEmit = strConsumerRecordItor31;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout27.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer34 = strKafkaSpout27.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType40, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long47 = charSequenceConsumerRecord46.offset();
        long long48 = charSequenceConsumerRecord46.checksum();
        int int49 = charSequenceConsumerRecord46.serializedKeySize();
        org.apache.kafka.common.header.Headers headers50 = charSequenceConsumerRecord46.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType23, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout27, (java.lang.CharSequence) "hi!", headers50);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 1, 0L, (long) (byte) 0, timestampType23, (long) ' ', (int) (short) -1, (int) (byte) 10, (java.lang.CharSequence) "", "");
        java.lang.CharSequence charSequence58 = charSequenceConsumerRecord57.key();
        org.apache.kafka.common.record.TimestampType timestampType59 = charSequenceConsumerRecord57.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord65 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 0, (long) '4', (long) 100, timestampType59, (long) (short) 100, 100, (int) '#', (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 0, (long) (-1), (long) (byte) 1, timestampType59, (long) (short) -1, (int) (byte) 1, 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}))");
        java.lang.CharSequence charSequence72 = charSequenceConsumerRecord71.key();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(strKafkaConsumer34);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 0L + "'", long47 == 0L);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 52 + "'", int49 == 52);
        org.junit.Assert.assertNotNull(headers50);
        org.junit.Assert.assertEquals("'" + charSequence58 + "' != '" + "" + "'", charSequence58, "");
        org.junit.Assert.assertTrue("'" + timestampType59 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType59.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + charSequence72 + "' != '" + "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})" + "'", charSequence72, "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
    }

    @Test
    public void test6816() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6816");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (-1), (long) ' ', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.util.Optional<java.lang.Integer> intOptional6 = charSequenceConsumerRecord5.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional7 = charSequenceConsumerRecord5.leaderEpoch();
        java.lang.CharSequence charSequence8 = charSequenceConsumerRecord5.key();
        long long9 = charSequenceConsumerRecord5.checksum();
        java.lang.String str10 = charSequenceConsumerRecord5.topic();
        org.apache.kafka.common.header.Headers headers11 = charSequenceConsumerRecord5.headers();
        int int12 = charSequenceConsumerRecord5.serializedValueSize();
        org.junit.Assert.assertNotNull(intOptional6);
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertEquals("'" + charSequence8 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence8, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "hi!" + "'", str10, "hi!");
        org.junit.Assert.assertNotNull(headers11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
    }

    @Test
    public void test6817() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6817");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional15 = charSequenceConsumerRecord10.leaderEpoch();
        long long16 = charSequenceConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional17 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str18 = charSequenceConsumerRecord10.toString();
        int int19 = charSequenceConsumerRecord10.partition();
        long long20 = charSequenceConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers21 = charSequenceConsumerRecord10.headers();
        int int22 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 52 + "'", int14 == 52);
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertNotNull(intOptional17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str18, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 0L + "'", long20 == 0L);
        org.junit.Assert.assertNotNull(headers21);
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 10 + "'", int22 == 10);
    }

    @Test
    public void test6818() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6818");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition8 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection9 = strKafkaSpout0.toArrayList(topicPartition8);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer10;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor12 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor12;
        boolean boolean14 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy15 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer16 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer16);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection9);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy15);
    }

    @Test
    public void test6819() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6819");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        int int13 = charSequenceConsumerRecord10.partition();
        int int14 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord10.timestampType();
        long long16 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertNull(timestampType15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
    }

    @Test
    public void test6820() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6820");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition8 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection9 = strKafkaSpout0.toArrayList(topicPartition8);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer10;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer12 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer12;
        java.lang.String str14 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams15 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams15;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams17 = strKafkaSpout0.kafkaSpoutStreams;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor18 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor18;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection9);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str14, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(kafkaSpoutStreams17);
    }

    @Test
    public void test6821() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6821");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService10;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor12 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor12;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService14 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService14;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
    }

    @Test
    public void test6822() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6822");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType23, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long30 = charSequenceConsumerRecord29.checksum();
        int int31 = charSequenceConsumerRecord29.partition();
        java.lang.String str32 = charSequenceConsumerRecord29.value();
        int int33 = charSequenceConsumerRecord29.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional34 = charSequenceConsumerRecord29.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet36 = strKafkaSpout35.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor37 = null;
        strKafkaSpout35.waitingToEmit = strConsumerRecordItor37;
        boolean boolean39 = strKafkaSpout35.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig40 = null;
        strKafkaSpout35.kafkaSpoutConfig = strKafkaSpoutConfig40;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy42 = strKafkaSpout35.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType15, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord29, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout35);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType53, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int60 = charSequenceConsumerRecord59.serializedValueSize();
        java.lang.CharSequence charSequence61 = charSequenceConsumerRecord59.key();
        org.apache.kafka.common.header.Headers headers62 = charSequenceConsumerRecord59.headers();
        int int63 = charSequenceConsumerRecord59.partition();
        int int64 = charSequenceConsumerRecord59.partition();
        org.apache.kafka.common.header.Headers headers65 = charSequenceConsumerRecord59.headers();
        org.apache.kafka.common.record.TimestampType timestampType70 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType70, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int77 = charSequenceConsumerRecord76.serializedValueSize();
        long long78 = charSequenceConsumerRecord76.checksum();
        java.util.Optional<java.lang.Integer> intOptional79 = charSequenceConsumerRecord76.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", (int) (short) 0, (long) (short) 10, (long) 1, timestampType15, (java.lang.Long) 100L, (int) (byte) -1, 52, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", headers65, intOptional79);
        java.util.Optional<java.lang.Integer> intOptional81 = charSequenceConsumerRecord80.leaderEpoch();
        long long82 = charSequenceConsumerRecord80.checksum();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 10 + "'", int31 == 10);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "hi!" + "'", str32, "hi!");
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + 52 + "'", int33 == 52);
        org.junit.Assert.assertNotNull(intOptional34);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet36);
        org.junit.Assert.assertTrue("'" + boolean39 + "' != '" + false + "'", boolean39 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy42);
        org.junit.Assert.assertTrue("'" + int60 + "' != '" + (-1) + "'", int60 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence61 + "' != '" + "" + "'", charSequence61, "");
        org.junit.Assert.assertNotNull(headers62);
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 10 + "'", int63 == 10);
        org.junit.Assert.assertTrue("'" + int64 + "' != '" + 10 + "'", int64 == 10);
        org.junit.Assert.assertNotNull(headers65);
        org.junit.Assert.assertTrue("'" + int77 + "' != '" + (-1) + "'", int77 == (-1));
        org.junit.Assert.assertTrue("'" + long78 + "' != '" + (-1L) + "'", long78 == (-1L));
        org.junit.Assert.assertNotNull(intOptional79);
        org.junit.Assert.assertNotNull(intOptional81);
        org.junit.Assert.assertTrue("'" + long82 + "' != '" + 100L + "'", long82 == 100L);
    }

    @Test
    public void test6823() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6823");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = strKafkaSpout0.kafkaConsumer;
        strKafkaSpout0.maxRetries = (byte) 100;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor7;
        long long9 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector10 = strKafkaSpout0.collector;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.emit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer4);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 0L + "'", long9 == 0L);
        org.junit.Assert.assertNull(spoutOutputCollector10);
    }

    @Test
    public void test6824() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6824");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer10 = strKafkaSpout0.commitTimer;
        boolean boolean11 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = strKafkaSpout0.collector;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.emit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(spoutOutputCollector9);
        org.junit.Assert.assertNull(timer10);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(spoutOutputCollector12);
    }

    @Test
    public void test6825() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6825");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        long long12 = charSequenceConsumerRecord10.offset();
        int int13 = charSequenceConsumerRecord10.partition();
        int int14 = charSequenceConsumerRecord10.partition();
        int int15 = charSequenceConsumerRecord10.serializedValueSize();
        int int16 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 0L + "'", long12 == 0L);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
    }

    @Test
    public void test6826() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6826");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams7;
        boolean boolean9 = strKafkaSpout0.initialized;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor10 = strKafkaSpout0.waitingToEmit;
        boolean boolean11 = strKafkaSpout0.initialized;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertTrue("'" + boolean9 + "' != '" + false + "'", boolean9 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor10);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
    }

    @Test
    public void test6827() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6827");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 1, 1L, (long) (byte) 10, timestampType4, (long) '#', (int) (byte) 100, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        java.lang.CharSequence charSequence11 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertEquals("'" + charSequence11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test6828() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6828");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        java.lang.String str13 = charSequenceConsumerRecord10.toString();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        int int15 = charSequenceConsumerRecord10.partition();
        java.util.Optional<java.lang.Integer> intOptional16 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.CharSequence charSequence17 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 52 + "'", int14 == 52);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertEquals("'" + charSequence17 + "' != '" + "" + "'", charSequence17, "");
    }

    @Test
    public void test6829() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6829");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray6 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet7 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean8 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet7, kafkaSpoutMessageIdArray6);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet7;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer10 = strKafkaSpout0.commitTimer;
        long long11 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService13 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService13;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams15 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy16 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy16;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray6);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
        org.junit.Assert.assertNull(timer10);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 35L + "'", long11 == 35L);
        org.junit.Assert.assertNull(spoutOutputCollector12);
        org.junit.Assert.assertNull(kafkaSpoutStreams15);
    }

    @Test
    public void test6830() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6830");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType23, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long30 = charSequenceConsumerRecord29.checksum();
        int int31 = charSequenceConsumerRecord29.partition();
        java.lang.String str32 = charSequenceConsumerRecord29.value();
        int int33 = charSequenceConsumerRecord29.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional34 = charSequenceConsumerRecord29.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet36 = strKafkaSpout35.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor37 = null;
        strKafkaSpout35.waitingToEmit = strConsumerRecordItor37;
        boolean boolean39 = strKafkaSpout35.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig40 = null;
        strKafkaSpout35.kafkaSpoutConfig = strKafkaSpoutConfig40;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy42 = strKafkaSpout35.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType15, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord29, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout35);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType53, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long60 = charSequenceConsumerRecord59.checksum();
        int int61 = charSequenceConsumerRecord59.partition();
        java.lang.String str62 = charSequenceConsumerRecord59.value();
        int int63 = charSequenceConsumerRecord59.serializedKeySize();
        org.apache.kafka.common.header.Headers headers64 = charSequenceConsumerRecord59.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str71 = charSequenceConsumerRecord70.topic();
        java.util.Optional<java.lang.Integer> intOptional72 = charSequenceConsumerRecord70.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 0, (long) (short) 10, (long) (-1), timestampType15, (java.lang.Long) 35L, 10, (int) (short) 10, (java.lang.CharSequence) "", "KafkaSpout{acked=null, emitted=null}", headers64, intOptional72);
        long long74 = charSequenceConsumerRecord73.timestamp();
        int int75 = charSequenceConsumerRecord73.serializedKeySize();
        java.lang.String str76 = charSequenceConsumerRecord73.value();
        java.util.Optional<java.lang.Integer> intOptional77 = charSequenceConsumerRecord73.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType78 = charSequenceConsumerRecord73.timestampType();
        int int79 = charSequenceConsumerRecord73.partition();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 10 + "'", int31 == 10);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "hi!" + "'", str32, "hi!");
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + 52 + "'", int33 == 52);
        org.junit.Assert.assertNotNull(intOptional34);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet36);
        org.junit.Assert.assertTrue("'" + boolean39 + "' != '" + false + "'", boolean39 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy42);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + 10 + "'", int61 == 10);
        org.junit.Assert.assertEquals("'" + str62 + "' != '" + "hi!" + "'", str62, "hi!");
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 52 + "'", int63 == 52);
        org.junit.Assert.assertNotNull(headers64);
        org.junit.Assert.assertEquals("'" + str71 + "' != '" + "" + "'", str71, "");
        org.junit.Assert.assertNotNull(intOptional72);
        org.junit.Assert.assertTrue("'" + long74 + "' != '" + (-1L) + "'", long74 == (-1L));
        org.junit.Assert.assertTrue("'" + int75 + "' != '" + 10 + "'", int75 == 10);
        org.junit.Assert.assertEquals("'" + str76 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str76, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertTrue("'" + timestampType78 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType78.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int79 + "' != '" + 0 + "'", int79 == 0);
    }

    @Test
    public void test6831() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6831");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        java.lang.String str10 = strKafkaSpout0.toString();
        boolean boolean11 = strKafkaSpout0.initialized;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer12 = strKafkaSpout0.kafkaConsumer;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str10, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(strKafkaConsumer12);
    }

    @Test
    public void test6832() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6832");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        boolean boolean5 = strKafkaSpout0.waitingToEmit();
        long long6 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder7;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig9 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig9;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.doSeekRetriableTopicPartitions();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + 0L + "'", long6 == 0L);
    }

    @Test
    public void test6833() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6833");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray6 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet7 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean8 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet7, kafkaSpoutMessageIdArray6);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet7;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer10 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService11 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService11;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = strKafkaSpout0.tuplesBuilder;
        long long14 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer15 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer15);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray6);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
        org.junit.Assert.assertNull(timer10);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder13);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 35L + "'", long14 == 35L);
    }

    @Test
    public void test6834() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6834");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        strKafkaSpout0.maxRetries = 1;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        boolean boolean5 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService6;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer8 = strKafkaSpout0.kafkaConsumer;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord9 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean10 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord9);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertNull(strKafkaConsumer8);
    }

    @Test
    public void test6835() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6835");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional12 = charSequenceConsumerRecord10.leaderEpoch();
        long long13 = charSequenceConsumerRecord10.offset();
        long long14 = charSequenceConsumerRecord10.checksum();
        long long15 = charSequenceConsumerRecord10.offset();
        long long16 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 0L + "'", long15 == 0L);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
    }

    @Test
    public void test6836() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6836");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = offsetComparator11.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator7.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator11);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = kafkaSpoutMessageIdComparator15.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = kafkaSpoutMessageIdComparator16.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = offsetComparator18.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator25 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator25;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator25);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = kafkaSpoutMessageIdComparator20.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator25);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = offsetComparator25.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = offsetComparator25.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = kafkaSpoutMessageIdComparator30.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = kafkaSpoutMessageIdComparator17.thenComparing(kafkaSpoutMessageIdComparator30);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator17;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
    }

    @Test
    public void test6837() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6837");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long14 = charSequenceConsumerRecord13.checksum();
        long long15 = charSequenceConsumerRecord13.timestamp();
        int int16 = charSequenceConsumerRecord13.partition();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (-1), (long) ' ', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long29 = charSequenceConsumerRecord28.timestamp();
        java.lang.String str30 = charSequenceConsumerRecord28.topic();
        org.apache.kafka.common.header.Headers headers31 = charSequenceConsumerRecord28.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", (int) 'a', 52L, (long) 35, timestampType17, (java.lang.Long) 1L, (int) (byte) 0, (int) ' ', (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=[]}", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", headers31);
        org.apache.kafka.common.record.TimestampType timestampType42 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType42, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int49 = charSequenceConsumerRecord48.serializedValueSize();
        java.lang.CharSequence charSequence50 = charSequenceConsumerRecord48.key();
        org.apache.kafka.common.header.Headers headers51 = charSequenceConsumerRecord48.headers();
        int int52 = charSequenceConsumerRecord48.partition();
        java.lang.CharSequence charSequence53 = charSequenceConsumerRecord48.key();
        long long54 = charSequenceConsumerRecord48.offset();
        long long55 = charSequenceConsumerRecord48.checksum();
        long long56 = charSequenceConsumerRecord48.timestamp();
        org.apache.kafka.common.header.Headers headers57 = charSequenceConsumerRecord48.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 0, leaderEpoch = null, offset = -1, null = 100, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", 10, (long) (byte) 10, (long) (short) 100, timestampType17, (java.lang.Long) 35L, (int) '4', (int) (short) 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", headers57);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 100 + "'", int16 == 100);
        org.junit.Assert.assertTrue("'" + timestampType17 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType17.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long29 + "' != '" + (-1L) + "'", long29 == (-1L));
        org.junit.Assert.assertEquals("'" + str30 + "' != '" + "hi!" + "'", str30, "hi!");
        org.junit.Assert.assertNotNull(headers31);
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + (-1) + "'", int49 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence50 + "' != '" + "" + "'", charSequence50, "");
        org.junit.Assert.assertNotNull(headers51);
        org.junit.Assert.assertTrue("'" + int52 + "' != '" + 10 + "'", int52 == 10);
        org.junit.Assert.assertEquals("'" + charSequence53 + "' != '" + "" + "'", charSequence53, "");
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + 0L + "'", long54 == 0L);
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + (-1L) + "'", long55 == (-1L));
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + (-1L) + "'", long56 == (-1L));
        org.junit.Assert.assertNotNull(headers57);
    }

    @Test
    public void test6838() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6838");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = offsetComparator7.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator7.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator13.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator20 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator20;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = kafkaSpoutMessageIdComparator15.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator15.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator7.thenComparing(kafkaSpoutMessageIdComparator24);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator7.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = kafkaSpoutMessageIdComparator26.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = kafkaSpoutMessageIdComparator26.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = kafkaSpoutMessageIdComparator28.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = kafkaSpoutMessageIdComparator28.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
    }

    @Test
    public void test6839() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6839");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType13 = charSequenceConsumerRecord10.timestampType();
        int int14 = charSequenceConsumerRecord10.partition();
        int int15 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str18 = charSequenceConsumerRecord10.topic();
        java.lang.String str19 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNull(timestampType13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test6840() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6840");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord15 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (-1), (long) ' ', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long16 = charSequenceConsumerRecord15.timestamp();
        java.lang.String str17 = charSequenceConsumerRecord15.topic();
        org.apache.kafka.common.header.Headers headers18 = charSequenceConsumerRecord15.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.CharSequence charSequence25 = charSequenceConsumerRecord24.key();
        java.util.Optional<java.lang.Integer> intOptional26 = charSequenceConsumerRecord24.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", (int) (short) 100, (long) '#', 35L, timestampType4, (java.lang.Long) 100L, (int) (byte) 10, 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 35, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)))", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", headers18, intOptional26);
        int int28 = charSequenceConsumerRecord27.partition();
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertNotNull(headers18);
        org.junit.Assert.assertEquals("'" + charSequence25 + "' != '" + "" + "'", charSequence25, "");
        org.junit.Assert.assertNotNull(intOptional26);
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + 100 + "'", int28 == 100);
    }

    @Test
    public void test6841() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6841");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer10;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = strKafkaSpout0.tuplesBuilder;
        org.apache.kafka.common.TopicPartition topicPartition14 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection15 = strKafkaSpout0.toArrayList(topicPartition14);
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer16 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer16);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(spoutOutputCollector12);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder13);
        org.junit.Assert.assertNotNull(topicPartitionCollection15);
    }

    @Test
    public void test6842() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6842");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator5 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator5;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator5.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator12 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator12;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = kafkaSpoutMessageIdComparator7.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator12);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator16 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator16;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = offsetComparator16.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator23;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = kafkaSpoutMessageIdComparator18.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = kafkaSpoutMessageIdComparator7.thenComparing(kafkaSpoutMessageIdComparator26);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator28 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator29 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator29;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = offsetComparator29.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator36 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator36;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator36);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = kafkaSpoutMessageIdComparator31.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator36);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator40 = offsetComparator28.thenComparing(kafkaSpoutMessageIdComparator39);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = kafkaSpoutMessageIdComparator39.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator42 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator42;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = offsetComparator42.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator49 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator49;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator49);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator52 = kafkaSpoutMessageIdComparator44.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator49);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator53 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator53;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator55 = offsetComparator53.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator60 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator60;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord62 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator60);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator63 = kafkaSpoutMessageIdComparator55.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator60);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator64 = kafkaSpoutMessageIdComparator44.thenComparing(kafkaSpoutMessageIdComparator63);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator65 = kafkaSpoutMessageIdComparator63.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator66 = kafkaSpoutMessageIdComparator39.thenComparing(kafkaSpoutMessageIdComparator63);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator67 = kafkaSpoutMessageIdComparator27.thenComparing(kafkaSpoutMessageIdComparator63);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator68 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator63);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator68;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator40);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator52);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator63);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator64);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator65);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator66);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator67);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator68);
    }

    @Test
    public void test6843() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6843");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService5 = strKafkaSpout0.retryService;
        strKafkaSpout0.initialized = false;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer8 = strKafkaSpout0.kafkaConsumer;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + 0 + "'", int3 == 0);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertNull(kafkaSpoutRetryService5);
        org.junit.Assert.assertNull(strKafkaConsumer8);
    }

    @Test
    public void test6844() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6844");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        int int8 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor9 = strKafkaSpout0.waitingToEmit;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet10 = strKafkaSpout0.emitted;
        strKafkaSpout0.maxRetries = (short) -1;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.commitOffsetsForAckedTuples();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strConsumerRecordItor9);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet10);
    }

    @Test
    public void test6845() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6845");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str18 = charSequenceConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = charSequenceConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long34 = charSequenceConsumerRecord33.checksum();
        int int35 = charSequenceConsumerRecord33.partition();
        java.lang.String str36 = charSequenceConsumerRecord33.value();
        int int37 = charSequenceConsumerRecord33.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional38 = charSequenceConsumerRecord33.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout39 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet40 = strKafkaSpout39.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor41 = null;
        strKafkaSpout39.waitingToEmit = strConsumerRecordItor41;
        boolean boolean43 = strKafkaSpout39.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig44 = null;
        strKafkaSpout39.kafkaSpoutConfig = strKafkaSpoutConfig44;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy46 = strKafkaSpout39.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType19, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord33, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout39);
        org.apache.kafka.common.record.TimestampType timestampType57 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType57, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long64 = charSequenceConsumerRecord63.checksum();
        int int65 = charSequenceConsumerRecord63.partition();
        java.lang.String str66 = charSequenceConsumerRecord63.value();
        int int67 = charSequenceConsumerRecord63.serializedKeySize();
        org.apache.kafka.common.header.Headers headers68 = charSequenceConsumerRecord63.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str75 = charSequenceConsumerRecord74.topic();
        java.util.Optional<java.lang.Integer> intOptional76 = charSequenceConsumerRecord74.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 0, (long) (short) 10, (long) (-1), timestampType19, (java.lang.Long) 35L, 10, (int) (short) 10, (java.lang.CharSequence) "", "KafkaSpout{acked=null, emitted=null}", headers68, intOptional76);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 0, (long) (byte) -1, (long) (short) 10, timestampType19, (-1L), 100, 10, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        long long84 = charSequenceConsumerRecord83.offset();
        java.lang.String str85 = charSequenceConsumerRecord83.topic();
        java.lang.String str86 = charSequenceConsumerRecord83.topic();
        long long87 = charSequenceConsumerRecord83.offset();
        java.lang.CharSequence charSequence88 = charSequenceConsumerRecord83.key();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertTrue("'" + int35 + "' != '" + 10 + "'", int35 == 10);
        org.junit.Assert.assertEquals("'" + str36 + "' != '" + "hi!" + "'", str36, "hi!");
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + 52 + "'", int37 == 52);
        org.junit.Assert.assertNotNull(intOptional38);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet40);
        org.junit.Assert.assertTrue("'" + boolean43 + "' != '" + false + "'", boolean43 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy46);
        org.junit.Assert.assertTrue("'" + long64 + "' != '" + (-1L) + "'", long64 == (-1L));
        org.junit.Assert.assertTrue("'" + int65 + "' != '" + 10 + "'", int65 == 10);
        org.junit.Assert.assertEquals("'" + str66 + "' != '" + "hi!" + "'", str66, "hi!");
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + 52 + "'", int67 == 52);
        org.junit.Assert.assertNotNull(headers68);
        org.junit.Assert.assertEquals("'" + str75 + "' != '" + "" + "'", str75, "");
        org.junit.Assert.assertNotNull(intOptional76);
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + (-1L) + "'", long84 == (-1L));
        org.junit.Assert.assertEquals("'" + str85 + "' != '" + "" + "'", str85, "");
        org.junit.Assert.assertEquals("'" + str86 + "' != '" + "" + "'", str86, "");
        org.junit.Assert.assertTrue("'" + long87 + "' != '" + (-1L) + "'", long87 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence88 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", charSequence88, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
    }

    @Test
    public void test6846() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6846");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = kafkaSpoutMessageIdComparator10.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator12 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator12;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = offsetComparator12.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator19 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator19;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator19);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = kafkaSpoutMessageIdComparator14.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator19);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = kafkaSpoutMessageIdComparator22.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator23.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = kafkaSpoutMessageIdComparator10.thenComparing(kafkaSpoutMessageIdComparator23);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator26 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = offsetComparator26.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator33 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator33;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator33);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = kafkaSpoutMessageIdComparator28.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator33);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = offsetComparator33.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = offsetComparator33.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator39 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator39;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = offsetComparator39.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator46 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator46;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator46);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator49 = kafkaSpoutMessageIdComparator41.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator46);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator50 = kafkaSpoutMessageIdComparator41.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator51 = offsetComparator33.thenComparing(kafkaSpoutMessageIdComparator50);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator52 = offsetComparator33.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator57 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator57;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator57);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator60 = offsetComparator57.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator61 = kafkaSpoutMessageIdComparator52.thenComparing(kafkaSpoutMessageIdComparator60);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator62 = kafkaSpoutMessageIdComparator23.thenComparing(kafkaSpoutMessageIdComparator52);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator49);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator50);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator51);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator52);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator60);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator61);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator62);
    }

    @Test
    public void test6847() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6847");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService1 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService1;
        long long3 = strKafkaSpout0.numUncommittedOffsets;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = strKafkaSpout0.waitingToEmit;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = strKafkaSpout0.emitted;
        int int6 = strKafkaSpout0.maxRetries;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector8 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.junit.Assert.assertTrue("'" + long3 + "' != '" + 0L + "'", long3 == 0L);
        org.junit.Assert.assertNull(strConsumerRecordItor4);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet5);
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + 0 + "'", int6 == 0);
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(spoutOutputCollector8);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
    }

    @Test
    public void test6848() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6848");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) '#', 0L, timestampType4, (long) 0, (int) (byte) -1, (int) (short) 10, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        java.lang.String str12 = charSequenceConsumerRecord10.topic();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str15 = charSequenceConsumerRecord10.topic();
        long long16 = charSequenceConsumerRecord10.checksum();
        int int17 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 35L + "'", long11 == 35L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str12, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + (-1) + "'", int17 == (-1));
    }

    @Test
    public void test6849() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6849");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout19 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout19.maxRetries = (byte) -1;
        int int22 = strKafkaSpout19.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor23 = null;
        strKafkaSpout19.waitingToEmit = strConsumerRecordItor23;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer25 = strKafkaSpout19.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer26 = strKafkaSpout19.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType32, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long39 = charSequenceConsumerRecord38.offset();
        long long40 = charSequenceConsumerRecord38.checksum();
        int int41 = charSequenceConsumerRecord38.serializedKeySize();
        org.apache.kafka.common.header.Headers headers42 = charSequenceConsumerRecord38.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType15, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout19, (java.lang.CharSequence) "hi!", headers42);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.common.record.TimestampType timestampType63 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType63, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int70 = charSequenceConsumerRecord69.serializedValueSize();
        java.lang.CharSequence charSequence71 = charSequenceConsumerRecord69.key();
        org.apache.kafka.common.header.Headers headers72 = charSequenceConsumerRecord69.headers();
        java.util.Optional<java.lang.Integer> intOptional73 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType53, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers72, intOptional73);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (byte) -1, (-1L), (long) (short) 10, timestampType15, (java.lang.Long) 0L, (int) (short) 1, 97, (java.lang.CharSequence) "", "KafkaSpout{acked=null, emitted=null}", headers72);
        java.lang.Class<?> wildcardClass76 = timestampType15.getClass();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertNull(timer25);
        org.junit.Assert.assertNull(strKafkaConsumer26);
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + 0L + "'", long39 == 0L);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + 52 + "'", int41 == 52);
        org.junit.Assert.assertNotNull(headers42);
        org.junit.Assert.assertTrue("'" + int70 + "' != '" + (-1) + "'", int70 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence71 + "' != '" + "" + "'", charSequence71, "");
        org.junit.Assert.assertNotNull(headers72);
        org.junit.Assert.assertNotNull(wildcardClass76);
    }

    @Test
    public void test6850() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6850");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator14 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator14;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator14.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = offsetComparator13.thenComparing(kafkaSpoutMessageIdComparator16);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = offsetComparator11.thenComparing(kafkaSpoutMessageIdComparator17);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = offsetComparator7.thenComparing(kafkaSpoutMessageIdComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = kafkaSpoutMessageIdComparator18.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator20;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator22 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator22;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = offsetComparator22.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator29 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator29;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator29);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = kafkaSpoutMessageIdComparator24.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator29);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator33 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator33;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = offsetComparator33.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator40 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator40;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator40);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator43 = kafkaSpoutMessageIdComparator35.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator40);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = kafkaSpoutMessageIdComparator24.thenComparing(kafkaSpoutMessageIdComparator43);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator45 = kafkaSpoutMessageIdComparator20.thenComparing(kafkaSpoutMessageIdComparator44);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator44;
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator44;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator43);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator45);
    }

    @Test
    public void test6851() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6851");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", 100, (long) '#', 100L, timestampType4, (long) 10, (int) '#', (int) (byte) 100, (java.lang.CharSequence) "", "");
        long long11 = charSequenceConsumerRecord10.timestamp();
        long long12 = charSequenceConsumerRecord10.offset();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.header.Headers headers14 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 100L + "'", long11 == 100L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 35L + "'", long12 == 35L);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
        org.junit.Assert.assertNotNull(headers14);
    }

    @Test
    public void test6852() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6852");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy6 = strKafkaSpout0.firstPollOffsetStrategy;
        java.lang.String str7 = strKafkaSpout0.toString();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet8 = strKafkaSpout0.emitted;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertNull(strKafkaSpoutConfig5);
        org.junit.Assert.assertNull(firstPollOffsetStrategy6);
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet8);
    }

    @Test
    public void test6853() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6853");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer5 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer5;
        long long7 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        boolean boolean9 = strKafkaSpout0.consumerAutoCommitMode;
        strKafkaSpout0.numUncommittedOffsets = 0L;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + 0L + "'", long7 == 0L);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertTrue("'" + boolean9 + "' != '" + false + "'", boolean9 == false);
    }

    @Test
    public void test6854() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6854");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout19 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout19.maxRetries = (byte) -1;
        int int22 = strKafkaSpout19.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor23 = null;
        strKafkaSpout19.waitingToEmit = strConsumerRecordItor23;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer25 = strKafkaSpout19.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer26 = strKafkaSpout19.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType32, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long39 = charSequenceConsumerRecord38.offset();
        long long40 = charSequenceConsumerRecord38.checksum();
        int int41 = charSequenceConsumerRecord38.serializedKeySize();
        org.apache.kafka.common.header.Headers headers42 = charSequenceConsumerRecord38.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType15, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout19, (java.lang.CharSequence) "hi!", headers42);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 1, 0L, (long) (byte) 0, timestampType15, (long) ' ', (int) (short) -1, (int) (byte) 10, (java.lang.CharSequence) "", "");
        java.lang.CharSequence charSequence50 = charSequenceConsumerRecord49.key();
        org.apache.kafka.common.record.TimestampType timestampType51 = charSequenceConsumerRecord49.timestampType();
        java.lang.CharSequence charSequence52 = charSequenceConsumerRecord49.key();
        int int53 = charSequenceConsumerRecord49.partition();
        long long54 = charSequenceConsumerRecord49.timestamp();
        long long55 = charSequenceConsumerRecord49.timestamp();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertNull(timer25);
        org.junit.Assert.assertNull(strKafkaConsumer26);
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + 0L + "'", long39 == 0L);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + 52 + "'", int41 == 52);
        org.junit.Assert.assertNotNull(headers42);
        org.junit.Assert.assertEquals("'" + charSequence50 + "' != '" + "" + "'", charSequence50, "");
        org.junit.Assert.assertTrue("'" + timestampType51 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType51.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + charSequence52 + "' != '" + "" + "'", charSequence52, "");
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + 1 + "'", int53 == 1);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + 0L + "'", long54 == 0L);
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + 0L + "'", long55 == 0L);
    }

    @Test
    public void test6855() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6855");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType23, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long30 = charSequenceConsumerRecord29.checksum();
        int int31 = charSequenceConsumerRecord29.partition();
        java.lang.String str32 = charSequenceConsumerRecord29.value();
        int int33 = charSequenceConsumerRecord29.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional34 = charSequenceConsumerRecord29.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet36 = strKafkaSpout35.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor37 = null;
        strKafkaSpout35.waitingToEmit = strConsumerRecordItor37;
        boolean boolean39 = strKafkaSpout35.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig40 = null;
        strKafkaSpout35.kafkaSpoutConfig = strKafkaSpoutConfig40;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy42 = strKafkaSpout35.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType15, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord29, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout35);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType53, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long60 = charSequenceConsumerRecord59.checksum();
        int int61 = charSequenceConsumerRecord59.partition();
        java.lang.String str62 = charSequenceConsumerRecord59.value();
        int int63 = charSequenceConsumerRecord59.serializedKeySize();
        org.apache.kafka.common.header.Headers headers64 = charSequenceConsumerRecord59.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str71 = charSequenceConsumerRecord70.topic();
        java.util.Optional<java.lang.Integer> intOptional72 = charSequenceConsumerRecord70.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 0, (long) (short) 10, (long) (-1), timestampType15, (java.lang.Long) 35L, 10, (int) (short) 10, (java.lang.CharSequence) "", "KafkaSpout{acked=null, emitted=null}", headers64, intOptional72);
        java.util.Optional<java.lang.Integer> intOptional74 = charSequenceConsumerRecord73.leaderEpoch();
        long long75 = charSequenceConsumerRecord73.checksum();
        java.util.Optional<java.lang.Integer> intOptional76 = charSequenceConsumerRecord73.leaderEpoch();
        long long77 = charSequenceConsumerRecord73.offset();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 10 + "'", int31 == 10);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "hi!" + "'", str32, "hi!");
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + 52 + "'", int33 == 52);
        org.junit.Assert.assertNotNull(intOptional34);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet36);
        org.junit.Assert.assertTrue("'" + boolean39 + "' != '" + false + "'", boolean39 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy42);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + 10 + "'", int61 == 10);
        org.junit.Assert.assertEquals("'" + str62 + "' != '" + "hi!" + "'", str62, "hi!");
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 52 + "'", int63 == 52);
        org.junit.Assert.assertNotNull(headers64);
        org.junit.Assert.assertEquals("'" + str71 + "' != '" + "" + "'", str71, "");
        org.junit.Assert.assertNotNull(intOptional72);
        org.junit.Assert.assertNotNull(intOptional74);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + 35L + "'", long75 == 35L);
        org.junit.Assert.assertNotNull(intOptional76);
        org.junit.Assert.assertTrue("'" + long77 + "' != '" + 10L + "'", long77 == 10L);
    }

    @Test
    public void test6856() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6856");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams9 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        int int11 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig14 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig14;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams16 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams16;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer18 = strKafkaSpout0.commitTimer;
        org.apache.kafka.common.TopicPartition topicPartition19 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection20 = strKafkaSpout0.toArrayList(topicPartition19);
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
        org.junit.Assert.assertNull(kafkaSpoutStreams9);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertNull(timer18);
        org.junit.Assert.assertNotNull(topicPartitionCollection20);
    }

    @Test
    public void test6857() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6857");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.offset();
        int int19 = charSequenceConsumerRecord10.partition();
        java.lang.String str20 = charSequenceConsumerRecord10.value();
        java.lang.String str21 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.header.Headers headers22 = charSequenceConsumerRecord10.headers();
        java.lang.String str23 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "" + "'", str21, "");
        org.junit.Assert.assertNotNull(headers22);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "hi!" + "'", str23, "hi!");
    }

    @Test
    public void test6858() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6858");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType4, (long) (short) -1, (int) (byte) 1, (int) (short) -1, (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long11 = charSequenceConsumerRecord10.offset();
        long long12 = charSequenceConsumerRecord10.timestamp();
        long long13 = charSequenceConsumerRecord10.offset();
        int int14 = charSequenceConsumerRecord10.partition();
        long long15 = charSequenceConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional16 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.Class<?> wildcardClass17 = charSequenceConsumerRecord10.getClass();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 1L + "'", long11 == 1L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 0L + "'", long12 == 0L);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 1L + "'", long13 == 1L);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 97 + "'", int14 == 97);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 0L + "'", long15 == 0L);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertNotNull(wildcardClass17);
    }

    @Test
    public void test6859() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6859");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        boolean boolean4 = strKafkaSpout0.waitingToEmit();
        strKafkaSpout0.initialized = false;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy7;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService11 = strKafkaSpout0.retryService;
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertNull(kafkaSpoutRetryService11);
    }

    @Test
    public void test6860() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6860");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 1, 1L, (long) (byte) 10, timestampType4, (long) '#', (int) (byte) 100, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        long long11 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str12 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 10L + "'", long11 == 10L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "" + "'", str12, "");
    }

    @Test
    public void test6861() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6861");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = kafkaSpoutMessageIdComparator10.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator11;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator13.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = offsetComparator18.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator25 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator25;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator25);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = kafkaSpoutMessageIdComparator20.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator25);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator29 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator29;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = offsetComparator29.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator36 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator36;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator36);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = kafkaSpoutMessageIdComparator31.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator36);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator40 = kafkaSpoutMessageIdComparator20.thenComparing(kafkaSpoutMessageIdComparator39);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator41 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator42 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator42;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = offsetComparator42.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator49 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator49;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator49);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator52 = kafkaSpoutMessageIdComparator44.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator49);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator53 = offsetComparator41.thenComparing(kafkaSpoutMessageIdComparator52);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator54 = kafkaSpoutMessageIdComparator52.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator55 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator55;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator57 = offsetComparator55.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator62 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator62;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator62);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator65 = kafkaSpoutMessageIdComparator57.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator62);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator66 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator66;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator68 = offsetComparator66.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator73 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator73;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator73);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator76 = kafkaSpoutMessageIdComparator68.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator73);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator77 = kafkaSpoutMessageIdComparator57.thenComparing(kafkaSpoutMessageIdComparator76);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator78 = kafkaSpoutMessageIdComparator76.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator79 = kafkaSpoutMessageIdComparator52.thenComparing(kafkaSpoutMessageIdComparator76);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator80 = kafkaSpoutMessageIdComparator40.thenComparing(kafkaSpoutMessageIdComparator76);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator81 = offsetComparator13.thenComparing(kafkaSpoutMessageIdComparator76);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator82 = kafkaSpoutMessageIdComparator11.thenComparing(kafkaSpoutMessageIdComparator81);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator81;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator40);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator52);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator53);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator54);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator57);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator65);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator68);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator76);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator77);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator78);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator79);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator80);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator81);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator82);
    }

    @Test
    public void test6862() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6862");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        long long12 = charSequenceConsumerRecord10.checksum();
        int int13 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.String str14 = charSequenceConsumerRecord10.value();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 52 + "'", int13 == 52);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
    }

    @Test
    public void test6863() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6863");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str18 = charSequenceConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = charSequenceConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long34 = charSequenceConsumerRecord33.checksum();
        int int35 = charSequenceConsumerRecord33.partition();
        java.lang.String str36 = charSequenceConsumerRecord33.value();
        int int37 = charSequenceConsumerRecord33.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional38 = charSequenceConsumerRecord33.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout39 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet40 = strKafkaSpout39.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor41 = null;
        strKafkaSpout39.waitingToEmit = strConsumerRecordItor41;
        boolean boolean43 = strKafkaSpout39.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig44 = null;
        strKafkaSpout39.kafkaSpoutConfig = strKafkaSpoutConfig44;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy46 = strKafkaSpout39.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType19, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord33, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout39);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long59 = charSequenceConsumerRecord58.checksum();
        long long60 = charSequenceConsumerRecord58.timestamp();
        org.apache.kafka.common.header.Headers headers61 = charSequenceConsumerRecord58.headers();
        org.apache.kafka.common.record.TimestampType timestampType66 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType66, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long73 = charSequenceConsumerRecord72.offset();
        int int74 = charSequenceConsumerRecord72.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional75 = charSequenceConsumerRecord72.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType76 = charSequenceConsumerRecord72.timestampType();
        java.util.Optional<java.lang.Integer> intOptional77 = charSequenceConsumerRecord72.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 52, 0L, (-1L), timestampType19, (java.lang.Long) 35L, (int) (short) -1, 0, (java.lang.CharSequence) "", "hi!", headers61, intOptional77);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (byte) 100, (long) '#', (long) 0, timestampType19, (long) 'a', 52, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "hi!");
        java.lang.String str85 = charSequenceConsumerRecord84.value();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertTrue("'" + int35 + "' != '" + 10 + "'", int35 == 10);
        org.junit.Assert.assertEquals("'" + str36 + "' != '" + "hi!" + "'", str36, "hi!");
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + 52 + "'", int37 == 52);
        org.junit.Assert.assertNotNull(intOptional38);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet40);
        org.junit.Assert.assertTrue("'" + boolean43 + "' != '" + false + "'", boolean43 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy46);
        org.junit.Assert.assertTrue("'" + long59 + "' != '" + (-1L) + "'", long59 == (-1L));
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertNotNull(headers61);
        org.junit.Assert.assertTrue("'" + long73 + "' != '" + 0L + "'", long73 == 0L);
        org.junit.Assert.assertTrue("'" + int74 + "' != '" + (-1) + "'", int74 == (-1));
        org.junit.Assert.assertNotNull(intOptional75);
        org.junit.Assert.assertNull(timestampType76);
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertEquals("'" + str85 + "' != '" + "hi!" + "'", str85, "hi!");
    }

    @Test
    public void test6864() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6864");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder6 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder6;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
    }

    @Test
    public void test6865() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6865");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 1, 1L, (long) (byte) 10, timestampType4, (long) '#', (int) (byte) 100, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        java.lang.String str11 = charSequenceConsumerRecord10.value();
        java.lang.String str12 = charSequenceConsumerRecord10.topic();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str14 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord10.timestampType();
        long long16 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str12, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertNull(timestampType15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 1L + "'", long16 == 1L);
    }

    @Test
    public void test6866() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6866");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.offset();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        long long16 = charSequenceConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers17 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.header.Headers headers18 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertNotNull(headers17);
        org.junit.Assert.assertNotNull(headers18);
    }

    @Test
    public void test6867() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6867");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str19 = charSequenceConsumerRecord10.value();
        java.lang.CharSequence charSequence20 = charSequenceConsumerRecord10.key();
        long long21 = charSequenceConsumerRecord10.checksum();
        int int22 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
        org.junit.Assert.assertEquals("'" + charSequence20 + "' != '" + "" + "'", charSequence20, "");
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 52 + "'", int22 == 52);
    }

    @Test
    public void test6868() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6868");
        org.apache.kafka.common.record.TimestampType timestampType8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType8, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long15 = charSequenceConsumerRecord14.checksum();
        int int16 = charSequenceConsumerRecord14.partition();
        long long17 = charSequenceConsumerRecord14.timestamp();
        long long18 = charSequenceConsumerRecord14.offset();
        int int19 = charSequenceConsumerRecord14.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType20 = charSequenceConsumerRecord14.timestampType();
        int int21 = charSequenceConsumerRecord14.partition();
        long long22 = charSequenceConsumerRecord14.checksum();
        java.util.Optional<java.lang.Integer> intOptional23 = charSequenceConsumerRecord14.leaderEpoch();
        org.apache.kafka.common.header.Headers headers24 = charSequenceConsumerRecord14.headers();
        java.lang.String str25 = charSequenceConsumerRecord14.value();
        java.lang.String str26 = charSequenceConsumerRecord14.value();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>> strComparableConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", (int) (byte) 10, 32L, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", charSequenceConsumerRecord14);
        org.apache.kafka.common.header.Headers headers28 = charSequenceConsumerRecord14.headers();
        int int29 = charSequenceConsumerRecord14.partition();
        long long30 = charSequenceConsumerRecord14.timestamp();
        java.util.Optional<java.lang.Integer> intOptional31 = charSequenceConsumerRecord14.leaderEpoch();
        java.lang.String str32 = charSequenceConsumerRecord14.value();
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 52 + "'", int19 == 52);
        org.junit.Assert.assertNull(timestampType20);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 10 + "'", int21 == 10);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
        org.junit.Assert.assertNotNull(intOptional23);
        org.junit.Assert.assertNotNull(headers24);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "hi!" + "'", str25, "hi!");
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "hi!" + "'", str26, "hi!");
        org.junit.Assert.assertNotNull(headers28);
        org.junit.Assert.assertTrue("'" + int29 + "' != '" + 10 + "'", int29 == 10);
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertNotNull(intOptional31);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "hi!" + "'", str32, "hi!");
    }

    @Test
    public void test6869() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6869");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        long long16 = charSequenceConsumerRecord10.offset();
        long long17 = charSequenceConsumerRecord10.checksum();
        long long18 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str19 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
    }

    @Test
    public void test6870() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6870");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        java.lang.String str11 = charSequenceConsumerRecord10.toString();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        long long13 = charSequenceConsumerRecord10.timestamp();
        int int14 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.String str15 = charSequenceConsumerRecord10.toString();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        long long17 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str15, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
    }

    @Test
    public void test6871() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6871");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}))", (int) (short) 0, 0L, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 100, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
        int int6 = charSequenceConsumerRecord5.serializedValueSize();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
    }

    @Test
    public void test6872() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6872");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator14 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator14;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator14.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = offsetComparator13.thenComparing(kafkaSpoutMessageIdComparator16);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = offsetComparator11.thenComparing(kafkaSpoutMessageIdComparator17);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = offsetComparator7.thenComparing(kafkaSpoutMessageIdComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = kafkaSpoutMessageIdComparator18.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator21 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator21;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = offsetComparator21.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator28 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator28;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator28);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = kafkaSpoutMessageIdComparator23.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator28);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = offsetComparator28.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator33 = kafkaSpoutMessageIdComparator18.thenComparing(kafkaSpoutMessageIdComparator32);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator33;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = kafkaSpoutMessageIdComparator33.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator36 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = offsetComparator36.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = offsetComparator36.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = kafkaSpoutMessageIdComparator35.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator36);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator40 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator40;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator42 = offsetComparator40.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator47 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator47;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator47);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator50 = kafkaSpoutMessageIdComparator42.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator47);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator51 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator51;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator53 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator54 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator54;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator56 = offsetComparator54.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator57 = offsetComparator53.thenComparing(kafkaSpoutMessageIdComparator56);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator58 = offsetComparator51.thenComparing(kafkaSpoutMessageIdComparator57);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator59 = offsetComparator47.thenComparing(kafkaSpoutMessageIdComparator58);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator60 = kafkaSpoutMessageIdComparator59.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator61 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator61;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator63 = offsetComparator61.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator68 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator68;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator68);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator71 = kafkaSpoutMessageIdComparator63.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator68);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator72 = offsetComparator68.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator73 = kafkaSpoutMessageIdComparator72.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator74 = kafkaSpoutMessageIdComparator60.thenComparing(kafkaSpoutMessageIdComparator72);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator75 = offsetComparator36.thenComparing(kafkaSpoutMessageIdComparator72);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator76 = kafkaSpoutMessageIdComparator72.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator33);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator42);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator50);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator56);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator57);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator58);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator59);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator60);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator63);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator71);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator72);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator73);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator74);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator75);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator76);
    }

    @Test
    public void test6873() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6873");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        int int3 = strKafkaSpout0.maxRetries;
        boolean boolean4 = strKafkaSpout0.waitingToEmit();
        int int5 = strKafkaSpout0.maxRetries;
        int int6 = strKafkaSpout0.maxRetries;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + 0 + "'", int3 == 0);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertTrue("'" + int5 + "' != '" + 0 + "'", int5 == 0);
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + 0 + "'", int6 == 0);
    }

    @Test
    public void test6874() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6874");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = strKafkaSpout0.kafkaConsumer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor5 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor5;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        java.lang.String str8 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService9;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer4);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test6875() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6875");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams7;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = strKafkaSpout0.retryService;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        strKafkaSpout0.maxRetries = (-1);
        long long13 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder14 = strKafkaSpout0.tuplesBuilder;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor15 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor15;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(kafkaSpoutRetryService9);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 35L + "'", long13 == 35L);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder14);
    }

    @Test
    public void test6876() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6876");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        java.lang.String str17 = charSequenceConsumerRecord10.toString();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType19 = charSequenceConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str17, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertNull(timestampType19);
    }

    @Test
    public void test6877() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6877");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        strKafkaSpout0.maxRetries = 1;
        strKafkaSpout0.initialized = false;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
    }

    @Test
    public void test6878() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6878");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        java.lang.String str4 = strKafkaSpout0.toString();
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer7;
        java.lang.String str9 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams10;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer12 = strKafkaSpout0.kafkaConsumer;
        int int13 = strKafkaSpout0.maxRetries;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertEquals("'" + str4 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str4, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str9, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaConsumer12);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 0 + "'", int13 == 0);
    }

    @Test
    public void test6879() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6879");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        java.lang.String str11 = charSequenceConsumerRecord10.toString();
        java.lang.String str12 = charSequenceConsumerRecord10.topic();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        java.lang.String str14 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.header.Headers headers15 = charSequenceConsumerRecord10.headers();
        long long16 = charSequenceConsumerRecord10.offset();
        int int17 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "" + "'", str12, "");
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertNotNull(headers15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 52 + "'", int17 == 52);
    }

    @Test
    public void test6880() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6880");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        boolean boolean7 = strKafkaSpout0.initialized;
        strKafkaSpout0.maxRetries = (byte) 10;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService10;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy12 = strKafkaSpout0.firstPollOffsetStrategy;
        strKafkaSpout0.initialized = false;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy12);
    }

    @Test
    public void test6881() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6881");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray6 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet7 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean8 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet7, kafkaSpoutMessageIdArray6);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet7;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer10 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService11 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService11;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
// flaky:             org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray6);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
        org.junit.Assert.assertNull(timer10);
    }

    @Test
    public void test6882() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6882");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=[]}", (int) (byte) -1, (long) '4', (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "hi!");
        java.lang.String str6 = charSequenceConsumerRecord5.value();
        org.apache.kafka.common.header.Headers headers7 = charSequenceConsumerRecord5.headers();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        java.lang.CharSequence charSequence9 = charSequenceConsumerRecord5.key();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "hi!" + "'", str6, "hi!");
        org.junit.Assert.assertNotNull(headers7);
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertEquals("'" + charSequence9 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", charSequence9, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
    }

    @Test
    public void test6883() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6883");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = offsetComparator7.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator7.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = kafkaSpoutMessageIdComparator12.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator12;
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator12;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
    }

    @Test
    public void test6884() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6884");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer4;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder6 = strKafkaSpout0.tuplesBuilder;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str7 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder6);
    }

    @Test
    public void test6885() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6885");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer5 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer5;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy8 = strKafkaSpout0.firstPollOffsetStrategy;
        boolean boolean9 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder10 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = null;
        strKafkaSpout0.collector = spoutOutputCollector11;
        strKafkaSpout0.initialized = true;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertNull(firstPollOffsetStrategy8);
        org.junit.Assert.assertTrue("'" + boolean9 + "' != '" + false + "'", boolean9 == false);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder10);
    }

    @Test
    public void test6886() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6886");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        int int20 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.String str21 = charSequenceConsumerRecord10.value();
        java.lang.CharSequence charSequence22 = charSequenceConsumerRecord10.key();
        java.lang.String str23 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 52 + "'", int20 == 52);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "hi!" + "'", str21, "hi!");
        org.junit.Assert.assertEquals("'" + charSequence22 + "' != '" + "" + "'", charSequence22, "");
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "" + "'", str23, "");
    }

    @Test
    public void test6887() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6887");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>, org.apache.storm.kafka.spout.KafkaSpout<org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>, org.apache.storm.topology.base.BaseRichSpout>.KafkaSpoutConsumerRebalanceListener> charSequenceConsumerRecordKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>, org.apache.storm.kafka.spout.KafkaSpout<org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>, org.apache.storm.topology.base.BaseRichSpout>.KafkaSpoutConsumerRebalanceListener> charSequenceConsumerRecordKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>, org.apache.storm.kafka.spout.KafkaSpout<org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>, org.apache.storm.topology.base.BaseRichSpout>.KafkaSpoutConsumerRebalanceListener>(charSequenceConsumerRecordKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test6888() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6888");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.CharSequence charSequence14 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence14 + "' != '" + "" + "'", charSequence14, "");
    }

    @Test
    public void test6889() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6889");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        java.lang.String str16 = charSequenceConsumerRecord10.toString();
        long long17 = charSequenceConsumerRecord10.checksum();
        java.lang.CharSequence charSequence18 = charSequenceConsumerRecord10.key();
        long long19 = charSequenceConsumerRecord10.checksum();
        long long20 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence18 + "' != '" + "" + "'", charSequence18, "");
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
    }

    @Test
    public void test6890() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6890");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator4 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator4;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator6 = offsetComparator4.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator6);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator8 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator9 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator10 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator10;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator10.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator9.thenComparing(kafkaSpoutMessageIdComparator12);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator14 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator14;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator14.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator21 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator21;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator21);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator16.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator21);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator9.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator21);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator21.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator27 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator27;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = offsetComparator27.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator34 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator34;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = kafkaSpoutMessageIdComparator29.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = offsetComparator34.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = kafkaSpoutMessageIdComparator26.thenComparing(kafkaSpoutMessageIdComparator38);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator40 = kafkaSpoutMessageIdComparator8.thenComparing(kafkaSpoutMessageIdComparator26);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator41 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator42 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator42;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = offsetComparator42.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator45 = offsetComparator41.thenComparing(kafkaSpoutMessageIdComparator44);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator46 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator46;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator48 = offsetComparator46.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator53 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator53;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator53);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator56 = kafkaSpoutMessageIdComparator48.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator53);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator57 = offsetComparator41.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator53);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator58 = offsetComparator53.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator59 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator59;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator61 = offsetComparator59.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator66 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator66;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator66);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator69 = kafkaSpoutMessageIdComparator61.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator66);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator70 = offsetComparator66.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator71 = kafkaSpoutMessageIdComparator58.thenComparing(kafkaSpoutMessageIdComparator70);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator71;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator73 = kafkaSpoutMessageIdComparator8.thenComparing(kafkaSpoutMessageIdComparator71);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator6);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator8);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator40);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator48);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator56);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator57);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator58);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator61);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator69);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator70);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator71);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator73);
    }

    @Test
    public void test6891() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6891");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer4;
        strKafkaSpout0.maxRetries = 0;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.doSeekRetriableTopicPartitions();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
    }

    @Test
    public void test6892() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6892");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        boolean boolean5 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder6 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder6;
        strKafkaSpout0.maxRetries = (short) -1;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.commitOffsetsForAckedTuples();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
    }

    @Test
    public void test6893() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6893");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout9 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout9.maxRetries = (byte) -1;
        int int12 = strKafkaSpout9.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor13 = null;
        strKafkaSpout9.waitingToEmit = strConsumerRecordItor13;
        org.apache.kafka.common.TopicPartition topicPartition15 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection16 = strKafkaSpout9.toArrayList(topicPartition15);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer17 = strKafkaSpout9.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector18 = strKafkaSpout9.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout19 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout19.maxRetries = (byte) -1;
        int int22 = strKafkaSpout19.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray23 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet24 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean25 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet24, kafkaSpoutMessageIdArray23);
        strKafkaSpout19.emitted = kafkaSpoutMessageIdSet24;
        strKafkaSpout9.emitted = kafkaSpoutMessageIdSet24;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet24;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder29 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder29;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy31 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy31;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig33 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig33;
        java.util.Map map35 = null;
        org.apache.storm.task.TopologyContext topologyContext36 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector37 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map35, topologyContext36, spoutOutputCollector37);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection16);
        org.junit.Assert.assertNull(timer17);
        org.junit.Assert.assertNull(spoutOutputCollector18);
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray23);
        org.junit.Assert.assertTrue("'" + boolean25 + "' != '" + false + "'", boolean25 == false);
    }

    @Test
    public void test6894() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6894");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.timestamp();
        long long16 = charSequenceConsumerRecord10.offset();
        long long17 = charSequenceConsumerRecord10.offset();
        long long18 = charSequenceConsumerRecord10.offset();
        long long19 = charSequenceConsumerRecord10.checksum();
        long long20 = charSequenceConsumerRecord10.checksum();
        java.lang.String str21 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "hi!" + "'", str21, "hi!");
    }

    @Test
    public void test6895() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6895");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        long long19 = charSequenceConsumerRecord10.offset();
        org.apache.kafka.common.record.TimestampType timestampType20 = charSequenceConsumerRecord10.timestampType();
        int int21 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.String str22 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertNull(timestampType20);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 52 + "'", int21 == 52);
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
    }

    @Test
    public void test6896() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6896");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (byte) 0, (long) (byte) -1, (long) (short) 100, timestampType4, (long) (short) 1, (int) (byte) 1, (int) (short) 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        java.lang.String str11 = charSequenceConsumerRecord10.value();
        long long12 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
    }

    @Test
    public void test6897() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6897");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence17 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence18 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType20 = charSequenceConsumerRecord10.timestampType();
        int int21 = charSequenceConsumerRecord10.partition();
        int int22 = charSequenceConsumerRecord10.partition();
        int int23 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertEquals("'" + charSequence17 + "' != '" + "" + "'", charSequence17, "");
        org.junit.Assert.assertEquals("'" + charSequence18 + "' != '" + "" + "'", charSequence18, "");
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertNull(timestampType20);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 10 + "'", int21 == 10);
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 10 + "'", int22 == 10);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
    }

    @Test
    public void test6898() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6898");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        int int15 = charSequenceConsumerRecord10.partition();
        long long16 = charSequenceConsumerRecord10.checksum();
        java.lang.String str17 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.header.Headers headers18 = charSequenceConsumerRecord10.headers();
        int int19 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertNotNull(headers18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
    }

    @Test
    public void test6899() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6899");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long10 = charSequenceConsumerRecord9.checksum();
        long long11 = charSequenceConsumerRecord9.timestamp();
        org.apache.kafka.common.header.Headers headers12 = charSequenceConsumerRecord9.headers();
        org.apache.kafka.common.record.TimestampType timestampType13 = charSequenceConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.CharSequence charSequence33 = charSequenceConsumerRecord32.key();
        long long34 = charSequenceConsumerRecord32.timestamp();
        java.lang.Class<?> wildcardClass35 = charSequenceConsumerRecord32.getClass();
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType40, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long47 = charSequenceConsumerRecord46.checksum();
        int int48 = charSequenceConsumerRecord46.partition();
        long long49 = charSequenceConsumerRecord46.timestamp();
        java.lang.String str50 = charSequenceConsumerRecord46.toString();
        org.apache.kafka.common.header.Headers headers51 = charSequenceConsumerRecord46.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, org.apache.kafka.common.header.Headers> genericDeclarationConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.reflect.GenericDeclaration, org.apache.kafka.common.header.Headers>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)", 100, 100L, (long) 10, timestampType23, (long) 52, 97, (-1), (java.lang.reflect.GenericDeclaration) wildcardClass35, headers51);
        org.apache.kafka.common.record.TimestampType timestampType57 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType57, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int64 = charSequenceConsumerRecord63.serializedValueSize();
        java.lang.CharSequence charSequence65 = charSequenceConsumerRecord63.key();
        org.apache.kafka.common.header.Headers headers66 = charSequenceConsumerRecord63.headers();
        int int67 = charSequenceConsumerRecord63.partition();
        int int68 = charSequenceConsumerRecord63.partition();
        java.lang.String str69 = charSequenceConsumerRecord63.toString();
        java.util.Optional<java.lang.Integer> intOptional70 = charSequenceConsumerRecord63.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) 0, (long) (short) 0, (long) (-1), timestampType13, (java.lang.Long) 100L, (int) '#', (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", headers51, intOptional70);
        org.apache.kafka.common.record.TimestampType timestampType72 = charSequenceConsumerRecord71.timestampType();
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertTrue("'" + timestampType13 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType13.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + charSequence33 + "' != '" + "" + "'", charSequence33, "");
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertNotNull(wildcardClass35);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + (-1L) + "'", long47 == (-1L));
        org.junit.Assert.assertTrue("'" + int48 + "' != '" + 10 + "'", int48 == 10);
        org.junit.Assert.assertTrue("'" + long49 + "' != '" + (-1L) + "'", long49 == (-1L));
        org.junit.Assert.assertEquals("'" + str50 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str50, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers51);
        org.junit.Assert.assertTrue("'" + int64 + "' != '" + (-1) + "'", int64 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence65 + "' != '" + "" + "'", charSequence65, "");
        org.junit.Assert.assertNotNull(headers66);
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + 10 + "'", int67 == 10);
        org.junit.Assert.assertTrue("'" + int68 + "' != '" + 10 + "'", int68 == 10);
        org.junit.Assert.assertEquals("'" + str69 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str69, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(intOptional70);
        org.junit.Assert.assertTrue("'" + timestampType72 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType72.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test6900() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6900");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        strKafkaSpout0.maxRetries = (byte) 1;
        boolean boolean10 = strKafkaSpout0.initialized;
        boolean boolean11 = strKafkaSpout0.consumerAutoCommitMode;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean12 = strKafkaSpout0.poll();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
    }

    @Test
    public void test6901() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6901");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) 10, (long) 52, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        int int6 = charSequenceConsumerRecord5.serializedValueSize();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
    }

    @Test
    public void test6902() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6902");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer4 = strKafkaSpout0.commitTimer;
        java.lang.String str5 = strKafkaSpout0.toString();
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords6 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords6);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer4);
        org.junit.Assert.assertEquals("'" + str5 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str5, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test6903() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6903");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.header.Headers headers15 = charSequenceConsumerRecord10.headers();
        long long16 = charSequenceConsumerRecord10.timestamp();
        int int17 = charSequenceConsumerRecord10.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional18 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        int int20 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 52 + "'", int14 == 52);
        org.junit.Assert.assertNotNull(headers15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 52 + "'", int17 == 52);
        org.junit.Assert.assertNotNull(intOptional18);
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + (-1) + "'", int20 == (-1));
    }

    @Test
    public void test6904() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6904");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str18 = charSequenceConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = charSequenceConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long34 = charSequenceConsumerRecord33.checksum();
        int int35 = charSequenceConsumerRecord33.partition();
        java.lang.String str36 = charSequenceConsumerRecord33.value();
        int int37 = charSequenceConsumerRecord33.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional38 = charSequenceConsumerRecord33.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout39 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet40 = strKafkaSpout39.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor41 = null;
        strKafkaSpout39.waitingToEmit = strConsumerRecordItor41;
        boolean boolean43 = strKafkaSpout39.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig44 = null;
        strKafkaSpout39.kafkaSpoutConfig = strKafkaSpoutConfig44;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy46 = strKafkaSpout39.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType19, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord33, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout39);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long59 = charSequenceConsumerRecord58.checksum();
        long long60 = charSequenceConsumerRecord58.timestamp();
        org.apache.kafka.common.header.Headers headers61 = charSequenceConsumerRecord58.headers();
        org.apache.kafka.common.record.TimestampType timestampType66 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType66, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long73 = charSequenceConsumerRecord72.offset();
        int int74 = charSequenceConsumerRecord72.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional75 = charSequenceConsumerRecord72.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType76 = charSequenceConsumerRecord72.timestampType();
        java.util.Optional<java.lang.Integer> intOptional77 = charSequenceConsumerRecord72.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 52, 0L, (-1L), timestampType19, (java.lang.Long) 35L, (int) (short) -1, 0, (java.lang.CharSequence) "", "hi!", headers61, intOptional77);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord84 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (byte) 100, (long) '#', (long) 0, timestampType19, (long) 'a', 52, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "hi!");
        java.util.Optional<java.lang.Integer> intOptional85 = charSequenceConsumerRecord84.leaderEpoch();
        java.lang.String str86 = charSequenceConsumerRecord84.topic();
        org.apache.kafka.common.record.TimestampType timestampType87 = charSequenceConsumerRecord84.timestampType();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertTrue("'" + int35 + "' != '" + 10 + "'", int35 == 10);
        org.junit.Assert.assertEquals("'" + str36 + "' != '" + "hi!" + "'", str36, "hi!");
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + 52 + "'", int37 == 52);
        org.junit.Assert.assertNotNull(intOptional38);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet40);
        org.junit.Assert.assertTrue("'" + boolean43 + "' != '" + false + "'", boolean43 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy46);
        org.junit.Assert.assertTrue("'" + long59 + "' != '" + (-1L) + "'", long59 == (-1L));
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertNotNull(headers61);
        org.junit.Assert.assertTrue("'" + long73 + "' != '" + 0L + "'", long73 == 0L);
        org.junit.Assert.assertTrue("'" + int74 + "' != '" + (-1) + "'", int74 == (-1));
        org.junit.Assert.assertNotNull(intOptional75);
        org.junit.Assert.assertNull(timestampType76);
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertNotNull(intOptional85);
        org.junit.Assert.assertEquals("'" + str86 + "' != '" + "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str86, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + timestampType87 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType87.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test6905() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6905");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        strKafkaSpout0.initialized = true;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet8 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer9 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy10 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy10;
        strKafkaSpout0.initialized = true;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords14 = strKafkaSpout0.pollKafkaBroker();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet8);
        org.junit.Assert.assertNull(timer9);
    }

    @Test
    public void test6906() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6906");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", 1, (long) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = 97, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = )", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
    }

    @Test
    public void test6907() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6907");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        boolean boolean10 = strKafkaSpout0.consumerAutoCommitMode;
        strKafkaSpout0.maxRetries = (short) 10;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = strKafkaSpout0.tuplesBuilder;
        strKafkaSpout0.initialized = true;
        boolean boolean16 = strKafkaSpout0.waitingToEmit();
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder13);
        org.junit.Assert.assertTrue("'" + boolean16 + "' != '" + false + "'", boolean16 == false);
    }

    @Test
    public void test6908() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6908");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer9 = strKafkaSpout0.commitTimer;
        boolean boolean10 = strKafkaSpout0.waitingToEmit();
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder12 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder12;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig14 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer15 = strKafkaSpout0.commitTimer;
        boolean boolean16 = strKafkaSpout0.waitingToEmit();
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertNull(timer9);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNull(strKafkaConsumer11);
        org.junit.Assert.assertNull(strKafkaSpoutConfig14);
        org.junit.Assert.assertNull(timer15);
        org.junit.Assert.assertTrue("'" + boolean16 + "' != '" + false + "'", boolean16 == false);
    }

    @Test
    public void test6909() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6909");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType31 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType31, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long38 = charSequenceConsumerRecord37.checksum();
        int int39 = charSequenceConsumerRecord37.partition();
        java.lang.String str40 = charSequenceConsumerRecord37.value();
        int int41 = charSequenceConsumerRecord37.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional42 = charSequenceConsumerRecord37.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout43 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet44 = strKafkaSpout43.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor45 = null;
        strKafkaSpout43.waitingToEmit = strConsumerRecordItor45;
        boolean boolean47 = strKafkaSpout43.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig48 = null;
        strKafkaSpout43.kafkaSpoutConfig = strKafkaSpoutConfig48;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy50 = strKafkaSpout43.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType23, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord37, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout43);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord62 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long63 = charSequenceConsumerRecord62.checksum();
        long long64 = charSequenceConsumerRecord62.timestamp();
        org.apache.kafka.common.header.Headers headers65 = charSequenceConsumerRecord62.headers();
        org.apache.kafka.common.record.TimestampType timestampType70 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType70, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long77 = charSequenceConsumerRecord76.offset();
        int int78 = charSequenceConsumerRecord76.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional79 = charSequenceConsumerRecord76.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType80 = charSequenceConsumerRecord76.timestampType();
        java.util.Optional<java.lang.Integer> intOptional81 = charSequenceConsumerRecord76.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 52, 0L, (-1L), timestampType23, (java.lang.Long) 35L, (int) (short) -1, 0, (java.lang.CharSequence) "", "hi!", headers65, intOptional81);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 10, (long) 0, (long) (byte) 1, timestampType23, 52L, (int) (byte) 100, (int) 'a', (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 35, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)))");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord94 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (byte) -1, (long) (byte) 100, (long) (short) 0, timestampType23, 0L, 0, (int) (short) 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )");
        java.util.Optional<java.lang.Integer> intOptional95 = charSequenceConsumerRecord94.leaderEpoch();
        java.lang.Class<?> wildcardClass96 = intOptional95.getClass();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + (-1L) + "'", long38 == (-1L));
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + 10 + "'", int39 == 10);
        org.junit.Assert.assertEquals("'" + str40 + "' != '" + "hi!" + "'", str40, "hi!");
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + 52 + "'", int41 == 52);
        org.junit.Assert.assertNotNull(intOptional42);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet44);
        org.junit.Assert.assertTrue("'" + boolean47 + "' != '" + false + "'", boolean47 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy50);
        org.junit.Assert.assertTrue("'" + long63 + "' != '" + (-1L) + "'", long63 == (-1L));
        org.junit.Assert.assertTrue("'" + long64 + "' != '" + (-1L) + "'", long64 == (-1L));
        org.junit.Assert.assertNotNull(headers65);
        org.junit.Assert.assertTrue("'" + long77 + "' != '" + 0L + "'", long77 == 0L);
        org.junit.Assert.assertTrue("'" + int78 + "' != '" + (-1) + "'", int78 == (-1));
        org.junit.Assert.assertNotNull(intOptional79);
        org.junit.Assert.assertNull(timestampType80);
        org.junit.Assert.assertNotNull(intOptional81);
        org.junit.Assert.assertNotNull(intOptional95);
        org.junit.Assert.assertNotNull(wildcardClass96);
    }

    @Test
    public void test6910() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6910");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.header.Headers headers15 = charSequenceConsumerRecord10.headers();
        long long16 = charSequenceConsumerRecord10.timestamp();
        int int17 = charSequenceConsumerRecord10.serializedKeySize();
        int int18 = charSequenceConsumerRecord10.serializedValueSize();
        int int19 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 52 + "'", int14 == 52);
        org.junit.Assert.assertNotNull(headers15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 52 + "'", int17 == 52);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + (-1) + "'", int18 == (-1));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
    }

    @Test
    public void test6911() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6911");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        long long18 = charSequenceConsumerRecord10.timestamp();
        long long19 = charSequenceConsumerRecord10.timestamp();
        int int20 = charSequenceConsumerRecord10.serializedKeySize();
        int int21 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 52 + "'", int20 == 52);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
    }

    @Test
    public void test6912() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6912");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        org.apache.kafka.common.TopicPartition topicPartition3 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection4 = strKafkaSpout0.toArrayList(topicPartition3);
        boolean boolean5 = strKafkaSpout0.initialized;
        long long6 = strKafkaSpout0.numUncommittedOffsets;
        org.junit.Assert.assertNotNull(topicPartitionCollection4);
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + 0L + "'", long6 == 0L);
    }

    @Test
    public void test6913() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6913");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.numUncommittedOffsets = (byte) 1;
        strKafkaSpout0.initialized = false;
        strKafkaSpout0.maxRetries = (byte) 100;
        strKafkaSpout0.initialized = false;
        boolean boolean18 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition19 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection20 = strKafkaSpout0.toArrayList(topicPartition19);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + boolean18 + "' != '" + false + "'", boolean18 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection20);
    }

    @Test
    public void test6914() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6914");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer1 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy2 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams3 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams3;
        strKafkaSpout0.numUncommittedOffsets = 35L;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams7;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer9 = strKafkaSpout0.kafkaConsumer;
        org.junit.Assert.assertNull(timer1);
        org.junit.Assert.assertNull(firstPollOffsetStrategy2);
        org.junit.Assert.assertNull(strKafkaConsumer9);
    }

    @Test
    public void test6915() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6915");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        boolean boolean11 = strKafkaSpout0.consumerAutoCommitMode;
        boolean boolean12 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy13 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.kafka.common.TopicPartition topicPartition14 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection15 = strKafkaSpout0.toArrayList(topicPartition14);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService16 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService16;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + false + "'", boolean12 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy13);
        org.junit.Assert.assertNotNull(topicPartitionCollection15);
    }

    @Test
    public void test6916() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6916");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        long long11 = strKafkaSpout0.numUncommittedOffsets;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor12 = strKafkaSpout0.waitingToEmit;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 35L + "'", long11 == 35L);
        org.junit.Assert.assertNull(strConsumerRecordItor12);
    }

    @Test
    public void test6917() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6917");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams3 = strKafkaSpout0.kafkaSpoutStreams;
        org.junit.Assert.assertNull(kafkaSpoutStreams3);
    }

    @Test
    public void test6918() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6918");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        java.lang.String str12 = charSequenceConsumerRecord10.value();
        java.lang.String str13 = charSequenceConsumerRecord10.toString();
        java.lang.String str14 = charSequenceConsumerRecord10.topic();
        java.util.Optional<java.lang.Integer> intOptional15 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str16 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "hi!" + "'", str16, "hi!");
    }

    @Test
    public void test6919() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6919");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional16 = charSequenceConsumerRecord10.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional17 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertNotNull(intOptional17);
    }

    @Test
    public void test6920() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6920");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = 0;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer5 = strKafkaSpout0.kafkaConsumer;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertNull(strKafkaConsumer5);
    }

    @Test
    public void test6921() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6921");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer1 = strKafkaSpout0.commitTimer;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer2 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer2);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(timer1);
    }

    @Test
    public void test6922() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6922");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams10;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder13;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(spoutOutputCollector12);
    }

    @Test
    public void test6923() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6923");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", 0, 1L, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", "");
        org.apache.kafka.common.header.Headers headers6 = charSequenceConsumerRecord5.headers();
        java.lang.CharSequence charSequence7 = charSequenceConsumerRecord5.key();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertEquals("'" + charSequence7 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", charSequence7, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
    }

    @Test
    public void test6924() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6924");
        org.apache.kafka.common.record.TimestampType timestampType8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType8, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord14.timestampType();
        long long16 = charSequenceConsumerRecord14.offset();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.Object> strComparableConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.Object>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) -1, 10L, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", (java.lang.Object) charSequenceConsumerRecord14);
        int int18 = charSequenceConsumerRecord14.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord14.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord14.leaderEpoch();
        org.junit.Assert.assertNull(timestampType15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + (-1) + "'", int18 == (-1));
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertNotNull(intOptional20);
    }

    @Test
    public void test6925() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6925");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        java.lang.String str8 = strKafkaSpout0.toString();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor9 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams12;
        boolean boolean14 = strKafkaSpout0.consumerAutoCommitMode;
        boolean boolean15 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords16 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords16);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strConsumerRecordItor9);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + true + "'", boolean14 == true);
        org.junit.Assert.assertTrue("'" + boolean15 + "' != '" + true + "'", boolean15 == true);
    }

    @Test
    public void test6926() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6926");
        org.apache.kafka.common.record.TimestampType timestampType8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType8, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long15 = charSequenceConsumerRecord14.checksum();
        int int16 = charSequenceConsumerRecord14.partition();
        long long17 = charSequenceConsumerRecord14.timestamp();
        long long18 = charSequenceConsumerRecord14.offset();
        int int19 = charSequenceConsumerRecord14.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType20 = charSequenceConsumerRecord14.timestampType();
        int int21 = charSequenceConsumerRecord14.partition();
        long long22 = charSequenceConsumerRecord14.checksum();
        java.util.Optional<java.lang.Integer> intOptional23 = charSequenceConsumerRecord14.leaderEpoch();
        org.apache.kafka.common.header.Headers headers24 = charSequenceConsumerRecord14.headers();
        java.lang.String str25 = charSequenceConsumerRecord14.value();
        java.lang.String str26 = charSequenceConsumerRecord14.value();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>> strComparableConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", (int) (byte) 10, 32L, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", charSequenceConsumerRecord14);
        java.lang.CharSequence charSequence28 = charSequenceConsumerRecord14.key();
        long long29 = charSequenceConsumerRecord14.timestamp();
        long long30 = charSequenceConsumerRecord14.timestamp();
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 52 + "'", int19 == 52);
        org.junit.Assert.assertNull(timestampType20);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 10 + "'", int21 == 10);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
        org.junit.Assert.assertNotNull(intOptional23);
        org.junit.Assert.assertNotNull(headers24);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "hi!" + "'", str25, "hi!");
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "hi!" + "'", str26, "hi!");
        org.junit.Assert.assertEquals("'" + charSequence28 + "' != '" + "" + "'", charSequence28, "");
        org.junit.Assert.assertTrue("'" + long29 + "' != '" + (-1L) + "'", long29 == (-1L));
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
    }

    @Test
    public void test6927() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6927");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        boolean boolean11 = strKafkaSpout0.consumerAutoCommitMode;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.commitOffsetsForAckedTuples();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
    }

    @Test
    public void test6928() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6928");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = offsetComparator7.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator7.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator12;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator14 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator14;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator14.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator21 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator21;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator21);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator16.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator21);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = kafkaSpoutMessageIdComparator16.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator26 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator27 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator27;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = offsetComparator27.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator34 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator34;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = kafkaSpoutMessageIdComparator29.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = offsetComparator26.thenComparing(kafkaSpoutMessageIdComparator37);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = kafkaSpoutMessageIdComparator25.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator26);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator39;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = kafkaSpoutMessageIdComparator12.thenComparing(kafkaSpoutMessageIdComparator39);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator42 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator43 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator43;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator45 = offsetComparator43.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator46 = offsetComparator42.thenComparing(kafkaSpoutMessageIdComparator45);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator47 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator47;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator49 = offsetComparator47.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator54 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator54;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator54);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator57 = kafkaSpoutMessageIdComparator49.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator54);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator58 = offsetComparator42.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator54);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator59 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator59;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator61 = offsetComparator59.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator59;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator63 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator63;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator65 = offsetComparator63.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator66 = offsetComparator59.thenComparing(kafkaSpoutMessageIdComparator65);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator67 = kafkaSpoutMessageIdComparator65.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator68 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator68;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator70 = offsetComparator68.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator75 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator75;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator75);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator78 = kafkaSpoutMessageIdComparator70.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator75);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator79 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator79;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator81 = offsetComparator79.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator86 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator86;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator86);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator89 = kafkaSpoutMessageIdComparator81.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator86);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator90 = kafkaSpoutMessageIdComparator70.thenComparing(kafkaSpoutMessageIdComparator89);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator91 = kafkaSpoutMessageIdComparator90.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator92 = kafkaSpoutMessageIdComparator65.thenComparing(kafkaSpoutMessageIdComparator90);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator92;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator94 = offsetComparator54.thenComparing(kafkaSpoutMessageIdComparator92);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator95 = kafkaSpoutMessageIdComparator39.thenComparing(kafkaSpoutMessageIdComparator92);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator96 = kafkaSpoutMessageIdComparator92.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator46);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator49);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator57);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator58);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator61);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator65);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator66);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator67);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator70);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator78);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator81);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator89);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator90);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator91);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator92);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator94);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator95);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator96);
    }

    @Test
    public void test6929() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6929");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator4 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator5 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator6 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator6;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator8 = offsetComparator6.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord15 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator13);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = kafkaSpoutMessageIdComparator8.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator13);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = offsetComparator5.thenComparing(kafkaSpoutMessageIdComparator16);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = kafkaSpoutMessageIdComparator16.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator19 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator19;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = offsetComparator19.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator19;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator23;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator23.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator19.thenComparing(kafkaSpoutMessageIdComparator25);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = offsetComparator19.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = kafkaSpoutMessageIdComparator18.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator19);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = kafkaSpoutMessageIdComparator4.thenComparing(kafkaSpoutMessageIdComparator28);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator30 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator31 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator32 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator32;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator32.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator39 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator39;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator39);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator42 = kafkaSpoutMessageIdComparator34.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator39);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator43 = offsetComparator31.thenComparing(kafkaSpoutMessageIdComparator42);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = kafkaSpoutMessageIdComparator42.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator45 = offsetComparator30.thenComparing(kafkaSpoutMessageIdComparator42);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator46 = kafkaSpoutMessageIdComparator42.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator47 = kafkaSpoutMessageIdComparator42.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator48 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator49 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator49;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator51 = offsetComparator49.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator52 = offsetComparator48.thenComparing(kafkaSpoutMessageIdComparator51);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator53 = kafkaSpoutMessageIdComparator42.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator48);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator54 = kafkaSpoutMessageIdComparator4.thenComparing(kafkaSpoutMessageIdComparator42);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator55 = kafkaSpoutMessageIdComparator42.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator4);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator8);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator42);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator43);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator46);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator47);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator51);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator52);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator53);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator54);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator55);
    }

    @Test
    public void test6930() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6930");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer16;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer18 = strKafkaSpout0.kafkaConsumer;
        long long19 = strKafkaSpout0.numUncommittedOffsets;
        boolean boolean20 = strKafkaSpout0.waitingToEmit();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertNull(strKafkaConsumer18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertTrue("'" + boolean20 + "' != '" + false + "'", boolean20 == false);
    }

    @Test
    public void test6931() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6931");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams7;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = strKafkaSpout0.retryService;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        strKafkaSpout0.maxRetries = (-1);
        boolean boolean13 = strKafkaSpout0.initialized;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer14 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer14;
        java.lang.String str16 = strKafkaSpout0.toString();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(kafkaSpoutRetryService9);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertTrue("'" + boolean13 + "' != '" + false + "'", boolean13 == false);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str16, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test6932() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6932");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer4;
        boolean boolean6 = strKafkaSpout0.initialized;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
    }

    @Test
    public void test6933() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6933");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        long long8 = strKafkaSpout0.numUncommittedOffsets;
        strKafkaSpout0.numUncommittedOffsets = (-1L);
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder11 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder11;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder13;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 0L + "'", long8 == 0L);
    }

    @Test
    public void test6934() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6934");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig3 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService7 = strKafkaSpout0.retryService;
        boolean boolean8 = strKafkaSpout0.initialized;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor9 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor9;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = null;
        strKafkaSpout0.collector = spoutOutputCollector11;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer13 = strKafkaSpout0.commitTimer;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutRetryService7);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
        org.junit.Assert.assertNull(timer13);
    }

    @Test
    public void test6935() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6935");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        boolean boolean10 = strKafkaSpout0.consumerAutoCommitMode;
        strKafkaSpout0.maxRetries = (short) 10;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService14 = strKafkaSpout0.retryService;
        org.apache.kafka.common.TopicPartition topicPartition15 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection16 = strKafkaSpout0.toArrayList(topicPartition15);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder13);
        org.junit.Assert.assertNull(kafkaSpoutRetryService14);
        org.junit.Assert.assertNotNull(topicPartitionCollection16);
    }

    @Test
    public void test6936() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6936");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", 1, (long) (short) -1, (java.lang.CharSequence) "", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 0, null = 97, serialized key size = 32, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
    }

    @Test
    public void test6937() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6937");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator4 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator4;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord6 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator4);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator4.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator8 = offsetComparator4.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator9 = kafkaSpoutMessageIdComparator8.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator10 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator12 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator12;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = offsetComparator12.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator11.thenComparing(kafkaSpoutMessageIdComparator14);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator16 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator16;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = offsetComparator16.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = offsetComparator16.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = kafkaSpoutMessageIdComparator14.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator16);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = offsetComparator10.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator16);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = kafkaSpoutMessageIdComparator8.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator10);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = kafkaSpoutMessageIdComparator22.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator23.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator8);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator9);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
    }

    @Test
    public void test6938() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6938");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        long long8 = strKafkaSpout0.numUncommittedOffsets;
        boolean boolean9 = strKafkaSpout0.initialized;
        boolean boolean10 = strKafkaSpout0.waitingToEmit();
        strKafkaSpout0.consumerAutoCommitMode = false;
        long long13 = strKafkaSpout0.numUncommittedOffsets;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 0L + "'", long8 == 0L);
        org.junit.Assert.assertTrue("'" + boolean9 + "' != '" + false + "'", boolean9 == false);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
    }

    @Test
    public void test6939() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6939");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str18 = charSequenceConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = charSequenceConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long34 = charSequenceConsumerRecord33.checksum();
        int int35 = charSequenceConsumerRecord33.partition();
        java.lang.String str36 = charSequenceConsumerRecord33.value();
        int int37 = charSequenceConsumerRecord33.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional38 = charSequenceConsumerRecord33.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout39 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet40 = strKafkaSpout39.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor41 = null;
        strKafkaSpout39.waitingToEmit = strConsumerRecordItor41;
        boolean boolean43 = strKafkaSpout39.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig44 = null;
        strKafkaSpout39.kafkaSpoutConfig = strKafkaSpoutConfig44;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy46 = strKafkaSpout39.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType19, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord33, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout39);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout51 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout51.maxRetries = (byte) -1;
        int int54 = strKafkaSpout51.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor55 = null;
        strKafkaSpout51.waitingToEmit = strConsumerRecordItor55;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer57 = strKafkaSpout51.commitTimer;
        boolean boolean58 = strKafkaSpout51.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService59 = null;
        strKafkaSpout51.retryService = kafkaSpoutRetryService59;
        java.lang.Object obj61 = null;
        org.apache.kafka.common.record.TimestampType timestampType66 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType66, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long73 = charSequenceConsumerRecord72.checksum();
        int int74 = charSequenceConsumerRecord72.partition();
        long long75 = charSequenceConsumerRecord72.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType76 = charSequenceConsumerRecord72.timestampType();
        int int77 = charSequenceConsumerRecord72.serializedKeySize();
        org.apache.kafka.common.header.Headers headers78 = charSequenceConsumerRecord72.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Object> objConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Object>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (byte) 100, (long) (short) 10, (long) ' ', timestampType19, (java.lang.Long) (-1L), 97, (int) (byte) 1, (java.lang.Object) kafkaSpoutRetryService59, obj61, headers78);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 1, 97L, (long) 0, timestampType19, (long) 1, 100, 1, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "KafkaSpout{acked=null, emitted=[]}");
        long long86 = charSequenceConsumerRecord85.timestamp();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertTrue("'" + int35 + "' != '" + 10 + "'", int35 == 10);
        org.junit.Assert.assertEquals("'" + str36 + "' != '" + "hi!" + "'", str36, "hi!");
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + 52 + "'", int37 == 52);
        org.junit.Assert.assertNotNull(intOptional38);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet40);
        org.junit.Assert.assertTrue("'" + boolean43 + "' != '" + false + "'", boolean43 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy46);
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + (-1) + "'", int54 == (-1));
        org.junit.Assert.assertNull(timer57);
        org.junit.Assert.assertTrue("'" + boolean58 + "' != '" + false + "'", boolean58 == false);
        org.junit.Assert.assertTrue("'" + long73 + "' != '" + (-1L) + "'", long73 == (-1L));
        org.junit.Assert.assertTrue("'" + int74 + "' != '" + 10 + "'", int74 == 10);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + (-1L) + "'", long75 == (-1L));
        org.junit.Assert.assertNull(timestampType76);
        org.junit.Assert.assertTrue("'" + int77 + "' != '" + 52 + "'", int77 == 52);
        org.junit.Assert.assertNotNull(headers78);
        org.junit.Assert.assertTrue("'" + long86 + "' != '" + 0L + "'", long86 == 0L);
    }

    @Test
    public void test6940() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6940");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 97, leaderEpoch = null, offset = 100, NoTimestampType = 97, serialized key size = 97, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=[]}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 0, 32L, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 35, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)))");
        java.lang.Class<?> wildcardClass6 = charSequenceConsumerRecord5.getClass();
        org.junit.Assert.assertNotNull(wildcardClass6);
    }

    @Test
    public void test6941() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6941");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long14 = charSequenceConsumerRecord13.checksum();
        long long15 = charSequenceConsumerRecord13.timestamp();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord13.headers();
        java.lang.String str17 = charSequenceConsumerRecord13.toString();
        org.apache.kafka.common.header.Headers headers18 = charSequenceConsumerRecord13.headers();
        java.lang.String str19 = charSequenceConsumerRecord13.topic();
        long long20 = charSequenceConsumerRecord13.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType21 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (byte) 1, (long) 100, timestampType21, (long) 1, 35, (int) (byte) 10, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.apache.kafka.common.record.TimestampType timestampType37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType37, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int44 = charSequenceConsumerRecord43.serializedValueSize();
        java.lang.CharSequence charSequence45 = charSequenceConsumerRecord43.key();
        int int46 = charSequenceConsumerRecord43.serializedKeySize();
        int int47 = charSequenceConsumerRecord43.serializedKeySize();
        org.apache.kafka.common.header.Headers headers48 = charSequenceConsumerRecord43.headers();
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType53, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long60 = charSequenceConsumerRecord59.checksum();
        int int61 = charSequenceConsumerRecord59.partition();
        java.lang.String str62 = charSequenceConsumerRecord59.value();
        int int63 = charSequenceConsumerRecord59.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional64 = charSequenceConsumerRecord59.leaderEpoch();
        long long65 = charSequenceConsumerRecord59.timestamp();
        java.util.Optional<java.lang.Integer> intOptional66 = charSequenceConsumerRecord59.leaderEpoch();
        int int67 = charSequenceConsumerRecord59.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional68 = charSequenceConsumerRecord59.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", 0, 0L, 0L, timestampType21, (java.lang.Long) 35L, (int) (short) -1, (int) '#', (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "hi!", headers48, intOptional68);
        java.lang.String str70 = charSequenceConsumerRecord69.value();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str17, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "" + "'", str19, "");
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType21 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType21.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int44 + "' != '" + (-1) + "'", int44 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence45 + "' != '" + "" + "'", charSequence45, "");
        org.junit.Assert.assertTrue("'" + int46 + "' != '" + 52 + "'", int46 == 52);
        org.junit.Assert.assertTrue("'" + int47 + "' != '" + 52 + "'", int47 == 52);
        org.junit.Assert.assertNotNull(headers48);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + 10 + "'", int61 == 10);
        org.junit.Assert.assertEquals("'" + str62 + "' != '" + "hi!" + "'", str62, "hi!");
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 52 + "'", int63 == 52);
        org.junit.Assert.assertNotNull(intOptional64);
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + (-1L) + "'", long65 == (-1L));
        org.junit.Assert.assertNotNull(intOptional66);
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + (-1) + "'", int67 == (-1));
        org.junit.Assert.assertNotNull(intOptional68);
        org.junit.Assert.assertEquals("'" + str70 + "' != '" + "hi!" + "'", str70, "hi!");
    }

    @Test
    public void test6942() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6942");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams6 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams6;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertNull(strKafkaSpoutConfig5);
    }

    @Test
    public void test6943() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6943");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer16;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector18 = null;
        strKafkaSpout0.collector = spoutOutputCollector18;
        strKafkaSpout0.numUncommittedOffsets = 1L;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector22 = null;
        strKafkaSpout0.collector = spoutOutputCollector22;
        long long24 = strKafkaSpout0.numUncommittedOffsets;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.doSeekRetriableTopicPartitions();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 1L + "'", long24 == 1L);
    }

    @Test
    public void test6944() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6944");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType23, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long30 = charSequenceConsumerRecord29.checksum();
        int int31 = charSequenceConsumerRecord29.partition();
        long long32 = charSequenceConsumerRecord29.timestamp();
        java.lang.String str33 = charSequenceConsumerRecord29.toString();
        long long34 = charSequenceConsumerRecord29.timestamp();
        org.apache.kafka.common.header.Headers headers35 = charSequenceConsumerRecord29.headers();
        org.apache.kafka.common.record.TimestampType timestampType36 = charSequenceConsumerRecord29.timestampType();
        java.util.Optional<java.lang.Integer> intOptional37 = charSequenceConsumerRecord29.leaderEpoch();
        org.apache.storm.topology.IComponent iComponent38 = null;
        org.apache.kafka.common.record.TimestampType timestampType43 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType43, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long50 = charSequenceConsumerRecord49.checksum();
        int int51 = charSequenceConsumerRecord49.partition();
        long long52 = charSequenceConsumerRecord49.timestamp();
        java.lang.String str53 = charSequenceConsumerRecord49.toString();
        org.apache.kafka.common.header.Headers headers54 = charSequenceConsumerRecord49.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent> intOptionalConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent>("hi!", (int) ' ', (long) (byte) -1, (long) (-1), timestampType15, (java.lang.Long) 100L, (int) 'a', (-1), intOptional37, iComponent38, headers54);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", (int) ' ', (long) (short) 10, (long) '4', timestampType15, (long) (short) 1, 97, 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )");
        int int62 = charSequenceConsumerRecord61.partition();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 10 + "'", int31 == 10);
        org.junit.Assert.assertTrue("'" + long32 + "' != '" + (-1L) + "'", long32 == (-1L));
        org.junit.Assert.assertEquals("'" + str33 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str33, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertNotNull(headers35);
        org.junit.Assert.assertNull(timestampType36);
        org.junit.Assert.assertNotNull(intOptional37);
        org.junit.Assert.assertTrue("'" + long50 + "' != '" + (-1L) + "'", long50 == (-1L));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 10 + "'", int51 == 10);
        org.junit.Assert.assertTrue("'" + long52 + "' != '" + (-1L) + "'", long52 == (-1L));
        org.junit.Assert.assertEquals("'" + str53 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str53, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers54);
        org.junit.Assert.assertTrue("'" + int62 + "' != '" + 32 + "'", int62 == 32);
    }

    @Test
    public void test6945() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6945");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str15 = charSequenceConsumerRecord10.topic();
        int int16 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.header.Headers headers17 = charSequenceConsumerRecord10.headers();
        int int18 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "" + "'", str15, "");
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertNotNull(headers17);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 10 + "'", int18 == 10);
    }

    @Test
    public void test6946() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6946");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        int int18 = charSequenceConsumerRecord10.partition();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.header.Headers headers20 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 10 + "'", int18 == 10);
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertNotNull(headers20);
    }

    @Test
    public void test6947() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6947");
        org.apache.kafka.common.record.TimestampType timestampType8 = null;
        org.apache.kafka.common.record.TimestampType timestampType18 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType18, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int25 = charSequenceConsumerRecord24.serializedValueSize();
        java.lang.CharSequence charSequence26 = charSequenceConsumerRecord24.key();
        org.apache.kafka.common.header.Headers headers27 = charSequenceConsumerRecord24.headers();
        java.util.Optional<java.lang.Integer> intOptional28 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType8, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers27, intOptional28);
        java.lang.String str30 = charSequenceConsumerRecord29.value();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) 1, (long) 10, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", charSequenceConsumerRecord29);
        long long32 = charSequenceConsumerRecord29.timestamp();
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + (-1) + "'", int25 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence26 + "' != '" + "" + "'", charSequence26, "");
        org.junit.Assert.assertNotNull(headers27);
        org.junit.Assert.assertEquals("'" + str30 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str30, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long32 + "' != '" + 35L + "'", long32 == 35L);
    }

    @Test
    public void test6948() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6948");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.timestamp();
        long long19 = charSequenceConsumerRecord10.offset();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str21 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str21, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test6949() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6949");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams4;
        boolean boolean6 = strKafkaSpout0.waitingToEmit();
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer7;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord11 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean12 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord11);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + 0 + "'", int3 == 0);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
    }

    @Test
    public void test6950() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6950");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (byte) 0, (long) (byte) -1, (long) (short) 100, timestampType4, (long) (short) 1, (int) (byte) 1, (int) (short) 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        org.apache.kafka.common.record.TimestampType timestampType11 = charSequenceConsumerRecord10.timestampType();
        // The following exception was thrown during execution in test generation
        try {
            java.lang.Class<?> wildcardClass12 = timestampType11.getClass();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(timestampType11);
    }

    @Test
    public void test6951() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6951");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy8 = strKafkaSpout0.firstPollOffsetStrategy;
        boolean boolean9 = strKafkaSpout0.consumerAutoCommitMode;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy7);
        org.junit.Assert.assertNull(firstPollOffsetStrategy8);
        org.junit.Assert.assertTrue("'" + boolean9 + "' != '" + false + "'", boolean9 == false);
    }

    @Test
    public void test6952() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6952");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        int int12 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder13;
        strKafkaSpout0.numUncommittedOffsets = (short) 10;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor17 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor17;
        boolean boolean19 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy20 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord21 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean22 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord21);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + boolean19 + "' != '" + false + "'", boolean19 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy20);
    }

    @Test
    public void test6953() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6953");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig3 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService7 = strKafkaSpout0.retryService;
        boolean boolean8 = strKafkaSpout0.initialized;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor9 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor9;
        org.apache.kafka.common.TopicPartition topicPartition11 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection12 = strKafkaSpout0.toArrayList(topicPartition11);
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy13 = strKafkaSpout0.firstPollOffsetStrategy;
        org.junit.Assert.assertNull(kafkaSpoutRetryService7);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection12);
        org.junit.Assert.assertNull(firstPollOffsetStrategy13);
    }

    @Test
    public void test6954() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6954");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector3 = null;
        strKafkaSpout0.collector = spoutOutputCollector3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder6 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder6;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig8 = strKafkaSpout0.kafkaSpoutConfig;
        org.junit.Assert.assertNull(strKafkaSpoutConfig5);
        org.junit.Assert.assertNull(strKafkaSpoutConfig8);
    }

    @Test
    public void test6955() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6955");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) -1, (long) 100, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
        long long6 = charSequenceConsumerRecord5.offset();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + 100L + "'", long6 == 100L);
    }

    @Test
    public void test6956() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6956");
        org.apache.storm.kafka.spout.KafkaSpout kafkaSpout0 = null;
        java.util.concurrent.TimeUnit timeUnit3 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRebalanceListener, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>.Timer timer4 = kafkaSpout0.new Timer(97L, (long) (byte) 100, timeUnit3);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: reflection call to org.apache.storm.kafka.spout.KafkaSpout$Timer with null for superclass argument");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test6957() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6957");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService1 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService1;
        long long3 = strKafkaSpout0.numUncommittedOffsets;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = strKafkaSpout0.waitingToEmit;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = strKafkaSpout0.emitted;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig8 = strKafkaSpout0.kafkaSpoutConfig;
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.initialized = true;
        int int13 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor14 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.numUncommittedOffsets = ' ';
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor17 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor17;
        org.junit.Assert.assertTrue("'" + long3 + "' != '" + 0L + "'", long3 == 0L);
        org.junit.Assert.assertNull(strConsumerRecordItor4);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet5);
        org.junit.Assert.assertNull(strKafkaSpoutConfig8);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 0 + "'", int13 == 0);
        org.junit.Assert.assertNull(strConsumerRecordItor14);
    }

    @Test
    public void test6958() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6958");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        int int21 = charSequenceConsumerRecord10.serializedValueSize();
        int int22 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.CharSequence charSequence23 = charSequenceConsumerRecord10.key();
        java.lang.String str24 = charSequenceConsumerRecord10.toString();
        java.lang.Class<?> wildcardClass25 = charSequenceConsumerRecord10.getClass();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 52 + "'", int22 == 52);
        org.junit.Assert.assertEquals("'" + charSequence23 + "' != '" + "" + "'", charSequence23, "");
        org.junit.Assert.assertEquals("'" + str24 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str24, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(wildcardClass25);
    }

    @Test
    public void test6959() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6959");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        int int18 = charSequenceConsumerRecord10.serializedKeySize();
        long long19 = charSequenceConsumerRecord10.offset();
        int int20 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 52 + "'", int18 == 52);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 52 + "'", int20 == 52);
    }

    @Test
    public void test6960() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6960");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.header.Headers headers15 = charSequenceConsumerRecord10.headers();
        long long16 = charSequenceConsumerRecord10.checksum();
        java.lang.String str17 = charSequenceConsumerRecord10.value();
        java.util.Optional<java.lang.Integer> intOptional18 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 52 + "'", int14 == 52);
        org.junit.Assert.assertNotNull(headers15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertNotNull(intOptional18);
    }

    @Test
    public void test6961() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6961");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 10, 1L, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=[]}");
        long long6 = charSequenceConsumerRecord5.checksum();
        java.lang.String str7 = charSequenceConsumerRecord5.value();
        int int8 = charSequenceConsumerRecord5.serializedKeySize();
        long long9 = charSequenceConsumerRecord5.checksum();
        long long10 = charSequenceConsumerRecord5.timestamp();
        int int11 = charSequenceConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=[]}" + "'", str7, "KafkaSpout{acked=null, emitted=[]}");
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
    }

    @Test
    public void test6962() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6962");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams6 = strKafkaSpout0.kafkaSpoutStreams;
        boolean boolean7 = strKafkaSpout0.waitingToEmit();
        int int8 = strKafkaSpout0.maxRetries;
        boolean boolean9 = strKafkaSpout0.initialized;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer11 = strKafkaSpout0.commitTimer;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + 0 + "'", int3 == 0);
        org.junit.Assert.assertNull(kafkaSpoutStreams6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 0 + "'", int8 == 0);
        org.junit.Assert.assertTrue("'" + boolean9 + "' != '" + false + "'", boolean9 == false);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertNull(timer11);
    }

    @Test
    public void test6963() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6963");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", 10, 100L, (long) 10, timestampType4, (-1L), (int) (short) 10, (int) (byte) 100, (java.lang.CharSequence) "", "KafkaSpout{acked=null, emitted=null}");
        java.lang.String str11 = charSequenceConsumerRecord10.value();
        java.lang.String str12 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str11, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})" + "'", str12, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
    }

    @Test
    public void test6964() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6964");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder2 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder2;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy4 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy4;
        boolean boolean6 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy8 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy8;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor10 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor10;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNull(kafkaSpoutStreams7);
    }

    @Test
    public void test6965() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6965");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout3 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout3.maxRetries = (byte) -1;
        int int6 = strKafkaSpout3.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout3.waitingToEmit = strConsumerRecordItor7;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig9 = null;
        strKafkaSpout3.kafkaSpoutConfig = strKafkaSpoutConfig9;
        int int11 = strKafkaSpout3.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy12 = null;
        strKafkaSpout3.firstPollOffsetStrategy = firstPollOffsetStrategy12;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig14 = strKafkaSpout3.kafkaSpoutConfig;
        int int15 = strKafkaSpout3.maxRetries;
        boolean boolean16 = strKafkaSpout3.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder17 = strKafkaSpout3.tuplesBuilder;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord18 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>> iSpoutConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) 0, (long) 10, (org.apache.storm.spout.ISpout) strKafkaSpout3, charSequenceConsumerRecord18);
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder20 = strKafkaSpout3.tuplesBuilder;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer21 = null;
        strKafkaSpout3.kafkaConsumer = strKafkaConsumer21;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder23 = null;
        strKafkaSpout3.tuplesBuilder = strKafkaSpoutTuplesBuilder23;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector25 = null;
        strKafkaSpout3.collector = spoutOutputCollector25;
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig14);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + boolean16 + "' != '" + false + "'", boolean16 == false);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder17);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder20);
    }

    @Test
    public void test6966() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6966");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        int int7 = charSequenceConsumerRecord5.partition();
        int int8 = charSequenceConsumerRecord5.serializedKeySize();
        int int9 = charSequenceConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.header.Headers headers10 = charSequenceConsumerRecord5.headers();
        java.lang.String str11 = charSequenceConsumerRecord5.value();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test6967() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6967");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.reflect.Type, java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> typeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> typeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>(typeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test6968() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6968");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService1 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService1;
        long long3 = strKafkaSpout0.numUncommittedOffsets;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = strKafkaSpout0.waitingToEmit;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = strKafkaSpout0.emitted;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy8 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy8;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder10 = strKafkaSpout0.tuplesBuilder;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.emit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long3 + "' != '" + 0L + "'", long3 == 0L);
        org.junit.Assert.assertNull(strConsumerRecordItor4);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet5);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder10);
    }

    @Test
    public void test6969() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6969");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) 100, 1L, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=[]}");
        org.apache.kafka.common.record.TimestampType timestampType6 = charSequenceConsumerRecord5.timestampType();
        java.lang.String str7 = charSequenceConsumerRecord5.topic();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test6970() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6970");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        int int19 = charSequenceConsumerRecord10.partition();
        long long20 = charSequenceConsumerRecord10.checksum();
        org.apache.kafka.common.header.Headers headers21 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
        org.junit.Assert.assertNotNull(headers21);
    }

    @Test
    public void test6971() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6971");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        strKafkaSpout0.maxRetries = (short) 1;
        boolean boolean10 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition11 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection12 = strKafkaSpout0.toArrayList(topicPartition11);
        int int13 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService14 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService14;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection12);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 1 + "'", int13 == 1);
    }

    @Test
    public void test6972() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6972");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.numUncommittedOffsets = (byte) 1;
        strKafkaSpout0.initialized = false;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet14 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService15 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService15;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder17 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder17;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy19 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy19;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str21 = strKafkaSpout0.getNamedTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet14);
    }

    @Test
    public void test6973() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6973");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams6 = strKafkaSpout0.kafkaSpoutStreams;
        boolean boolean7 = strKafkaSpout0.waitingToEmit();
        int int8 = strKafkaSpout0.maxRetries;
        boolean boolean9 = strKafkaSpout0.initialized;
        long long10 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig11;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + 0 + "'", int3 == 0);
        org.junit.Assert.assertNull(kafkaSpoutStreams6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 0 + "'", int8 == 0);
        org.junit.Assert.assertTrue("'" + boolean9 + "' != '" + false + "'", boolean9 == false);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 0L + "'", long10 == 0L);
    }

    @Test
    public void test6974() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6974");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        java.lang.String str8 = strKafkaSpout0.toString();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor9 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams12;
        boolean boolean14 = strKafkaSpout0.consumerAutoCommitMode;
        java.lang.String str15 = strKafkaSpout0.toString();
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer16;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strConsumerRecordItor9);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + true + "'", boolean14 == true);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test6975() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6975");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout3 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout3.maxRetries = (byte) -1;
        int int6 = strKafkaSpout3.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout3.waitingToEmit = strConsumerRecordItor7;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig9 = null;
        strKafkaSpout3.kafkaSpoutConfig = strKafkaSpoutConfig9;
        int int11 = strKafkaSpout3.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy12 = null;
        strKafkaSpout3.firstPollOffsetStrategy = firstPollOffsetStrategy12;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig14 = strKafkaSpout3.kafkaSpoutConfig;
        int int15 = strKafkaSpout3.maxRetries;
        boolean boolean16 = strKafkaSpout3.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder17 = strKafkaSpout3.tuplesBuilder;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord18 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>> iSpoutConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) 0, (long) 10, (org.apache.storm.spout.ISpout) strKafkaSpout3, charSequenceConsumerRecord18);
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder20 = strKafkaSpout3.tuplesBuilder;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer21 = null;
        strKafkaSpout3.kafkaConsumer = strKafkaConsumer21;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams23 = null;
        strKafkaSpout3.kafkaSpoutStreams = kafkaSpoutStreams23;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService25 = strKafkaSpout3.retryService;
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig14);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + boolean16 + "' != '" + false + "'", boolean16 == false);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder17);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder20);
        org.junit.Assert.assertNull(kafkaSpoutRetryService25);
    }

    @Test
    public void test6976() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6976");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator1 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator2 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator2;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator4 = offsetComparator2.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator5 = offsetComparator1.thenComparing(kafkaSpoutMessageIdComparator4);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator6 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator6;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator8 = offsetComparator6.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator9 = offsetComparator6.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator4.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator6);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = offsetComparator0.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator6);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = kafkaSpoutMessageIdComparator11.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator14 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator14;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator14.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator21 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator21;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator21);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator16.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator21);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator13.thenComparing(kafkaSpoutMessageIdComparator24);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator13.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = kafkaSpoutMessageIdComparator12.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator13);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = offsetComparator13.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator4);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator5);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator8);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator9);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
    }

    @Test
    public void test6977() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6977");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = strKafkaSpout0.kafkaConsumer;
        java.lang.String str8 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = strKafkaSpout0.tuplesBuilder;
        long long14 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams15 = strKafkaSpout0.kafkaSpoutStreams;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertNull(strKafkaConsumer7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder13);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutStreams15);
    }

    @Test
    public void test6978() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6978");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (-1), (long) ' ', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.timestamp();
        java.lang.String str7 = charSequenceConsumerRecord5.topic();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        long long9 = charSequenceConsumerRecord5.checksum();
        org.apache.kafka.common.record.TimestampType timestampType10 = charSequenceConsumerRecord5.timestampType();
        long long11 = charSequenceConsumerRecord5.offset();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord5.timestampType();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "hi!" + "'", str7, "hi!");
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType10 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType10.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 32L + "'", long11 == 32L);
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test6979() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6979");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy6 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig7 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig7;
        org.apache.kafka.common.record.TimestampType timestampType13 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType13, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int20 = charSequenceConsumerRecord19.serializedValueSize();
        java.lang.CharSequence charSequence21 = charSequenceConsumerRecord19.key();
        org.apache.kafka.common.header.Headers headers22 = charSequenceConsumerRecord19.headers();
        int int23 = charSequenceConsumerRecord19.partition();
        java.lang.CharSequence charSequence24 = charSequenceConsumerRecord19.key();
        int int25 = charSequenceConsumerRecord19.serializedValueSize();
        int int26 = charSequenceConsumerRecord19.serializedValueSize();
        java.lang.String str27 = charSequenceConsumerRecord19.topic();
        int int28 = charSequenceConsumerRecord19.serializedValueSize();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.ack((java.lang.Object) int28);
            org.junit.Assert.fail("Expected exception of type java.lang.ClassCastException; message: java.lang.Integer cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId");
        } catch (java.lang.ClassCastException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(firstPollOffsetStrategy6);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + (-1) + "'", int20 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence21 + "' != '" + "" + "'", charSequence21, "");
        org.junit.Assert.assertNotNull(headers22);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 10 + "'", int23 == 10);
        org.junit.Assert.assertEquals("'" + charSequence24 + "' != '" + "" + "'", charSequence24, "");
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + (-1) + "'", int25 == (-1));
        org.junit.Assert.assertTrue("'" + int26 + "' != '" + (-1) + "'", int26 == (-1));
        org.junit.Assert.assertEquals("'" + str27 + "' != '" + "" + "'", str27, "");
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + (-1) + "'", int28 == (-1));
    }

    @Test
    public void test6980() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6980");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.timestamp();
        long long16 = charSequenceConsumerRecord10.offset();
        long long17 = charSequenceConsumerRecord10.offset();
        int int18 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        int int20 = charSequenceConsumerRecord10.serializedKeySize();
        int int21 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence22 = charSequenceConsumerRecord10.key();
        java.lang.String str23 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 52 + "'", int18 == 52);
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 52 + "'", int20 == 52);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 10 + "'", int21 == 10);
        org.junit.Assert.assertEquals("'" + charSequence22 + "' != '" + "" + "'", charSequence22, "");
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "" + "'", str23, "");
    }

    @Test
    public void test6981() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6981");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer1 = strKafkaSpout0.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector2 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService3 = strKafkaSpout0.retryService;
        strKafkaSpout0.numUncommittedOffsets = 0;
        int int6 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig7 = strKafkaSpout0.kafkaSpoutConfig;
        org.junit.Assert.assertNull(timer1);
        org.junit.Assert.assertNull(spoutOutputCollector2);
        org.junit.Assert.assertNull(kafkaSpoutRetryService3);
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + 0 + "'", int6 == 0);
        org.junit.Assert.assertNull(strKafkaSpoutConfig7);
    }

    @Test
    public void test6982() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6982");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        org.apache.kafka.common.TopicPartition topicPartition3 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection4 = strKafkaSpout0.toArrayList(topicPartition3);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService5 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService5;
        strKafkaSpout0.numUncommittedOffsets = ' ';
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig9 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig9;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams11 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams11;
        org.junit.Assert.assertNotNull(topicPartitionCollection4);
    }

    @Test
    public void test6983() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6983");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        long long19 = charSequenceConsumerRecord10.offset();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        long long21 = charSequenceConsumerRecord10.offset();
        org.apache.kafka.common.record.TimestampType timestampType22 = charSequenceConsumerRecord10.timestampType();
        org.apache.kafka.common.header.Headers headers23 = charSequenceConsumerRecord10.headers();
        int int24 = charSequenceConsumerRecord10.partition();
        long long25 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 0L + "'", long21 == 0L);
        org.junit.Assert.assertNull(timestampType22);
        org.junit.Assert.assertNotNull(headers23);
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + 10 + "'", int24 == 10);
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + (-1L) + "'", long25 == (-1L));
    }

    @Test
    public void test6984() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6984");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = offsetComparator11.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator7.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator11);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = kafkaSpoutMessageIdComparator15.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = kafkaSpoutMessageIdComparator15.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = kafkaSpoutMessageIdComparator17.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = kafkaSpoutMessageIdComparator17.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
    }

    @Test
    public void test6985() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6985");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        boolean boolean4 = strKafkaSpout0.waitingToEmit();
        strKafkaSpout0.initialized = false;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy7;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = null;
        strKafkaSpout0.collector = spoutOutputCollector9;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
    }

    @Test
    public void test6986() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6986");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig8 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder9;
        int int11 = strKafkaSpout0.maxRetries;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(strKafkaSpoutConfig8);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 0 + "'", int11 == 0);
    }

    @Test
    public void test6987() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6987");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.reflect.AnnotatedElement> kafkaSpoutMessageIdCollectionKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.reflect.AnnotatedElement> kafkaSpoutMessageIdCollectionKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.reflect.AnnotatedElement>(kafkaSpoutMessageIdCollectionKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test6988() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6988");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        strKafkaSpout0.maxRetries = (short) 0;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        strKafkaSpout0.numUncommittedOffsets = (byte) 10;
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
    }

    @Test
    public void test6989() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6989");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        long long8 = strKafkaSpout0.numUncommittedOffsets;
        boolean boolean9 = strKafkaSpout0.initialized;
        boolean boolean10 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer11 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder12 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder12;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 0L + "'", long8 == 0L);
        org.junit.Assert.assertTrue("'" + boolean9 + "' != '" + false + "'", boolean9 == false);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNull(timer11);
    }

    @Test
    public void test6990() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6990");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        boolean boolean6 = strKafkaSpout0.waitingToEmit();
        org.apache.kafka.common.TopicPartition topicPartition7 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection8 = strKafkaSpout0.toArrayList(topicPartition7);
        boolean boolean9 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams10;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams12;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor14 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor14;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy16 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy16;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection8);
        org.junit.Assert.assertTrue("'" + boolean9 + "' != '" + false + "'", boolean9 == false);
    }

    @Test
    public void test6991() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6991");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType4, (long) (short) -1, (int) (byte) 1, (int) (short) -1, (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long11 = charSequenceConsumerRecord10.offset();
        long long12 = charSequenceConsumerRecord10.timestamp();
        long long13 = charSequenceConsumerRecord10.offset();
        long long14 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str15 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 1L + "'", long11 == 1L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 0L + "'", long12 == 0L);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 1L + "'", long13 == 1L);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
    }

    @Test
    public void test6992() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6992");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.toString();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.serializedValueSize();
        int int18 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str15, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + (-1) + "'", int17 == (-1));
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + (-1) + "'", int18 == (-1));
    }

    @Test
    public void test6993() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6993");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor6 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor6;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder9;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
// flaky:             org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
    }

    @Test
    public void test6994() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6994");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator1 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator1;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator3 = offsetComparator1.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator4 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator3);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator5 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator5;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator5.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator12 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator12;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = kafkaSpoutMessageIdComparator7.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = kafkaSpoutMessageIdComparator7.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = kafkaSpoutMessageIdComparator4.thenComparing(kafkaSpoutMessageIdComparator16);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = kafkaSpoutMessageIdComparator16.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator19 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator19;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = offsetComparator19.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator26 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator26);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = kafkaSpoutMessageIdComparator21.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator26);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator30 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator30;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = offsetComparator30.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator33 = offsetComparator30.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator26.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator30);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = kafkaSpoutMessageIdComparator34.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = kafkaSpoutMessageIdComparator34.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = kafkaSpoutMessageIdComparator16.thenComparing(kafkaSpoutMessageIdComparator34);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator37;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator3);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator4);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator33);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
    }

    @Test
    public void test6995() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6995");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        long long16 = charSequenceConsumerRecord10.offset();
        java.lang.CharSequence charSequence17 = charSequenceConsumerRecord10.key();
        java.util.Optional<java.lang.Integer> intOptional18 = charSequenceConsumerRecord10.leaderEpoch();
        long long19 = charSequenceConsumerRecord10.checksum();
        java.lang.String str20 = charSequenceConsumerRecord10.topic();
        java.lang.String str21 = charSequenceConsumerRecord10.toString();
        org.apache.kafka.common.header.Headers headers22 = charSequenceConsumerRecord10.headers();
        java.lang.CharSequence charSequence23 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertEquals("'" + charSequence17 + "' != '" + "" + "'", charSequence17, "");
        org.junit.Assert.assertNotNull(intOptional18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "" + "'", str20, "");
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str21, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers22);
        org.junit.Assert.assertEquals("'" + charSequence23 + "' != '" + "" + "'", charSequence23, "");
    }

    @Test
    public void test6996() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6996");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = kafkaSpoutMessageIdComparator13.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = kafkaSpoutMessageIdComparator2.thenComparing(kafkaSpoutMessageIdComparator21);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator23;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator23.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator23.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = kafkaSpoutMessageIdComparator21.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator23);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator28 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator28;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = offsetComparator28.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator28;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator32 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator32;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator32.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = offsetComparator28.thenComparing(kafkaSpoutMessageIdComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = kafkaSpoutMessageIdComparator34.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = kafkaSpoutMessageIdComparator21.thenComparing(kafkaSpoutMessageIdComparator34);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator38 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator39 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator39;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = offsetComparator39.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator42 = offsetComparator38.thenComparing(kafkaSpoutMessageIdComparator41);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator43 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator43;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator45 = offsetComparator43.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator50 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator50;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator50);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator53 = kafkaSpoutMessageIdComparator45.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator50);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator54 = kafkaSpoutMessageIdComparator45.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator55 = kafkaSpoutMessageIdComparator42.thenComparing(kafkaSpoutMessageIdComparator54);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator56 = kafkaSpoutMessageIdComparator21.thenComparing(kafkaSpoutMessageIdComparator55);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator57 = kafkaSpoutMessageIdComparator21.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator42);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator53);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator54);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator56);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator57);
    }

    @Test
    public void test6997() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6997");
        org.apache.kafka.common.record.TimestampType timestampType8 = null;
        org.apache.kafka.common.record.TimestampType timestampType18 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord24 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType18, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int25 = charSequenceConsumerRecord24.serializedValueSize();
        java.lang.CharSequence charSequence26 = charSequenceConsumerRecord24.key();
        org.apache.kafka.common.header.Headers headers27 = charSequenceConsumerRecord24.headers();
        java.util.Optional<java.lang.Integer> intOptional28 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType8, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers27, intOptional28);
        java.lang.String str30 = charSequenceConsumerRecord29.value();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) 1, (long) 10, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", charSequenceConsumerRecord29);
        int int32 = charSequenceConsumerRecord29.serializedValueSize();
        int int33 = charSequenceConsumerRecord29.serializedKeySize();
        java.lang.String str34 = charSequenceConsumerRecord29.topic();
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + (-1) + "'", int25 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence26 + "' != '" + "" + "'", charSequence26, "");
        org.junit.Assert.assertNotNull(headers27);
        org.junit.Assert.assertEquals("'" + str30 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str30, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int32 + "' != '" + 0 + "'", int32 == 0);
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + 1 + "'", int33 == 1);
        org.junit.Assert.assertEquals("'" + str34 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str34, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test6998() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6998");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        boolean boolean7 = strKafkaSpout0.initialized;
        strKafkaSpout0.consumerAutoCommitMode = true;
        boolean boolean10 = strKafkaSpout0.commit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor11 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer12 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector14 = null;
        strKafkaSpout0.collector = spoutOutputCollector14;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer16;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Map<java.lang.String, java.lang.Object> strMap18 = strKafkaSpout0.getComponentConfiguration();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor11);
        org.junit.Assert.assertNull(timer12);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder13);
    }

    @Test
    public void test6999() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test6999");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        int int9 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.maxRetries = (byte) 100;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService12 = strKafkaSpout0.retryService;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService12);
    }

    @Test
    public void test7000() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest13.test7000");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional12 = charSequenceConsumerRecord10.leaderEpoch();
        long long13 = charSequenceConsumerRecord10.offset();
        long long14 = charSequenceConsumerRecord10.checksum();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertNotNull(headers16);
    }
}
