import org.junit.FixMethodOrder;
import org.junit.Test;
import org.junit.runners.MethodSorters;

@FixMethodOrder(MethodSorters.NAME_ASCENDING)
public class RegressionTest14 {

    public static boolean debug = false;

    @Test
    public void test7001() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7001");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        int int19 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.header.Headers headers20 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType21 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str22 = charSequenceConsumerRecord10.toString();
        org.apache.kafka.common.header.Headers headers23 = charSequenceConsumerRecord10.headers();
        java.util.Optional<java.lang.Integer> intOptional24 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertNull(timestampType21);
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str22, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers23);
        org.junit.Assert.assertNotNull(intOptional24);
    }

    @Test
    public void test7002() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7002");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition8 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection9 = strKafkaSpout0.toArrayList(topicPartition8);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = strKafkaSpout0.retryService;
        boolean boolean11 = strKafkaSpout0.initialized;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor12 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor12;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.activate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection9);
        org.junit.Assert.assertNull(kafkaSpoutRetryService10);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
    }

    @Test
    public void test7003() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7003");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector3 = null;
        strKafkaSpout0.collector = spoutOutputCollector3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService6;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType12, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long19 = charSequenceConsumerRecord18.checksum();
        int int20 = charSequenceConsumerRecord18.partition();
        long long21 = charSequenceConsumerRecord18.timestamp();
        long long22 = charSequenceConsumerRecord18.offset();
        int int23 = charSequenceConsumerRecord18.serializedKeySize();
        java.lang.CharSequence charSequence24 = charSequenceConsumerRecord18.key();
        java.lang.String str25 = charSequenceConsumerRecord18.value();
        java.lang.String str26 = charSequenceConsumerRecord18.toString();
        java.lang.String str27 = charSequenceConsumerRecord18.value();
        long long28 = charSequenceConsumerRecord18.offset();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.fail((java.lang.Object) long28);
            org.junit.Assert.fail("Expected exception of type java.lang.ClassCastException; message: java.lang.Long cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId");
        } catch (java.lang.ClassCastException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(strKafkaSpoutConfig5);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 10 + "'", int20 == 10);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 0L + "'", long22 == 0L);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 52 + "'", int23 == 52);
        org.junit.Assert.assertEquals("'" + charSequence24 + "' != '" + "" + "'", charSequence24, "");
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "hi!" + "'", str25, "hi!");
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str26, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str27 + "' != '" + "hi!" + "'", str27, "hi!");
        org.junit.Assert.assertTrue("'" + long28 + "' != '" + 0L + "'", long28 == 0L);
    }

    @Test
    public void test7004() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7004");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=[]}", (int) (byte) -1, (long) '4', (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "hi!");
        java.lang.String str6 = charSequenceConsumerRecord5.topic();
        int int7 = charSequenceConsumerRecord5.serializedKeySize();
        long long8 = charSequenceConsumerRecord5.offset();
        long long9 = charSequenceConsumerRecord5.checksum();
        long long10 = charSequenceConsumerRecord5.offset();
        int int11 = charSequenceConsumerRecord5.serializedValueSize();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "KafkaSpout{acked=null, emitted=[]}" + "'", str6, "KafkaSpout{acked=null, emitted=[]}");
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 52L + "'", long8 == 52L);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 52L + "'", long10 == 52L);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
    }

    @Test
    public void test7005() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7005");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        long long19 = charSequenceConsumerRecord10.offset();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        long long21 = charSequenceConsumerRecord10.offset();
        long long22 = charSequenceConsumerRecord10.timestamp();
        java.lang.CharSequence charSequence23 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 0L + "'", long21 == 0L);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence23 + "' != '" + "" + "'", charSequence23, "");
    }

    @Test
    public void test7006() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7006");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig12 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig12;
        strKafkaSpout0.maxRetries = (byte) 100;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig16 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig16;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
    }

    @Test
    public void test7007() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7007");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams2 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig3 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig3;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer5 = strKafkaSpout0.kafkaConsumer;
        strKafkaSpout0.maxRetries = (short) 1;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy8 = strKafkaSpout0.firstPollOffsetStrategy;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(kafkaSpoutStreams2);
        org.junit.Assert.assertNull(strKafkaConsumer5);
        org.junit.Assert.assertNull(firstPollOffsetStrategy8);
    }

    @Test
    public void test7008() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7008");
        java.lang.CharSequence charSequence3 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) ' ', (long) (byte) -1, charSequence3, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)");
        java.lang.String str6 = charSequenceConsumerRecord5.value();
        long long7 = charSequenceConsumerRecord5.checksum();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)" + "'", str6, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)");
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
    }

    @Test
    public void test7009() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7009");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType31 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType31, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long38 = charSequenceConsumerRecord37.checksum();
        int int39 = charSequenceConsumerRecord37.partition();
        java.lang.String str40 = charSequenceConsumerRecord37.value();
        int int41 = charSequenceConsumerRecord37.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional42 = charSequenceConsumerRecord37.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout43 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet44 = strKafkaSpout43.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor45 = null;
        strKafkaSpout43.waitingToEmit = strConsumerRecordItor45;
        boolean boolean47 = strKafkaSpout43.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig48 = null;
        strKafkaSpout43.kafkaSpoutConfig = strKafkaSpoutConfig48;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy50 = strKafkaSpout43.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType23, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord37, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout43);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout55 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout55.maxRetries = (byte) -1;
        int int58 = strKafkaSpout55.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor59 = null;
        strKafkaSpout55.waitingToEmit = strConsumerRecordItor59;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer61 = strKafkaSpout55.commitTimer;
        boolean boolean62 = strKafkaSpout55.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService63 = null;
        strKafkaSpout55.retryService = kafkaSpoutRetryService63;
        java.lang.Object obj65 = null;
        org.apache.kafka.common.record.TimestampType timestampType70 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType70, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long77 = charSequenceConsumerRecord76.checksum();
        int int78 = charSequenceConsumerRecord76.partition();
        long long79 = charSequenceConsumerRecord76.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType80 = charSequenceConsumerRecord76.timestampType();
        int int81 = charSequenceConsumerRecord76.serializedKeySize();
        org.apache.kafka.common.header.Headers headers82 = charSequenceConsumerRecord76.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Object> objConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Object>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (byte) 100, (long) (short) 10, (long) ' ', timestampType23, (java.lang.Long) (-1L), 97, (int) (byte) 1, (java.lang.Object) kafkaSpoutRetryService63, obj65, headers82);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord89 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", (int) (short) 10, (long) 0, (long) (byte) 0, timestampType23, (long) 1, 35, 0, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        java.lang.String str90 = charSequenceConsumerRecord89.value();
        org.apache.kafka.common.record.TimestampType timestampType91 = charSequenceConsumerRecord89.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord97 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = 97, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = )", (int) (short) 10, 0L, (long) (byte) 100, timestampType91, 10L, (int) (short) -1, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 0, NoTimestampType = 0, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = )", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + (-1L) + "'", long38 == (-1L));
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + 10 + "'", int39 == 10);
        org.junit.Assert.assertEquals("'" + str40 + "' != '" + "hi!" + "'", str40, "hi!");
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + 52 + "'", int41 == 52);
        org.junit.Assert.assertNotNull(intOptional42);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet44);
        org.junit.Assert.assertTrue("'" + boolean47 + "' != '" + false + "'", boolean47 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy50);
        org.junit.Assert.assertTrue("'" + int58 + "' != '" + (-1) + "'", int58 == (-1));
        org.junit.Assert.assertNull(timer61);
        org.junit.Assert.assertTrue("'" + boolean62 + "' != '" + false + "'", boolean62 == false);
        org.junit.Assert.assertTrue("'" + long77 + "' != '" + (-1L) + "'", long77 == (-1L));
        org.junit.Assert.assertTrue("'" + int78 + "' != '" + 10 + "'", int78 == 10);
        org.junit.Assert.assertTrue("'" + long79 + "' != '" + (-1L) + "'", long79 == (-1L));
        org.junit.Assert.assertNull(timestampType80);
        org.junit.Assert.assertTrue("'" + int81 + "' != '" + 52 + "'", int81 == 52);
        org.junit.Assert.assertNotNull(headers82);
        org.junit.Assert.assertEquals("'" + str90 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str90, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + timestampType91 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType91.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test7010() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7010");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        int int3 = strKafkaSpout0.maxRetries;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + 0 + "'", int3 == 0);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
    }

    @Test
    public void test7011() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7011");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 1, 1L, (long) (byte) 10, timestampType4, (long) '#', (int) (byte) 100, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        java.lang.String str11 = charSequenceConsumerRecord10.value();
        java.lang.String str12 = charSequenceConsumerRecord10.topic();
        int int13 = charSequenceConsumerRecord10.partition();
        java.lang.String str14 = charSequenceConsumerRecord10.topic();
        java.util.Optional<java.lang.Integer> intOptional15 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str12, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 1 + "'", int13 == 1);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(intOptional15);
    }

    @Test
    public void test7012() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7012");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        java.lang.String str4 = strKafkaSpout0.toString();
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer7;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer11 = strKafkaSpout0.commitTimer;
        boolean boolean12 = strKafkaSpout0.initialized;
        boolean boolean13 = strKafkaSpout0.commit();
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertEquals("'" + str4 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str4, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(firstPollOffsetStrategy9);
        org.junit.Assert.assertNull(kafkaSpoutRetryService10);
        org.junit.Assert.assertNull(timer11);
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + false + "'", boolean12 == false);
        org.junit.Assert.assertTrue("'" + boolean13 + "' != '" + false + "'", boolean13 == false);
    }

    @Test
    public void test7013() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7013");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService8;
        long long10 = strKafkaSpout0.numUncommittedOffsets;
        strKafkaSpout0.initialized = false;
        int int13 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.maxRetries = (short) 10;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.emit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 0L + "'", long10 == 0L);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
    }

    @Test
    public void test7014() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7014");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = kafkaSpoutMessageIdComparator13.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = kafkaSpoutMessageIdComparator2.thenComparing(kafkaSpoutMessageIdComparator21);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = kafkaSpoutMessageIdComparator21.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator23;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
    }

    @Test
    public void test7015() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7015");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition8 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection9 = strKafkaSpout0.toArrayList(topicPartition8);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer10;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor12 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor12;
        boolean boolean14 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy15 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig16 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig16;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor18 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig19 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig19;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams21 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams21;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection9);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy15);
        org.junit.Assert.assertNull(strConsumerRecordItor18);
    }

    @Test
    public void test7016() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7016");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = offsetComparator7.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator7.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator13.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator20 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator20;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = kafkaSpoutMessageIdComparator15.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator15.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator7.thenComparing(kafkaSpoutMessageIdComparator24);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = offsetComparator7.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = kafkaSpoutMessageIdComparator27.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator28;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
    }

    @Test
    public void test7017() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7017");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        java.lang.String str12 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.serializedValueSize();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        int int16 = charSequenceConsumerRecord10.partition();
        java.util.Optional<java.lang.Integer> intOptional17 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertNotNull(intOptional17);
    }

    @Test
    public void test7018() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7018");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.AbstractList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.reflect.AnnotatedElement> kafkaSpoutMessageIdListKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.AbstractList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.reflect.AnnotatedElement> kafkaSpoutMessageIdListKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.AbstractList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.reflect.AnnotatedElement>(kafkaSpoutMessageIdListKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test7019() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7019");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator1 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator1;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator3 = offsetComparator1.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator8 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator8;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator8);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = kafkaSpoutMessageIdComparator3.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator8);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator11);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = kafkaSpoutMessageIdComparator11.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator14 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator14;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator14.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator14;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = offsetComparator18.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = offsetComparator14.thenComparing(kafkaSpoutMessageIdComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = offsetComparator14.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = kafkaSpoutMessageIdComparator13.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator14);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator14;
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator14;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator3);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
    }

    @Test
    public void test7020() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7020");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str18 = charSequenceConsumerRecord10.topic();
        long long19 = charSequenceConsumerRecord10.timestamp();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
    }

    @Test
    public void test7021() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7021");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        java.lang.String str12 = strKafkaSpout0.toString();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str12, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test7022() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7022");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        strKafkaSpout0.maxRetries = (short) 100;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService11 = strKafkaSpout0.retryService;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(kafkaSpoutRetryService11);
    }

    @Test
    public void test7023() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7023");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long14 = charSequenceConsumerRecord13.checksum();
        long long15 = charSequenceConsumerRecord13.timestamp();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord13.headers();
        java.lang.String str17 = charSequenceConsumerRecord13.toString();
        org.apache.kafka.common.header.Headers headers18 = charSequenceConsumerRecord13.headers();
        java.lang.String str19 = charSequenceConsumerRecord13.topic();
        long long20 = charSequenceConsumerRecord13.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType21 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType22 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, null = 1, serialized key size = 32, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", 0, (long) (byte) 0, 0L, timestampType22, (long) 100, 97, (int) '#', (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)", "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        java.lang.CharSequence charSequence29 = charSequenceConsumerRecord28.key();
        long long30 = charSequenceConsumerRecord28.checksum();
        long long31 = charSequenceConsumerRecord28.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType32 = charSequenceConsumerRecord28.timestampType();
        org.apache.kafka.common.header.Headers headers38 = null;
        org.apache.kafka.common.record.TimestampType timestampType43 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType43, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long50 = charSequenceConsumerRecord49.checksum();
        int int51 = charSequenceConsumerRecord49.partition();
        long long52 = charSequenceConsumerRecord49.timestamp();
        long long53 = charSequenceConsumerRecord49.offset();
        int int54 = charSequenceConsumerRecord49.partition();
        java.lang.CharSequence charSequence55 = charSequenceConsumerRecord49.key();
        org.apache.kafka.common.record.TimestampType timestampType56 = charSequenceConsumerRecord49.timestampType();
        long long57 = charSequenceConsumerRecord49.checksum();
        java.util.Optional<java.lang.Integer> intOptional58 = charSequenceConsumerRecord49.leaderEpoch();
        int int59 = charSequenceConsumerRecord49.partition();
        java.util.Optional<java.lang.Integer> intOptional60 = charSequenceConsumerRecord49.leaderEpoch();
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 0, null = 97, serialized key size = 32, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (byte) 0, (long) ' ', (long) 10, timestampType32, (java.lang.Long) 0L, 0, 100, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]}), value = ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null}))", headers38, intOptional60);
            org.junit.Assert.fail("Expected exception of type java.lang.IllegalArgumentException; message: Headers cannot be null");
        } catch (java.lang.IllegalArgumentException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str17, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "" + "'", str19, "");
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType21 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType21.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + timestampType22 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType22.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + charSequence29 + "' != '" + "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)" + "'", charSequence29, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)");
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + 100L + "'", long30 == 100L);
        org.junit.Assert.assertTrue("'" + long31 + "' != '" + 0L + "'", long31 == 0L);
        org.junit.Assert.assertTrue("'" + timestampType32 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType32.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long50 + "' != '" + (-1L) + "'", long50 == (-1L));
        org.junit.Assert.assertTrue("'" + int51 + "' != '" + 10 + "'", int51 == 10);
        org.junit.Assert.assertTrue("'" + long52 + "' != '" + (-1L) + "'", long52 == (-1L));
        org.junit.Assert.assertTrue("'" + long53 + "' != '" + 0L + "'", long53 == 0L);
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + 10 + "'", int54 == 10);
        org.junit.Assert.assertEquals("'" + charSequence55 + "' != '" + "" + "'", charSequence55, "");
        org.junit.Assert.assertNull(timestampType56);
        org.junit.Assert.assertTrue("'" + long57 + "' != '" + (-1L) + "'", long57 == (-1L));
        org.junit.Assert.assertNotNull(intOptional58);
        org.junit.Assert.assertTrue("'" + int59 + "' != '" + 10 + "'", int59 == 10);
        org.junit.Assert.assertNotNull(intOptional60);
    }

    @Test
    public void test7024() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7024");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy6 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy6;
        java.lang.String str8 = strKafkaSpout0.toString();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.commitOffsetsForAckedTuples();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test7025() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7025");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = strKafkaSpout0.firstPollOffsetStrategy;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer9 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer9;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords11 = strKafkaSpout0.pollKafkaBroker();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 0 + "'", int8 == 0);
    }

    @Test
    public void test7026() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7026");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator1 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator1;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator3 = offsetComparator1.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator8 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator8;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator8);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = kafkaSpoutMessageIdComparator3.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator8);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator11);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator13.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator20 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator20;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = kafkaSpoutMessageIdComparator15.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator20);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator24 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator24;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator24.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator31 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator31;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = kafkaSpoutMessageIdComparator26.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = kafkaSpoutMessageIdComparator15.thenComparing(kafkaSpoutMessageIdComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = kafkaSpoutMessageIdComparator12.thenComparing(kafkaSpoutMessageIdComparator35);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = kafkaSpoutMessageIdComparator35.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator37;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator3);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
    }

    @Test
    public void test7027() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7027");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy11 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder12 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig13 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig13;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertNull(firstPollOffsetStrategy11);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder12);
    }

    @Test
    public void test7028() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7028");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout19 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout19.maxRetries = (byte) -1;
        int int22 = strKafkaSpout19.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor23 = null;
        strKafkaSpout19.waitingToEmit = strConsumerRecordItor23;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer25 = strKafkaSpout19.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer26 = strKafkaSpout19.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType32, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long39 = charSequenceConsumerRecord38.offset();
        long long40 = charSequenceConsumerRecord38.checksum();
        int int41 = charSequenceConsumerRecord38.serializedKeySize();
        org.apache.kafka.common.header.Headers headers42 = charSequenceConsumerRecord38.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType15, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout19, (java.lang.CharSequence) "hi!", headers42);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.common.record.TimestampType timestampType63 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType63, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int70 = charSequenceConsumerRecord69.serializedValueSize();
        java.lang.CharSequence charSequence71 = charSequenceConsumerRecord69.key();
        org.apache.kafka.common.header.Headers headers72 = charSequenceConsumerRecord69.headers();
        java.util.Optional<java.lang.Integer> intOptional73 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType53, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers72, intOptional73);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (byte) -1, (-1L), (long) (short) 10, timestampType15, (java.lang.Long) 0L, (int) (short) 1, 97, (java.lang.CharSequence) "", "KafkaSpout{acked=null, emitted=null}", headers72);
        int int76 = charSequenceConsumerRecord75.serializedValueSize();
        java.lang.String str77 = charSequenceConsumerRecord75.toString();
        long long78 = charSequenceConsumerRecord75.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType79 = charSequenceConsumerRecord75.timestampType();
        java.lang.String str80 = charSequenceConsumerRecord75.value();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertNull(timer25);
        org.junit.Assert.assertNull(strKafkaConsumer26);
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + 0L + "'", long39 == 0L);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + 52 + "'", int41 == 52);
        org.junit.Assert.assertNotNull(headers42);
        org.junit.Assert.assertTrue("'" + int70 + "' != '" + (-1) + "'", int70 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence71 + "' != '" + "" + "'", charSequence71, "");
        org.junit.Assert.assertNotNull(headers72);
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + 97 + "'", int76 == 97);
        org.junit.Assert.assertEquals("'" + str77 + "' != '" + "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})" + "'", str77, "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
        org.junit.Assert.assertTrue("'" + long78 + "' != '" + 10L + "'", long78 == 10L);
        org.junit.Assert.assertTrue("'" + timestampType79 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType79.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str80, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test7029() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7029");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", 1, (long) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        int int6 = charSequenceConsumerRecord5.serializedValueSize();
        long long7 = charSequenceConsumerRecord5.timestamp();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
    }

    @Test
    public void test7030() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7030");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (-1), (long) ' ', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.util.Optional<java.lang.Integer> intOptional6 = charSequenceConsumerRecord5.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional7 = charSequenceConsumerRecord5.leaderEpoch();
        java.lang.String str8 = charSequenceConsumerRecord5.value();
        long long9 = charSequenceConsumerRecord5.timestamp();
        int int10 = charSequenceConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertNotNull(intOptional6);
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str8, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
    }

    @Test
    public void test7031() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7031");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator2 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator3 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator3;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator5 = offsetComparator3.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator6 = offsetComparator2.thenComparing(kafkaSpoutMessageIdComparator5);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator6);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator8 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator9 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator9;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = offsetComparator9.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator9.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator9;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = offsetComparator9.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = kafkaSpoutMessageIdComparator8.thenComparing(kafkaSpoutMessageIdComparator14);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = kafkaSpoutMessageIdComparator8.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator5);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator6);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator8);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
    }

    @Test
    public void test7032() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7032");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        boolean boolean12 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy13 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy13;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor15 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder16 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder16;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.deactivate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + false + "'", boolean12 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor15);
    }

    @Test
    public void test7033() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7033");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        int int13 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        int int15 = charSequenceConsumerRecord10.serializedValueSize();
        int int16 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 52 + "'", int13 == 52);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 52 + "'", int16 == 52);
    }

    @Test
    public void test7034() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7034");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        int int19 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.header.Headers headers20 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType21 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str22 = charSequenceConsumerRecord10.value();
        int int23 = charSequenceConsumerRecord10.serializedKeySize();
        int int24 = charSequenceConsumerRecord10.serializedValueSize();
        int int25 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.String str26 = charSequenceConsumerRecord10.toString();
        java.lang.String str27 = charSequenceConsumerRecord10.value();
        long long28 = charSequenceConsumerRecord10.offset();
        java.lang.String str29 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertNull(timestampType21);
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "hi!" + "'", str22, "hi!");
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 52 + "'", int23 == 52);
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + (-1) + "'", int25 == (-1));
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str26, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str27 + "' != '" + "hi!" + "'", str27, "hi!");
        org.junit.Assert.assertTrue("'" + long28 + "' != '" + 0L + "'", long28 == 0L);
        org.junit.Assert.assertEquals("'" + str29 + "' != '" + "" + "'", str29, "");
    }

    @Test
    public void test7035() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7035");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str18 = charSequenceConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = charSequenceConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long34 = charSequenceConsumerRecord33.checksum();
        int int35 = charSequenceConsumerRecord33.partition();
        java.lang.String str36 = charSequenceConsumerRecord33.value();
        int int37 = charSequenceConsumerRecord33.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional38 = charSequenceConsumerRecord33.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout39 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet40 = strKafkaSpout39.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor41 = null;
        strKafkaSpout39.waitingToEmit = strConsumerRecordItor41;
        boolean boolean43 = strKafkaSpout39.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig44 = null;
        strKafkaSpout39.kafkaSpoutConfig = strKafkaSpoutConfig44;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy46 = strKafkaSpout39.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType19, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord33, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout39);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout51 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout51.maxRetries = (byte) -1;
        int int54 = strKafkaSpout51.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor55 = null;
        strKafkaSpout51.waitingToEmit = strConsumerRecordItor55;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer57 = strKafkaSpout51.commitTimer;
        boolean boolean58 = strKafkaSpout51.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService59 = null;
        strKafkaSpout51.retryService = kafkaSpoutRetryService59;
        java.lang.Object obj61 = null;
        org.apache.kafka.common.record.TimestampType timestampType66 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType66, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long73 = charSequenceConsumerRecord72.checksum();
        int int74 = charSequenceConsumerRecord72.partition();
        long long75 = charSequenceConsumerRecord72.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType76 = charSequenceConsumerRecord72.timestampType();
        int int77 = charSequenceConsumerRecord72.serializedKeySize();
        org.apache.kafka.common.header.Headers headers78 = charSequenceConsumerRecord72.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Object> objConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.lang.Object>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (byte) 100, (long) (short) 10, (long) ' ', timestampType19, (java.lang.Long) (-1L), 97, (int) (byte) 1, (java.lang.Object) kafkaSpoutRetryService59, obj61, headers78);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", (-1), 97L, 100L, timestampType19, (long) (byte) 1, 100, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = 97, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = )", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}))");
        java.lang.CharSequence charSequence86 = charSequenceConsumerRecord85.key();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertTrue("'" + int35 + "' != '" + 10 + "'", int35 == 10);
        org.junit.Assert.assertEquals("'" + str36 + "' != '" + "hi!" + "'", str36, "hi!");
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + 52 + "'", int37 == 52);
        org.junit.Assert.assertNotNull(intOptional38);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet40);
        org.junit.Assert.assertTrue("'" + boolean43 + "' != '" + false + "'", boolean43 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy46);
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + (-1) + "'", int54 == (-1));
        org.junit.Assert.assertNull(timer57);
        org.junit.Assert.assertTrue("'" + boolean58 + "' != '" + false + "'", boolean58 == false);
        org.junit.Assert.assertTrue("'" + long73 + "' != '" + (-1L) + "'", long73 == (-1L));
        org.junit.Assert.assertTrue("'" + int74 + "' != '" + 10 + "'", int74 == 10);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + (-1L) + "'", long75 == (-1L));
        org.junit.Assert.assertNull(timestampType76);
        org.junit.Assert.assertTrue("'" + int77 + "' != '" + 52 + "'", int77 == 52);
        org.junit.Assert.assertNotNull(headers78);
        org.junit.Assert.assertEquals("'" + charSequence86 + "' != '" + "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = 97, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = )" + "'", charSequence86, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = 97, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = )");
    }

    @Test
    public void test7036() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7036");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        boolean boolean11 = strKafkaSpout0.consumerAutoCommitMode;
        long long12 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig13 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig13;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams15 = strKafkaSpout0.kafkaSpoutStreams;
        java.util.Map map16 = null;
        org.apache.storm.task.TopologyContext topologyContext17 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector18 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map16, topologyContext17, spoutOutputCollector18);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 0L + "'", long12 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutStreams15);
    }

    @Test
    public void test7037() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7037");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService11 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService11;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig13 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig13;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer15 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer15);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer10);
    }

    @Test
    public void test7038() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7038");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        long long7 = charSequenceConsumerRecord5.timestamp();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        org.apache.kafka.common.header.Headers headers9 = charSequenceConsumerRecord5.headers();
        org.apache.kafka.common.header.Headers headers10 = charSequenceConsumerRecord5.headers();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertNotNull(headers9);
        org.junit.Assert.assertNotNull(headers10);
    }

    @Test
    public void test7039() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7039");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray6 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet7 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean8 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet7, kafkaSpoutMessageIdArray6);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet7;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer10 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService11 = strKafkaSpout0.retryService;
        long long12 = strKafkaSpout0.numUncommittedOffsets;
        boolean boolean13 = strKafkaSpout0.initialized;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray6);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
        org.junit.Assert.assertNull(timer10);
        org.junit.Assert.assertNull(kafkaSpoutRetryService11);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 35L + "'", long12 == 35L);
        org.junit.Assert.assertTrue("'" + boolean13 + "' != '" + false + "'", boolean13 == false);
    }

    @Test
    public void test7040() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7040");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType4, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord10.timestampType();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        long long15 = charSequenceConsumerRecord10.checksum();
        long long16 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 35L + "'", long11 == 35L);
        org.junit.Assert.assertNull(timestampType12);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 10L + "'", long15 == 10L);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 10L + "'", long16 == 10L);
    }

    @Test
    public void test7041() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7041");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet4 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer5 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService6;
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet4);
        org.junit.Assert.assertNull(timer5);
    }

    @Test
    public void test7042() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7042");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition8 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection9 = strKafkaSpout0.toArrayList(topicPartition8);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer10;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor12 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor12;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig14 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig14;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector16 = strKafkaSpout0.collector;
        java.util.Map map17 = null;
        org.apache.storm.task.TopologyContext topologyContext18 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector19 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map17, topologyContext18, spoutOutputCollector19);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection9);
        org.junit.Assert.assertNull(spoutOutputCollector16);
    }

    @Test
    public void test7043() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7043");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy6 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy6;
        java.lang.String str8 = strKafkaSpout0.toString();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor9 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor9;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test7044() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7044");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator4 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator4;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord6 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator4);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator4.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator8 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator9 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator9;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = offsetComparator9.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator8.thenComparing(kafkaSpoutMessageIdComparator11);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator13.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator13.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = kafkaSpoutMessageIdComparator11.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator13);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator17;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = offsetComparator4.thenComparing(kafkaSpoutMessageIdComparator17);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator17;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = kafkaSpoutMessageIdComparator17.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator22 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator23;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator23.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator22.thenComparing(kafkaSpoutMessageIdComparator25);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator27 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator27;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = offsetComparator27.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator34 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator34;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = kafkaSpoutMessageIdComparator29.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = offsetComparator22.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator34);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator39 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator39;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = offsetComparator39.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator39;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator43 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator43;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator45 = offsetComparator43.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator46 = offsetComparator39.thenComparing(kafkaSpoutMessageIdComparator45);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator47 = kafkaSpoutMessageIdComparator45.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator48 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator48;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator50 = offsetComparator48.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator55 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator55;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator55);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator58 = kafkaSpoutMessageIdComparator50.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator55);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator59 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator59;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator61 = offsetComparator59.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator66 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator66;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator66);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator69 = kafkaSpoutMessageIdComparator61.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator66);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator70 = kafkaSpoutMessageIdComparator50.thenComparing(kafkaSpoutMessageIdComparator69);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator71 = kafkaSpoutMessageIdComparator70.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator72 = kafkaSpoutMessageIdComparator45.thenComparing(kafkaSpoutMessageIdComparator70);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator72;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator74 = offsetComparator34.thenComparing(kafkaSpoutMessageIdComparator72);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator75 = kafkaSpoutMessageIdComparator17.thenComparing(kafkaSpoutMessageIdComparator72);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator75;
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator75;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator46);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator47);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator50);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator58);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator61);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator69);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator70);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator71);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator72);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator74);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator75);
    }

    @Test
    public void test7045() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7045");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType23, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long30 = charSequenceConsumerRecord29.checksum();
        int int31 = charSequenceConsumerRecord29.partition();
        java.lang.String str32 = charSequenceConsumerRecord29.value();
        int int33 = charSequenceConsumerRecord29.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional34 = charSequenceConsumerRecord29.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet36 = strKafkaSpout35.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor37 = null;
        strKafkaSpout35.waitingToEmit = strConsumerRecordItor37;
        boolean boolean39 = strKafkaSpout35.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig40 = null;
        strKafkaSpout35.kafkaSpoutConfig = strKafkaSpoutConfig40;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy42 = strKafkaSpout35.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType15, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord29, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout35);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType53, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long60 = charSequenceConsumerRecord59.checksum();
        int int61 = charSequenceConsumerRecord59.partition();
        java.lang.String str62 = charSequenceConsumerRecord59.value();
        int int63 = charSequenceConsumerRecord59.serializedKeySize();
        org.apache.kafka.common.header.Headers headers64 = charSequenceConsumerRecord59.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str71 = charSequenceConsumerRecord70.topic();
        java.util.Optional<java.lang.Integer> intOptional72 = charSequenceConsumerRecord70.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 0, (long) (short) 10, (long) (-1), timestampType15, (java.lang.Long) 35L, 10, (int) (short) 10, (java.lang.CharSequence) "", "KafkaSpout{acked=null, emitted=null}", headers64, intOptional72);
        java.util.Optional<java.lang.Integer> intOptional74 = charSequenceConsumerRecord73.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType75 = charSequenceConsumerRecord73.timestampType();
        int int76 = charSequenceConsumerRecord73.serializedKeySize();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 10 + "'", int31 == 10);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "hi!" + "'", str32, "hi!");
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + 52 + "'", int33 == 52);
        org.junit.Assert.assertNotNull(intOptional34);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet36);
        org.junit.Assert.assertTrue("'" + boolean39 + "' != '" + false + "'", boolean39 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy42);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + 10 + "'", int61 == 10);
        org.junit.Assert.assertEquals("'" + str62 + "' != '" + "hi!" + "'", str62, "hi!");
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 52 + "'", int63 == 52);
        org.junit.Assert.assertNotNull(headers64);
        org.junit.Assert.assertEquals("'" + str71 + "' != '" + "" + "'", str71, "");
        org.junit.Assert.assertNotNull(intOptional72);
        org.junit.Assert.assertNotNull(intOptional74);
        org.junit.Assert.assertTrue("'" + timestampType75 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType75.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + 10 + "'", int76 == 10);
    }

    @Test
    public void test7046() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7046");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector3 = null;
        strKafkaSpout0.collector = spoutOutputCollector3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = strKafkaSpout0.kafkaSpoutConfig;
        long long6 = strKafkaSpout0.numUncommittedOffsets;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str7 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(strKafkaSpoutConfig5);
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + 0L + "'", long6 == 0L);
    }

    @Test
    public void test7047() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7047");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        java.lang.String str4 = strKafkaSpout0.toString();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = strKafkaSpout0.emitted;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertEquals("'" + str4 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str4, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet5);
    }

    @Test
    public void test7048() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7048");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray6 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet7 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean8 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet7, kafkaSpoutMessageIdArray6);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet7;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer10 = strKafkaSpout0.commitTimer;
        java.lang.String str11 = strKafkaSpout0.toString();
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams13 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams13;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray6);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
        org.junit.Assert.assertNull(timer10);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "KafkaSpout{acked=null, emitted=[]}" + "'", str11, "KafkaSpout{acked=null, emitted=[]}");
        org.junit.Assert.assertNull(spoutOutputCollector12);
    }

    @Test
    public void test7049() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7049");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.initialized = false;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor5 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy6 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy6;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords8 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords8);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertNull(strConsumerRecordItor5);
    }

    @Test
    public void test7050() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7050");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        java.util.Optional<java.lang.Integer> intOptional17 = charSequenceConsumerRecord10.leaderEpoch();
        int int18 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.String str19 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertNotNull(intOptional17);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + (-1) + "'", int18 == (-1));
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test7051() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7051");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = ' ';
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams10;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig13 = strKafkaSpout0.kafkaSpoutConfig;
        strKafkaSpout0.maxRetries = (short) -1;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertNull(spoutOutputCollector12);
        org.junit.Assert.assertNull(strKafkaSpoutConfig13);
    }

    @Test
    public void test7052() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7052");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator3 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator3;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator5 = offsetComparator3.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator10 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator10;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord12 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator10);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = kafkaSpoutMessageIdComparator5.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator10);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator14 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator14;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator14.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator21 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator21;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator21);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator16.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator21);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = kafkaSpoutMessageIdComparator5.thenComparing(kafkaSpoutMessageIdComparator24);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator26 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = offsetComparator26.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = offsetComparator26.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = kafkaSpoutMessageIdComparator24.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator26);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator, java.lang.Comparable<java.lang.String>> offsetComparatorConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, 1L, offsetComparator26, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator26;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId37 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId38 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int39 = offsetComparator26.compare(kafkaSpoutMessageId37, kafkaSpoutMessageId38);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator5);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
    }

    @Test
    public void test7053() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7053");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str26 = charSequenceConsumerRecord25.topic();
        org.apache.kafka.common.record.TimestampType timestampType27 = charSequenceConsumerRecord25.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType35 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType35, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long42 = charSequenceConsumerRecord41.checksum();
        int int43 = charSequenceConsumerRecord41.partition();
        long long44 = charSequenceConsumerRecord41.timestamp();
        java.lang.String str45 = charSequenceConsumerRecord41.toString();
        long long46 = charSequenceConsumerRecord41.timestamp();
        org.apache.kafka.common.header.Headers headers47 = charSequenceConsumerRecord41.headers();
        org.apache.kafka.common.record.TimestampType timestampType48 = charSequenceConsumerRecord41.timestampType();
        java.util.Optional<java.lang.Integer> intOptional49 = charSequenceConsumerRecord41.leaderEpoch();
        org.apache.storm.topology.IComponent iComponent50 = null;
        org.apache.kafka.common.record.TimestampType timestampType55 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType55, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long62 = charSequenceConsumerRecord61.checksum();
        int int63 = charSequenceConsumerRecord61.partition();
        long long64 = charSequenceConsumerRecord61.timestamp();
        java.lang.String str65 = charSequenceConsumerRecord61.toString();
        org.apache.kafka.common.header.Headers headers66 = charSequenceConsumerRecord61.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent> intOptionalConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent>("hi!", (int) ' ', (long) (byte) -1, (long) (-1), timestampType27, (java.lang.Long) 100L, (int) 'a', (-1), intOptional49, iComponent50, headers66);
        org.apache.storm.topology.IRichSpout iRichSpout72 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.storm.topology.IRichSpout> strComparableConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.storm.topology.IRichSpout>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", (int) (byte) 0, (long) 10, (long) (-1), timestampType27, (long) 0, (int) (short) 10, (int) (byte) 1, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", iRichSpout72);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (short) 100, 0L, (long) (short) 1, timestampType27, 0L, (int) (byte) 0, (int) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord85 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) -1, 52L, (long) (short) 1, timestampType27, 0L, (int) (short) -1, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord91 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 100, (long) (byte) -1, 1L, timestampType27, 10L, 1, 1, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = 35, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)");
        java.util.Optional<java.lang.Integer> intOptional92 = charSequenceConsumerRecord91.leaderEpoch();
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "" + "'", str26, "");
        org.junit.Assert.assertTrue("'" + timestampType27 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType27.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long42 + "' != '" + (-1L) + "'", long42 == (-1L));
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + 10 + "'", int43 == 10);
        org.junit.Assert.assertTrue("'" + long44 + "' != '" + (-1L) + "'", long44 == (-1L));
        org.junit.Assert.assertEquals("'" + str45 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str45, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long46 + "' != '" + (-1L) + "'", long46 == (-1L));
        org.junit.Assert.assertNotNull(headers47);
        org.junit.Assert.assertNull(timestampType48);
        org.junit.Assert.assertNotNull(intOptional49);
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + (-1L) + "'", long62 == (-1L));
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 10 + "'", int63 == 10);
        org.junit.Assert.assertTrue("'" + long64 + "' != '" + (-1L) + "'", long64 == (-1L));
        org.junit.Assert.assertEquals("'" + str65 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str65, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers66);
        org.junit.Assert.assertNotNull(intOptional92);
    }

    @Test
    public void test7054() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7054");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig3 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig3;
        strKafkaSpout0.numUncommittedOffsets = 1;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService7 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService7;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = null;
        strKafkaSpout0.collector = spoutOutputCollector9;
        org.apache.kafka.common.TopicPartition topicPartition11 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection12 = strKafkaSpout0.toArrayList(topicPartition11);
        org.apache.kafka.common.TopicPartition topicPartition13 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection14 = strKafkaSpout0.toArrayList(topicPartition13);
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.commitOffsetsForAckedTuples();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertNotNull(topicPartitionCollection12);
        org.junit.Assert.assertNotNull(topicPartitionCollection14);
    }

    @Test
    public void test7055() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7055");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        int int12 = strKafkaSpout0.maxRetries;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = strKafkaSpout0.emitted;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet13);
    }

    @Test
    public void test7056() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7056");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        java.lang.String str7 = charSequenceConsumerRecord5.toString();
        java.lang.String str8 = charSequenceConsumerRecord5.toString();
        org.apache.kafka.common.record.TimestampType timestampType9 = charSequenceConsumerRecord5.timestampType();
        java.lang.String str10 = charSequenceConsumerRecord5.value();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str7, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str8, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + timestampType9 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType9.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str10, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test7057() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7057");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        int int20 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType21 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str22 = charSequenceConsumerRecord10.value();
        int int23 = charSequenceConsumerRecord10.serializedKeySize();
        int int24 = charSequenceConsumerRecord10.partition();
        long long25 = charSequenceConsumerRecord10.timestamp();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 10 + "'", int20 == 10);
        org.junit.Assert.assertNull(timestampType21);
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "hi!" + "'", str22, "hi!");
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 52 + "'", int23 == 52);
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + 10 + "'", int24 == 10);
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + (-1L) + "'", long25 == (-1L));
    }

    @Test
    public void test7058() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7058");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}))", (int) 'a', 100L, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.apache.kafka.common.record.TimestampType timestampType6 = charSequenceConsumerRecord5.timestampType();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test7059() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7059");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", (int) '#', (long) 52, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!), partition = 1, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = )", "ConsumerRecord(topic = ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})");
    }

    @Test
    public void test7060() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7060");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = strKafkaSpout0.kafkaConsumer;
        java.lang.String str8 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig11;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str13 = strKafkaSpout0.getNamedTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertNull(strKafkaConsumer7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test7061() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7061");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer5 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer5;
        long long7 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        boolean boolean9 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams10;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + 0L + "'", long7 == 0L);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertTrue("'" + boolean9 + "' != '" + false + "'", boolean9 == false);
    }

    @Test
    public void test7062() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7062");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet4 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer5 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy6 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy6;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet8 = strKafkaSpout0.emitted;
        strKafkaSpout0.maxRetries = (short) 1;
        strKafkaSpout0.numUncommittedOffsets = ' ';
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder13;
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet4);
        org.junit.Assert.assertNull(timer5);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet8);
    }

    @Test
    public void test7063() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7063");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        java.lang.String str12 = charSequenceConsumerRecord10.value();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord10.timestampType();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord10.headers();
        java.lang.Class<?> wildcardClass17 = charSequenceConsumerRecord10.getClass();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertNull(timestampType15);
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertNotNull(wildcardClass17);
    }

    @Test
    public void test7064() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7064");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray6 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet7 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean8 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet7, kafkaSpoutMessageIdArray6);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet7;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor11 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor11;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig13 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig13;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray6);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
        org.junit.Assert.assertNull(strKafkaConsumer10);
    }

    @Test
    public void test7065() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7065");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        java.lang.String str12 = charSequenceConsumerRecord10.value();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord10.timestampType();
        long long16 = charSequenceConsumerRecord10.checksum();
        org.apache.kafka.common.header.Headers headers17 = charSequenceConsumerRecord10.headers();
        java.lang.String str18 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertNull(timestampType15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertNotNull(headers17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "hi!" + "'", str18, "hi!");
    }

    @Test
    public void test7066() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7066");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        long long7 = charSequenceConsumerRecord5.timestamp();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        java.lang.String str9 = charSequenceConsumerRecord5.toString();
        java.lang.String str10 = charSequenceConsumerRecord5.topic();
        int int11 = charSequenceConsumerRecord5.serializedKeySize();
        int int12 = charSequenceConsumerRecord5.partition();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str9, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "" + "'", str10, "");
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
    }

    @Test
    public void test7067() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7067");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService1 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService1;
        long long3 = strKafkaSpout0.numUncommittedOffsets;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = strKafkaSpout0.waitingToEmit;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = strKafkaSpout0.emitted;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy8 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy8;
        java.lang.Class<?> wildcardClass10 = strKafkaSpout0.getClass();
        org.junit.Assert.assertTrue("'" + long3 + "' != '" + 0L + "'", long3 == 0L);
        org.junit.Assert.assertNull(strConsumerRecordItor4);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet5);
        org.junit.Assert.assertNotNull(wildcardClass10);
    }

    @Test
    public void test7068() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7068");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        boolean boolean7 = strKafkaSpout0.initialized;
        strKafkaSpout0.maxRetries = (byte) 10;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService10;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService12 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService12;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy14 = strKafkaSpout0.firstPollOffsetStrategy;
        boolean boolean15 = strKafkaSpout0.waitingToEmit();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy14);
        org.junit.Assert.assertTrue("'" + boolean15 + "' != '" + false + "'", boolean15 == false);
    }

    @Test
    public void test7069() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7069");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer5 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer5;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer8 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer8;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector10 = strKafkaSpout0.collector;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = strKafkaSpout0.collector;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertNull(spoutOutputCollector10);
        org.junit.Assert.assertNull(spoutOutputCollector11);
    }

    @Test
    public void test7070() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7070");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        long long8 = strKafkaSpout0.numUncommittedOffsets;
        strKafkaSpout0.numUncommittedOffsets = (-1L);
        strKafkaSpout0.numUncommittedOffsets = 32L;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean13 = strKafkaSpout0.commit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 0L + "'", long8 == 0L);
    }

    @Test
    public void test7071() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7071");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=[]}", 35, 10L, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = , partition = 52, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test7072() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7072");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder2 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder2;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy4 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = strKafkaSpout0.kafkaSpoutConfig;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor7;
        int int9 = strKafkaSpout0.maxRetries;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strKafkaSpoutConfig6);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + 0 + "'", int9 == 0);
    }

    @Test
    public void test7073() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7073");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        int int12 = strKafkaSpout0.maxRetries;
        long long13 = strKafkaSpout0.numUncommittedOffsets;
        java.lang.String str14 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams15 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams15;
        boolean boolean17 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService18 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService18;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams20 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams21 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams21;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str14, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + boolean17 + "' != '" + false + "'", boolean17 == false);
        org.junit.Assert.assertNull(kafkaSpoutStreams20);
    }

    @Test
    public void test7074() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7074");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        java.lang.String str13 = charSequenceConsumerRecord10.toString();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 52 + "'", int14 == 52);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
    }

    @Test
    public void test7075() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7075");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = strKafkaSpout0.kafkaConsumer;
        strKafkaSpout0.maxRetries = (byte) 100;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams7;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords9 = strKafkaSpout0.pollKafkaBroker();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer4);
    }

    @Test
    public void test7076() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7076");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        java.lang.String str12 = charSequenceConsumerRecord10.value();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord10.timestampType();
        long long16 = charSequenceConsumerRecord10.checksum();
        java.lang.String str17 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str20 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertNull(timestampType15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "" + "'", str20, "");
    }

    @Test
    public void test7077() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7077");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", (int) ' ', (long) (byte) 100, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = 97, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = )");
    }

    @Test
    public void test7078() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7078");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        long long17 = charSequenceConsumerRecord10.checksum();
        long long18 = charSequenceConsumerRecord10.checksum();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        int int20 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence21 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers22 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + (-1) + "'", int20 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence21 + "' != '" + "" + "'", charSequence21, "");
        org.junit.Assert.assertNotNull(headers22);
        org.junit.Assert.assertNull(timestampType23);
    }

    @Test
    public void test7079() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7079");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy2 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor5 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy6 = strKafkaSpout0.firstPollOffsetStrategy;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(firstPollOffsetStrategy2);
        org.junit.Assert.assertNull(strConsumerRecordItor5);
        org.junit.Assert.assertNull(firstPollOffsetStrategy6);
    }

    @Test
    public void test7080() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7080");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.Cloneable> kafkaSpoutMessageIdListKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.Cloneable> kafkaSpoutMessageIdListKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.Cloneable>(kafkaSpoutMessageIdListKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test7081() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7081");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer16;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector18 = null;
        strKafkaSpout0.collector = spoutOutputCollector18;
        int int20 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams21 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams21;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy23 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy23;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + (-1) + "'", int20 == (-1));
    }

    @Test
    public void test7082() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7082");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        boolean boolean2 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.kafka.common.TopicPartition topicPartition3 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection4 = strKafkaSpout0.toArrayList(topicPartition3);
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor5 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder6 = strKafkaSpout0.tuplesBuilder;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertTrue("'" + boolean2 + "' != '" + false + "'", boolean2 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection4);
        org.junit.Assert.assertNull(strConsumerRecordItor5);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder6);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
    }

    @Test
    public void test7083() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7083");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 52, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) ' ', 0L, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        int int6 = charSequenceConsumerRecord5.serializedValueSize();
        java.lang.String str7 = charSequenceConsumerRecord5.value();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str7, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
    }

    @Test
    public void test7084() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7084");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        java.lang.CharSequence charSequence11 = charSequenceConsumerRecord10.key();
        long long12 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertEquals("'" + charSequence11 + "' != '" + "" + "'", charSequence11, "");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
    }

    @Test
    public void test7085() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7085");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        strKafkaSpout0.maxRetries = 100;
        int int12 = strKafkaSpout0.maxRetries;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
    }

    @Test
    public void test7086() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7086");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator4 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator4;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator6 = offsetComparator4.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator6);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator8 = offsetComparator0.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator9 = kafkaSpoutMessageIdComparator8.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator6);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator8);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator9);
    }

    @Test
    public void test7087() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7087");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", (int) (byte) -1, (long) (short) 100, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]}), value = ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null}))", "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, null = 1, serialized key size = 32, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )");
    }

    @Test
    public void test7088() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7088");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams6 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.common.TopicPartition topicPartition7 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection8 = strKafkaSpout0.toArrayList(topicPartition7);
        strKafkaSpout0.initialized = false;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = null;
        strKafkaSpout0.collector = spoutOutputCollector11;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + 0 + "'", int3 == 0);
        org.junit.Assert.assertNull(kafkaSpoutStreams6);
        org.junit.Assert.assertNotNull(topicPartitionCollection8);
    }

    @Test
    public void test7089() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7089");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) 'a', (long) 32, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 97, leaderEpoch = null, offset = 100, NoTimestampType = 97, serialized key size = 97, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=[]}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        java.lang.CharSequence charSequence6 = charSequenceConsumerRecord5.key();
        int int7 = charSequenceConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertEquals("'" + charSequence6 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", charSequence6, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
    }

    @Test
    public void test7090() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7090");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        strKafkaSpout0.maxRetries = (short) 100;
        org.apache.kafka.common.TopicPartition topicPartition11 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection12 = strKafkaSpout0.toArrayList(topicPartition11);
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector13 = strKafkaSpout0.collector;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.doSeekRetriableTopicPartitions();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNotNull(topicPartitionCollection12);
        org.junit.Assert.assertNull(spoutOutputCollector13);
    }

    @Test
    public void test7091() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7091");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        long long8 = strKafkaSpout0.numUncommittedOffsets;
        strKafkaSpout0.numUncommittedOffsets = (-1L);
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams11 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService12 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService12;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords14 = strKafkaSpout0.pollKafkaBroker();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 0L + "'", long8 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutStreams11);
    }

    @Test
    public void test7092() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7092");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = strKafkaSpout0.kafkaConsumer;
        strKafkaSpout0.maxRetries = (byte) 100;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor7;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor9 = strKafkaSpout0.waitingToEmit;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Map<java.lang.String, java.lang.Object> strMap10 = strKafkaSpout0.getComponentConfiguration();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer4);
        org.junit.Assert.assertNull(strConsumerRecordItor9);
    }

    @Test
    public void test7093() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7093");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.kafka.common.record.TimestampType, org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>> timestampTypeKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>> timestampTypeKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.record.TimestampType, org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>>(timestampTypeKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test7094() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7094");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        java.lang.CharSequence charSequence11 = charSequenceConsumerRecord10.key();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType13 = charSequenceConsumerRecord10.timestampType();
        long long14 = charSequenceConsumerRecord10.checksum();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertEquals("'" + charSequence11 + "' != '" + "" + "'", charSequence11, "");
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNull(timestampType13);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
    }

    @Test
    public void test7095() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7095");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType14, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int21 = charSequenceConsumerRecord20.serializedValueSize();
        java.lang.CharSequence charSequence22 = charSequenceConsumerRecord20.key();
        org.apache.kafka.common.header.Headers headers23 = charSequenceConsumerRecord20.headers();
        java.util.Optional<java.lang.Integer> intOptional24 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType4, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers23, intOptional24);
        long long26 = charSequenceConsumerRecord25.checksum();
        long long27 = charSequenceConsumerRecord25.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType28 = charSequenceConsumerRecord25.timestampType();
        int int29 = charSequenceConsumerRecord25.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType30 = charSequenceConsumerRecord25.timestampType();
        int int31 = charSequenceConsumerRecord25.serializedKeySize();
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence22 + "' != '" + "" + "'", charSequence22, "");
        org.junit.Assert.assertNotNull(headers23);
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + (-1L) + "'", long26 == (-1L));
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + 35L + "'", long27 == 35L);
        org.junit.Assert.assertNull(timestampType28);
        org.junit.Assert.assertTrue("'" + int29 + "' != '" + 0 + "'", int29 == 0);
        org.junit.Assert.assertNull(timestampType30);
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 1 + "'", int31 == 1);
    }

    @Test
    public void test7096() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7096");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str10 = charSequenceConsumerRecord9.topic();
        org.apache.kafka.common.record.TimestampType timestampType11 = charSequenceConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType19, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long26 = charSequenceConsumerRecord25.checksum();
        int int27 = charSequenceConsumerRecord25.partition();
        java.lang.String str28 = charSequenceConsumerRecord25.value();
        int int29 = charSequenceConsumerRecord25.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional30 = charSequenceConsumerRecord25.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout31 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet32 = strKafkaSpout31.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor33 = null;
        strKafkaSpout31.waitingToEmit = strConsumerRecordItor33;
        boolean boolean35 = strKafkaSpout31.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig36 = null;
        strKafkaSpout31.kafkaSpoutConfig = strKafkaSpoutConfig36;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy38 = strKafkaSpout31.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType11, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord25, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout31);
        java.util.Optional<java.lang.Integer> intOptional40 = charSequenceConsumerRecord25.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional41 = charSequenceConsumerRecord25.leaderEpoch();
        int int42 = charSequenceConsumerRecord25.serializedKeySize();
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "" + "'", str10, "");
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + (-1L) + "'", long26 == (-1L));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + 10 + "'", int27 == 10);
        org.junit.Assert.assertEquals("'" + str28 + "' != '" + "hi!" + "'", str28, "hi!");
        org.junit.Assert.assertTrue("'" + int29 + "' != '" + 52 + "'", int29 == 52);
        org.junit.Assert.assertNotNull(intOptional30);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet32);
        org.junit.Assert.assertTrue("'" + boolean35 + "' != '" + false + "'", boolean35 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy38);
        org.junit.Assert.assertNotNull(intOptional40);
        org.junit.Assert.assertNotNull(intOptional41);
        org.junit.Assert.assertTrue("'" + int42 + "' != '" + 52 + "'", int42 == 52);
    }

    @Test
    public void test7097() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7097");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType17 = null;
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int34 = charSequenceConsumerRecord33.serializedValueSize();
        java.lang.CharSequence charSequence35 = charSequenceConsumerRecord33.key();
        org.apache.kafka.common.header.Headers headers36 = charSequenceConsumerRecord33.headers();
        java.util.Optional<java.lang.Integer> intOptional37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType17, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers36, intOptional37);
        org.apache.kafka.common.record.TimestampType timestampType46 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType46, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int53 = charSequenceConsumerRecord52.serializedValueSize();
        java.lang.CharSequence charSequence54 = charSequenceConsumerRecord52.key();
        org.apache.kafka.common.header.Headers headers55 = charSequenceConsumerRecord52.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray56 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList57 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean58 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57, kafkaSpoutMessageIdArray56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers55, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headersConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("", (int) '#', 1L, headers36, kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType4, (java.lang.Long) (-1L), (int) (short) 100, 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}", headers36);
        int int62 = charSequenceConsumerRecord61.partition();
        org.apache.kafka.common.record.TimestampType timestampType63 = charSequenceConsumerRecord61.timestampType();
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + (-1) + "'", int34 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence35 + "' != '" + "" + "'", charSequence35, "");
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + (-1) + "'", int53 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence54 + "' != '" + "" + "'", charSequence54, "");
        org.junit.Assert.assertNotNull(headers55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray56);
        org.junit.Assert.assertTrue("'" + boolean58 + "' != '" + false + "'", boolean58 == false);
        org.junit.Assert.assertTrue("'" + int62 + "' != '" + 97 + "'", int62 == 97);
        org.junit.Assert.assertNull(timestampType63);
    }

    @Test
    public void test7098() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7098");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition8 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection9 = strKafkaSpout0.toArrayList(topicPartition8);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = strKafkaSpout0.retryService;
        boolean boolean11 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.numUncommittedOffsets = (-1L);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer15 = strKafkaSpout0.commitTimer;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection9);
        org.junit.Assert.assertNull(kafkaSpoutRetryService10);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(kafkaSpoutStreams12);
        org.junit.Assert.assertNull(timer15);
    }

    @Test
    public void test7099() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7099");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = offsetComparator11.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator7.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator11);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = kafkaSpoutMessageIdComparator15.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = kafkaSpoutMessageIdComparator16.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = offsetComparator18.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator25 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator25;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator25);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = kafkaSpoutMessageIdComparator20.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator25);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator29 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator29;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator31 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator32 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator32;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator32.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = offsetComparator31.thenComparing(kafkaSpoutMessageIdComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = offsetComparator29.thenComparing(kafkaSpoutMessageIdComparator35);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = offsetComparator25.thenComparing(kafkaSpoutMessageIdComparator36);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = kafkaSpoutMessageIdComparator16.thenComparing(kafkaSpoutMessageIdComparator36);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator39 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator40 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator41 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator41;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator43 = offsetComparator41.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator48 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator48;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator48);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator51 = kafkaSpoutMessageIdComparator43.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator48);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator52 = offsetComparator40.thenComparing(kafkaSpoutMessageIdComparator51);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator53 = kafkaSpoutMessageIdComparator51.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator54 = offsetComparator39.thenComparing(kafkaSpoutMessageIdComparator53);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator55 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator56 = offsetComparator55.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator57 = offsetComparator39.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator55);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator58 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator59 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator60 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator60;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator62 = offsetComparator60.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator67 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator67;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator67);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator70 = kafkaSpoutMessageIdComparator62.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator67);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator71 = offsetComparator59.thenComparing(kafkaSpoutMessageIdComparator70);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator72 = kafkaSpoutMessageIdComparator70.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator73 = offsetComparator58.thenComparing(kafkaSpoutMessageIdComparator70);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator74 = kafkaSpoutMessageIdComparator70.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator75 = kafkaSpoutMessageIdComparator70.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator76 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator77 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator77;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator79 = offsetComparator77.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator80 = offsetComparator76.thenComparing(kafkaSpoutMessageIdComparator79);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator81 = kafkaSpoutMessageIdComparator70.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator76);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator82 = offsetComparator76.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator83 = offsetComparator39.thenComparing(kafkaSpoutMessageIdComparator82);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator84 = kafkaSpoutMessageIdComparator16.thenComparing(kafkaSpoutMessageIdComparator83);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator84;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator43);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator51);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator52);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator53);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator54);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator56);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator57);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator62);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator70);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator71);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator72);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator73);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator74);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator75);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator79);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator80);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator81);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator82);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator83);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator84);
    }

    @Test
    public void test7100() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7100");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams12;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector14 = strKafkaSpout0.collector;
        java.lang.String str15 = strKafkaSpout0.toString();
        java.lang.String str16 = strKafkaSpout0.toString();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNull(spoutOutputCollector14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str16, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test7101() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7101");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        long long7 = charSequenceConsumerRecord5.timestamp();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        java.lang.String str9 = charSequenceConsumerRecord5.toString();
        org.apache.kafka.common.header.Headers headers10 = charSequenceConsumerRecord5.headers();
        java.lang.String str11 = charSequenceConsumerRecord5.topic();
        long long12 = charSequenceConsumerRecord5.timestamp();
        int int13 = charSequenceConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional14 = charSequenceConsumerRecord5.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord5.timestampType();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str9, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
        org.junit.Assert.assertNotNull(intOptional14);
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test7102() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7102");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        java.lang.String str13 = charSequenceConsumerRecord10.toString();
        int int14 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
    }

    @Test
    public void test7103() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7103");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        boolean boolean7 = strKafkaSpout0.initialized;
        strKafkaSpout0.maxRetries = (byte) 10;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService10;
        int int12 = strKafkaSpout0.maxRetries;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Map<java.lang.String, java.lang.Object> strMap13 = strKafkaSpout0.getComponentConfiguration();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
    }

    @Test
    public void test7104() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7104");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout11 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = strKafkaSpout11.kafkaSpoutStreams;
        strKafkaSpout11.consumerAutoCommitMode = false;
        java.lang.String str15 = strKafkaSpout11.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout16 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout16.maxRetries = (byte) -1;
        int int19 = strKafkaSpout16.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray20 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet21 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean22 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, kafkaSpoutMessageIdArray20);
        strKafkaSpout16.emitted = kafkaSpoutMessageIdSet21;
        strKafkaSpout11.emitted = kafkaSpoutMessageIdSet21;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout25 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout25.maxRetries = (byte) -1;
        int int28 = strKafkaSpout25.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor29 = null;
        strKafkaSpout25.waitingToEmit = strConsumerRecordItor29;
        org.apache.kafka.common.TopicPartition topicPartition31 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection32 = strKafkaSpout25.toArrayList(topicPartition31);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout25.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector34 = strKafkaSpout25.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout35.maxRetries = (byte) -1;
        int int38 = strKafkaSpout35.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray39 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet40 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean41 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40, kafkaSpoutMessageIdArray39);
        strKafkaSpout35.emitted = kafkaSpoutMessageIdSet40;
        strKafkaSpout25.emitted = kafkaSpoutMessageIdSet40;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType7, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet40;
        long long46 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService47 = strKafkaSpout0.retryService;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.emit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(strKafkaSpoutConfig2);
        org.junit.Assert.assertNull(kafkaSpoutStreams12);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray20);
        org.junit.Assert.assertTrue("'" + boolean22 + "' != '" + false + "'", boolean22 == false);
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + (-1) + "'", int28 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection32);
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(spoutOutputCollector34);
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + (-1) + "'", int38 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray39);
        org.junit.Assert.assertTrue("'" + boolean41 + "' != '" + false + "'", boolean41 == false);
        org.junit.Assert.assertTrue("'" + long46 + "' != '" + 0L + "'", long46 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutRetryService47);
    }

    @Test
    public void test7105() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7105");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.checksum();
        int int16 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.String str17 = charSequenceConsumerRecord10.value();
        java.lang.String str18 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 52 + "'", int16 == 52);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
    }

    @Test
    public void test7106() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7106");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams9 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        int int11 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector14 = null;
        strKafkaSpout0.collector = spoutOutputCollector14;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
        org.junit.Assert.assertNull(kafkaSpoutStreams9);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
    }

    @Test
    public void test7107() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7107");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.offset();
        int int19 = charSequenceConsumerRecord10.partition();
        java.lang.String str20 = charSequenceConsumerRecord10.value();
        java.lang.String str21 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.header.Headers headers22 = charSequenceConsumerRecord10.headers();
        java.lang.String str23 = charSequenceConsumerRecord10.toString();
        java.util.Optional<java.lang.Integer> intOptional24 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.header.Headers headers25 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "" + "'", str21, "");
        org.junit.Assert.assertNotNull(headers22);
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str23, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(intOptional24);
        org.junit.Assert.assertNotNull(headers25);
    }

    @Test
    public void test7108() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7108");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        long long17 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str18 = charSequenceConsumerRecord10.toString();
        java.lang.String str19 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str18, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
    }

    @Test
    public void test7109() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7109");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str21 = charSequenceConsumerRecord10.value();
        java.util.Optional<java.lang.Integer> intOptional22 = charSequenceConsumerRecord10.leaderEpoch();
        long long23 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str24 = charSequenceConsumerRecord10.toString();
        java.lang.String str25 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.header.Headers headers26 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "hi!" + "'", str21, "hi!");
        org.junit.Assert.assertNotNull(intOptional22);
        org.junit.Assert.assertTrue("'" + long23 + "' != '" + (-1L) + "'", long23 == (-1L));
        org.junit.Assert.assertEquals("'" + str24 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str24, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "hi!" + "'", str25, "hi!");
        org.junit.Assert.assertNotNull(headers26);
    }

    @Test
    public void test7110() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7110");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = offsetComparator7.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator7.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator13.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator20 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator20;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = kafkaSpoutMessageIdComparator15.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator15.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator7.thenComparing(kafkaSpoutMessageIdComparator24);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator7.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator31 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator31;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator31.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = kafkaSpoutMessageIdComparator26.thenComparing(kafkaSpoutMessageIdComparator34);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator36 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator37 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator37;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = offsetComparator37.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator40 = offsetComparator36.thenComparing(kafkaSpoutMessageIdComparator39);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator39;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator42 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator42;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = offsetComparator42.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator42;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator46 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator46;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator48 = offsetComparator46.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator49 = offsetComparator42.thenComparing(kafkaSpoutMessageIdComparator48);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator50 = kafkaSpoutMessageIdComparator48.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator51 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator51;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator53 = offsetComparator51.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator58 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator58;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator58);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator61 = kafkaSpoutMessageIdComparator53.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator58);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator62 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator62;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator64 = offsetComparator62.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator69 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator69;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator69);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator72 = kafkaSpoutMessageIdComparator64.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator69);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator73 = kafkaSpoutMessageIdComparator53.thenComparing(kafkaSpoutMessageIdComparator72);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator74 = kafkaSpoutMessageIdComparator73.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator75 = kafkaSpoutMessageIdComparator48.thenComparing(kafkaSpoutMessageIdComparator73);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator75;
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator75;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator78 = kafkaSpoutMessageIdComparator39.thenComparing(kafkaSpoutMessageIdComparator75);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator79 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator79;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator81 = offsetComparator79.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator86 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator86;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord88 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator86);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator89 = kafkaSpoutMessageIdComparator81.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator86);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator90 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator90;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator92 = offsetComparator90.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator93 = offsetComparator90.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator94 = offsetComparator86.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator90);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator95 = kafkaSpoutMessageIdComparator94.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator96 = kafkaSpoutMessageIdComparator94.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator97 = kafkaSpoutMessageIdComparator78.thenComparing(kafkaSpoutMessageIdComparator96);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator98 = kafkaSpoutMessageIdComparator34.thenComparing(kafkaSpoutMessageIdComparator97);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator40);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator48);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator49);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator50);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator53);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator61);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator64);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator72);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator73);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator74);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator75);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator78);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator81);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator89);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator92);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator93);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator94);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator95);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator96);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator97);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator98);
    }

    @Test
    public void test7111() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7111");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = strKafkaSpout0.tuplesBuilder;
        strKafkaSpout0.numUncommittedOffsets = 1L;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout10 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor11 = null;
        strKafkaSpout10.waitingToEmit = strConsumerRecordItor11;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer13 = null;
        strKafkaSpout10.kafkaConsumer = strKafkaConsumer13;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy15 = null;
        strKafkaSpout10.firstPollOffsetStrategy = firstPollOffsetStrategy15;
        java.lang.String str17 = strKafkaSpout10.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder18 = strKafkaSpout10.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder19 = null;
        strKafkaSpout10.tuplesBuilder = strKafkaSpoutTuplesBuilder19;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray21 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet22 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean23 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet22, kafkaSpoutMessageIdArray21);
        strKafkaSpout10.emitted = kafkaSpoutMessageIdSet22;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet22;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder7);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str17, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray21);
        org.junit.Assert.assertTrue("'" + boolean23 + "' != '" + false + "'", boolean23 == false);
    }

    @Test
    public void test7112() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7112");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        int int13 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence14 = charSequenceConsumerRecord10.key();
        java.lang.String str15 = charSequenceConsumerRecord10.topic();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.header.Headers headers17 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
        org.junit.Assert.assertEquals("'" + charSequence14 + "' != '" + "" + "'", charSequence14, "");
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "" + "'", str15, "");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertNotNull(headers17);
    }

    @Test
    public void test7113() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7113");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        int int3 = strKafkaSpout0.maxRetries;
        boolean boolean4 = strKafkaSpout0.waitingToEmit();
        org.apache.kafka.common.TopicPartition topicPartition5 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setAcked(topicPartition5, (long) 0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + 0 + "'", int3 == 0);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
    }

    @Test
    public void test7114() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7114");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition8 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection9 = strKafkaSpout0.toArrayList(topicPartition8);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = strKafkaSpout0.retryService;
        boolean boolean11 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService12 = strKafkaSpout0.retryService;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer13 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer13;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection9);
        org.junit.Assert.assertNull(kafkaSpoutRetryService10);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(kafkaSpoutRetryService12);
    }

    @Test
    public void test7115() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7115");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", (int) 'a', (long) 10, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        java.lang.CharSequence charSequence6 = charSequenceConsumerRecord5.key();
        org.apache.kafka.common.header.Headers headers7 = charSequenceConsumerRecord5.headers();
        long long8 = charSequenceConsumerRecord5.timestamp();
        org.apache.kafka.common.header.Headers headers9 = charSequenceConsumerRecord5.headers();
        long long10 = charSequenceConsumerRecord5.checksum();
        java.lang.CharSequence charSequence11 = charSequenceConsumerRecord5.key();
        org.junit.Assert.assertEquals("'" + charSequence6 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", charSequence6, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNotNull(headers7);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + (-1L) + "'", long8 == (-1L));
        org.junit.Assert.assertNotNull(headers9);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence11 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", charSequence11, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test7116() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7116");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        java.lang.String str17 = charSequenceConsumerRecord10.value();
        java.lang.String str18 = charSequenceConsumerRecord10.toString();
        java.lang.String str19 = charSequenceConsumerRecord10.toString();
        long long20 = charSequenceConsumerRecord10.timestamp();
        java.lang.CharSequence charSequence21 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str18, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str19, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence21 + "' != '" + "" + "'", charSequence21, "");
    }

    @Test
    public void test7117() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7117");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder2 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder2;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy4 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = strKafkaSpout0.kafkaSpoutConfig;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor7;
        org.apache.kafka.common.record.TimestampType timestampType13 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout17 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams18 = strKafkaSpout17.kafkaSpoutStreams;
        strKafkaSpout17.consumerAutoCommitMode = false;
        java.lang.String str21 = strKafkaSpout17.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout22 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout22.maxRetries = (byte) -1;
        int int25 = strKafkaSpout22.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray26 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet27 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean28 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet27, kafkaSpoutMessageIdArray26);
        strKafkaSpout22.emitted = kafkaSpoutMessageIdSet27;
        strKafkaSpout17.emitted = kafkaSpoutMessageIdSet27;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout31 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout31.maxRetries = (byte) -1;
        int int34 = strKafkaSpout31.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor35 = null;
        strKafkaSpout31.waitingToEmit = strConsumerRecordItor35;
        org.apache.kafka.common.TopicPartition topicPartition37 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection38 = strKafkaSpout31.toArrayList(topicPartition37);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer39 = strKafkaSpout31.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector40 = strKafkaSpout31.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout41 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout41.maxRetries = (byte) -1;
        int int44 = strKafkaSpout41.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray45 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet46 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean47 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet46, kafkaSpoutMessageIdArray45);
        strKafkaSpout41.emitted = kafkaSpoutMessageIdSet46;
        strKafkaSpout31.emitted = kafkaSpoutMessageIdSet46;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType13, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet27, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet46);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet27;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor52 = strKafkaSpout0.waitingToEmit;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strKafkaSpoutConfig6);
        org.junit.Assert.assertNull(kafkaSpoutStreams18);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str21, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + (-1) + "'", int25 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray26);
        org.junit.Assert.assertTrue("'" + boolean28 + "' != '" + false + "'", boolean28 == false);
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + (-1) + "'", int34 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection38);
        org.junit.Assert.assertNull(timer39);
        org.junit.Assert.assertNull(spoutOutputCollector40);
        org.junit.Assert.assertTrue("'" + int44 + "' != '" + (-1) + "'", int44 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray45);
        org.junit.Assert.assertTrue("'" + boolean47 + "' != '" + false + "'", boolean47 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor52);
    }

    @Test
    public void test7118() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7118");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", (int) (short) 10, (long) (short) 0, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)");
        java.lang.String str6 = charSequenceConsumerRecord5.value();
        java.lang.String str7 = charSequenceConsumerRecord5.value();
        java.lang.String str8 = charSequenceConsumerRecord5.topic();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)" + "'", str6, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)");
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)" + "'", str7, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)");
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})" + "'", str8, "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
    }

    @Test
    public void test7119() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7119");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout9 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout9.maxRetries = (byte) -1;
        int int12 = strKafkaSpout9.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor13 = null;
        strKafkaSpout9.waitingToEmit = strConsumerRecordItor13;
        org.apache.kafka.common.TopicPartition topicPartition15 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection16 = strKafkaSpout9.toArrayList(topicPartition15);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer17 = strKafkaSpout9.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector18 = strKafkaSpout9.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout19 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout19.maxRetries = (byte) -1;
        int int22 = strKafkaSpout19.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray23 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet24 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean25 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet24, kafkaSpoutMessageIdArray23);
        strKafkaSpout19.emitted = kafkaSpoutMessageIdSet24;
        strKafkaSpout9.emitted = kafkaSpoutMessageIdSet24;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet24;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder29 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder29;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy31 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy31;
        long long33 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService34 = strKafkaSpout0.retryService;
        strKafkaSpout0.initialized = false;
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection16);
        org.junit.Assert.assertNull(timer17);
        org.junit.Assert.assertNull(spoutOutputCollector18);
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray23);
        org.junit.Assert.assertTrue("'" + boolean25 + "' != '" + false + "'", boolean25 == false);
        org.junit.Assert.assertTrue("'" + long33 + "' != '" + 0L + "'", long33 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutRetryService34);
    }

    @Test
    public void test7120() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7120");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator4 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator4;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator6 = offsetComparator4.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator6);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator6;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator9 = kafkaSpoutMessageIdComparator6.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator10 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator10;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator10.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator17 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator17;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator17);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = kafkaSpoutMessageIdComparator12.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator17);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator21 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator21;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator24 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator24;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator24.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = offsetComparator23.thenComparing(kafkaSpoutMessageIdComparator26);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = offsetComparator21.thenComparing(kafkaSpoutMessageIdComparator27);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = offsetComparator17.thenComparing(kafkaSpoutMessageIdComparator28);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = kafkaSpoutMessageIdComparator29.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator31 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator31;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator33 = offsetComparator31.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator38 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator38;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord40 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator38);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = kafkaSpoutMessageIdComparator33.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator38);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator42 = offsetComparator38.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator43 = kafkaSpoutMessageIdComparator42.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = kafkaSpoutMessageIdComparator30.thenComparing(kafkaSpoutMessageIdComparator42);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator45 = kafkaSpoutMessageIdComparator30.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator46 = kafkaSpoutMessageIdComparator9.thenComparing(kafkaSpoutMessageIdComparator45);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator47 = kafkaSpoutMessageIdComparator9.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator6);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator9);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator33);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator42);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator43);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator46);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator47);
    }

    @Test
    public void test7121() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7121");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (-1), (long) ' ', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.util.Optional<java.lang.Integer> intOptional10 = charSequenceConsumerRecord9.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType11 = charSequenceConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType19, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long26 = charSequenceConsumerRecord25.checksum();
        int int27 = charSequenceConsumerRecord25.partition();
        long long28 = charSequenceConsumerRecord25.timestamp();
        long long29 = charSequenceConsumerRecord25.offset();
        int int30 = charSequenceConsumerRecord25.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType31 = charSequenceConsumerRecord25.timestampType();
        int int32 = charSequenceConsumerRecord25.partition();
        long long33 = charSequenceConsumerRecord25.checksum();
        java.util.Optional<java.lang.Integer> intOptional34 = charSequenceConsumerRecord25.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional35 = charSequenceConsumerRecord25.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType40, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long47 = charSequenceConsumerRecord46.offset();
        long long48 = charSequenceConsumerRecord46.timestamp();
        int int49 = charSequenceConsumerRecord46.partition();
        java.util.Optional<java.lang.Integer> intOptional50 = charSequenceConsumerRecord46.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>, java.util.Optional<java.lang.Integer>> charSequenceConsumerRecordConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>, java.util.Optional<java.lang.Integer>>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) '4', 100L, 10L, timestampType11, (long) 100, (int) (byte) 10, (int) (short) 100, charSequenceConsumerRecord25, intOptional50);
        org.junit.Assert.assertNotNull(intOptional10);
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + (-1L) + "'", long26 == (-1L));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + 10 + "'", int27 == 10);
        org.junit.Assert.assertTrue("'" + long28 + "' != '" + (-1L) + "'", long28 == (-1L));
        org.junit.Assert.assertTrue("'" + long29 + "' != '" + 0L + "'", long29 == 0L);
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + 52 + "'", int30 == 52);
        org.junit.Assert.assertNull(timestampType31);
        org.junit.Assert.assertTrue("'" + int32 + "' != '" + 10 + "'", int32 == 10);
        org.junit.Assert.assertTrue("'" + long33 + "' != '" + (-1L) + "'", long33 == (-1L));
        org.junit.Assert.assertNotNull(intOptional34);
        org.junit.Assert.assertNotNull(intOptional35);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 0L + "'", long47 == 0L);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 10 + "'", int49 == 10);
        org.junit.Assert.assertNotNull(intOptional50);
    }

    @Test
    public void test7122() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7122");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.header.Headers headers20 = charSequenceConsumerRecord10.headers();
        java.lang.String str21 = charSequenceConsumerRecord10.value();
        int int22 = charSequenceConsumerRecord10.serializedKeySize();
        long long23 = charSequenceConsumerRecord10.offset();
        long long24 = charSequenceConsumerRecord10.checksum();
        int int25 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.String str26 = charSequenceConsumerRecord10.topic();
        java.lang.CharSequence charSequence27 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "hi!" + "'", str21, "hi!");
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 52 + "'", int22 == 52);
        org.junit.Assert.assertTrue("'" + long23 + "' != '" + 0L + "'", long23 == 0L);
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + (-1L) + "'", long24 == (-1L));
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + 52 + "'", int25 == 52);
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "" + "'", str26, "");
        org.junit.Assert.assertEquals("'" + charSequence27 + "' != '" + "" + "'", charSequence27, "");
    }

    @Test
    public void test7123() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7123");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        long long7 = charSequenceConsumerRecord5.timestamp();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        java.lang.String str9 = charSequenceConsumerRecord5.toString();
        java.lang.String str10 = charSequenceConsumerRecord5.topic();
        int int11 = charSequenceConsumerRecord5.serializedKeySize();
        java.lang.Class<?> wildcardClass12 = charSequenceConsumerRecord5.getClass();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str9, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "" + "'", str10, "");
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertNotNull(wildcardClass12);
    }

    @Test
    public void test7124() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7124");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer1 = strKafkaSpout0.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector2 = strKafkaSpout0.collector;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector3 = strKafkaSpout0.collector;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams5 = strKafkaSpout0.kafkaSpoutStreams;
        org.junit.Assert.assertNull(timer1);
        org.junit.Assert.assertNull(spoutOutputCollector2);
        org.junit.Assert.assertNull(spoutOutputCollector3);
        org.junit.Assert.assertNull(strConsumerRecordItor4);
        org.junit.Assert.assertNull(kafkaSpoutStreams5);
    }

    @Test
    public void test7125() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7125");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector8 = null;
        strKafkaSpout0.collector = spoutOutputCollector8;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder10 = strKafkaSpout0.tuplesBuilder;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder10);
    }

    @Test
    public void test7126() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7126");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        long long8 = strKafkaSpout0.numUncommittedOffsets;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet9 = strKafkaSpout0.emitted;
        boolean boolean10 = strKafkaSpout0.waitingToEmit();
        java.lang.String str11 = strKafkaSpout0.toString();
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 0L + "'", long8 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet9);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str11, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test7127() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7127");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService3 = strKafkaSpout0.retryService;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams5 = strKafkaSpout0.kafkaSpoutStreams;
        org.junit.Assert.assertNull(kafkaSpoutRetryService3);
        org.junit.Assert.assertNull(strConsumerRecordItor4);
        org.junit.Assert.assertNull(kafkaSpoutStreams5);
    }

    @Test
    public void test7128() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7128");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.header.Headers headers14 = charSequenceConsumerRecord10.headers();
        long long15 = charSequenceConsumerRecord10.checksum();
        long long16 = charSequenceConsumerRecord10.timestamp();
        java.lang.CharSequence charSequence17 = charSequenceConsumerRecord10.key();
        long long18 = charSequenceConsumerRecord10.checksum();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertNotNull(headers14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence17 + "' != '" + "" + "'", charSequence17, "");
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(headers19);
    }

    @Test
    public void test7129() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7129");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator1 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator2 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator2;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator4 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator5 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator5;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator5.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator8 = offsetComparator4.thenComparing(kafkaSpoutMessageIdComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator9 = offsetComparator2.thenComparing(kafkaSpoutMessageIdComparator8);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = offsetComparator2.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = offsetComparator2.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator12 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator13.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator20 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator20;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = kafkaSpoutMessageIdComparator15.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = offsetComparator12.thenComparing(kafkaSpoutMessageIdComparator23);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator23;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = kafkaSpoutMessageIdComparator11.thenComparing(kafkaSpoutMessageIdComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator26);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator30 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator30;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator32 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator33 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator33;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = offsetComparator33.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = offsetComparator32.thenComparing(kafkaSpoutMessageIdComparator35);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = offsetComparator30.thenComparing(kafkaSpoutMessageIdComparator36);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = offsetComparator30.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = offsetComparator30.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator40 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator40;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator42 = offsetComparator40.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator47 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator47;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator47);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator50 = kafkaSpoutMessageIdComparator42.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator47);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator51 = offsetComparator47.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator52 = offsetComparator47.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator52;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator54 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator54;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator56 = offsetComparator54.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator61 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator61;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator61);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator64 = kafkaSpoutMessageIdComparator56.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator61);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator65 = kafkaSpoutMessageIdComparator56.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator66 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator67 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator67;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator69 = offsetComparator67.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator74 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator74;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator74);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator77 = kafkaSpoutMessageIdComparator69.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator74);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator78 = offsetComparator66.thenComparing(kafkaSpoutMessageIdComparator77);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator79 = kafkaSpoutMessageIdComparator65.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator66);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator79;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator81 = kafkaSpoutMessageIdComparator52.thenComparing(kafkaSpoutMessageIdComparator79);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator82 = kafkaSpoutMessageIdComparator79.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator83 = offsetComparator30.thenComparing(kafkaSpoutMessageIdComparator79);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator30;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator85 = offsetComparator0.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator30);
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId86 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId87 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int88 = offsetComparator0.compare(kafkaSpoutMessageId86, kafkaSpoutMessageId87);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator1);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator8);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator9);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator42);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator50);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator51);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator52);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator56);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator64);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator65);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator69);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator77);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator78);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator79);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator81);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator82);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator83);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator85);
    }

    @Test
    public void test7130() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7130");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = kafkaSpoutMessageIdComparator13.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator18);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator22 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator22;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = offsetComparator22.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator29 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator29;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator29);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = kafkaSpoutMessageIdComparator24.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator29);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator33 = kafkaSpoutMessageIdComparator13.thenComparing(kafkaSpoutMessageIdComparator32);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = kafkaSpoutMessageIdComparator10.thenComparing(kafkaSpoutMessageIdComparator32);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = kafkaSpoutMessageIdComparator10.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator39 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator39;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = offsetComparator39.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator46 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator46;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator46);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator49 = kafkaSpoutMessageIdComparator41.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator46);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator50 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator50;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator52 = offsetComparator50.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator57 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator57;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator57);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator60 = kafkaSpoutMessageIdComparator52.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator57);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator61 = kafkaSpoutMessageIdComparator41.thenComparing(kafkaSpoutMessageIdComparator60);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator62 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator62;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator64 = offsetComparator62.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator65 = offsetComparator62.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator66 = kafkaSpoutMessageIdComparator60.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator62);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator62;
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator62;
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator62;
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator, java.lang.Comparable<java.lang.String>> offsetComparatorConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, 1L, offsetComparator62, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator72 = offsetComparator62.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator73 = offsetComparator62.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator74 = kafkaSpoutMessageIdComparator73.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator75 = kafkaSpoutMessageIdComparator35.thenComparing(kafkaSpoutMessageIdComparator73);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator73;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator33);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator49);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator52);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator60);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator61);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator64);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator65);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator66);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator72);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator73);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator74);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator75);
    }

    @Test
    public void test7131() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7131");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        boolean boolean2 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.kafka.common.TopicPartition topicPartition3 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection4 = strKafkaSpout0.toArrayList(topicPartition3);
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor5 = strKafkaSpout0.waitingToEmit;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer6 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer6;
        int int8 = strKafkaSpout0.maxRetries;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertTrue("'" + boolean2 + "' != '" + false + "'", boolean2 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection4);
        org.junit.Assert.assertNull(strConsumerRecordItor5);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 0 + "'", int8 == 0);
    }

    @Test
    public void test7132() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7132");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService1 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService1;
        long long3 = strKafkaSpout0.numUncommittedOffsets;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = strKafkaSpout0.waitingToEmit;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = strKafkaSpout0.emitted;
        int int6 = strKafkaSpout0.maxRetries;
        int int7 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord8 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean9 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord8);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long3 + "' != '" + 0L + "'", long3 == 0L);
        org.junit.Assert.assertNull(strConsumerRecordItor4);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet5);
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + 0 + "'", int6 == 0);
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 0 + "'", int7 == 0);
    }

    @Test
    public void test7133() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7133");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        java.lang.String str11 = charSequenceConsumerRecord10.toString();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        long long13 = charSequenceConsumerRecord10.timestamp();
        int int14 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.String str15 = charSequenceConsumerRecord10.toString();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str17 = charSequenceConsumerRecord10.value();
        java.lang.CharSequence charSequence18 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str15, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertEquals("'" + charSequence18 + "' != '" + "" + "'", charSequence18, "");
    }

    @Test
    public void test7134() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7134");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy11 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy11;
        int int13 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = 0L;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + (-1) + "'", int13 == (-1));
    }

    @Test
    public void test7135() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7135");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 0, NoTimestampType = 0, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = )", (int) (short) 10, (long) 0, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 97, leaderEpoch = null, offset = 100, NoTimestampType = 97, serialized key size = 97, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=[]}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}))", 0, 97L, 32L, timestampType14, 0L, 10, (int) '#', (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null}), partition = 0, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)");
        org.apache.kafka.common.record.TimestampType timestampType28 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord34 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) ' ', (long) (byte) 100, (long) (byte) -1, timestampType28, (long) (byte) -1, (int) (byte) 10, 10, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long35 = charSequenceConsumerRecord34.timestamp();
        java.lang.String str36 = charSequenceConsumerRecord34.toString();
        long long37 = charSequenceConsumerRecord34.offset();
        java.lang.String str38 = charSequenceConsumerRecord34.value();
        java.util.Optional<java.lang.Integer> intOptional39 = charSequenceConsumerRecord34.leaderEpoch();
        org.apache.kafka.common.header.Headers headers40 = charSequenceConsumerRecord34.headers();
        org.apache.kafka.common.record.TimestampType timestampType45 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType45, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        java.lang.CharSequence charSequence52 = charSequenceConsumerRecord51.key();
        long long53 = charSequenceConsumerRecord51.timestamp();
        java.lang.String str54 = charSequenceConsumerRecord51.value();
        java.util.Optional<java.lang.Integer> intOptional55 = charSequenceConsumerRecord51.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Optional<java.lang.Integer>> headerIterableConsumerRecord56 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Optional<java.lang.Integer>>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}))", (int) (short) -1, (long) (byte) 0, (long) (byte) -1, timestampType14, 1L, (int) (short) -1, (int) (byte) -1, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers40, intOptional55);
        org.junit.Assert.assertTrue("'" + timestampType14 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType14.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long35 + "' != '" + (-1L) + "'", long35 == (-1L));
        org.junit.Assert.assertEquals("'" + str36 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str36, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + long37 + "' != '" + 100L + "'", long37 == 100L);
        org.junit.Assert.assertEquals("'" + str38 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str38, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(intOptional39);
        org.junit.Assert.assertNotNull(headers40);
        org.junit.Assert.assertEquals("'" + charSequence52 + "' != '" + "" + "'", charSequence52, "");
        org.junit.Assert.assertTrue("'" + long53 + "' != '" + (-1L) + "'", long53 == (-1L));
        org.junit.Assert.assertEquals("'" + str54 + "' != '" + "hi!" + "'", str54, "hi!");
        org.junit.Assert.assertNotNull(intOptional55);
    }

    @Test
    public void test7136() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7136");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        strKafkaSpout0.maxRetries = 1;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        boolean boolean5 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService6;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = strKafkaSpout0.kafkaSpoutStreams;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
// flaky:             org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertNull(kafkaSpoutStreams8);
    }

    @Test
    public void test7137() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7137");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        boolean boolean7 = strKafkaSpout0.initialized;
        strKafkaSpout0.consumerAutoCommitMode = true;
        boolean boolean10 = strKafkaSpout0.commit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor11 = strKafkaSpout0.waitingToEmit;
        org.apache.kafka.common.TopicPartition topicPartition12 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection13 = strKafkaSpout0.toArrayList(topicPartition12);
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig14 = strKafkaSpout0.kafkaSpoutConfig;
        boolean boolean15 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams16 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams16;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService18 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService18;
        boolean boolean20 = strKafkaSpout0.waitingToEmit();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor11);
        org.junit.Assert.assertNotNull(topicPartitionCollection13);
        org.junit.Assert.assertNull(strKafkaSpoutConfig14);
        org.junit.Assert.assertTrue("'" + boolean15 + "' != '" + false + "'", boolean15 == false);
        org.junit.Assert.assertTrue("'" + boolean20 + "' != '" + false + "'", boolean20 == false);
    }

    @Test
    public void test7138() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7138");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer16;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder18 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder18;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams20 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams20;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer22 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer22;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
    }

    @Test
    public void test7139() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7139");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams7;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = null;
        strKafkaSpout0.collector = spoutOutputCollector9;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = null;
        strKafkaSpout0.collector = spoutOutputCollector11;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams13 = strKafkaSpout0.kafkaSpoutStreams;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(kafkaSpoutStreams13);
    }

    @Test
    public void test7140() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7140");
        org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>, org.apache.storm.spout.ISpout> charSequenceConsumerRecordKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>, org.apache.storm.spout.ISpout>();
    }

    @Test
    public void test7141() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7141");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout11 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = strKafkaSpout11.kafkaSpoutStreams;
        strKafkaSpout11.consumerAutoCommitMode = false;
        java.lang.String str15 = strKafkaSpout11.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout16 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout16.maxRetries = (byte) -1;
        int int19 = strKafkaSpout16.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray20 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet21 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean22 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, kafkaSpoutMessageIdArray20);
        strKafkaSpout16.emitted = kafkaSpoutMessageIdSet21;
        strKafkaSpout11.emitted = kafkaSpoutMessageIdSet21;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout25 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout25.maxRetries = (byte) -1;
        int int28 = strKafkaSpout25.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor29 = null;
        strKafkaSpout25.waitingToEmit = strConsumerRecordItor29;
        org.apache.kafka.common.TopicPartition topicPartition31 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection32 = strKafkaSpout25.toArrayList(topicPartition31);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout25.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector34 = strKafkaSpout25.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout35.maxRetries = (byte) -1;
        int int38 = strKafkaSpout35.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray39 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet40 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean41 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40, kafkaSpoutMessageIdArray39);
        strKafkaSpout35.emitted = kafkaSpoutMessageIdSet40;
        strKafkaSpout25.emitted = kafkaSpoutMessageIdSet40;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType7, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet40;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector46 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer47 = strKafkaSpout0.commitTimer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor48 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor48;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy50 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder51 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder51;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(strKafkaSpoutConfig2);
        org.junit.Assert.assertNull(kafkaSpoutStreams12);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray20);
        org.junit.Assert.assertTrue("'" + boolean22 + "' != '" + false + "'", boolean22 == false);
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + (-1) + "'", int28 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection32);
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(spoutOutputCollector34);
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + (-1) + "'", int38 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray39);
        org.junit.Assert.assertTrue("'" + boolean41 + "' != '" + false + "'", boolean41 == false);
        org.junit.Assert.assertNull(spoutOutputCollector46);
        org.junit.Assert.assertNull(timer47);
        org.junit.Assert.assertNull(firstPollOffsetStrategy50);
    }

    @Test
    public void test7142() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7142");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = strKafkaSpout0.kafkaConsumer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor5 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor5;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setAcked(topicPartition10, (long) (short) 10);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer4);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
    }

    @Test
    public void test7143() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7143");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType14 = null;
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.common.record.TimestampType timestampType37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType37, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int44 = charSequenceConsumerRecord43.serializedValueSize();
        java.lang.CharSequence charSequence45 = charSequenceConsumerRecord43.key();
        org.apache.kafka.common.header.Headers headers46 = charSequenceConsumerRecord43.headers();
        java.util.Optional<java.lang.Integer> intOptional47 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType27, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers46, intOptional47);
        org.apache.kafka.common.record.TimestampType timestampType56 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord62 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType56, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int63 = charSequenceConsumerRecord62.serializedValueSize();
        java.lang.CharSequence charSequence64 = charSequenceConsumerRecord62.key();
        org.apache.kafka.common.header.Headers headers65 = charSequenceConsumerRecord62.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray66 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList67 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean68 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList67, kafkaSpoutMessageIdArray66);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers65, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList67);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headersConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("", (int) '#', 1L, headers46, kafkaSpoutMessageIdList67);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType14, (java.lang.Long) (-1L), (int) (short) 100, 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}", headers46);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) 10, (long) (byte) -1, (long) '#', timestampType4, (java.lang.Long) 100L, (int) (byte) -1, 100, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers46);
        java.lang.String str73 = charSequenceConsumerRecord72.toString();
        int int74 = charSequenceConsumerRecord72.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType75 = charSequenceConsumerRecord72.timestampType();
        long long76 = charSequenceConsumerRecord72.timestamp();
        org.junit.Assert.assertTrue("'" + int44 + "' != '" + (-1) + "'", int44 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence45 + "' != '" + "" + "'", charSequence45, "");
        org.junit.Assert.assertNotNull(headers46);
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + (-1) + "'", int63 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence64 + "' != '" + "" + "'", charSequence64, "");
        org.junit.Assert.assertNotNull(headers65);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray66);
        org.junit.Assert.assertTrue("'" + boolean68 + "' != '" + false + "'", boolean68 == false);
        org.junit.Assert.assertEquals("'" + str73 + "' != '" + "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str73, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + int74 + "' != '" + 100 + "'", int74 == 100);
        org.junit.Assert.assertNull(timestampType75);
        org.junit.Assert.assertTrue("'" + long76 + "' != '" + 35L + "'", long76 == 35L);
    }

    @Test
    public void test7144() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7144");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor11 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.initialized = false;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(strConsumerRecordItor11);
    }

    @Test
    public void test7145() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7145");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str16 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.header.Headers headers17 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 52 + "'", int14 == 52);
        org.junit.Assert.assertNull(timestampType15);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "hi!" + "'", str16, "hi!");
        org.junit.Assert.assertNotNull(headers17);
    }

    @Test
    public void test7146() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7146");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = strKafkaSpout0.collector;
        java.lang.String str10 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService11 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService11;
        strKafkaSpout0.maxRetries = (byte) -1;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(spoutOutputCollector9);
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str10, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test7147() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7147");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (-1), (long) ' ', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.util.Optional<java.lang.Integer> intOptional6 = charSequenceConsumerRecord5.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType7 = charSequenceConsumerRecord5.timestampType();
        java.lang.String str8 = charSequenceConsumerRecord5.value();
        org.junit.Assert.assertNotNull(intOptional6);
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str8, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test7148() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7148");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams1;
        strKafkaSpout0.maxRetries = '#';
    }

    @Test
    public void test7149() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7149");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence17 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence18 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType20 = charSequenceConsumerRecord10.timestampType();
        int int21 = charSequenceConsumerRecord10.partition();
        int int22 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertEquals("'" + charSequence17 + "' != '" + "" + "'", charSequence17, "");
        org.junit.Assert.assertEquals("'" + charSequence18 + "' != '" + "" + "'", charSequence18, "");
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertNull(timestampType20);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 10 + "'", int21 == 10);
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 10 + "'", int22 == 10);
        org.junit.Assert.assertNull(timestampType23);
    }

    @Test
    public void test7150() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7150");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        java.lang.String str8 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer9 = strKafkaSpout0.commitTimer;
        int int10 = strKafkaSpout0.maxRetries;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(timer9);
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + 0 + "'", int10 == 0);
    }

    @Test
    public void test7151() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7151");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService1 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService1;
        long long3 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy4 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy4;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet8 = strKafkaSpout0.emitted;
        java.lang.String str9 = strKafkaSpout0.toString();
        org.junit.Assert.assertTrue("'" + long3 + "' != '" + 0L + "'", long3 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str9, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test7152() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7152");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        strKafkaSpout0.maxRetries = (byte) 10;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig8 = strKafkaSpout0.kafkaSpoutConfig;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean9 = strKafkaSpout0.commit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig8);
    }

    @Test
    public void test7153() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7153");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder12 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder12;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder14 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder14;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer16 = strKafkaSpout0.commitTimer;
        strKafkaSpout0.maxRetries = 100;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNull(timer16);
    }

    @Test
    public void test7154() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7154");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator3 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator3;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator5 = kafkaSpoutMessageIdComparator3.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator6 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator6;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator8 = offsetComparator6.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord15 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator13);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = kafkaSpoutMessageIdComparator8.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator13);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = offsetComparator13.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = offsetComparator13.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = kafkaSpoutMessageIdComparator18.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = kafkaSpoutMessageIdComparator5.thenComparing(kafkaSpoutMessageIdComparator19);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator21 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator22 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator22;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = offsetComparator22.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator29 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator29;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator29);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = kafkaSpoutMessageIdComparator24.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator29);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator33 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator33;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = offsetComparator33.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = offsetComparator33.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = offsetComparator29.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator33);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = offsetComparator21.thenComparing(kafkaSpoutMessageIdComparator37);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator39 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator40 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator40;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator42 = offsetComparator40.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator43 = offsetComparator39.thenComparing(kafkaSpoutMessageIdComparator42);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator44 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator44;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator46 = offsetComparator44.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator51 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator51;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator51);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator54 = kafkaSpoutMessageIdComparator46.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator51);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator55 = offsetComparator39.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator51);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator55;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator57 = kafkaSpoutMessageIdComparator55.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator58 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator59 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator59;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator61 = offsetComparator59.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator66 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator66;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator66);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator69 = kafkaSpoutMessageIdComparator61.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator66);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator70 = offsetComparator58.thenComparing(kafkaSpoutMessageIdComparator69);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator71 = kafkaSpoutMessageIdComparator55.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator58);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator72 = offsetComparator21.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator58);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator73 = kafkaSpoutMessageIdComparator20.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator21);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator74 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator74;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator76 = offsetComparator74.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator74;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator78 = kafkaSpoutMessageIdComparator20.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator74);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator74;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator3);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator5);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator8);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator42);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator43);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator46);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator54);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator57);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator61);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator69);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator70);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator71);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator72);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator73);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator76);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator78);
    }

    @Test
    public void test7155() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7155");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        strKafkaSpout0.maxRetries = (short) 0;
        strKafkaSpout0.maxRetries = (short) -1;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams7;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer9 = strKafkaSpout0.commitTimer;
        org.junit.Assert.assertNull(timer9);
    }

    @Test
    public void test7156() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7156");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        long long8 = strKafkaSpout0.numUncommittedOffsets;
        strKafkaSpout0.numUncommittedOffsets = (-1L);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = null;
        strKafkaSpout0.collector = spoutOutputCollector12;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 0L + "'", long8 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer11);
    }

    @Test
    public void test7157() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7157");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        java.util.Optional<java.lang.Integer> intOptional18 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.CharSequence charSequence19 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertNotNull(intOptional18);
        org.junit.Assert.assertEquals("'" + charSequence19 + "' != '" + "" + "'", charSequence19, "");
    }

    @Test
    public void test7158() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7158");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = ' ';
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig10 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig10;
        java.lang.String str12 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy13 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector14 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams15 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams15;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str12, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(firstPollOffsetStrategy13);
        org.junit.Assert.assertNull(spoutOutputCollector14);
    }

    @Test
    public void test7159() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7159");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer4;
        long long6 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder7;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + 0L + "'", long6 == 0L);
    }

    @Test
    public void test7160() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7160");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig5;
        strKafkaSpout0.maxRetries = (short) 0;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams9 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams9;
        int int11 = strKafkaSpout0.maxRetries;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 0 + "'", int11 == 0);
    }

    @Test
    public void test7161() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7161");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout19 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout19.maxRetries = (byte) -1;
        int int22 = strKafkaSpout19.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor23 = null;
        strKafkaSpout19.waitingToEmit = strConsumerRecordItor23;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer25 = strKafkaSpout19.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer26 = strKafkaSpout19.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType32, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long39 = charSequenceConsumerRecord38.offset();
        long long40 = charSequenceConsumerRecord38.checksum();
        int int41 = charSequenceConsumerRecord38.serializedKeySize();
        org.apache.kafka.common.header.Headers headers42 = charSequenceConsumerRecord38.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType15, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout19, (java.lang.CharSequence) "hi!", headers42);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType53, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long60 = charSequenceConsumerRecord59.checksum();
        int int61 = charSequenceConsumerRecord59.partition();
        long long62 = charSequenceConsumerRecord59.offset();
        org.apache.kafka.common.header.Headers headers63 = charSequenceConsumerRecord59.headers();
        org.apache.kafka.common.record.TimestampType timestampType68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType68, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long75 = charSequenceConsumerRecord74.offset();
        int int76 = charSequenceConsumerRecord74.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional77 = charSequenceConsumerRecord74.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) 10, 10L, 0L, timestampType15, (java.lang.Long) 35L, (int) (byte) 0, (-1), (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers63, intOptional77);
        long long79 = charSequenceConsumerRecord78.checksum();
        java.lang.CharSequence charSequence80 = charSequenceConsumerRecord78.key();
        int int81 = charSequenceConsumerRecord78.partition();
        java.lang.CharSequence charSequence82 = charSequenceConsumerRecord78.key();
        java.lang.String str83 = charSequenceConsumerRecord78.value();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertNull(timer25);
        org.junit.Assert.assertNull(strKafkaConsumer26);
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + 0L + "'", long39 == 0L);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + 52 + "'", int41 == 52);
        org.junit.Assert.assertNotNull(headers42);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + 10 + "'", int61 == 10);
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + 0L + "'", long62 == 0L);
        org.junit.Assert.assertNotNull(headers63);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + 0L + "'", long75 == 0L);
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + (-1) + "'", int76 == (-1));
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertTrue("'" + long79 + "' != '" + 35L + "'", long79 == 35L);
        org.junit.Assert.assertEquals("'" + charSequence80 + "' != '" + "hi!" + "'", charSequence80, "hi!");
        org.junit.Assert.assertTrue("'" + int81 + "' != '" + 10 + "'", int81 == 10);
        org.junit.Assert.assertEquals("'" + charSequence82 + "' != '" + "hi!" + "'", charSequence82, "hi!");
        org.junit.Assert.assertEquals("'" + str83 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str83, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test7162() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7162");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy6 = strKafkaSpout0.firstPollOffsetStrategy;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str7 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(firstPollOffsetStrategy6);
    }

    @Test
    public void test7163() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7163");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = kafkaSpoutMessageIdComparator13.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = kafkaSpoutMessageIdComparator2.thenComparing(kafkaSpoutMessageIdComparator21);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator23;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator23.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator23.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = kafkaSpoutMessageIdComparator21.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator23);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator28 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator28;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = offsetComparator28.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator35 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator35;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator35);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = kafkaSpoutMessageIdComparator30.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator35);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = offsetComparator35.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator40 = offsetComparator35.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator41 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator41;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator43 = offsetComparator41.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator48 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator48;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord50 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator48);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator51 = kafkaSpoutMessageIdComparator43.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator48);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator52 = kafkaSpoutMessageIdComparator43.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator53 = offsetComparator35.thenComparing(kafkaSpoutMessageIdComparator52);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator54 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator55 = offsetComparator54.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator56 = kafkaSpoutMessageIdComparator53.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator54);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator57 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator57;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator59 = offsetComparator57.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator64 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator64;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord66 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator64);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator67 = kafkaSpoutMessageIdComparator59.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator64);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator68 = kafkaSpoutMessageIdComparator59.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator69 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator69;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator71 = offsetComparator69.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator69;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator73 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator73;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator75 = offsetComparator73.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator76 = offsetComparator69.thenComparing(kafkaSpoutMessageIdComparator75);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator77 = kafkaSpoutMessageIdComparator75.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator78 = kafkaSpoutMessageIdComparator68.thenComparing(kafkaSpoutMessageIdComparator75);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator79 = kafkaSpoutMessageIdComparator53.thenComparing(kafkaSpoutMessageIdComparator78);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator80 = offsetComparator23.thenComparing(kafkaSpoutMessageIdComparator79);
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId81 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId82 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int83 = offsetComparator23.compare(kafkaSpoutMessageId81, kafkaSpoutMessageId82);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator40);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator43);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator51);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator52);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator53);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator56);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator59);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator67);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator68);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator71);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator75);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator76);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator77);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator78);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator79);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator80);
    }

    @Test
    public void test7164() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7164");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = strKafkaSpout0.tuplesBuilder;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer8 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer8;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy10 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy10;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy12 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.kafka.common.TopicPartition topicPartition13 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection14 = strKafkaSpout0.toArrayList(topicPartition13);
        strKafkaSpout0.numUncommittedOffsets = 97;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams17 = strKafkaSpout0.kafkaSpoutStreams;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder7);
        org.junit.Assert.assertNull(firstPollOffsetStrategy12);
        org.junit.Assert.assertNotNull(topicPartitionCollection14);
        org.junit.Assert.assertNull(kafkaSpoutStreams17);
    }

    @Test
    public void test7165() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7165");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 97, leaderEpoch = null, offset = 100, NoTimestampType = 97, serialized key size = 97, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=[]}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (byte) 0, 52L, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 97, leaderEpoch = null, offset = 100, NoTimestampType = 97, serialized key size = 97, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=[]}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        int int6 = charSequenceConsumerRecord5.partition();
        org.apache.kafka.common.header.Headers headers7 = charSequenceConsumerRecord5.headers();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + 0 + "'", int6 == 0);
        org.junit.Assert.assertNotNull(headers7);
    }

    @Test
    public void test7166() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7166");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long22 = charSequenceConsumerRecord21.checksum();
        long long23 = charSequenceConsumerRecord21.timestamp();
        int int24 = charSequenceConsumerRecord21.partition();
        org.apache.kafka.common.record.TimestampType timestampType25 = charSequenceConsumerRecord21.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord36 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (-1), (long) ' ', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long37 = charSequenceConsumerRecord36.timestamp();
        java.lang.String str38 = charSequenceConsumerRecord36.topic();
        org.apache.kafka.common.header.Headers headers39 = charSequenceConsumerRecord36.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord40 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", (int) 'a', 52L, (long) 35, timestampType25, (java.lang.Long) 1L, (int) (byte) 0, (int) ' ', (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=[]}", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", headers39);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", 100, (long) (byte) 1, (long) (byte) 1, timestampType25, (long) 10, 10, (int) (short) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", 32, 1L, 0L, timestampType25, (long) (byte) 0, (int) (short) 1, 97, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 35, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)))", "ConsumerRecord(topic = hi!, partition = 0, leaderEpoch = null, offset = -1, null = 100, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long68 = charSequenceConsumerRecord67.checksum();
        long long69 = charSequenceConsumerRecord67.timestamp();
        int int70 = charSequenceConsumerRecord67.partition();
        org.apache.kafka.common.record.TimestampType timestampType71 = charSequenceConsumerRecord67.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (-1), (long) ' ', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long83 = charSequenceConsumerRecord82.timestamp();
        java.lang.String str84 = charSequenceConsumerRecord82.topic();
        org.apache.kafka.common.header.Headers headers85 = charSequenceConsumerRecord82.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", (int) 'a', 52L, (long) 35, timestampType71, (java.lang.Long) 1L, (int) (byte) 0, (int) ' ', (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=[]}", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", headers85);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord87 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)", (-1), (long) (byte) 1, 1L, timestampType25, (java.lang.Long) 100L, (int) (byte) 100, (int) (short) 1, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "KafkaSpout{acked=null, emitted=[]}", headers85);
        org.apache.kafka.common.record.TimestampType timestampType88 = charSequenceConsumerRecord87.timestampType();
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
        org.junit.Assert.assertTrue("'" + long23 + "' != '" + (-1L) + "'", long23 == (-1L));
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + 100 + "'", int24 == 100);
        org.junit.Assert.assertTrue("'" + timestampType25 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType25.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long37 + "' != '" + (-1L) + "'", long37 == (-1L));
        org.junit.Assert.assertEquals("'" + str38 + "' != '" + "hi!" + "'", str38, "hi!");
        org.junit.Assert.assertNotNull(headers39);
        org.junit.Assert.assertTrue("'" + long68 + "' != '" + (-1L) + "'", long68 == (-1L));
        org.junit.Assert.assertTrue("'" + long69 + "' != '" + (-1L) + "'", long69 == (-1L));
        org.junit.Assert.assertTrue("'" + int70 + "' != '" + 100 + "'", int70 == 100);
        org.junit.Assert.assertTrue("'" + timestampType71 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType71.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + (-1L) + "'", long83 == (-1L));
        org.junit.Assert.assertEquals("'" + str84 + "' != '" + "hi!" + "'", str84, "hi!");
        org.junit.Assert.assertNotNull(headers85);
        org.junit.Assert.assertTrue("'" + timestampType88 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType88.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test7167() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7167");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy3 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy4 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = strKafkaSpout0.firstPollOffsetStrategy;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor6 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor6;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy8 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy8;
        boolean boolean10 = strKafkaSpout0.consumerAutoCommitMode;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str11 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(firstPollOffsetStrategy3);
        org.junit.Assert.assertNull(firstPollOffsetStrategy4);
        org.junit.Assert.assertNull(firstPollOffsetStrategy5);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
    }

    @Test
    public void test7168() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7168");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = strKafkaSpout0.firstPollOffsetStrategy;
        int int8 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = (byte) 10;
        java.util.Map map11 = null;
        org.apache.storm.task.TopologyContext topologyContext12 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector13 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map11, topologyContext12, spoutOutputCollector13);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 0 + "'", int8 == 0);
    }

    @Test
    public void test7169() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7169");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType23, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long30 = charSequenceConsumerRecord29.checksum();
        int int31 = charSequenceConsumerRecord29.partition();
        java.lang.String str32 = charSequenceConsumerRecord29.value();
        int int33 = charSequenceConsumerRecord29.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional34 = charSequenceConsumerRecord29.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet36 = strKafkaSpout35.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor37 = null;
        strKafkaSpout35.waitingToEmit = strConsumerRecordItor37;
        boolean boolean39 = strKafkaSpout35.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig40 = null;
        strKafkaSpout35.kafkaSpoutConfig = strKafkaSpoutConfig40;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy42 = strKafkaSpout35.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType15, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord29, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout35);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType53, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long60 = charSequenceConsumerRecord59.checksum();
        int int61 = charSequenceConsumerRecord59.partition();
        java.lang.String str62 = charSequenceConsumerRecord59.value();
        int int63 = charSequenceConsumerRecord59.serializedKeySize();
        org.apache.kafka.common.header.Headers headers64 = charSequenceConsumerRecord59.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str71 = charSequenceConsumerRecord70.topic();
        java.util.Optional<java.lang.Integer> intOptional72 = charSequenceConsumerRecord70.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 0, (long) (short) 10, (long) (-1), timestampType15, (java.lang.Long) 35L, 10, (int) (short) 10, (java.lang.CharSequence) "", "KafkaSpout{acked=null, emitted=null}", headers64, intOptional72);
        java.util.Optional<java.lang.Integer> intOptional74 = charSequenceConsumerRecord73.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType75 = charSequenceConsumerRecord73.timestampType();
        java.lang.Class<?> wildcardClass76 = timestampType75.getClass();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 10 + "'", int31 == 10);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "hi!" + "'", str32, "hi!");
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + 52 + "'", int33 == 52);
        org.junit.Assert.assertNotNull(intOptional34);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet36);
        org.junit.Assert.assertTrue("'" + boolean39 + "' != '" + false + "'", boolean39 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy42);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + 10 + "'", int61 == 10);
        org.junit.Assert.assertEquals("'" + str62 + "' != '" + "hi!" + "'", str62, "hi!");
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 52 + "'", int63 == 52);
        org.junit.Assert.assertNotNull(headers64);
        org.junit.Assert.assertEquals("'" + str71 + "' != '" + "" + "'", str71, "");
        org.junit.Assert.assertNotNull(intOptional72);
        org.junit.Assert.assertNotNull(intOptional74);
        org.junit.Assert.assertTrue("'" + timestampType75 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType75.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass76);
    }

    @Test
    public void test7170() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7170");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig3 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = strKafkaSpout0.kafkaSpoutStreams;
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNull(kafkaSpoutStreams8);
    }

    @Test
    public void test7171() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7171");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        java.lang.String str12 = charSequenceConsumerRecord10.value();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.String str15 = charSequenceConsumerRecord10.toString();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str15, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers16);
    }

    @Test
    public void test7172() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7172");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator12 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator12;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = offsetComparator12.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator19 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator19;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator19);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = kafkaSpoutMessageIdComparator14.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator19);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = offsetComparator11.thenComparing(kafkaSpoutMessageIdComparator22);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator22.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator25 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator25;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = offsetComparator25.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator25;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator29 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator29;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = offsetComparator29.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = offsetComparator25.thenComparing(kafkaSpoutMessageIdComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator33 = offsetComparator25.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = kafkaSpoutMessageIdComparator24.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator25);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = kafkaSpoutMessageIdComparator24.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = kafkaSpoutMessageIdComparator10.thenComparing(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator33);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
    }

    @Test
    public void test7173() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7173");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout3 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout3.maxRetries = (byte) -1;
        int int6 = strKafkaSpout3.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout3.waitingToEmit = strConsumerRecordItor7;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout3.toArrayList(topicPartition9);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = strKafkaSpout3.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType16 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout20 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout20.maxRetries = (byte) -1;
        int int23 = strKafkaSpout20.maxRetries;
        strKafkaSpout20.numUncommittedOffsets = '#';
        strKafkaSpout20.initialized = true;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet28 = strKafkaSpout20.emitted;
        org.apache.kafka.common.record.TimestampType timestampType36 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType36, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int43 = charSequenceConsumerRecord42.serializedValueSize();
        java.lang.CharSequence charSequence44 = charSequenceConsumerRecord42.key();
        org.apache.kafka.common.header.Headers headers45 = charSequenceConsumerRecord42.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray46 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList47 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean48 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47, kafkaSpoutMessageIdArray46);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers45, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47);
        org.apache.kafka.common.record.TimestampType timestampType54 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType54, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int61 = charSequenceConsumerRecord60.serializedValueSize();
        java.lang.CharSequence charSequence62 = charSequenceConsumerRecord60.key();
        org.apache.kafka.common.header.Headers headers63 = charSequenceConsumerRecord60.headers();
        org.apache.kafka.common.record.TimestampType timestampType68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType68, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long75 = charSequenceConsumerRecord74.offset();
        int int76 = charSequenceConsumerRecord74.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional77 = charSequenceConsumerRecord74.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> objConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) '4', (long) (short) 0, (long) 100, timestampType16, (java.lang.Long) 1L, (int) (short) 0, 0, (java.lang.Object) kafkaSpoutMessageIdSet28, (java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47, headers63, intOptional77);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.common.header.Headers> iSpoutConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.common.header.Headers>("KafkaSpout{acked=null, emitted=null}", (int) '#', (long) 1, (org.apache.storm.spout.ISpout) strKafkaSpout3, headers63);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer80 = strKafkaSpout3.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService81 = strKafkaSpout3.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder82 = strKafkaSpout3.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy83 = strKafkaSpout3.firstPollOffsetStrategy;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout3.commitOffsetsForAckedTuples();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(strKafkaConsumer11);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet28);
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + (-1) + "'", int43 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence44 + "' != '" + "" + "'", charSequence44, "");
        org.junit.Assert.assertNotNull(headers45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray46);
        org.junit.Assert.assertTrue("'" + boolean48 + "' != '" + false + "'", boolean48 == false);
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + (-1) + "'", int61 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence62 + "' != '" + "" + "'", charSequence62, "");
        org.junit.Assert.assertNotNull(headers63);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + 0L + "'", long75 == 0L);
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + (-1) + "'", int76 == (-1));
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertNull(timer80);
        org.junit.Assert.assertNull(kafkaSpoutRetryService81);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder82);
        org.junit.Assert.assertNull(firstPollOffsetStrategy83);
    }

    @Test
    public void test7174() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7174");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType14, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int21 = charSequenceConsumerRecord20.serializedValueSize();
        java.lang.CharSequence charSequence22 = charSequenceConsumerRecord20.key();
        org.apache.kafka.common.header.Headers headers23 = charSequenceConsumerRecord20.headers();
        java.util.Optional<java.lang.Integer> intOptional24 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType4, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers23, intOptional24);
        long long26 = charSequenceConsumerRecord25.checksum();
        long long27 = charSequenceConsumerRecord25.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType28 = charSequenceConsumerRecord25.timestampType();
        int int29 = charSequenceConsumerRecord25.serializedValueSize();
        int int30 = charSequenceConsumerRecord25.serializedKeySize();
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence22 + "' != '" + "" + "'", charSequence22, "");
        org.junit.Assert.assertNotNull(headers23);
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + (-1L) + "'", long26 == (-1L));
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + 35L + "'", long27 == 35L);
        org.junit.Assert.assertNull(timestampType28);
        org.junit.Assert.assertTrue("'" + int29 + "' != '" + 0 + "'", int29 == 0);
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + 1 + "'", int30 == 1);
    }

    @Test
    public void test7175() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7175");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = kafkaSpoutMessageIdComparator13.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = kafkaSpoutMessageIdComparator2.thenComparing(kafkaSpoutMessageIdComparator21);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator24 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator24;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator24.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator31 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator31;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = kafkaSpoutMessageIdComparator26.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = offsetComparator23.thenComparing(kafkaSpoutMessageIdComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = kafkaSpoutMessageIdComparator34.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator37 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator37;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = offsetComparator37.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator44 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator44;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator44);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator47 = kafkaSpoutMessageIdComparator39.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator44);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator48 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator48;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator50 = offsetComparator48.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator55 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator55;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator55);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator58 = kafkaSpoutMessageIdComparator50.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator55);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator59 = kafkaSpoutMessageIdComparator39.thenComparing(kafkaSpoutMessageIdComparator58);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator60 = kafkaSpoutMessageIdComparator58.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator61 = kafkaSpoutMessageIdComparator34.thenComparing(kafkaSpoutMessageIdComparator58);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator62 = kafkaSpoutMessageIdComparator22.thenComparing(kafkaSpoutMessageIdComparator58);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator62;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator64 = kafkaSpoutMessageIdComparator62.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator65 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator66 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator67 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator67;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator69 = offsetComparator67.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator74 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator74;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator74);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator77 = kafkaSpoutMessageIdComparator69.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator74);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator78 = offsetComparator66.thenComparing(kafkaSpoutMessageIdComparator77);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator79 = kafkaSpoutMessageIdComparator77.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator80 = offsetComparator65.thenComparing(kafkaSpoutMessageIdComparator79);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator81 = kafkaSpoutMessageIdComparator64.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator65);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator82 = kafkaSpoutMessageIdComparator64.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator83 = kafkaSpoutMessageIdComparator64.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator47);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator50);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator58);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator59);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator60);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator61);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator62);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator64);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator69);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator77);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator78);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator79);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator80);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator81);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator82);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator83);
    }

    @Test
    public void test7176() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7176");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) ' ', (long) (byte) 100, (long) (byte) -1, timestampType4, (long) (byte) -1, (int) (byte) 10, 10, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long11 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str12 = charSequenceConsumerRecord10.toString();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional15 = charSequenceConsumerRecord10.leaderEpoch();
        int int16 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str12, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
    }

    @Test
    public void test7177() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7177");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str18 = charSequenceConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = charSequenceConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long34 = charSequenceConsumerRecord33.checksum();
        int int35 = charSequenceConsumerRecord33.partition();
        long long36 = charSequenceConsumerRecord33.timestamp();
        java.lang.String str37 = charSequenceConsumerRecord33.toString();
        long long38 = charSequenceConsumerRecord33.timestamp();
        org.apache.kafka.common.header.Headers headers39 = charSequenceConsumerRecord33.headers();
        org.apache.kafka.common.record.TimestampType timestampType40 = charSequenceConsumerRecord33.timestampType();
        java.util.Optional<java.lang.Integer> intOptional41 = charSequenceConsumerRecord33.leaderEpoch();
        org.apache.storm.topology.IComponent iComponent42 = null;
        org.apache.kafka.common.record.TimestampType timestampType47 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord53 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType47, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long54 = charSequenceConsumerRecord53.checksum();
        int int55 = charSequenceConsumerRecord53.partition();
        long long56 = charSequenceConsumerRecord53.timestamp();
        java.lang.String str57 = charSequenceConsumerRecord53.toString();
        org.apache.kafka.common.header.Headers headers58 = charSequenceConsumerRecord53.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent> intOptionalConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent>("hi!", (int) ' ', (long) (byte) -1, (long) (-1), timestampType19, (java.lang.Long) 100L, (int) 'a', (-1), intOptional41, iComponent42, headers58);
        org.apache.kafka.common.record.TimestampType timestampType69 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType69, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long76 = charSequenceConsumerRecord75.checksum();
        int int77 = charSequenceConsumerRecord75.partition();
        long long78 = charSequenceConsumerRecord75.timestamp();
        long long79 = charSequenceConsumerRecord75.offset();
        int int80 = charSequenceConsumerRecord75.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType81 = charSequenceConsumerRecord75.timestampType();
        int int82 = charSequenceConsumerRecord75.partition();
        long long83 = charSequenceConsumerRecord75.checksum();
        java.util.Optional<java.lang.Integer> intOptional84 = charSequenceConsumerRecord75.leaderEpoch();
        org.apache.kafka.common.header.Headers headers85 = charSequenceConsumerRecord75.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) 'a', (-1L), (long) 10, timestampType19, (java.lang.Long) 1L, 97, (int) (short) 1, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=[]}", "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", headers85);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord92 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 35, (long) (-1), 0L, timestampType19, (long) (-1), 100, (int) (byte) 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 0, NoTimestampType = 0, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = )", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 97, leaderEpoch = null, offset = 100, NoTimestampType = 97, serialized key size = 97, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=[]}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        long long93 = charSequenceConsumerRecord92.checksum();
        long long94 = charSequenceConsumerRecord92.timestamp();
        long long95 = charSequenceConsumerRecord92.checksum();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertTrue("'" + int35 + "' != '" + 10 + "'", int35 == 10);
        org.junit.Assert.assertTrue("'" + long36 + "' != '" + (-1L) + "'", long36 == (-1L));
        org.junit.Assert.assertEquals("'" + str37 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str37, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + (-1L) + "'", long38 == (-1L));
        org.junit.Assert.assertNotNull(headers39);
        org.junit.Assert.assertNull(timestampType40);
        org.junit.Assert.assertNotNull(intOptional41);
        org.junit.Assert.assertTrue("'" + long54 + "' != '" + (-1L) + "'", long54 == (-1L));
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + 10 + "'", int55 == 10);
        org.junit.Assert.assertTrue("'" + long56 + "' != '" + (-1L) + "'", long56 == (-1L));
        org.junit.Assert.assertEquals("'" + str57 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str57, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers58);
        org.junit.Assert.assertTrue("'" + long76 + "' != '" + (-1L) + "'", long76 == (-1L));
        org.junit.Assert.assertTrue("'" + int77 + "' != '" + 10 + "'", int77 == 10);
        org.junit.Assert.assertTrue("'" + long78 + "' != '" + (-1L) + "'", long78 == (-1L));
        org.junit.Assert.assertTrue("'" + long79 + "' != '" + 0L + "'", long79 == 0L);
        org.junit.Assert.assertTrue("'" + int80 + "' != '" + 52 + "'", int80 == 52);
        org.junit.Assert.assertNull(timestampType81);
        org.junit.Assert.assertTrue("'" + int82 + "' != '" + 10 + "'", int82 == 10);
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + (-1L) + "'", long83 == (-1L));
        org.junit.Assert.assertNotNull(intOptional84);
        org.junit.Assert.assertNotNull(headers85);
        org.junit.Assert.assertTrue("'" + long93 + "' != '" + (-1L) + "'", long93 == (-1L));
        org.junit.Assert.assertTrue("'" + long94 + "' != '" + 0L + "'", long94 == 0L);
        org.junit.Assert.assertTrue("'" + long95 + "' != '" + (-1L) + "'", long95 == (-1L));
    }

    @Test
    public void test7178() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7178");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig9 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig9;
        java.lang.String str11 = strKafkaSpout0.toString();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor12 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy13 = strKafkaSpout0.firstPollOffsetStrategy;
        strKafkaSpout0.consumerAutoCommitMode = true;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Map<java.lang.String, java.lang.Object> strMap16 = strKafkaSpout0.getComponentConfiguration();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "KafkaSpout{acked=null, emitted=[]}" + "'", str11, "KafkaSpout{acked=null, emitted=[]}");
        org.junit.Assert.assertNull(strConsumerRecordItor12);
        org.junit.Assert.assertNull(firstPollOffsetStrategy13);
    }

    @Test
    public void test7179() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7179");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers12 = charSequenceConsumerRecord10.headers();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        java.lang.String str14 = charSequenceConsumerRecord10.topic();
        long long15 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
    }

    @Test
    public void test7180() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7180");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout27 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout27.maxRetries = (byte) -1;
        int int30 = strKafkaSpout27.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor31 = null;
        strKafkaSpout27.waitingToEmit = strConsumerRecordItor31;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout27.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer34 = strKafkaSpout27.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType40, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long47 = charSequenceConsumerRecord46.offset();
        long long48 = charSequenceConsumerRecord46.checksum();
        int int49 = charSequenceConsumerRecord46.serializedKeySize();
        org.apache.kafka.common.header.Headers headers50 = charSequenceConsumerRecord46.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType23, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout27, (java.lang.CharSequence) "hi!", headers50);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 1, 0L, (long) (byte) 0, timestampType23, (long) ' ', (int) (short) -1, (int) (byte) 10, (java.lang.CharSequence) "", "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) -1, (long) ' ', (long) (short) 0, timestampType23, (long) (short) 1, (int) (byte) 10, (int) '#', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        org.apache.kafka.common.record.TimestampType timestampType73 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType73, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        java.lang.String str80 = charSequenceConsumerRecord79.topic();
        org.apache.kafka.common.header.Headers headers81 = charSequenceConsumerRecord79.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 0, (long) 52, (long) (byte) -1, timestampType23, (java.lang.Long) 1L, (int) (short) 0, (-1), (java.lang.CharSequence) "hi!", "hi!", headers81);
        long long83 = charSequenceConsumerRecord82.timestamp();
        long long84 = charSequenceConsumerRecord82.checksum();
        java.util.Optional<java.lang.Integer> intOptional85 = charSequenceConsumerRecord82.leaderEpoch();
        int int86 = charSequenceConsumerRecord82.serializedValueSize();
        java.lang.String str87 = charSequenceConsumerRecord82.toString();
        java.lang.String str88 = charSequenceConsumerRecord82.topic();
        long long89 = charSequenceConsumerRecord82.offset();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(strKafkaConsumer34);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 0L + "'", long47 == 0L);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 52 + "'", int49 == 52);
        org.junit.Assert.assertNotNull(headers50);
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "hi!" + "'", str80, "hi!");
        org.junit.Assert.assertNotNull(headers81);
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + (-1L) + "'", long83 == (-1L));
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + 1L + "'", long84 == 1L);
        org.junit.Assert.assertNotNull(intOptional85);
        org.junit.Assert.assertTrue("'" + int86 + "' != '" + (-1) + "'", int86 == (-1));
        org.junit.Assert.assertEquals("'" + str87 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)" + "'", str87, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)");
        org.junit.Assert.assertEquals("'" + str88 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str88, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + long89 + "' != '" + 52L + "'", long89 == 52L);
    }

    @Test
    public void test7181() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7181");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService11 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService11;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig13 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig13;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.emit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer10);
    }

    @Test
    public void test7182() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7182");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams6 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig7 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer8 = strKafkaSpout0.kafkaConsumer;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutStreams6);
        org.junit.Assert.assertNull(strKafkaSpoutConfig7);
        org.junit.Assert.assertNull(strKafkaConsumer8);
    }

    @Test
    public void test7183() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7183");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = strKafkaSpout0.kafkaConsumer;
        java.lang.String str8 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig11;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = strKafkaSpout0.emitted;
        int int14 = strKafkaSpout0.maxRetries;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertNull(strKafkaConsumer7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
    }

    @Test
    public void test7184() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7184");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = strKafkaSpout0.tuplesBuilder;
        boolean boolean10 = strKafkaSpout0.initialized;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer13 = strKafkaSpout0.kafkaConsumer;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder9);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNull(strKafkaConsumer13);
    }

    @Test
    public void test7185() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7185");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        boolean boolean7 = strKafkaSpout0.initialized;
        strKafkaSpout0.consumerAutoCommitMode = true;
        boolean boolean10 = strKafkaSpout0.commit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor11 = strKafkaSpout0.waitingToEmit;
        org.apache.kafka.common.TopicPartition topicPartition12 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection13 = strKafkaSpout0.toArrayList(topicPartition12);
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig14 = strKafkaSpout0.kafkaSpoutConfig;
        boolean boolean15 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams16 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams16;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet18 = strKafkaSpout0.emitted;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor11);
        org.junit.Assert.assertNotNull(topicPartitionCollection13);
        org.junit.Assert.assertNull(strKafkaSpoutConfig14);
        org.junit.Assert.assertTrue("'" + boolean15 + "' != '" + false + "'", boolean15 == false);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet18);
    }

    @Test
    public void test7186() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7186");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        long long13 = charSequenceConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers14 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertNotNull(headers14);
    }

    @Test
    public void test7187() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7187");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 1, 1L, (long) (byte) 10, timestampType4, (long) '#', (int) (byte) 100, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        java.lang.String str11 = charSequenceConsumerRecord10.value();
        java.lang.String str12 = charSequenceConsumerRecord10.topic();
        int int13 = charSequenceConsumerRecord10.partition();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.header.Headers headers15 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str12, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 1 + "'", int13 == 1);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 100 + "'", int14 == 100);
        org.junit.Assert.assertNotNull(headers15);
    }

    @Test
    public void test7188() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7188");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        boolean boolean2 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.kafka.common.TopicPartition topicPartition3 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection4 = strKafkaSpout0.toArrayList(topicPartition3);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService5 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams6 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams6;
        strKafkaSpout0.maxRetries = 32;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Map<java.lang.String, java.lang.Object> strMap10 = strKafkaSpout0.getComponentConfiguration();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertTrue("'" + boolean2 + "' != '" + false + "'", boolean2 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection4);
        org.junit.Assert.assertNull(kafkaSpoutRetryService5);
    }

    @Test
    public void test7189() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7189");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray6 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet7 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean8 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet7, kafkaSpoutMessageIdArray6);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet7;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer10 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService11 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService11;
        boolean boolean13 = strKafkaSpout0.initialized;
        boolean boolean14 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector15 = strKafkaSpout0.collector;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.commitOffsetsForAckedTuples();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray6);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
        org.junit.Assert.assertNull(timer10);
        org.junit.Assert.assertTrue("'" + boolean13 + "' != '" + false + "'", boolean13 == false);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertNull(spoutOutputCollector15);
    }

    @Test
    public void test7190() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7190");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 1, 1L, (long) (byte) 10, timestampType4, (long) '#', (int) (byte) 100, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        java.lang.String str11 = charSequenceConsumerRecord10.value();
        java.lang.String str12 = charSequenceConsumerRecord10.topic();
        java.lang.String str13 = charSequenceConsumerRecord10.toString();
        int int14 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str12, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )" + "'", str13, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
    }

    @Test
    public void test7191() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7191");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        java.lang.String str12 = charSequenceConsumerRecord10.toString();
        int int13 = charSequenceConsumerRecord10.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional14 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str12, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 52 + "'", int13 == 52);
        org.junit.Assert.assertNotNull(intOptional14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test7192() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7192");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor10 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor10;
        org.apache.kafka.common.TopicPartition topicPartition12 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection13 = strKafkaSpout0.toArrayList(topicPartition12);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer14 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer14;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService16 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService16;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection13);
    }

    @Test
    public void test7193() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7193");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long14 = charSequenceConsumerRecord13.checksum();
        long long15 = charSequenceConsumerRecord13.timestamp();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord13.headers();
        java.lang.String str17 = charSequenceConsumerRecord13.toString();
        org.apache.kafka.common.header.Headers headers18 = charSequenceConsumerRecord13.headers();
        java.lang.String str19 = charSequenceConsumerRecord13.topic();
        long long20 = charSequenceConsumerRecord13.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType21 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (byte) 1, (long) 100, timestampType21, (long) 1, 35, (int) (byte) 10, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.apache.kafka.common.header.Headers headers28 = charSequenceConsumerRecord27.headers();
        org.apache.kafka.common.record.TimestampType timestampType29 = charSequenceConsumerRecord27.timestampType();
        java.lang.CharSequence charSequence33 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 0, 35L, 10L, timestampType29, (long) (short) -1, (int) (byte) 100, 32, charSequence33, "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str17, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "" + "'", str19, "");
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType21 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType21.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers28);
        org.junit.Assert.assertTrue("'" + timestampType29 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType29.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test7194() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7194");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout19 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout19.maxRetries = (byte) -1;
        int int22 = strKafkaSpout19.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor23 = null;
        strKafkaSpout19.waitingToEmit = strConsumerRecordItor23;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer25 = strKafkaSpout19.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer26 = strKafkaSpout19.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType32, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long39 = charSequenceConsumerRecord38.offset();
        long long40 = charSequenceConsumerRecord38.checksum();
        int int41 = charSequenceConsumerRecord38.serializedKeySize();
        org.apache.kafka.common.header.Headers headers42 = charSequenceConsumerRecord38.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType15, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout19, (java.lang.CharSequence) "hi!", headers42);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType53, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long60 = charSequenceConsumerRecord59.checksum();
        int int61 = charSequenceConsumerRecord59.partition();
        long long62 = charSequenceConsumerRecord59.offset();
        org.apache.kafka.common.header.Headers headers63 = charSequenceConsumerRecord59.headers();
        org.apache.kafka.common.record.TimestampType timestampType68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType68, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long75 = charSequenceConsumerRecord74.offset();
        int int76 = charSequenceConsumerRecord74.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional77 = charSequenceConsumerRecord74.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) 10, 10L, 0L, timestampType15, (java.lang.Long) 35L, (int) (byte) 0, (-1), (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers63, intOptional77);
        long long79 = charSequenceConsumerRecord78.checksum();
        java.lang.CharSequence charSequence80 = charSequenceConsumerRecord78.key();
        int int81 = charSequenceConsumerRecord78.partition();
        org.apache.kafka.common.record.TimestampType timestampType82 = charSequenceConsumerRecord78.timestampType();
        java.lang.Class<?> wildcardClass83 = timestampType82.getClass();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertNull(timer25);
        org.junit.Assert.assertNull(strKafkaConsumer26);
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + 0L + "'", long39 == 0L);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + 52 + "'", int41 == 52);
        org.junit.Assert.assertNotNull(headers42);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + 10 + "'", int61 == 10);
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + 0L + "'", long62 == 0L);
        org.junit.Assert.assertNotNull(headers63);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + 0L + "'", long75 == 0L);
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + (-1) + "'", int76 == (-1));
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertTrue("'" + long79 + "' != '" + 35L + "'", long79 == 35L);
        org.junit.Assert.assertEquals("'" + charSequence80 + "' != '" + "hi!" + "'", charSequence80, "hi!");
        org.junit.Assert.assertTrue("'" + int81 + "' != '" + 10 + "'", int81 == 10);
        org.junit.Assert.assertTrue("'" + timestampType82 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType82.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(wildcardClass83);
    }

    @Test
    public void test7195() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7195");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (-1), (long) ' ', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.util.Optional<java.lang.Integer> intOptional6 = charSequenceConsumerRecord5.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional7 = charSequenceConsumerRecord5.leaderEpoch();
        long long8 = charSequenceConsumerRecord5.timestamp();
        java.lang.String str9 = charSequenceConsumerRecord5.topic();
        org.junit.Assert.assertNotNull(intOptional6);
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + (-1L) + "'", long8 == (-1L));
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "hi!" + "'", str9, "hi!");
    }

    @Test
    public void test7196() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7196");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=[]}", (int) (byte) -1, (long) '4', (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "hi!");
        java.lang.String str6 = charSequenceConsumerRecord5.topic();
        int int7 = charSequenceConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional8 = charSequenceConsumerRecord5.leaderEpoch();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "KafkaSpout{acked=null, emitted=[]}" + "'", str6, "KafkaSpout{acked=null, emitted=[]}");
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(intOptional8);
    }

    @Test
    public void test7197() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7197");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer16;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector18 = null;
        strKafkaSpout0.collector = spoutOutputCollector18;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor20 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor20;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService22 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService22;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor24 = strKafkaSpout0.waitingToEmit;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Map<java.lang.String, java.lang.Object> strMap25 = strKafkaSpout0.getComponentConfiguration();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor24);
    }

    @Test
    public void test7198() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7198");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout3 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout3.maxRetries = (byte) -1;
        int int6 = strKafkaSpout3.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout3.waitingToEmit = strConsumerRecordItor7;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout3.toArrayList(topicPartition9);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = strKafkaSpout3.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType16 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout20 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout20.maxRetries = (byte) -1;
        int int23 = strKafkaSpout20.maxRetries;
        strKafkaSpout20.numUncommittedOffsets = '#';
        strKafkaSpout20.initialized = true;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet28 = strKafkaSpout20.emitted;
        org.apache.kafka.common.record.TimestampType timestampType36 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType36, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int43 = charSequenceConsumerRecord42.serializedValueSize();
        java.lang.CharSequence charSequence44 = charSequenceConsumerRecord42.key();
        org.apache.kafka.common.header.Headers headers45 = charSequenceConsumerRecord42.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray46 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList47 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean48 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47, kafkaSpoutMessageIdArray46);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers45, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47);
        org.apache.kafka.common.record.TimestampType timestampType54 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType54, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int61 = charSequenceConsumerRecord60.serializedValueSize();
        java.lang.CharSequence charSequence62 = charSequenceConsumerRecord60.key();
        org.apache.kafka.common.header.Headers headers63 = charSequenceConsumerRecord60.headers();
        org.apache.kafka.common.record.TimestampType timestampType68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType68, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long75 = charSequenceConsumerRecord74.offset();
        int int76 = charSequenceConsumerRecord74.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional77 = charSequenceConsumerRecord74.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> objConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) '4', (long) (short) 0, (long) 100, timestampType16, (java.lang.Long) 1L, (int) (short) 0, 0, (java.lang.Object) kafkaSpoutMessageIdSet28, (java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47, headers63, intOptional77);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.common.header.Headers> iSpoutConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.common.header.Headers>("KafkaSpout{acked=null, emitted=null}", (int) '#', (long) 1, (org.apache.storm.spout.ISpout) strKafkaSpout3, headers63);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService80 = null;
        strKafkaSpout3.retryService = kafkaSpoutRetryService80;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy82 = null;
        strKafkaSpout3.firstPollOffsetStrategy = firstPollOffsetStrategy82;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor84 = null;
        strKafkaSpout3.waitingToEmit = strConsumerRecordItor84;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet86 = strKafkaSpout3.emitted;
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(strKafkaConsumer11);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet28);
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + (-1) + "'", int43 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence44 + "' != '" + "" + "'", charSequence44, "");
        org.junit.Assert.assertNotNull(headers45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray46);
        org.junit.Assert.assertTrue("'" + boolean48 + "' != '" + false + "'", boolean48 == false);
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + (-1) + "'", int61 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence62 + "' != '" + "" + "'", charSequence62, "");
        org.junit.Assert.assertNotNull(headers63);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + 0L + "'", long75 == 0L);
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + (-1) + "'", int76 == (-1));
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet86);
    }

    @Test
    public void test7199() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7199");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams10;
        strKafkaSpout0.numUncommittedOffsets = ' ';
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy14 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy14;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer16 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer16);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
    }

    @Test
    public void test7200() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7200");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType13 = charSequenceConsumerRecord10.timestampType();
        long long14 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers15 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNull(timestampType13);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertNotNull(headers15);
        org.junit.Assert.assertNull(timestampType16);
    }

    @Test
    public void test7201() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7201");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        java.lang.String str4 = strKafkaSpout0.toString();
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer7;
        java.lang.String str9 = strKafkaSpout0.toString();
        boolean boolean10 = strKafkaSpout0.initialized;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        int int12 = strKafkaSpout0.maxRetries;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertEquals("'" + str4 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str4, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str9, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 0 + "'", int12 == 0);
    }

    @Test
    public void test7202() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7202");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.util.Optional<java.lang.Integer> intOptional16 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str17 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        java.lang.CharSequence charSequence19 = charSequenceConsumerRecord10.key();
        int int20 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertEquals("'" + charSequence19 + "' != '" + "" + "'", charSequence19, "");
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 10 + "'", int20 == 10);
    }

    @Test
    public void test7203() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7203");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers12 = charSequenceConsumerRecord10.headers();
        int int13 = charSequenceConsumerRecord10.serializedKeySize();
        int int14 = charSequenceConsumerRecord10.serializedValueSize();
        int int15 = charSequenceConsumerRecord10.serializedValueSize();
        int int16 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 52 + "'", int13 == 52);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 52 + "'", int16 == 52);
    }

    @Test
    public void test7204() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7204");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (-1), (long) ' ', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.util.Optional<java.lang.Integer> intOptional6 = charSequenceConsumerRecord5.leaderEpoch();
        java.util.Optional<java.lang.Integer> intOptional7 = charSequenceConsumerRecord5.leaderEpoch();
        java.lang.CharSequence charSequence8 = charSequenceConsumerRecord5.key();
        long long9 = charSequenceConsumerRecord5.offset();
        java.lang.CharSequence charSequence10 = charSequenceConsumerRecord5.key();
        java.lang.Class<?> wildcardClass11 = charSequenceConsumerRecord5.getClass();
        org.junit.Assert.assertNotNull(intOptional6);
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertEquals("'" + charSequence8 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence8, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 32L + "'", long9 == 32L);
        org.junit.Assert.assertEquals("'" + charSequence10 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence10, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(wildcardClass11);
    }

    @Test
    public void test7205() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7205");
        org.apache.storm.kafka.spout.KafkaSpout kafkaSpout0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.storm.topology.base.BaseRichSpout, java.util.AbstractCollection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>.Timer timer1 = kafkaSpout0.new Timer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: reflection call to org.apache.storm.kafka.spout.KafkaSpout$Timer with null for superclass argument");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test7206() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7206");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (byte) 0, (long) (byte) -1, (long) (short) 100, timestampType4, (long) (short) 1, (int) (byte) 1, (int) (short) 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        long long11 = charSequenceConsumerRecord10.offset();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord10.timestampType();
        int int13 = charSequenceConsumerRecord10.serializedKeySize();
        long long14 = charSequenceConsumerRecord10.checksum();
        long long15 = charSequenceConsumerRecord10.timestamp();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNull(timestampType12);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 1 + "'", int13 == 1);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 1L + "'", long14 == 1L);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 100L + "'", long15 == 100L);
    }

    @Test
    public void test7207() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7207");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout11 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = strKafkaSpout11.kafkaSpoutStreams;
        strKafkaSpout11.consumerAutoCommitMode = false;
        java.lang.String str15 = strKafkaSpout11.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout16 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout16.maxRetries = (byte) -1;
        int int19 = strKafkaSpout16.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray20 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet21 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean22 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, kafkaSpoutMessageIdArray20);
        strKafkaSpout16.emitted = kafkaSpoutMessageIdSet21;
        strKafkaSpout11.emitted = kafkaSpoutMessageIdSet21;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout25 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout25.maxRetries = (byte) -1;
        int int28 = strKafkaSpout25.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor29 = null;
        strKafkaSpout25.waitingToEmit = strConsumerRecordItor29;
        org.apache.kafka.common.TopicPartition topicPartition31 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection32 = strKafkaSpout25.toArrayList(topicPartition31);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout25.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector34 = strKafkaSpout25.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout35.maxRetries = (byte) -1;
        int int38 = strKafkaSpout35.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray39 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet40 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean41 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40, kafkaSpoutMessageIdArray39);
        strKafkaSpout35.emitted = kafkaSpoutMessageIdSet40;
        strKafkaSpout25.emitted = kafkaSpoutMessageIdSet40;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType7, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet21, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet40);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet40;
        strKafkaSpout0.maxRetries = '4';
        strKafkaSpout0.numUncommittedOffsets = 0L;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor50 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector51 = strKafkaSpout0.collector;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(strKafkaSpoutConfig2);
        org.junit.Assert.assertNull(kafkaSpoutStreams12);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray20);
        org.junit.Assert.assertTrue("'" + boolean22 + "' != '" + false + "'", boolean22 == false);
        org.junit.Assert.assertTrue("'" + int28 + "' != '" + (-1) + "'", int28 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection32);
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(spoutOutputCollector34);
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + (-1) + "'", int38 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray39);
        org.junit.Assert.assertTrue("'" + boolean41 + "' != '" + false + "'", boolean41 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor50);
        org.junit.Assert.assertNull(spoutOutputCollector51);
    }

    @Test
    public void test7208() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7208");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        long long16 = charSequenceConsumerRecord10.offset();
        java.lang.CharSequence charSequence17 = charSequenceConsumerRecord10.key();
        java.util.Optional<java.lang.Integer> intOptional18 = charSequenceConsumerRecord10.leaderEpoch();
        long long19 = charSequenceConsumerRecord10.checksum();
        java.lang.String str20 = charSequenceConsumerRecord10.topic();
        int int21 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertEquals("'" + charSequence17 + "' != '" + "" + "'", charSequence17, "");
        org.junit.Assert.assertNotNull(intOptional18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "" + "'", str20, "");
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 10 + "'", int21 == 10);
    }

    @Test
    public void test7209() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7209");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = strKafkaSpout0.tuplesBuilder;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer8 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer8;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy10 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy10;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy12 = strKafkaSpout0.firstPollOffsetStrategy;
        strKafkaSpout0.initialized = true;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long21 = charSequenceConsumerRecord20.checksum();
        long long22 = charSequenceConsumerRecord20.timestamp();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.fail((java.lang.Object) charSequenceConsumerRecord20);
            org.junit.Assert.fail("Expected exception of type java.lang.ClassCastException; message: org.apache.kafka.clients.consumer.ConsumerRecord cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId");
        } catch (java.lang.ClassCastException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder7);
        org.junit.Assert.assertNull(firstPollOffsetStrategy12);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
    }

    @Test
    public void test7210() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7210");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        java.lang.String str4 = strKafkaSpout0.toString();
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer7;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = strKafkaSpout0.retryService;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer11;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService13 = strKafkaSpout0.retryService;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertEquals("'" + str4 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str4, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(firstPollOffsetStrategy9);
        org.junit.Assert.assertNull(kafkaSpoutRetryService10);
        org.junit.Assert.assertNull(kafkaSpoutRetryService13);
    }

    @Test
    public void test7211() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7211");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers12 = charSequenceConsumerRecord10.headers();
        int int13 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.CharSequence charSequence14 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 52 + "'", int13 == 52);
        org.junit.Assert.assertEquals("'" + charSequence14 + "' != '" + "" + "'", charSequence14, "");
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
    }

    @Test
    public void test7212() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7212");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", (int) '#', (long) '4', (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        java.lang.String str6 = charSequenceConsumerRecord5.topic();
        int int7 = charSequenceConsumerRecord5.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional8 = charSequenceConsumerRecord5.leaderEpoch();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", str6, "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertNotNull(intOptional8);
    }

    @Test
    public void test7213() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7213");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> typeKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>();
    }

    @Test
    public void test7214() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7214");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer4 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy7;
        strKafkaSpout0.numUncommittedOffsets = 35;
        strKafkaSpout0.numUncommittedOffsets = 97L;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig13 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer14 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer14;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer4);
        org.junit.Assert.assertNull(strKafkaSpoutConfig13);
    }

    @Test
    public void test7215() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7215");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition8 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection9 = strKafkaSpout0.toArrayList(topicPartition8);
        boolean boolean10 = strKafkaSpout0.initialized;
        int int11 = strKafkaSpout0.maxRetries;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet12 = strKafkaSpout0.emitted;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords13 = strKafkaSpout0.pollKafkaBroker();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection9);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet12);
    }

    @Test
    public void test7216() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7216");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        boolean boolean7 = strKafkaSpout0.initialized;
        strKafkaSpout0.maxRetries = (byte) 10;
        strKafkaSpout0.maxRetries = 97;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
    }

    @Test
    public void test7217() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7217");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy3 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy4 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = strKafkaSpout0.firstPollOffsetStrategy;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor6 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor6;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy8 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy8;
        strKafkaSpout0.maxRetries = (byte) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor12 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor12;
        org.junit.Assert.assertNull(firstPollOffsetStrategy3);
        org.junit.Assert.assertNull(firstPollOffsetStrategy4);
        org.junit.Assert.assertNull(firstPollOffsetStrategy5);
    }

    @Test
    public void test7218() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7218");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        strKafkaSpout0.maxRetries = 'a';
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor11 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor11;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer15 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer15);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
    }

    @Test
    public void test7219() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7219");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        long long16 = charSequenceConsumerRecord10.offset();
        long long17 = charSequenceConsumerRecord10.checksum();
        java.lang.CharSequence charSequence18 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence18 + "' != '" + "" + "'", charSequence18, "");
    }

    @Test
    public void test7220() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7220");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService5 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = strKafkaSpout0.kafkaSpoutConfig;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + 0 + "'", int3 == 0);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertNull(kafkaSpoutRetryService5);
        org.junit.Assert.assertNull(strKafkaSpoutConfig6);
    }

    @Test
    public void test7221() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7221");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = kafkaSpoutMessageIdComparator13.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator18);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator22 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator22;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = offsetComparator22.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator29 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator29;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator29);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = kafkaSpoutMessageIdComparator24.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator29);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator33 = kafkaSpoutMessageIdComparator13.thenComparing(kafkaSpoutMessageIdComparator32);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator7.thenComparing(kafkaSpoutMessageIdComparator33);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator35 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator35;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = offsetComparator35.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator42 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator42;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord44 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator42);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator45 = kafkaSpoutMessageIdComparator37.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator42);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator46 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator46;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator48 = offsetComparator46.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator53 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator53;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord55 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator53);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator56 = kafkaSpoutMessageIdComparator48.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator53);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator57 = kafkaSpoutMessageIdComparator37.thenComparing(kafkaSpoutMessageIdComparator56);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator58 = kafkaSpoutMessageIdComparator34.thenComparing(kafkaSpoutMessageIdComparator56);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator59 = kafkaSpoutMessageIdComparator56.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator33);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator48);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator56);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator57);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator58);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator59);
    }

    @Test
    public void test7222() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7222");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        boolean boolean2 = strKafkaSpout0.waitingToEmit();
        boolean boolean3 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer4 = strKafkaSpout0.commitTimer;
        boolean boolean5 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        int int7 = strKafkaSpout0.maxRetries;
        java.util.Map map8 = null;
        org.apache.storm.task.TopologyContext topologyContext9 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector10 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map8, topologyContext9, spoutOutputCollector10);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertTrue("'" + boolean2 + "' != '" + false + "'", boolean2 == false);
        org.junit.Assert.assertTrue("'" + boolean3 + "' != '" + false + "'", boolean3 == false);
        org.junit.Assert.assertNull(timer4);
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 0 + "'", int7 == 0);
    }

    @Test
    public void test7223() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7223");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.offset();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        int int16 = charSequenceConsumerRecord10.partition();
        java.lang.String str17 = charSequenceConsumerRecord10.topic();
        long long18 = charSequenceConsumerRecord10.offset();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertNotNull(intOptional19);
    }

    @Test
    public void test7224() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7224");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType17 = null;
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int34 = charSequenceConsumerRecord33.serializedValueSize();
        java.lang.CharSequence charSequence35 = charSequenceConsumerRecord33.key();
        org.apache.kafka.common.header.Headers headers36 = charSequenceConsumerRecord33.headers();
        java.util.Optional<java.lang.Integer> intOptional37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType17, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers36, intOptional37);
        org.apache.kafka.common.record.TimestampType timestampType46 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType46, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int53 = charSequenceConsumerRecord52.serializedValueSize();
        java.lang.CharSequence charSequence54 = charSequenceConsumerRecord52.key();
        org.apache.kafka.common.header.Headers headers55 = charSequenceConsumerRecord52.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray56 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList57 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean58 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57, kafkaSpoutMessageIdArray56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers55, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headersConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("", (int) '#', 1L, headers36, kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType4, (java.lang.Long) (-1L), (int) (short) 100, 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}", headers36);
        int int62 = charSequenceConsumerRecord61.partition();
        java.lang.String str63 = charSequenceConsumerRecord61.topic();
        int int64 = charSequenceConsumerRecord61.partition();
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + (-1) + "'", int34 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence35 + "' != '" + "" + "'", charSequence35, "");
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + (-1) + "'", int53 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence54 + "' != '" + "" + "'", charSequence54, "");
        org.junit.Assert.assertNotNull(headers55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray56);
        org.junit.Assert.assertTrue("'" + boolean58 + "' != '" + false + "'", boolean58 == false);
        org.junit.Assert.assertTrue("'" + int62 + "' != '" + 97 + "'", int62 == 97);
        org.junit.Assert.assertEquals("'" + str63 + "' != '" + "hi!" + "'", str63, "hi!");
        org.junit.Assert.assertTrue("'" + int64 + "' != '" + 97 + "'", int64 == 97);
    }

    @Test
    public void test7225() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7225");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        java.lang.String str4 = strKafkaSpout0.toString();
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer7;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = strKafkaSpout0.retryService;
        strKafkaSpout0.maxRetries = 10;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService13 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService13;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertEquals("'" + str4 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str4, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(firstPollOffsetStrategy9);
        org.junit.Assert.assertNull(kafkaSpoutRetryService10);
    }

    @Test
    public void test7226() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7226");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType13 = charSequenceConsumerRecord10.timestampType();
        int int14 = charSequenceConsumerRecord10.partition();
        int int15 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str18 = charSequenceConsumerRecord10.topic();
        long long19 = charSequenceConsumerRecord10.timestamp();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNull(timestampType13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
    }

    @Test
    public void test7227() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7227");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        long long12 = charSequenceConsumerRecord10.offset();
        int int13 = charSequenceConsumerRecord10.partition();
        int int14 = charSequenceConsumerRecord10.partition();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional16 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 0L + "'", long12 == 0L);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNotNull(intOptional16);
    }

    @Test
    public void test7228() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7228");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder2 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder2;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy4 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = strKafkaSpout0.kafkaSpoutConfig;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor7;
        strKafkaSpout0.maxRetries = (byte) 10;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strKafkaSpoutConfig6);
    }

    @Test
    public void test7229() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7229");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition8 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection9 = strKafkaSpout0.toArrayList(topicPartition8);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer10;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy12 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector13 = strKafkaSpout0.collector;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection9);
        org.junit.Assert.assertNull(firstPollOffsetStrategy12);
        org.junit.Assert.assertNull(spoutOutputCollector13);
    }

    @Test
    public void test7230() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7230");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType4, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        java.lang.CharSequence charSequence11 = charSequenceConsumerRecord10.key();
        java.lang.String str12 = charSequenceConsumerRecord10.topic();
        int int13 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertEquals("'" + charSequence11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "hi!" + "'", str12, "hi!");
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
    }

    @Test
    public void test7231() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7231");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence17 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence18 = charSequenceConsumerRecord10.key();
        long long19 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers20 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertEquals("'" + charSequence17 + "' != '" + "" + "'", charSequence17, "");
        org.junit.Assert.assertEquals("'" + charSequence18 + "' != '" + "" + "'", charSequence18, "");
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertNotNull(headers20);
    }

    @Test
    public void test7232() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7232");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType31 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType31, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long38 = charSequenceConsumerRecord37.checksum();
        int int39 = charSequenceConsumerRecord37.partition();
        long long40 = charSequenceConsumerRecord37.timestamp();
        java.lang.String str41 = charSequenceConsumerRecord37.toString();
        long long42 = charSequenceConsumerRecord37.timestamp();
        org.apache.kafka.common.header.Headers headers43 = charSequenceConsumerRecord37.headers();
        org.apache.kafka.common.record.TimestampType timestampType44 = charSequenceConsumerRecord37.timestampType();
        java.util.Optional<java.lang.Integer> intOptional45 = charSequenceConsumerRecord37.leaderEpoch();
        org.apache.storm.topology.IComponent iComponent46 = null;
        org.apache.kafka.common.record.TimestampType timestampType51 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType51, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long58 = charSequenceConsumerRecord57.checksum();
        int int59 = charSequenceConsumerRecord57.partition();
        long long60 = charSequenceConsumerRecord57.timestamp();
        java.lang.String str61 = charSequenceConsumerRecord57.toString();
        org.apache.kafka.common.header.Headers headers62 = charSequenceConsumerRecord57.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent> intOptionalConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.Optional<java.lang.Integer>, org.apache.storm.topology.IComponent>("hi!", (int) ' ', (long) (byte) -1, (long) (-1), timestampType23, (java.lang.Long) 100L, (int) 'a', (-1), intOptional45, iComponent46, headers62);
        org.apache.storm.topology.IRichSpout iRichSpout68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.storm.topology.IRichSpout> strComparableConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, org.apache.storm.topology.IRichSpout>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", (int) (byte) 0, (long) 10, (long) (-1), timestampType23, (long) 0, (int) (short) 10, (int) (byte) 1, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", iRichSpout68);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", (int) (byte) 100, 100L, (long) (short) 100, timestampType23, (long) 'a', (int) ' ', (-1), (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", 52, 0L, (long) 97, timestampType23, (long) (byte) -1, (int) ' ', 10, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        long long82 = charSequenceConsumerRecord81.timestamp();
        long long83 = charSequenceConsumerRecord81.checksum();
        int int84 = charSequenceConsumerRecord81.partition();
        int int85 = charSequenceConsumerRecord81.serializedValueSize();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long38 + "' != '" + (-1L) + "'", long38 == (-1L));
        org.junit.Assert.assertTrue("'" + int39 + "' != '" + 10 + "'", int39 == 10);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertEquals("'" + str41 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str41, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long42 + "' != '" + (-1L) + "'", long42 == (-1L));
        org.junit.Assert.assertNotNull(headers43);
        org.junit.Assert.assertNull(timestampType44);
        org.junit.Assert.assertNotNull(intOptional45);
        org.junit.Assert.assertTrue("'" + long58 + "' != '" + (-1L) + "'", long58 == (-1L));
        org.junit.Assert.assertTrue("'" + int59 + "' != '" + 10 + "'", int59 == 10);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertEquals("'" + str61 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str61, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers62);
        org.junit.Assert.assertTrue("'" + long82 + "' != '" + 97L + "'", long82 == 97L);
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + (-1L) + "'", long83 == (-1L));
        org.junit.Assert.assertTrue("'" + int84 + "' != '" + 52 + "'", int84 == 52);
        org.junit.Assert.assertTrue("'" + int85 + "' != '" + 10 + "'", int85 == 10);
    }

    @Test
    public void test7233() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7233");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = kafkaSpoutMessageIdComparator10.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = kafkaSpoutMessageIdComparator10.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
    }

    @Test
    public void test7234() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7234");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor6 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor6;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder9;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = strKafkaSpout0.kafkaConsumer;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords12 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords12);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
        org.junit.Assert.assertNull(strKafkaConsumer11);
    }

    @Test
    public void test7235() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7235");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", (int) (short) 0, (-1L), (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 0, leaderEpoch = null, offset = -1, null = 100, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
    }

    @Test
    public void test7236() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7236");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        long long16 = charSequenceConsumerRecord10.offset();
        java.lang.CharSequence charSequence17 = charSequenceConsumerRecord10.key();
        java.util.Optional<java.lang.Integer> intOptional18 = charSequenceConsumerRecord10.leaderEpoch();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType20 = charSequenceConsumerRecord10.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType21 = charSequenceConsumerRecord10.timestampType();
        long long22 = charSequenceConsumerRecord10.checksum();
        java.lang.CharSequence charSequence23 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertEquals("'" + charSequence17 + "' != '" + "" + "'", charSequence17, "");
        org.junit.Assert.assertNotNull(intOptional18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNull(timestampType20);
        org.junit.Assert.assertNull(timestampType21);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence23 + "' != '" + "" + "'", charSequence23, "");
    }

    @Test
    public void test7237() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7237");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        strKafkaSpout0.initialized = true;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord8 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean9 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord8);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
    }

    @Test
    public void test7238() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7238");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long14 = charSequenceConsumerRecord13.checksum();
        long long15 = charSequenceConsumerRecord13.timestamp();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord13.headers();
        java.lang.String str17 = charSequenceConsumerRecord13.toString();
        org.apache.kafka.common.header.Headers headers18 = charSequenceConsumerRecord13.headers();
        java.lang.String str19 = charSequenceConsumerRecord13.topic();
        long long20 = charSequenceConsumerRecord13.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType21 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord27 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (byte) 1, (long) 100, timestampType21, (long) 1, 35, (int) (byte) 10, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.apache.kafka.common.record.TimestampType timestampType37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType37, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int44 = charSequenceConsumerRecord43.serializedValueSize();
        java.lang.CharSequence charSequence45 = charSequenceConsumerRecord43.key();
        int int46 = charSequenceConsumerRecord43.serializedKeySize();
        int int47 = charSequenceConsumerRecord43.serializedKeySize();
        org.apache.kafka.common.header.Headers headers48 = charSequenceConsumerRecord43.headers();
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType53, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long60 = charSequenceConsumerRecord59.checksum();
        int int61 = charSequenceConsumerRecord59.partition();
        java.lang.String str62 = charSequenceConsumerRecord59.value();
        int int63 = charSequenceConsumerRecord59.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional64 = charSequenceConsumerRecord59.leaderEpoch();
        long long65 = charSequenceConsumerRecord59.timestamp();
        java.util.Optional<java.lang.Integer> intOptional66 = charSequenceConsumerRecord59.leaderEpoch();
        int int67 = charSequenceConsumerRecord59.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional68 = charSequenceConsumerRecord59.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", 0, 0L, 0L, timestampType21, (java.lang.Long) 35L, (int) (short) -1, (int) '#', (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "hi!", headers48, intOptional68);
        int int70 = charSequenceConsumerRecord69.serializedValueSize();
        java.lang.String str71 = charSequenceConsumerRecord69.value();
        long long72 = charSequenceConsumerRecord69.timestamp();
        long long73 = charSequenceConsumerRecord69.timestamp();
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str17, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers18);
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "" + "'", str19, "");
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType21 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType21.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int44 + "' != '" + (-1) + "'", int44 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence45 + "' != '" + "" + "'", charSequence45, "");
        org.junit.Assert.assertTrue("'" + int46 + "' != '" + 52 + "'", int46 == 52);
        org.junit.Assert.assertTrue("'" + int47 + "' != '" + 52 + "'", int47 == 52);
        org.junit.Assert.assertNotNull(headers48);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + 10 + "'", int61 == 10);
        org.junit.Assert.assertEquals("'" + str62 + "' != '" + "hi!" + "'", str62, "hi!");
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 52 + "'", int63 == 52);
        org.junit.Assert.assertNotNull(intOptional64);
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + (-1L) + "'", long65 == (-1L));
        org.junit.Assert.assertNotNull(intOptional66);
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + (-1) + "'", int67 == (-1));
        org.junit.Assert.assertNotNull(intOptional68);
        org.junit.Assert.assertTrue("'" + int70 + "' != '" + 35 + "'", int70 == 35);
        org.junit.Assert.assertEquals("'" + str71 + "' != '" + "hi!" + "'", str71, "hi!");
        org.junit.Assert.assertTrue("'" + long72 + "' != '" + 0L + "'", long72 == 0L);
        org.junit.Assert.assertTrue("'" + long73 + "' != '" + 0L + "'", long73 == 0L);
    }

    @Test
    public void test7239() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7239");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet4 = strKafkaSpout0.emitted;
        boolean boolean5 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy6 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy6;
        strKafkaSpout0.numUncommittedOffsets = 'a';
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet10 = strKafkaSpout0.emitted;
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet4);
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet10);
    }

    @Test
    public void test7240() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7240");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector2 = null;
        strKafkaSpout0.collector = spoutOutputCollector2;
        java.lang.String str4 = strKafkaSpout0.toString();
        int int5 = strKafkaSpout0.maxRetries;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertEquals("'" + str4 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str4, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int5 + "' != '" + 0 + "'", int5 == 0);
    }

    @Test
    public void test7241() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7241");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long10 = charSequenceConsumerRecord9.checksum();
        long long11 = charSequenceConsumerRecord9.timestamp();
        org.apache.kafka.common.header.Headers headers12 = charSequenceConsumerRecord9.headers();
        java.lang.String str13 = charSequenceConsumerRecord9.toString();
        org.apache.kafka.common.header.Headers headers14 = charSequenceConsumerRecord9.headers();
        java.lang.String str15 = charSequenceConsumerRecord9.topic();
        long long16 = charSequenceConsumerRecord9.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (byte) 1, (long) 100, timestampType17, (long) 1, 35, (int) (byte) 10, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        int int24 = charSequenceConsumerRecord23.serializedKeySize();
        java.lang.String str25 = charSequenceConsumerRecord23.value();
        java.util.Optional<java.lang.Integer> intOptional26 = charSequenceConsumerRecord23.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str13, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "" + "'", str15, "");
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType17 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType17.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + 35 + "'", int24 == 35);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str25, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(intOptional26);
    }

    @Test
    public void test7242() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7242");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str21 = charSequenceConsumerRecord10.value();
        java.util.Optional<java.lang.Integer> intOptional22 = charSequenceConsumerRecord10.leaderEpoch();
        int int23 = charSequenceConsumerRecord10.serializedKeySize();
        long long24 = charSequenceConsumerRecord10.timestamp();
        long long25 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str26 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "hi!" + "'", str21, "hi!");
        org.junit.Assert.assertNotNull(intOptional22);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 52 + "'", int23 == 52);
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + (-1L) + "'", long24 == (-1L));
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + (-1L) + "'", long25 == (-1L));
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "hi!" + "'", str26, "hi!");
    }

    @Test
    public void test7243() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7243");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        strKafkaSpout0.initialized = true;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams10;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor12 = strKafkaSpout0.waitingToEmit;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer13 = strKafkaSpout0.kafkaConsumer;
        strKafkaSpout0.maxRetries = (short) 10;
        boolean boolean16 = strKafkaSpout0.consumerAutoCommitMode;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strConsumerRecordItor12);
        org.junit.Assert.assertNull(strKafkaConsumer13);
        org.junit.Assert.assertTrue("'" + boolean16 + "' != '" + true + "'", boolean16 == true);
    }

    @Test
    public void test7244() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7244");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        long long12 = charSequenceConsumerRecord10.timestamp();
        int int13 = charSequenceConsumerRecord10.partition();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
    }

    @Test
    public void test7245() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7245");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        java.lang.CharSequence charSequence11 = charSequenceConsumerRecord10.key();
        long long12 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        int int14 = charSequenceConsumerRecord10.serializedValueSize();
        long long15 = charSequenceConsumerRecord10.timestamp();
        org.junit.Assert.assertEquals("'" + charSequence11 + "' != '" + "" + "'", charSequence11, "");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
    }

    @Test
    public void test7246() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7246");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional15 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord10.headers();
        java.lang.String str17 = charSequenceConsumerRecord10.toString();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        long long19 = charSequenceConsumerRecord10.checksum();
        long long20 = charSequenceConsumerRecord10.checksum();
        int int21 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 52 + "'", int14 == 52);
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str17, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
    }

    @Test
    public void test7247() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7247");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional19 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.header.Headers headers20 = charSequenceConsumerRecord10.headers();
        java.lang.String str21 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertNotNull(intOptional19);
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str21, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test7248() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7248");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        long long20 = charSequenceConsumerRecord10.timestamp();
        long long21 = charSequenceConsumerRecord10.offset();
        java.lang.String str22 = charSequenceConsumerRecord10.value();
        java.lang.CharSequence charSequence23 = charSequenceConsumerRecord10.key();
        long long24 = charSequenceConsumerRecord10.timestamp();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 0L + "'", long21 == 0L);
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "hi!" + "'", str22, "hi!");
        org.junit.Assert.assertEquals("'" + charSequence23 + "' != '" + "" + "'", charSequence23, "");
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + (-1L) + "'", long24 == (-1L));
    }

    @Test
    public void test7249() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7249");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer1 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy2 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams3 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams3;
        strKafkaSpout0.numUncommittedOffsets = 35L;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams7;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str9 = strKafkaSpout0.getNamedTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(timer1);
        org.junit.Assert.assertNull(firstPollOffsetStrategy2);
    }

    @Test
    public void test7250() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7250");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = strKafkaSpout0.kafkaConsumer;
        strKafkaSpout0.maxRetries = (byte) 100;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor7;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor9 = strKafkaSpout0.waitingToEmit;
        java.lang.String str10 = strKafkaSpout0.toString();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer4);
        org.junit.Assert.assertNull(strConsumerRecordItor9);
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str10, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test7251() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7251");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout27 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout27.maxRetries = (byte) -1;
        int int30 = strKafkaSpout27.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor31 = null;
        strKafkaSpout27.waitingToEmit = strConsumerRecordItor31;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout27.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer34 = strKafkaSpout27.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType40, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long47 = charSequenceConsumerRecord46.offset();
        long long48 = charSequenceConsumerRecord46.checksum();
        int int49 = charSequenceConsumerRecord46.serializedKeySize();
        org.apache.kafka.common.header.Headers headers50 = charSequenceConsumerRecord46.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType23, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout27, (java.lang.CharSequence) "hi!", headers50);
        org.apache.kafka.common.record.TimestampType timestampType61 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord67 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType61, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long68 = charSequenceConsumerRecord67.checksum();
        int int69 = charSequenceConsumerRecord67.partition();
        long long70 = charSequenceConsumerRecord67.offset();
        org.apache.kafka.common.header.Headers headers71 = charSequenceConsumerRecord67.headers();
        org.apache.kafka.common.record.TimestampType timestampType76 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType76, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long83 = charSequenceConsumerRecord82.offset();
        int int84 = charSequenceConsumerRecord82.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional85 = charSequenceConsumerRecord82.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord86 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) 10, 10L, 0L, timestampType23, (java.lang.Long) 35L, (int) (byte) 0, (-1), (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers71, intOptional85);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord92 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", 32, (long) (short) -1, (long) (byte) 10, timestampType23, (long) ' ', 35, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord98 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = 35, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)", (int) (short) 0, (long) (short) -1, (long) ' ', timestampType23, (long) 32, (int) (byte) 100, 97, (java.lang.CharSequence) "", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}))");
        java.util.Optional<java.lang.Integer> intOptional99 = charSequenceConsumerRecord98.leaderEpoch();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(strKafkaConsumer34);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 0L + "'", long47 == 0L);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 52 + "'", int49 == 52);
        org.junit.Assert.assertNotNull(headers50);
        org.junit.Assert.assertTrue("'" + long68 + "' != '" + (-1L) + "'", long68 == (-1L));
        org.junit.Assert.assertTrue("'" + int69 + "' != '" + 10 + "'", int69 == 10);
        org.junit.Assert.assertTrue("'" + long70 + "' != '" + 0L + "'", long70 == 0L);
        org.junit.Assert.assertNotNull(headers71);
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + 0L + "'", long83 == 0L);
        org.junit.Assert.assertTrue("'" + int84 + "' != '" + (-1) + "'", int84 == (-1));
        org.junit.Assert.assertNotNull(intOptional85);
        org.junit.Assert.assertNotNull(intOptional99);
    }

    @Test
    public void test7252() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7252");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", (int) '#', (long) (byte) 1, (long) 52, timestampType4, (long) (byte) 0, 52, 52, (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )");
        java.lang.String str11 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", str11, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
    }

    @Test
    public void test7253() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7253");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        strKafkaSpout0.maxRetries = 1;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        boolean boolean5 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService6;
        strKafkaSpout0.numUncommittedOffsets = (-1L);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout10 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout10.maxRetries = (short) 0;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy13 = strKafkaSpout10.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout14 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout14.maxRetries = (byte) -1;
        int int17 = strKafkaSpout14.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray18 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet19 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean20 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet19, kafkaSpoutMessageIdArray18);
        strKafkaSpout14.emitted = kafkaSpoutMessageIdSet19;
        strKafkaSpout10.emitted = kafkaSpoutMessageIdSet19;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet19;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService24 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy25 = strKafkaSpout0.firstPollOffsetStrategy;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.deactivate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy13);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + (-1) + "'", int17 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray18);
        org.junit.Assert.assertTrue("'" + boolean20 + "' != '" + false + "'", boolean20 == false);
        org.junit.Assert.assertNull(kafkaSpoutRetryService24);
        org.junit.Assert.assertNull(firstPollOffsetStrategy25);
    }

    @Test
    public void test7254() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7254");
        org.apache.storm.kafka.spout.KafkaSpout<org.apache.storm.topology.IRichSpout, java.lang.reflect.GenericDeclaration> iRichSpoutKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.storm.topology.IRichSpout, java.lang.reflect.GenericDeclaration>();
    }

    @Test
    public void test7255() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7255");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType17 = null;
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int34 = charSequenceConsumerRecord33.serializedValueSize();
        java.lang.CharSequence charSequence35 = charSequenceConsumerRecord33.key();
        org.apache.kafka.common.header.Headers headers36 = charSequenceConsumerRecord33.headers();
        java.util.Optional<java.lang.Integer> intOptional37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType17, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers36, intOptional37);
        org.apache.kafka.common.record.TimestampType timestampType46 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType46, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int53 = charSequenceConsumerRecord52.serializedValueSize();
        java.lang.CharSequence charSequence54 = charSequenceConsumerRecord52.key();
        org.apache.kafka.common.header.Headers headers55 = charSequenceConsumerRecord52.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray56 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList57 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean58 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57, kafkaSpoutMessageIdArray56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers55, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headersConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("", (int) '#', 1L, headers36, kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType4, (java.lang.Long) (-1L), (int) (short) 100, 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}", headers36);
        org.apache.kafka.common.header.Headers headers62 = charSequenceConsumerRecord61.headers();
        java.lang.String str63 = charSequenceConsumerRecord61.toString();
        org.apache.kafka.common.record.TimestampType timestampType64 = charSequenceConsumerRecord61.timestampType();
        long long65 = charSequenceConsumerRecord61.offset();
        int int66 = charSequenceConsumerRecord61.serializedValueSize();
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + (-1) + "'", int34 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence35 + "' != '" + "" + "'", charSequence35, "");
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + (-1) + "'", int53 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence54 + "' != '" + "" + "'", charSequence54, "");
        org.junit.Assert.assertNotNull(headers55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray56);
        org.junit.Assert.assertTrue("'" + boolean58 + "' != '" + false + "'", boolean58 == false);
        org.junit.Assert.assertNotNull(headers62);
        org.junit.Assert.assertEquals("'" + str63 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", str63, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.junit.Assert.assertNull(timestampType64);
        org.junit.Assert.assertTrue("'" + long65 + "' != '" + 1L + "'", long65 == 1L);
        org.junit.Assert.assertTrue("'" + int66 + "' != '" + 1 + "'", int66 == 1);
    }

    @Test
    public void test7256() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7256");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional16 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 52 + "'", int14 == 52);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertNull(timestampType17);
    }

    @Test
    public void test7257() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7257");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout27 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout27.maxRetries = (byte) -1;
        int int30 = strKafkaSpout27.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor31 = null;
        strKafkaSpout27.waitingToEmit = strConsumerRecordItor31;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout27.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer34 = strKafkaSpout27.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType40, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long47 = charSequenceConsumerRecord46.offset();
        long long48 = charSequenceConsumerRecord46.checksum();
        int int49 = charSequenceConsumerRecord46.serializedKeySize();
        org.apache.kafka.common.header.Headers headers50 = charSequenceConsumerRecord46.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType23, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout27, (java.lang.CharSequence) "hi!", headers50);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 1, 0L, (long) (byte) 0, timestampType23, (long) ' ', (int) (short) -1, (int) (byte) 10, (java.lang.CharSequence) "", "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) -1, (long) ' ', (long) (short) 0, timestampType23, (long) (short) 1, (int) (byte) 10, (int) '#', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        org.apache.kafka.common.record.TimestampType timestampType73 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType73, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        java.lang.String str80 = charSequenceConsumerRecord79.topic();
        org.apache.kafka.common.header.Headers headers81 = charSequenceConsumerRecord79.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 0, (long) 52, (long) (byte) -1, timestampType23, (java.lang.Long) 1L, (int) (short) 0, (-1), (java.lang.CharSequence) "hi!", "hi!", headers81);
        long long83 = charSequenceConsumerRecord82.timestamp();
        org.apache.kafka.common.header.Headers headers84 = charSequenceConsumerRecord82.headers();
        java.lang.String str85 = charSequenceConsumerRecord82.value();
        int int86 = charSequenceConsumerRecord82.partition();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(strKafkaConsumer34);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 0L + "'", long47 == 0L);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 52 + "'", int49 == 52);
        org.junit.Assert.assertNotNull(headers50);
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "hi!" + "'", str80, "hi!");
        org.junit.Assert.assertNotNull(headers81);
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + (-1L) + "'", long83 == (-1L));
        org.junit.Assert.assertNotNull(headers84);
        org.junit.Assert.assertEquals("'" + str85 + "' != '" + "hi!" + "'", str85, "hi!");
        org.junit.Assert.assertTrue("'" + int86 + "' != '" + 0 + "'", int86 == 0);
    }

    @Test
    public void test7258() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7258");
        org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.Comparable<java.lang.String>> headersKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.kafka.common.header.Headers, java.lang.Comparable<java.lang.String>>();
    }

    @Test
    public void test7259() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7259");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        boolean boolean6 = strKafkaSpout0.waitingToEmit();
        org.apache.kafka.common.TopicPartition topicPartition7 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection8 = strKafkaSpout0.toArrayList(topicPartition7);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService9;
        long long11 = strKafkaSpout0.numUncommittedOffsets;
        java.lang.String str12 = strKafkaSpout0.toString();
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder15 = strKafkaSpout0.tuplesBuilder;
        org.apache.kafka.common.TopicPartition topicPartition16 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setAcked(topicPartition16, 100L);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection8);
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 35L + "'", long11 == 35L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str12, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder15);
    }

    @Test
    public void test7260() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7260");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy7;
        strKafkaSpout0.initialized = true;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = null;
        strKafkaSpout0.collector = spoutOutputCollector11;
        org.apache.kafka.common.TopicPartition topicPartition13 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setAcked(topicPartition13, (long) 10);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
    }

    @Test
    public void test7261() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7261");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", (int) (short) 0, (long) (short) 0, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
        org.apache.kafka.common.header.Headers headers6 = charSequenceConsumerRecord5.headers();
        int int7 = charSequenceConsumerRecord5.partition();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        int int9 = charSequenceConsumerRecord5.partition();
        org.junit.Assert.assertNotNull(headers6);
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 0 + "'", int7 == 0);
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + 0 + "'", int9 == 0);
    }

    @Test
    public void test7262() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7262");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord10.headers();
        long long17 = charSequenceConsumerRecord10.timestamp();
        long long18 = charSequenceConsumerRecord10.checksum();
        long long19 = charSequenceConsumerRecord10.offset();
        long long20 = charSequenceConsumerRecord10.timestamp();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
    }

    @Test
    public void test7263() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7263");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.CharSequence charSequence6 = charSequenceConsumerRecord5.key();
        java.util.Optional<java.lang.Integer> intOptional7 = charSequenceConsumerRecord5.leaderEpoch();
        long long8 = charSequenceConsumerRecord5.offset();
        org.junit.Assert.assertEquals("'" + charSequence6 + "' != '" + "" + "'", charSequence6, "");
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 10L + "'", long8 == 10L);
    }

    @Test
    public void test7264() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7264");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=[]}", (int) (byte) -1, (long) '4', (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "hi!");
        java.lang.String str6 = charSequenceConsumerRecord5.value();
        org.apache.kafka.common.header.Headers headers7 = charSequenceConsumerRecord5.headers();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        org.apache.kafka.common.record.TimestampType timestampType9 = charSequenceConsumerRecord5.timestampType();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "hi!" + "'", str6, "hi!");
        org.junit.Assert.assertNotNull(headers7);
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertTrue("'" + timestampType9 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType9.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test7265() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7265");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = null;
        strKafkaSpout0.collector = spoutOutputCollector12;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer14 = strKafkaSpout0.commitTimer;
        boolean boolean15 = strKafkaSpout0.initialized;
        long long16 = strKafkaSpout0.numUncommittedOffsets;
        long long17 = strKafkaSpout0.numUncommittedOffsets;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertNull(timer14);
        org.junit.Assert.assertTrue("'" + boolean15 + "' != '" + false + "'", boolean15 == false);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + 0L + "'", long16 == 0L);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
    }

    @Test
    public void test7266() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7266");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout27 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout27.maxRetries = (byte) -1;
        int int30 = strKafkaSpout27.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor31 = null;
        strKafkaSpout27.waitingToEmit = strConsumerRecordItor31;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout27.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer34 = strKafkaSpout27.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType40, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long47 = charSequenceConsumerRecord46.offset();
        long long48 = charSequenceConsumerRecord46.checksum();
        int int49 = charSequenceConsumerRecord46.serializedKeySize();
        org.apache.kafka.common.header.Headers headers50 = charSequenceConsumerRecord46.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType23, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout27, (java.lang.CharSequence) "hi!", headers50);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 1, 0L, (long) (byte) 0, timestampType23, (long) ' ', (int) (short) -1, (int) (byte) 10, (java.lang.CharSequence) "", "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) -1, (long) ' ', (long) (short) 0, timestampType23, (long) (short) 1, (int) (byte) 10, (int) '#', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        org.apache.kafka.common.record.TimestampType timestampType73 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType73, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        java.lang.String str80 = charSequenceConsumerRecord79.topic();
        org.apache.kafka.common.header.Headers headers81 = charSequenceConsumerRecord79.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 0, (long) 52, (long) (byte) -1, timestampType23, (java.lang.Long) 1L, (int) (short) 0, (-1), (java.lang.CharSequence) "hi!", "hi!", headers81);
        long long83 = charSequenceConsumerRecord82.timestamp();
        org.apache.kafka.common.header.Headers headers84 = charSequenceConsumerRecord82.headers();
        java.lang.String str85 = charSequenceConsumerRecord82.toString();
        java.util.Optional<java.lang.Integer> intOptional86 = charSequenceConsumerRecord82.leaderEpoch();
        long long87 = charSequenceConsumerRecord82.offset();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(strKafkaConsumer34);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 0L + "'", long47 == 0L);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 52 + "'", int49 == 52);
        org.junit.Assert.assertNotNull(headers50);
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "hi!" + "'", str80, "hi!");
        org.junit.Assert.assertNotNull(headers81);
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + (-1L) + "'", long83 == (-1L));
        org.junit.Assert.assertNotNull(headers84);
        org.junit.Assert.assertEquals("'" + str85 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)" + "'", str85, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)");
        org.junit.Assert.assertNotNull(intOptional86);
        org.junit.Assert.assertTrue("'" + long87 + "' != '" + 52L + "'", long87 == 52L);
    }

    @Test
    public void test7267() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7267");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) -1, (long) 0, (long) 10, timestampType4, (long) (short) 100, 52, (int) (byte) 10, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
    }

    @Test
    public void test7268() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7268");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 10, 1L, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=[]}");
        int int6 = charSequenceConsumerRecord5.partition();
        int int7 = charSequenceConsumerRecord5.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType8 = charSequenceConsumerRecord5.timestampType();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + 10 + "'", int6 == 10);
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType8 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType8.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test7269() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7269");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator3 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator3;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator5 = kafkaSpoutMessageIdComparator3.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator6 = kafkaSpoutMessageIdComparator3.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator3);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator5);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator6);
    }

    @Test
    public void test7270() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7270");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout19 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout19.maxRetries = (byte) -1;
        int int22 = strKafkaSpout19.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor23 = null;
        strKafkaSpout19.waitingToEmit = strConsumerRecordItor23;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer25 = strKafkaSpout19.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer26 = strKafkaSpout19.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType32, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long39 = charSequenceConsumerRecord38.offset();
        long long40 = charSequenceConsumerRecord38.checksum();
        int int41 = charSequenceConsumerRecord38.serializedKeySize();
        org.apache.kafka.common.header.Headers headers42 = charSequenceConsumerRecord38.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType15, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout19, (java.lang.CharSequence) "hi!", headers42);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType53, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long60 = charSequenceConsumerRecord59.checksum();
        int int61 = charSequenceConsumerRecord59.partition();
        long long62 = charSequenceConsumerRecord59.offset();
        org.apache.kafka.common.header.Headers headers63 = charSequenceConsumerRecord59.headers();
        org.apache.kafka.common.record.TimestampType timestampType68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType68, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long75 = charSequenceConsumerRecord74.offset();
        int int76 = charSequenceConsumerRecord74.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional77 = charSequenceConsumerRecord74.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) 10, 10L, 0L, timestampType15, (java.lang.Long) 35L, (int) (byte) 0, (-1), (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers63, intOptional77);
        java.util.Optional<java.lang.Integer> intOptional79 = charSequenceConsumerRecord78.leaderEpoch();
        java.lang.String str80 = charSequenceConsumerRecord78.toString();
        int int81 = charSequenceConsumerRecord78.serializedValueSize();
        int int82 = charSequenceConsumerRecord78.partition();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertNull(timer25);
        org.junit.Assert.assertNull(strKafkaConsumer26);
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + 0L + "'", long39 == 0L);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + 52 + "'", int41 == 52);
        org.junit.Assert.assertNotNull(headers42);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + 10 + "'", int61 == 10);
        org.junit.Assert.assertTrue("'" + long62 + "' != '" + 0L + "'", long62 == 0L);
        org.junit.Assert.assertNotNull(headers63);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + 0L + "'", long75 == 0L);
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + (-1) + "'", int76 == (-1));
        org.junit.Assert.assertNotNull(intOptional77);
        org.junit.Assert.assertNotNull(intOptional79);
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str80, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + int81 + "' != '" + (-1) + "'", int81 == (-1));
        org.junit.Assert.assertTrue("'" + int82 + "' != '" + 10 + "'", int82 == 10);
    }

    @Test
    public void test7271() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7271");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig3 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence> strConsumerRecord7 = null;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean8 = strKafkaSpout0.emitTupleIfNotEmitted(strConsumerRecord7);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test7272() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7272");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        java.lang.String str13 = charSequenceConsumerRecord10.topic();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        int int16 = charSequenceConsumerRecord10.partition();
        java.lang.String str17 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.header.Headers headers18 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "" + "'", str17, "");
        org.junit.Assert.assertNotNull(headers18);
    }

    @Test
    public void test7273() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7273");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer1 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService2 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService2;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy4 = strKafkaSpout0.firstPollOffsetStrategy;
        strKafkaSpout0.maxRetries = 32;
        boolean boolean7 = strKafkaSpout0.initialized;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
// flaky:             org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(timer1);
        org.junit.Assert.assertNull(firstPollOffsetStrategy4);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
    }

    @Test
    public void test7274() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7274");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        int int16 = charSequenceConsumerRecord10.serializedValueSize();
        int int17 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.String str18 = charSequenceConsumerRecord10.topic();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        long long21 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + (-1) + "'", int16 == (-1));
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + (-1) + "'", int17 == (-1));
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 0L + "'", long21 == 0L);
    }

    @Test
    public void test7275() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7275");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", 10, 100L, (long) 10, timestampType4, (-1L), (int) (short) 10, (int) (byte) 100, (java.lang.CharSequence) "", "KafkaSpout{acked=null, emitted=null}");
        java.lang.String str11 = charSequenceConsumerRecord10.value();
        long long12 = charSequenceConsumerRecord10.checksum();
        org.apache.kafka.common.record.TimestampType timestampType13 = charSequenceConsumerRecord10.timestampType();
        int int14 = charSequenceConsumerRecord10.partition();
        long long15 = charSequenceConsumerRecord10.offset();
        java.util.Optional<java.lang.Integer> intOptional16 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str11, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertNull(timestampType13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 100L + "'", long15 == 100L);
        org.junit.Assert.assertNotNull(intOptional16);
    }

    @Test
    public void test7276() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7276");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout3 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout3.maxRetries = (byte) -1;
        int int6 = strKafkaSpout3.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout3.waitingToEmit = strConsumerRecordItor7;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout3.toArrayList(topicPartition9);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer11 = strKafkaSpout3.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType16 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout20 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout20.maxRetries = (byte) -1;
        int int23 = strKafkaSpout20.maxRetries;
        strKafkaSpout20.numUncommittedOffsets = '#';
        strKafkaSpout20.initialized = true;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet28 = strKafkaSpout20.emitted;
        org.apache.kafka.common.record.TimestampType timestampType36 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType36, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int43 = charSequenceConsumerRecord42.serializedValueSize();
        java.lang.CharSequence charSequence44 = charSequenceConsumerRecord42.key();
        org.apache.kafka.common.header.Headers headers45 = charSequenceConsumerRecord42.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray46 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList47 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean48 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47, kafkaSpoutMessageIdArray46);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers45, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47);
        org.apache.kafka.common.record.TimestampType timestampType54 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType54, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int61 = charSequenceConsumerRecord60.serializedValueSize();
        java.lang.CharSequence charSequence62 = charSequenceConsumerRecord60.key();
        org.apache.kafka.common.header.Headers headers63 = charSequenceConsumerRecord60.headers();
        org.apache.kafka.common.record.TimestampType timestampType68 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType68, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long75 = charSequenceConsumerRecord74.offset();
        int int76 = charSequenceConsumerRecord74.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional77 = charSequenceConsumerRecord74.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> objConsumerRecord78 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) '4', (long) (short) 0, (long) 100, timestampType16, (java.lang.Long) 1L, (int) (short) 0, 0, (java.lang.Object) kafkaSpoutMessageIdSet28, (java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList47, headers63, intOptional77);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.common.header.Headers> iSpoutConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, org.apache.kafka.common.header.Headers>("KafkaSpout{acked=null, emitted=null}", (int) '#', (long) 1, (org.apache.storm.spout.ISpout) strKafkaSpout3, headers63);
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords80 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout3.setWaitingToEmit(strConsumerRecords80);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(strKafkaConsumer11);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + (-1) + "'", int23 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet28);
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + (-1) + "'", int43 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence44 + "' != '" + "" + "'", charSequence44, "");
        org.junit.Assert.assertNotNull(headers45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray46);
        org.junit.Assert.assertTrue("'" + boolean48 + "' != '" + false + "'", boolean48 == false);
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + (-1) + "'", int61 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence62 + "' != '" + "" + "'", charSequence62, "");
        org.junit.Assert.assertNotNull(headers63);
        org.junit.Assert.assertTrue("'" + long75 + "' != '" + 0L + "'", long75 == 0L);
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + (-1) + "'", int76 == (-1));
        org.junit.Assert.assertNotNull(intOptional77);
    }

    @Test
    public void test7277() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7277");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet4 = strKafkaSpout0.emitted;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy6 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy6;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig9 = strKafkaSpout0.kafkaSpoutConfig;
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
        org.junit.Assert.assertNull(strKafkaSpoutConfig9);
    }

    @Test
    public void test7278() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7278");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)", 10, (long) (short) 0, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 97, leaderEpoch = null, offset = 100, NoTimestampType = 97, serialized key size = 97, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=[]}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        long long6 = charSequenceConsumerRecord5.checksum();
        long long7 = charSequenceConsumerRecord5.timestamp();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
    }

    @Test
    public void test7279() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7279");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer1 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService2 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService2;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        boolean boolean5 = strKafkaSpout0.initialized;
        org.junit.Assert.assertNull(timer1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
    }

    @Test
    public void test7280() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7280");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) 100, 1L, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=[]}");
        int int6 = charSequenceConsumerRecord5.serializedValueSize();
        long long7 = charSequenceConsumerRecord5.checksum();
        java.lang.String str8 = charSequenceConsumerRecord5.topic();
        long long9 = charSequenceConsumerRecord5.offset();
        java.util.Optional<java.lang.Integer> intOptional10 = charSequenceConsumerRecord5.leaderEpoch();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 1L + "'", long9 == 1L);
        org.junit.Assert.assertNotNull(intOptional10);
    }

    @Test
    public void test7281() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7281");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        long long17 = charSequenceConsumerRecord10.checksum();
        java.lang.String str18 = charSequenceConsumerRecord10.value();
        java.lang.String str19 = charSequenceConsumerRecord10.value();
        int int20 = charSequenceConsumerRecord10.serializedValueSize();
        long long21 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "hi!" + "'", str18, "hi!");
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "hi!" + "'", str19, "hi!");
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + (-1) + "'", int20 == (-1));
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
    }

    @Test
    public void test7282() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7282");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType4, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord10.timestampType();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        int int15 = charSequenceConsumerRecord10.partition();
        int int16 = charSequenceConsumerRecord10.partition();
        java.lang.String str17 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 35L + "'", long11 == 35L);
        org.junit.Assert.assertNull(timestampType12);
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 1 + "'", int15 == 1);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 1 + "'", int16 == 1);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", str17, "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
    }

    @Test
    public void test7283() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7283");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        int int9 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.maxRetries = (byte) 100;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = strKafkaSpout0.collector;
        strKafkaSpout0.maxRetries = '4';
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder15 = strKafkaSpout0.tuplesBuilder;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertNull(spoutOutputCollector12);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder15);
    }

    @Test
    public void test7284() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7284");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer9 = strKafkaSpout0.kafkaConsumer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor10 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor10;
        boolean boolean12 = strKafkaSpout0.initialized;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector13 = null;
        strKafkaSpout0.collector = spoutOutputCollector13;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor15 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor15;
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertNull(strKafkaConsumer9);
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + false + "'", boolean12 == false);
    }

    @Test
    public void test7285() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7285");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = strKafkaSpout0.kafkaConsumer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor5 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor5;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        java.lang.String str8 = strKafkaSpout0.toString();
        java.util.Map map9 = null;
        org.apache.storm.task.TopologyContext topologyContext10 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map9, topologyContext10, spoutOutputCollector11);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer4);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test7286() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7286");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams7;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = strKafkaSpout0.retryService;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        strKafkaSpout0.maxRetries = (-1);
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy13 = strKafkaSpout0.firstPollOffsetStrategy;
        strKafkaSpout0.maxRetries = (byte) 100;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor16 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor16;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(kafkaSpoutRetryService9);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertNull(firstPollOffsetStrategy13);
    }

    @Test
    public void test7287() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7287");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition8 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection9 = strKafkaSpout0.toArrayList(topicPartition8);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer10;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer12 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer12;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig14 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig14;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy16 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy17 = strKafkaSpout0.firstPollOffsetStrategy;
        java.util.Map map18 = null;
        org.apache.storm.task.TopologyContext topologyContext19 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector20 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map18, topologyContext19, spoutOutputCollector20);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection9);
        org.junit.Assert.assertNull(firstPollOffsetStrategy16);
        org.junit.Assert.assertNull(firstPollOffsetStrategy17);
    }

    @Test
    public void test7288() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7288");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.Class<?>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>> wildcardClassKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Class<?>, org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>>();
    }

    @Test
    public void test7289() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7289");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        java.util.Optional<java.lang.Integer> intOptional15 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        long long18 = charSequenceConsumerRecord10.timestamp();
        long long19 = charSequenceConsumerRecord10.timestamp();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
    }

    @Test
    public void test7290() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7290");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer8 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder10 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder10;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = strKafkaSpout0.collector;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean13 = strKafkaSpout0.commit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer8);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder9);
        org.junit.Assert.assertNull(spoutOutputCollector12);
    }

    @Test
    public void test7291() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7291");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        boolean boolean8 = strKafkaSpout0.consumerAutoCommitMode;
        java.lang.String str9 = strKafkaSpout0.toString();
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str9, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test7292() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7292");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        strKafkaSpout0.maxRetries = (short) 0;
        boolean boolean5 = strKafkaSpout0.consumerAutoCommitMode;
        boolean boolean6 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService7 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService7;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet9 = strKafkaSpout0.emitted;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
// flaky:             org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet9);
    }

    @Test
    public void test7293() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7293");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 97, (long) (-1), (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = 97, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = )", "ConsumerRecord(topic = , partition = 52, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test7294() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7294");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 1, 1L, (long) (byte) 10, timestampType4, (long) '#', (int) (byte) 100, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        java.lang.String str11 = charSequenceConsumerRecord10.value();
        java.lang.String str12 = charSequenceConsumerRecord10.topic();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        int int14 = charSequenceConsumerRecord10.serializedValueSize();
        long long15 = charSequenceConsumerRecord10.checksum();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str12, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 35L + "'", long15 == 35L);
    }

    @Test
    public void test7295() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7295");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray6 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet7 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean8 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet7, kafkaSpoutMessageIdArray6);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet7;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor11 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor11;
        strKafkaSpout0.initialized = false;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray6);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
        org.junit.Assert.assertNull(strKafkaConsumer10);
    }

    @Test
    public void test7296() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7296");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig5;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector7 = strKafkaSpout0.collector;
        org.apache.kafka.common.record.TimestampType timestampType12 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout16 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams17 = strKafkaSpout16.kafkaSpoutStreams;
        strKafkaSpout16.consumerAutoCommitMode = false;
        java.lang.String str20 = strKafkaSpout16.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout21 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout21.maxRetries = (byte) -1;
        int int24 = strKafkaSpout21.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray25 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet26 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean27 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet26, kafkaSpoutMessageIdArray25);
        strKafkaSpout21.emitted = kafkaSpoutMessageIdSet26;
        strKafkaSpout16.emitted = kafkaSpoutMessageIdSet26;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout30 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout30.maxRetries = (byte) -1;
        int int33 = strKafkaSpout30.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor34 = null;
        strKafkaSpout30.waitingToEmit = strConsumerRecordItor34;
        org.apache.kafka.common.TopicPartition topicPartition36 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection37 = strKafkaSpout30.toArrayList(topicPartition36);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer38 = strKafkaSpout30.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector39 = strKafkaSpout30.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout40 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout40.maxRetries = (byte) -1;
        int int43 = strKafkaSpout40.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray44 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet45 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean46 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet45, kafkaSpoutMessageIdArray44);
        strKafkaSpout40.emitted = kafkaSpoutMessageIdSet45;
        strKafkaSpout30.emitted = kafkaSpoutMessageIdSet45;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType12, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet26, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet45);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet45;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector51 = null;
        strKafkaSpout0.collector = spoutOutputCollector51;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig53 = strKafkaSpout0.kafkaSpoutConfig;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertNull(spoutOutputCollector7);
        org.junit.Assert.assertNull(kafkaSpoutStreams17);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str20, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + (-1) + "'", int24 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray25);
        org.junit.Assert.assertTrue("'" + boolean27 + "' != '" + false + "'", boolean27 == false);
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + (-1) + "'", int33 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection37);
        org.junit.Assert.assertNull(timer38);
        org.junit.Assert.assertNull(spoutOutputCollector39);
        org.junit.Assert.assertTrue("'" + int43 + "' != '" + (-1) + "'", int43 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray44);
        org.junit.Assert.assertTrue("'" + boolean46 + "' != '" + false + "'", boolean46 == false);
        org.junit.Assert.assertNull(strKafkaSpoutConfig53);
    }

    @Test
    public void test7297() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7297");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.header.Headers headers15 = charSequenceConsumerRecord10.headers();
        int int16 = charSequenceConsumerRecord10.serializedKeySize();
        int int17 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 52 + "'", int14 == 52);
        org.junit.Assert.assertNotNull(headers15);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 52 + "'", int16 == 52);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + (-1) + "'", int17 == (-1));
    }

    @Test
    public void test7298() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7298");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService7 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(kafkaSpoutRetryService7);
    }

    @Test
    public void test7299() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7299");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = offsetComparator11.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator7.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator11);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator16 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator17 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator17;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = offsetComparator17.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator24 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator24;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator24);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = kafkaSpoutMessageIdComparator19.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator24);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator28 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator28;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = offsetComparator28.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = offsetComparator28.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = offsetComparator24.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator28);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator33 = offsetComparator16.thenComparing(kafkaSpoutMessageIdComparator32);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator34 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator35 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator35;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator37 = offsetComparator35.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = offsetComparator34.thenComparing(kafkaSpoutMessageIdComparator37);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator39 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator39;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = offsetComparator39.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator46 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator46;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator46);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator49 = kafkaSpoutMessageIdComparator41.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator46);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator50 = offsetComparator34.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator46);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator50;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator52 = kafkaSpoutMessageIdComparator50.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator53 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator54 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator54;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator56 = offsetComparator54.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator61 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator61;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator61);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator64 = kafkaSpoutMessageIdComparator56.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator61);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator65 = offsetComparator53.thenComparing(kafkaSpoutMessageIdComparator64);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator66 = kafkaSpoutMessageIdComparator50.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator53);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator67 = offsetComparator16.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator53);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator68 = offsetComparator11.thenComparing(kafkaSpoutMessageIdComparator67);
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId69 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId70 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int71 = offsetComparator11.compare(kafkaSpoutMessageId69, kafkaSpoutMessageId70);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator33);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator37);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator49);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator50);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator52);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator56);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator64);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator65);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator66);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator67);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator68);
    }

    @Test
    public void test7300() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7300");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional15 = charSequenceConsumerRecord10.leaderEpoch();
        long long16 = charSequenceConsumerRecord10.checksum();
        java.lang.CharSequence charSequence17 = charSequenceConsumerRecord10.key();
        java.lang.String str18 = charSequenceConsumerRecord10.toString();
        long long19 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 52 + "'", int14 == 52);
        org.junit.Assert.assertNotNull(intOptional15);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence17 + "' != '" + "" + "'", charSequence17, "");
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str18, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + 0L + "'", long19 == 0L);
    }

    @Test
    public void test7301() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7301");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.checksum();
        int int19 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType20 = charSequenceConsumerRecord10.timestampType();
        long long21 = charSequenceConsumerRecord10.timestamp();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertNull(timestampType20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
    }

    @Test
    public void test7302() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7302");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        boolean boolean11 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService12 = strKafkaSpout0.retryService;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector13 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams14 = strKafkaSpout0.kafkaSpoutStreams;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor15 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor15;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(kafkaSpoutRetryService12);
        org.junit.Assert.assertNull(spoutOutputCollector13);
        org.junit.Assert.assertNull(kafkaSpoutStreams14);
    }

    @Test
    public void test7303() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7303");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType4, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str13 = charSequenceConsumerRecord10.toString();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.String str15 = charSequenceConsumerRecord10.topic();
        java.lang.String str16 = charSequenceConsumerRecord10.toString();
        java.lang.String str17 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 35L + "'", long11 == 35L);
        org.junit.Assert.assertNull(timestampType12);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", str13, "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", str16, "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", str17, "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
    }

    @Test
    public void test7304() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7304");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator1 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator2 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator2;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator4 = offsetComparator2.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator9 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator9;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord11 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator9);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = kafkaSpoutMessageIdComparator4.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator9);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator1.thenComparing(kafkaSpoutMessageIdComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = kafkaSpoutMessageIdComparator12.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = kafkaSpoutMessageIdComparator12.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator17 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator17;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = offsetComparator17.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator24 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator24;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator24);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = kafkaSpoutMessageIdComparator19.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator24);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = kafkaSpoutMessageIdComparator19.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator29 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator30 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator30;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = offsetComparator30.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator37 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator37;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator37);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator40 = kafkaSpoutMessageIdComparator32.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator37);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = offsetComparator29.thenComparing(kafkaSpoutMessageIdComparator40);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator42 = kafkaSpoutMessageIdComparator28.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator29);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator42;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = kafkaSpoutMessageIdComparator12.thenComparing(kafkaSpoutMessageIdComparator42);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator45 = kafkaSpoutMessageIdComparator42.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator46 = kafkaSpoutMessageIdComparator42.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator47 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator48 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator49 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator49;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator51 = offsetComparator49.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator56 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator56;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator56);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator59 = kafkaSpoutMessageIdComparator51.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator56);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator60 = offsetComparator48.thenComparing(kafkaSpoutMessageIdComparator59);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator61 = kafkaSpoutMessageIdComparator59.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator62 = offsetComparator47.thenComparing(kafkaSpoutMessageIdComparator59);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator63 = kafkaSpoutMessageIdComparator46.thenComparing(kafkaSpoutMessageIdComparator62);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator64 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator64;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator66 = offsetComparator64.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator67 = offsetComparator64.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator68 = kafkaSpoutMessageIdComparator67.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator69 = kafkaSpoutMessageIdComparator68.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator70 = kafkaSpoutMessageIdComparator68.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator71 = kafkaSpoutMessageIdComparator62.thenComparing(kafkaSpoutMessageIdComparator68);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator4);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator40);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator42);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator46);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator51);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator59);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator60);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator61);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator62);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator63);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator66);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator67);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator68);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator69);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator70);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator71);
    }

    @Test
    public void test7305() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7305");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        int int12 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder13;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService15 = strKafkaSpout0.retryService;
        boolean boolean16 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector17 = strKafkaSpout0.collector;
        boolean boolean18 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy19 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy19;
        int int21 = strKafkaSpout0.maxRetries;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.doSeekRetriableTopicPartitions();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService15);
        org.junit.Assert.assertTrue("'" + boolean16 + "' != '" + false + "'", boolean16 == false);
        org.junit.Assert.assertNull(spoutOutputCollector17);
        org.junit.Assert.assertTrue("'" + boolean18 + "' != '" + false + "'", boolean18 == false);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
    }

    @Test
    public void test7306() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7306");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType13 = charSequenceConsumerRecord10.timestampType();
        int int14 = charSequenceConsumerRecord10.partition();
        int int15 = charSequenceConsumerRecord10.serializedValueSize();
        long long16 = charSequenceConsumerRecord10.checksum();
        java.util.Optional<java.lang.Integer> intOptional17 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str18 = charSequenceConsumerRecord10.value();
        java.lang.String str19 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNull(timestampType13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertNotNull(intOptional17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "hi!" + "'", str18, "hi!");
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "" + "'", str19, "");
    }

    @Test
    public void test7307() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7307");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams4;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.commitOffsetsForAckedTuples();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
    }

    @Test
    public void test7308() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7308");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        java.lang.String str11 = charSequenceConsumerRecord10.toString();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.topic();
        long long15 = charSequenceConsumerRecord10.checksum();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(headers16);
    }

    @Test
    public void test7309() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7309");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        boolean boolean5 = strKafkaSpout0.waitingToEmit();
        long long6 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer7 = strKafkaSpout0.commitTimer;
        long long8 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams9 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams9;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + 0L + "'", long6 == 0L);
        org.junit.Assert.assertNull(timer7);
        org.junit.Assert.assertTrue("'" + long8 + "' != '" + 0L + "'", long8 == 0L);
    }

    @Test
    public void test7310() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7310");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType17 = null;
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int34 = charSequenceConsumerRecord33.serializedValueSize();
        java.lang.CharSequence charSequence35 = charSequenceConsumerRecord33.key();
        org.apache.kafka.common.header.Headers headers36 = charSequenceConsumerRecord33.headers();
        java.util.Optional<java.lang.Integer> intOptional37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType17, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers36, intOptional37);
        org.apache.kafka.common.record.TimestampType timestampType46 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord52 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType46, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int53 = charSequenceConsumerRecord52.serializedValueSize();
        java.lang.CharSequence charSequence54 = charSequenceConsumerRecord52.key();
        org.apache.kafka.common.header.Headers headers55 = charSequenceConsumerRecord52.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray56 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList57 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean58 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57, kafkaSpoutMessageIdArray56);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers55, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headersConsumerRecord60 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("", (int) '#', 1L, headers36, kafkaSpoutMessageIdList57);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType4, (java.lang.Long) (-1L), (int) (short) 100, 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}", headers36);
        int int62 = charSequenceConsumerRecord61.partition();
        java.lang.CharSequence charSequence63 = charSequenceConsumerRecord61.key();
        java.lang.String str64 = charSequenceConsumerRecord61.topic();
        java.lang.String str65 = charSequenceConsumerRecord61.toString();
        java.lang.CharSequence charSequence66 = charSequenceConsumerRecord61.key();
        org.junit.Assert.assertTrue("'" + int34 + "' != '" + (-1) + "'", int34 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence35 + "' != '" + "" + "'", charSequence35, "");
        org.junit.Assert.assertNotNull(headers36);
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + (-1) + "'", int53 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence54 + "' != '" + "" + "'", charSequence54, "");
        org.junit.Assert.assertNotNull(headers55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray56);
        org.junit.Assert.assertTrue("'" + boolean58 + "' != '" + false + "'", boolean58 == false);
        org.junit.Assert.assertTrue("'" + int62 + "' != '" + 97 + "'", int62 == 97);
        org.junit.Assert.assertEquals("'" + charSequence63 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence63, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str64 + "' != '" + "hi!" + "'", str64, "hi!");
        org.junit.Assert.assertEquals("'" + str65 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", str65, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.junit.Assert.assertEquals("'" + charSequence66 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence66, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test7311() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7311");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        long long13 = charSequenceConsumerRecord10.offset();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 52 + "'", int14 == 52);
    }

    @Test
    public void test7312() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7312");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long10 = charSequenceConsumerRecord9.checksum();
        long long11 = charSequenceConsumerRecord9.timestamp();
        org.apache.kafka.common.header.Headers headers12 = charSequenceConsumerRecord9.headers();
        java.lang.String str13 = charSequenceConsumerRecord9.toString();
        org.apache.kafka.common.header.Headers headers14 = charSequenceConsumerRecord9.headers();
        java.lang.String str15 = charSequenceConsumerRecord9.topic();
        long long16 = charSequenceConsumerRecord9.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (byte) 1, (long) 100, timestampType17, (long) 1, 35, (int) (byte) 10, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        int int24 = charSequenceConsumerRecord23.serializedKeySize();
        long long25 = charSequenceConsumerRecord23.checksum();
        int int26 = charSequenceConsumerRecord23.serializedKeySize();
        long long27 = charSequenceConsumerRecord23.checksum();
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str13, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "" + "'", str15, "");
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType17 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType17.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + 35 + "'", int24 == 35);
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + 1L + "'", long25 == 1L);
        org.junit.Assert.assertTrue("'" + int26 + "' != '" + 35 + "'", int26 == 35);
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + 1L + "'", long27 == 1L);
    }

    @Test
    public void test7313() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7313");
        org.apache.storm.kafka.spout.KafkaSpout<java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.reflect.AnnotatedElement> kafkaSpoutMessageIdListKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.lang.reflect.AnnotatedElement>();
    }

    @Test
    public void test7314() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7314");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator1 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator2 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator2;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator4 = offsetComparator2.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator9 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator9;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord11 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator9);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = kafkaSpoutMessageIdComparator4.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator9);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator1.thenComparing(kafkaSpoutMessageIdComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = kafkaSpoutMessageIdComparator12.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = kafkaSpoutMessageIdComparator12.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator17 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator17;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = offsetComparator17.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator24 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator24;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator24);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = kafkaSpoutMessageIdComparator19.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator24);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = offsetComparator24.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = offsetComparator24.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator30 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator30;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = offsetComparator30.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator37 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator37;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator37);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator40 = kafkaSpoutMessageIdComparator32.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator37);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = kafkaSpoutMessageIdComparator32.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator42 = offsetComparator24.thenComparing(kafkaSpoutMessageIdComparator41);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator43 = offsetComparator24.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = kafkaSpoutMessageIdComparator43.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator45 = kafkaSpoutMessageIdComparator43.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator45;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator47 = kafkaSpoutMessageIdComparator16.thenComparing(kafkaSpoutMessageIdComparator45);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator45;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator4);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator40);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator42);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator43);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator45);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator47);
    }

    @Test
    public void test7315() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7315");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        boolean boolean11 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy12 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.kafka.common.TopicPartition topicPartition13 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection14 = strKafkaSpout0.toArrayList(topicPartition13);
        strKafkaSpout0.initialized = false;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy12);
        org.junit.Assert.assertNotNull(topicPartitionCollection14);
    }

    @Test
    public void test7316() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7316");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        java.lang.String str11 = charSequenceConsumerRecord10.toString();
        java.lang.String str12 = charSequenceConsumerRecord10.topic();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.String str15 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "" + "'", str12, "");
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str15, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test7317() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7317");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        java.lang.String str12 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        long long14 = charSequenceConsumerRecord10.timestamp();
        int int15 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "" + "'", str12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
    }

    @Test
    public void test7318() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7318");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) ' ', (long) (byte) 100, (long) (byte) -1, timestampType4, (long) (byte) -1, (int) (byte) 10, 10, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional12 = charSequenceConsumerRecord10.leaderEpoch();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + 10 + "'", int11 == 10);
        org.junit.Assert.assertNotNull(intOptional12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test7319() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7319");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) 100, (long) 0, (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str6 = charSequenceConsumerRecord5.value();
        org.apache.kafka.common.header.Headers headers7 = charSequenceConsumerRecord5.headers();
        java.lang.String str8 = charSequenceConsumerRecord5.value();
        java.lang.String str9 = charSequenceConsumerRecord5.value();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str6, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str8, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str9, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test7320() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7320");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        java.lang.String str16 = charSequenceConsumerRecord10.toString();
        long long17 = charSequenceConsumerRecord10.checksum();
        java.lang.CharSequence charSequence18 = charSequenceConsumerRecord10.key();
        int int19 = charSequenceConsumerRecord10.serializedKeySize();
        long long20 = charSequenceConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers21 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + (-1L) + "'", long17 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence18 + "' != '" + "" + "'", charSequence18, "");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 52 + "'", int19 == 52);
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 0L + "'", long20 == 0L);
        org.junit.Assert.assertNotNull(headers21);
    }

    @Test
    public void test7321() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7321");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        int int12 = strKafkaSpout0.maxRetries;
        boolean boolean13 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder14 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder15 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder15;
        boolean boolean17 = strKafkaSpout0.consumerAutoCommitMode;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertTrue("'" + boolean13 + "' != '" + false + "'", boolean13 == false);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder14);
        org.junit.Assert.assertTrue("'" + boolean17 + "' != '" + false + "'", boolean17 == false);
    }

    @Test
    public void test7322() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7322");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer10;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder12 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder12;
        int int14 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer15 = strKafkaSpout0.kafkaConsumer;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.activate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 0 + "'", int14 == 0);
        org.junit.Assert.assertNull(strKafkaConsumer15);
    }

    @Test
    public void test7323() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7323");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType14, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int21 = charSequenceConsumerRecord20.serializedValueSize();
        java.lang.CharSequence charSequence22 = charSequenceConsumerRecord20.key();
        org.apache.kafka.common.header.Headers headers23 = charSequenceConsumerRecord20.headers();
        java.util.Optional<java.lang.Integer> intOptional24 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType4, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers23, intOptional24);
        long long26 = charSequenceConsumerRecord25.checksum();
        long long27 = charSequenceConsumerRecord25.timestamp();
        java.util.Optional<java.lang.Integer> intOptional28 = charSequenceConsumerRecord25.leaderEpoch();
        java.lang.CharSequence charSequence29 = charSequenceConsumerRecord25.key();
        java.util.Optional<java.lang.Integer> intOptional30 = charSequenceConsumerRecord25.leaderEpoch();
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence22 + "' != '" + "" + "'", charSequence22, "");
        org.junit.Assert.assertNotNull(headers23);
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + (-1L) + "'", long26 == (-1L));
        org.junit.Assert.assertTrue("'" + long27 + "' != '" + 35L + "'", long27 == 35L);
        org.junit.Assert.assertNull(intOptional28);
        org.junit.Assert.assertEquals("'" + charSequence29 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", charSequence29, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(intOptional30);
    }

    @Test
    public void test7324() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7324");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService7 = strKafkaSpout0.retryService;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords8 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords8);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer4);
        org.junit.Assert.assertNull(strKafkaSpoutConfig5);
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertNull(kafkaSpoutRetryService7);
    }

    @Test
    public void test7325() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7325");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer6 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector7 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig8 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = strKafkaSpout0.tuplesBuilder;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet10 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor11 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig12 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig12;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor14 = strKafkaSpout0.waitingToEmit;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.deactivate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer6);
        org.junit.Assert.assertNull(spoutOutputCollector7);
        org.junit.Assert.assertNull(strKafkaSpoutConfig8);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder9);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet10);
        org.junit.Assert.assertNull(strConsumerRecordItor11);
        org.junit.Assert.assertNull(strConsumerRecordItor14);
    }

    @Test
    public void test7326() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7326");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy6 = strKafkaSpout0.firstPollOffsetStrategy;
        boolean boolean7 = strKafkaSpout0.consumerAutoCommitMode;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet5);
        org.junit.Assert.assertNull(firstPollOffsetStrategy6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
    }

    @Test
    public void test7327() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7327");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        java.lang.String str17 = charSequenceConsumerRecord10.toString();
        int int18 = charSequenceConsumerRecord10.partition();
        int int19 = charSequenceConsumerRecord10.partition();
        java.lang.Class<?> wildcardClass20 = charSequenceConsumerRecord10.getClass();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str17, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 10 + "'", int18 == 10);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertNotNull(wildcardClass20);
    }

    @Test
    public void test7328() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7328");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator2 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator3 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator3;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator5 = offsetComparator3.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator6 = offsetComparator2.thenComparing(kafkaSpoutMessageIdComparator5);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator6);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator8 = offsetComparator0.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator9 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator10 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator10;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator10.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator17 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator17;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator17);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator20 = kafkaSpoutMessageIdComparator12.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator17);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = offsetComparator17.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = offsetComparator17.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator22;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator24 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator24;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator24.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator31 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator31;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = kafkaSpoutMessageIdComparator26.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = kafkaSpoutMessageIdComparator26.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator36 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator37 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator37;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = offsetComparator37.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator44 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator44;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator44);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator47 = kafkaSpoutMessageIdComparator39.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator44);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator48 = offsetComparator36.thenComparing(kafkaSpoutMessageIdComparator47);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator49 = kafkaSpoutMessageIdComparator35.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator36);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator49;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator51 = kafkaSpoutMessageIdComparator22.thenComparing(kafkaSpoutMessageIdComparator49);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator52 = kafkaSpoutMessageIdComparator49.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator53 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator49);
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId54 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId55 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int56 = offsetComparator0.compare(kafkaSpoutMessageId54, kafkaSpoutMessageId55);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator5);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator6);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator8);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator9);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator20);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator47);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator48);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator49);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator51);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator52);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator53);
    }

    @Test
    public void test7329() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7329");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator7.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = kafkaSpoutMessageIdComparator12.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator14 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator15 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator16 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator16;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = offsetComparator16.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = offsetComparator15.thenComparing(kafkaSpoutMessageIdComparator18);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator20 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator20;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = offsetComparator20.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = offsetComparator20.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator18.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator14.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = kafkaSpoutMessageIdComparator25.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator27 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator28 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator28;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = offsetComparator28.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator35 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator35;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator35);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator38 = kafkaSpoutMessageIdComparator30.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator35);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = offsetComparator27.thenComparing(kafkaSpoutMessageIdComparator38);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator40 = offsetComparator27.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = kafkaSpoutMessageIdComparator26.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator27);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator42 = kafkaSpoutMessageIdComparator12.thenComparing(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator38);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator40);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator42);
    }

    @Test
    public void test7330() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7330");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) '4', (long) 'a', (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "");
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord17.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout22 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams23 = strKafkaSpout22.kafkaSpoutStreams;
        strKafkaSpout22.consumerAutoCommitMode = false;
        strKafkaSpout22.maxRetries = (byte) -1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer28 = null;
        strKafkaSpout22.kafkaConsumer = strKafkaConsumer28;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector30 = strKafkaSpout22.collector;
        strKafkaSpout22.maxRetries = 97;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService33 = strKafkaSpout22.retryService;
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, java.lang.Comparable<java.lang.String>> iSpoutConsumerRecord35 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.spout.ISpout, java.lang.Comparable<java.lang.String>>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}))", 52, (long) 0, (long) 32, timestampType18, (long) 100, (-1), 52, (org.apache.storm.spout.ISpout) strKafkaSpout22, (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
        org.apache.kafka.common.record.TimestampType timestampType45 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType45, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        java.lang.String str52 = charSequenceConsumerRecord51.toString();
        int int53 = charSequenceConsumerRecord51.serializedValueSize();
        int int54 = charSequenceConsumerRecord51.serializedKeySize();
        long long55 = charSequenceConsumerRecord51.timestamp();
        int int56 = charSequenceConsumerRecord51.serializedKeySize();
        org.apache.kafka.common.header.Headers headers57 = charSequenceConsumerRecord51.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord58 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 1, leaderEpoch = null, offset = 0, NoTimestampType = 0, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = )", 1, 100L, (long) (short) -1, timestampType18, (java.lang.Long) 10L, 0, (int) (byte) -1, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]}), value = ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null}))", headers57);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord64 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", 32, 35L, 0L, timestampType18, 0L, (int) '#', (int) (byte) 100, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, null = 1, serialized key size = 32, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=[]}, value = ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)))");
        org.junit.Assert.assertTrue("'" + timestampType18 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType18.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNull(kafkaSpoutStreams23);
        org.junit.Assert.assertNull(spoutOutputCollector30);
        org.junit.Assert.assertNull(kafkaSpoutRetryService33);
        org.junit.Assert.assertEquals("'" + str52 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str52, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int53 + "' != '" + (-1) + "'", int53 == (-1));
        org.junit.Assert.assertTrue("'" + int54 + "' != '" + 52 + "'", int54 == 52);
        org.junit.Assert.assertTrue("'" + long55 + "' != '" + (-1L) + "'", long55 == (-1L));
        org.junit.Assert.assertTrue("'" + int56 + "' != '" + 52 + "'", int56 == 52);
        org.junit.Assert.assertNotNull(headers57);
    }

    @Test
    public void test7331() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7331");
        org.apache.kafka.common.record.TimestampType timestampType8 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord19 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (-1), (long) ' ', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long20 = charSequenceConsumerRecord19.timestamp();
        java.lang.String str21 = charSequenceConsumerRecord19.topic();
        org.apache.kafka.common.header.Headers headers22 = charSequenceConsumerRecord19.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.CharSequence charSequence29 = charSequenceConsumerRecord28.key();
        java.util.Optional<java.lang.Integer> intOptional30 = charSequenceConsumerRecord28.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord31 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", (int) (short) 100, (long) '#', 35L, timestampType8, (java.lang.Long) 100L, (int) (byte) 10, 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 35, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)))", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", headers22, intOptional30);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.Iterable<org.apache.kafka.common.header.Header>> strComparableConsumerRecord32 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Comparable<java.lang.String>, java.lang.Iterable<org.apache.kafka.common.header.Header>>("ConsumerRecord(topic = ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", 0, (long) '4', (java.lang.Comparable<java.lang.String>) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers22);
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + (-1L) + "'", long20 == (-1L));
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "hi!" + "'", str21, "hi!");
        org.junit.Assert.assertNotNull(headers22);
        org.junit.Assert.assertEquals("'" + charSequence29 + "' != '" + "" + "'", charSequence29, "");
        org.junit.Assert.assertNotNull(intOptional30);
    }

    @Test
    public void test7332() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7332");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.checksum();
        int int16 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.String str17 = charSequenceConsumerRecord10.value();
        java.util.Optional<java.lang.Integer> intOptional18 = charSequenceConsumerRecord10.leaderEpoch();
        org.apache.kafka.common.record.TimestampType timestampType19 = charSequenceConsumerRecord10.timestampType();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str21 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 52 + "'", int16 == 52);
        org.junit.Assert.assertEquals("'" + str17 + "' != '" + "hi!" + "'", str17, "hi!");
        org.junit.Assert.assertNotNull(intOptional18);
        org.junit.Assert.assertNull(timestampType19);
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str21, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test7333() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7333");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)", (int) ' ', 100L, (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}))");
        java.lang.String str6 = charSequenceConsumerRecord5.value();
        long long7 = charSequenceConsumerRecord5.offset();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}))" + "'", str6, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 10, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}))");
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + 100L + "'", long7 == 100L);
    }

    @Test
    public void test7334() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7334");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        strKafkaSpout0.numUncommittedOffsets = (byte) -1;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams5 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams5;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig7 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer8 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer8;
        long long10 = strKafkaSpout0.numUncommittedOffsets;
        strKafkaSpout0.maxRetries = 52;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(strKafkaSpoutConfig7);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
    }

    @Test
    public void test7335() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7335");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence17 = charSequenceConsumerRecord10.key();
        java.lang.CharSequence charSequence18 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        long long20 = charSequenceConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers21 = charSequenceConsumerRecord10.headers();
        int int22 = charSequenceConsumerRecord10.serializedKeySize();
        int int23 = charSequenceConsumerRecord10.partition();
        long long24 = charSequenceConsumerRecord10.offset();
        org.apache.kafka.common.header.Headers headers25 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertEquals("'" + charSequence17 + "' != '" + "" + "'", charSequence17, "");
        org.junit.Assert.assertEquals("'" + charSequence18 + "' != '" + "" + "'", charSequence18, "");
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertTrue("'" + long20 + "' != '" + 0L + "'", long20 == 0L);
        org.junit.Assert.assertNotNull(headers21);
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + 52 + "'", int22 == 52);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 10 + "'", int23 == 10);
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + 0L + "'", long24 == 0L);
        org.junit.Assert.assertNotNull(headers25);
    }

    @Test
    public void test7336() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7336");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) 100, (long) 0, (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        int int6 = charSequenceConsumerRecord5.serializedValueSize();
        org.apache.kafka.common.record.TimestampType timestampType7 = charSequenceConsumerRecord5.timestampType();
        java.lang.String str8 = charSequenceConsumerRecord5.value();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertTrue("'" + timestampType7 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType7.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str8, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test7337() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7337");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional13 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str14 = charSequenceConsumerRecord10.value();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        int int16 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNotNull(intOptional13);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 52 + "'", int16 == 52);
    }

    @Test
    public void test7338() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7338");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.value();
        long long15 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str16 = charSequenceConsumerRecord10.value();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "hi!" + "'", str16, "hi!");
    }

    @Test
    public void test7339() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7339");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) '#', (long) '4', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, null = 1, serialized key size = 32, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "KafkaSpout{acked=null, emitted=[]}");
        long long6 = charSequenceConsumerRecord5.checksum();
        org.apache.kafka.common.header.Headers headers7 = charSequenceConsumerRecord5.headers();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertNotNull(headers7);
    }

    @Test
    public void test7340() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7340");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = kafkaSpoutMessageIdComparator13.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = kafkaSpoutMessageIdComparator2.thenComparing(kafkaSpoutMessageIdComparator21);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator27 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator27;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator27);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = offsetComparator27.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator31 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator32 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator32;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator32.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator39 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator39;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator39);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator42 = kafkaSpoutMessageIdComparator34.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator39);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator43 = offsetComparator31.thenComparing(kafkaSpoutMessageIdComparator42);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = kafkaSpoutMessageIdComparator42.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator42;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator46 = kafkaSpoutMessageIdComparator30.thenComparing(kafkaSpoutMessageIdComparator42);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator47 = kafkaSpoutMessageIdComparator21.thenComparing(kafkaSpoutMessageIdComparator42);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator48 = kafkaSpoutMessageIdComparator21.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator42);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator43);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator46);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator47);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator48);
    }

    @Test
    public void test7341() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7341");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.common.TopicPartition topicPartition16 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection17 = strKafkaSpout0.toArrayList(topicPartition16);
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig20 = strKafkaSpout0.kafkaSpoutConfig;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection17);
        org.junit.Assert.assertNull(strKafkaSpoutConfig20);
    }

    @Test
    public void test7342() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7342");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.common.TopicPartition topicPartition12 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection13 = strKafkaSpout0.toArrayList(topicPartition12);
        boolean boolean14 = strKafkaSpout0.consumerAutoCommitMode;
        boolean boolean15 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer16 = strKafkaSpout0.commitTimer;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer17 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer17);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertNotNull(topicPartitionCollection13);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertTrue("'" + boolean15 + "' != '" + false + "'", boolean15 == false);
        org.junit.Assert.assertNull(timer16);
    }

    @Test
    public void test7343() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7343");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (byte) -1, (long) (byte) 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = 35, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)");
    }

    @Test
    public void test7344() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7344");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        java.lang.String str11 = charSequenceConsumerRecord10.toString();
        java.lang.String str12 = charSequenceConsumerRecord10.topic();
        long long13 = charSequenceConsumerRecord10.checksum();
        java.lang.CharSequence charSequence14 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers15 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "" + "'", str12, "");
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence14 + "' != '" + "" + "'", charSequence14, "");
        org.junit.Assert.assertNotNull(headers15);
    }

    @Test
    public void test7345() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7345");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator11 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator11;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator11.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator18 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator18;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = kafkaSpoutMessageIdComparator13.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator18);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = kafkaSpoutMessageIdComparator2.thenComparing(kafkaSpoutMessageIdComparator21);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator23 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator24 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator24;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator24.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator31 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator31;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = kafkaSpoutMessageIdComparator26.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator31);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = offsetComparator23.thenComparing(kafkaSpoutMessageIdComparator34);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator36 = kafkaSpoutMessageIdComparator34.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator37 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator37;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator39 = offsetComparator37.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator44 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator44;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator44);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator47 = kafkaSpoutMessageIdComparator39.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator44);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator48 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator48;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator50 = offsetComparator48.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator55 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator55;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator55);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator58 = kafkaSpoutMessageIdComparator50.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator55);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator59 = kafkaSpoutMessageIdComparator39.thenComparing(kafkaSpoutMessageIdComparator58);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator60 = kafkaSpoutMessageIdComparator58.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator61 = kafkaSpoutMessageIdComparator34.thenComparing(kafkaSpoutMessageIdComparator58);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator62 = kafkaSpoutMessageIdComparator22.thenComparing(kafkaSpoutMessageIdComparator58);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator67 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator67;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator67);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator70 = offsetComparator67.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator71 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator72 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator72;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator74 = offsetComparator72.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator79 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator79;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator79);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator82 = kafkaSpoutMessageIdComparator74.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator79);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator83 = offsetComparator71.thenComparing(kafkaSpoutMessageIdComparator82);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator84 = kafkaSpoutMessageIdComparator82.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator85 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator85;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator87 = offsetComparator85.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator85;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator89 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator89;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator91 = offsetComparator89.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator92 = offsetComparator85.thenComparing(kafkaSpoutMessageIdComparator91);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator93 = offsetComparator85.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator94 = kafkaSpoutMessageIdComparator84.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator85);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator95 = kafkaSpoutMessageIdComparator70.thenComparing(kafkaSpoutMessageIdComparator84);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator96 = kafkaSpoutMessageIdComparator58.thenComparing(kafkaSpoutMessageIdComparator84);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator58;
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator58;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator36);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator39);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator47);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator50);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator58);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator59);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator60);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator61);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator62);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator70);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator74);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator82);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator83);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator84);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator87);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator91);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator92);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator93);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator94);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator95);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator96);
    }

    @Test
    public void test7346() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7346");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig12 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig12;
        boolean boolean14 = strKafkaSpout0.initialized;
        boolean boolean15 = strKafkaSpout0.waitingToEmit();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertTrue("'" + boolean15 + "' != '" + false + "'", boolean15 == false);
    }

    @Test
    public void test7347() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7347");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder2 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder2;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy4 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = strKafkaSpout0.kafkaSpoutConfig;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor7;
        strKafkaSpout0.consumerAutoCommitMode = true;
        boolean boolean11 = strKafkaSpout0.commit();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService12 = strKafkaSpout0.retryService;
        boolean boolean13 = strKafkaSpout0.waitingToEmit();
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strKafkaSpoutConfig6);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNull(kafkaSpoutRetryService12);
        org.junit.Assert.assertTrue("'" + boolean13 + "' != '" + false + "'", boolean13 == false);
    }

    @Test
    public void test7348() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7348");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector8 = null;
        strKafkaSpout0.collector = spoutOutputCollector8;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor10 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = null;
        strKafkaSpout0.collector = spoutOutputCollector11;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(strConsumerRecordItor10);
    }

    @Test
    public void test7349() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7349");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str22 = charSequenceConsumerRecord21.topic();
        org.apache.kafka.common.record.TimestampType timestampType23 = charSequenceConsumerRecord21.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout27 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout27.maxRetries = (byte) -1;
        int int30 = strKafkaSpout27.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor31 = null;
        strKafkaSpout27.waitingToEmit = strConsumerRecordItor31;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer33 = strKafkaSpout27.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer34 = strKafkaSpout27.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType40 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord46 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType40, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long47 = charSequenceConsumerRecord46.offset();
        long long48 = charSequenceConsumerRecord46.checksum();
        int int49 = charSequenceConsumerRecord46.serializedKeySize();
        org.apache.kafka.common.header.Headers headers50 = charSequenceConsumerRecord46.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord51 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType23, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout27, (java.lang.CharSequence) "hi!", headers50);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 1, 0L, (long) (byte) 0, timestampType23, (long) ' ', (int) (short) -1, (int) (byte) 10, (java.lang.CharSequence) "", "");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) -1, (long) ' ', (long) (short) 0, timestampType23, (long) (short) 1, (int) (byte) 10, (int) '#', (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        org.apache.kafka.common.record.TimestampType timestampType73 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord79 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType73, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        java.lang.String str80 = charSequenceConsumerRecord79.topic();
        org.apache.kafka.common.header.Headers headers81 = charSequenceConsumerRecord79.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord82 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 0, (long) 52, (long) (byte) -1, timestampType23, (java.lang.Long) 1L, (int) (short) 0, (-1), (java.lang.CharSequence) "hi!", "hi!", headers81);
        long long83 = charSequenceConsumerRecord82.timestamp();
        long long84 = charSequenceConsumerRecord82.checksum();
        java.util.Optional<java.lang.Integer> intOptional85 = charSequenceConsumerRecord82.leaderEpoch();
        int int86 = charSequenceConsumerRecord82.serializedValueSize();
        long long87 = charSequenceConsumerRecord82.offset();
        int int88 = charSequenceConsumerRecord82.serializedValueSize();
        java.lang.String str89 = charSequenceConsumerRecord82.topic();
        java.lang.String str90 = charSequenceConsumerRecord82.value();
        int int91 = charSequenceConsumerRecord82.partition();
        java.lang.CharSequence charSequence92 = charSequenceConsumerRecord82.key();
        java.util.Optional<java.lang.Integer> intOptional93 = charSequenceConsumerRecord82.leaderEpoch();
        int int94 = charSequenceConsumerRecord82.serializedValueSize();
        java.lang.String str95 = charSequenceConsumerRecord82.toString();
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "" + "'", str22, "");
        org.junit.Assert.assertTrue("'" + timestampType23 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType23.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int30 + "' != '" + (-1) + "'", int30 == (-1));
        org.junit.Assert.assertNull(timer33);
        org.junit.Assert.assertNull(strKafkaConsumer34);
        org.junit.Assert.assertTrue("'" + long47 + "' != '" + 0L + "'", long47 == 0L);
        org.junit.Assert.assertTrue("'" + long48 + "' != '" + (-1L) + "'", long48 == (-1L));
        org.junit.Assert.assertTrue("'" + int49 + "' != '" + 52 + "'", int49 == 52);
        org.junit.Assert.assertNotNull(headers50);
        org.junit.Assert.assertEquals("'" + str80 + "' != '" + "hi!" + "'", str80, "hi!");
        org.junit.Assert.assertNotNull(headers81);
        org.junit.Assert.assertTrue("'" + long83 + "' != '" + (-1L) + "'", long83 == (-1L));
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + 1L + "'", long84 == 1L);
        org.junit.Assert.assertNotNull(intOptional85);
        org.junit.Assert.assertTrue("'" + int86 + "' != '" + (-1) + "'", int86 == (-1));
        org.junit.Assert.assertTrue("'" + long87 + "' != '" + 52L + "'", long87 == 52L);
        org.junit.Assert.assertTrue("'" + int88 + "' != '" + (-1) + "'", int88 == (-1));
        org.junit.Assert.assertEquals("'" + str89 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str89, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertEquals("'" + str90 + "' != '" + "hi!" + "'", str90, "hi!");
        org.junit.Assert.assertTrue("'" + int91 + "' != '" + 0 + "'", int91 == 0);
        org.junit.Assert.assertEquals("'" + charSequence92 + "' != '" + "hi!" + "'", charSequence92, "hi!");
        org.junit.Assert.assertNotNull(intOptional93);
        org.junit.Assert.assertTrue("'" + int94 + "' != '" + (-1) + "'", int94 == (-1));
        org.junit.Assert.assertEquals("'" + str95 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)" + "'", str95, "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)");
    }

    @Test
    public void test7350() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7350");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = null;
        strKafkaSpout0.collector = spoutOutputCollector12;
        boolean boolean14 = strKafkaSpout0.initialized;
        boolean boolean15 = strKafkaSpout0.waitingToEmit();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
        org.junit.Assert.assertTrue("'" + boolean15 + "' != '" + false + "'", boolean15 == false);
    }

    @Test
    public void test7351() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7351");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout3 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout3.maxRetries = (byte) -1;
        int int6 = strKafkaSpout3.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray7 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet8 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean9 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet8, kafkaSpoutMessageIdArray7);
        strKafkaSpout3.emitted = kafkaSpoutMessageIdSet8;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams11 = null;
        strKafkaSpout3.kafkaSpoutStreams = kafkaSpoutStreams11;
        org.apache.kafka.common.TopicPartition topicPartition13 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection14 = strKafkaSpout3.toArrayList(topicPartition13);
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector15 = null;
        strKafkaSpout3.collector = spoutOutputCollector15;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout17 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet18 = strKafkaSpout17.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig19 = null;
        strKafkaSpout17.kafkaSpoutConfig = strKafkaSpoutConfig19;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector21 = strKafkaSpout17.collector;
        long long22 = strKafkaSpout17.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector23 = null;
        strKafkaSpout17.collector = spoutOutputCollector23;
        boolean boolean25 = strKafkaSpout17.consumerAutoCommitMode;
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.base.BaseComponent, java.io.Serializable> baseComponentConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.base.BaseComponent, java.io.Serializable>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)", (int) (short) -1, (long) (short) 0, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout3, (java.io.Serializable) strKafkaSpout17);
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor27 = null;
        strKafkaSpout3.waitingToEmit = strConsumerRecordItor27;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService29 = strKafkaSpout3.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder30 = strKafkaSpout3.tuplesBuilder;
        boolean boolean31 = strKafkaSpout3.consumerAutoCommitMode;
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray7);
        org.junit.Assert.assertTrue("'" + boolean9 + "' != '" + false + "'", boolean9 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection14);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet18);
        org.junit.Assert.assertNull(spoutOutputCollector21);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + 0L + "'", long22 == 0L);
        org.junit.Assert.assertTrue("'" + boolean25 + "' != '" + false + "'", boolean25 == false);
        org.junit.Assert.assertNull(kafkaSpoutRetryService29);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder30);
        org.junit.Assert.assertTrue("'" + boolean31 + "' != '" + false + "'", boolean31 == false);
    }

    @Test
    public void test7352() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7352");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str18 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.header.Headers headers19 = charSequenceConsumerRecord10.headers();
        int int20 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertNotNull(headers19);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + (-1) + "'", int20 == (-1));
    }

    @Test
    public void test7353() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7353");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        int int8 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor9 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = (short) 0;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams12;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean14 = strKafkaSpout0.commit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strConsumerRecordItor9);
    }

    @Test
    public void test7354() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7354");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 1, 1L, (long) (byte) 10, timestampType4, (long) '#', (int) (byte) 100, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        java.lang.String str11 = charSequenceConsumerRecord10.value();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        java.util.Optional<java.lang.Integer> intOptional14 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
        org.junit.Assert.assertNotNull(intOptional14);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence15, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str16, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test7355() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7355");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers12 = charSequenceConsumerRecord10.headers();
        int int13 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType14 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str15 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 52 + "'", int13 == 52);
        org.junit.Assert.assertNull(timestampType14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str15, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test7356() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7356");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService8;
        long long10 = strKafkaSpout0.numUncommittedOffsets;
        strKafkaSpout0.initialized = false;
        strKafkaSpout0.maxRetries = 35;
        long long15 = strKafkaSpout0.numUncommittedOffsets;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.activate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + 0L + "'", long10 == 0L);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 0L + "'", long15 == 0L);
    }

    @Test
    public void test7357() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7357");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.storm.topology.base.BaseComponent, org.apache.storm.topology.IRichSpout> baseComponentKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.storm.topology.base.BaseComponent, org.apache.storm.topology.IRichSpout> baseComponentKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.storm.topology.base.BaseComponent, org.apache.storm.topology.IRichSpout>(baseComponentKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test7358() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7358");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams6 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.initialized = true;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService9;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor11 = strKafkaSpout0.waitingToEmit;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams6);
        org.junit.Assert.assertNull(strConsumerRecordItor11);
    }

    @Test
    public void test7359() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7359");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig8 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer9 = strKafkaSpout0.kafkaConsumer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer10;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer12 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy13 = strKafkaSpout0.firstPollOffsetStrategy;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.doSeekRetriableTopicPartitions();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(strKafkaSpoutConfig8);
        org.junit.Assert.assertNull(strKafkaConsumer9);
        org.junit.Assert.assertNull(timer12);
        org.junit.Assert.assertNull(firstPollOffsetStrategy13);
    }

    @Test
    public void test7360() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7360");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) 100, (long) 0, (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.apache.kafka.common.record.TimestampType timestampType6 = charSequenceConsumerRecord5.timestampType();
        org.apache.kafka.common.header.Headers headers7 = charSequenceConsumerRecord5.headers();
        java.util.Optional<java.lang.Integer> intOptional8 = charSequenceConsumerRecord5.leaderEpoch();
        org.junit.Assert.assertTrue("'" + timestampType6 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType6.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers7);
        org.junit.Assert.assertNotNull(intOptional8);
    }

    @Test
    public void test7361() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7361");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        java.lang.String str10 = strKafkaSpout0.toString();
        boolean boolean11 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition12 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection13 = strKafkaSpout0.toArrayList(topicPartition12);
        java.util.Map map14 = null;
        org.apache.storm.task.TopologyContext topologyContext15 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector16 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map14, topologyContext15, spoutOutputCollector16);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str10, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection13);
    }

    @Test
    public void test7362() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7362");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer1 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService2 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService2;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy4 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams5 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams5;
        strKafkaSpout0.numUncommittedOffsets = (-1);
        java.util.Map map9 = null;
        org.apache.storm.task.TopologyContext topologyContext10 = null;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.open(map9, topologyContext10, spoutOutputCollector11);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(timer1);
        org.junit.Assert.assertNull(firstPollOffsetStrategy4);
    }

    @Test
    public void test7363() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7363");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType23, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long30 = charSequenceConsumerRecord29.checksum();
        int int31 = charSequenceConsumerRecord29.partition();
        java.lang.String str32 = charSequenceConsumerRecord29.value();
        int int33 = charSequenceConsumerRecord29.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional34 = charSequenceConsumerRecord29.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet36 = strKafkaSpout35.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor37 = null;
        strKafkaSpout35.waitingToEmit = strConsumerRecordItor37;
        boolean boolean39 = strKafkaSpout35.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig40 = null;
        strKafkaSpout35.kafkaSpoutConfig = strKafkaSpoutConfig40;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy42 = strKafkaSpout35.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType15, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord29, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout35);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) 100, (long) 0, (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.apache.kafka.common.record.TimestampType timestampType55 = charSequenceConsumerRecord54.timestampType();
        org.apache.kafka.common.header.Headers headers56 = charSequenceConsumerRecord54.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord57 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", 97, 0L, 0L, timestampType15, (java.lang.Long) 97L, (int) (short) -1, (int) (short) 100, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 52, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 0, null = 97, serialized key size = 32, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", headers56);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 10 + "'", int31 == 10);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "hi!" + "'", str32, "hi!");
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + 52 + "'", int33 == 52);
        org.junit.Assert.assertNotNull(intOptional34);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet36);
        org.junit.Assert.assertTrue("'" + boolean39 + "' != '" + false + "'", boolean39 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy42);
        org.junit.Assert.assertTrue("'" + timestampType55 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType55.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertNotNull(headers56);
    }

    @Test
    public void test7364() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7364");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        int int7 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.initialized = true;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer4);
        org.junit.Assert.assertNull(strKafkaSpoutConfig5);
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + (-1) + "'", int7 == (-1));
    }

    @Test
    public void test7365() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7365");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams7;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = null;
        strKafkaSpout0.collector = spoutOutputCollector9;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector11 = strKafkaSpout0.collector;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(spoutOutputCollector11);
    }

    @Test
    public void test7366() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7366");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        boolean boolean11 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams12;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy14 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy14;
        java.lang.String str16 = strKafkaSpout0.toString();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str16, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test7367() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7367");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType14, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int21 = charSequenceConsumerRecord20.serializedValueSize();
        java.lang.CharSequence charSequence22 = charSequenceConsumerRecord20.key();
        org.apache.kafka.common.header.Headers headers23 = charSequenceConsumerRecord20.headers();
        int int24 = charSequenceConsumerRecord20.partition();
        java.lang.CharSequence charSequence25 = charSequenceConsumerRecord20.key();
        int int26 = charSequenceConsumerRecord20.serializedValueSize();
        int int27 = charSequenceConsumerRecord20.serializedValueSize();
        long long28 = charSequenceConsumerRecord20.checksum();
        org.apache.kafka.common.header.Headers headers29 = charSequenceConsumerRecord20.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord30 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 35, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)))", (int) (byte) 10, (long) (short) 10, 0L, timestampType4, (java.lang.Long) 32L, (int) 'a', (int) '#', (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 1, leaderEpoch = null, offset = 1, NoTimestampType = 35, serialized key size = 1, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = hi!)", headers29);
        java.lang.String str31 = charSequenceConsumerRecord30.topic();
        java.lang.String str32 = charSequenceConsumerRecord30.topic();
        org.apache.kafka.common.record.TimestampType timestampType33 = charSequenceConsumerRecord30.timestampType();
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence22 + "' != '" + "" + "'", charSequence22, "");
        org.junit.Assert.assertNotNull(headers23);
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + 10 + "'", int24 == 10);
        org.junit.Assert.assertEquals("'" + charSequence25 + "' != '" + "" + "'", charSequence25, "");
        org.junit.Assert.assertTrue("'" + int26 + "' != '" + (-1) + "'", int26 == (-1));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
        org.junit.Assert.assertTrue("'" + long28 + "' != '" + (-1L) + "'", long28 == (-1L));
        org.junit.Assert.assertNotNull(headers29);
        org.junit.Assert.assertEquals("'" + str31 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 35, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)))" + "'", str31, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 35, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)))");
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 35, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)))" + "'", str32, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 35, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)))");
        org.junit.Assert.assertNull(timestampType33);
    }

    @Test
    public void test7368() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7368");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        boolean boolean12 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy13 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy13;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor15 = strKafkaSpout0.waitingToEmit;
        java.lang.Class<?> wildcardClass16 = strKafkaSpout0.getClass();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + false + "'", boolean12 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor15);
        org.junit.Assert.assertNotNull(wildcardClass16);
    }

    @Test
    public void test7369() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7369");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig3 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig3;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer5 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor7;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertNull(strKafkaConsumer5);
        org.junit.Assert.assertNull(timer6);
    }

    @Test
    public void test7370() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7370");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = strKafkaSpout0.collector;
        java.lang.String str10 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService11 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService11;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer13 = strKafkaSpout0.kafkaConsumer;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords14 = strKafkaSpout0.pollKafkaBroker();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertNull(spoutOutputCollector9);
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str10, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaConsumer13);
    }

    @Test
    public void test7371() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7371");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.numUncommittedOffsets = 'a';
        java.lang.String str13 = strKafkaSpout0.toString();
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(timer8);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str13, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test7372() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7372");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = null;
        strKafkaSpout0.collector = spoutOutputCollector12;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer14 = strKafkaSpout0.commitTimer;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertNull(timer14);
    }

    @Test
    public void test7373() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7373");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.maxRetries = ' ';
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams10 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams10;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = strKafkaSpout0.collector;
        strKafkaSpout0.initialized = true;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean15 = strKafkaSpout0.commit();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertNull(spoutOutputCollector12);
    }

    @Test
    public void test7374() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7374");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        long long15 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        java.lang.String str18 = charSequenceConsumerRecord10.topic();
        int int19 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.String str20 = charSequenceConsumerRecord10.value();
        java.lang.CharSequence charSequence21 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 52 + "'", int19 == 52);
        org.junit.Assert.assertEquals("'" + str20 + "' != '" + "hi!" + "'", str20, "hi!");
        org.junit.Assert.assertEquals("'" + charSequence21 + "' != '" + "" + "'", charSequence21, "");
    }

    @Test
    public void test7375() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7375");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        long long7 = charSequenceConsumerRecord5.timestamp();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        java.lang.String str9 = charSequenceConsumerRecord5.toString();
        org.apache.kafka.common.header.Headers headers10 = charSequenceConsumerRecord5.headers();
        java.lang.String str11 = charSequenceConsumerRecord5.topic();
        long long12 = charSequenceConsumerRecord5.timestamp();
        java.lang.String str13 = charSequenceConsumerRecord5.toString();
        org.apache.kafka.common.header.Headers headers14 = charSequenceConsumerRecord5.headers();
        long long15 = charSequenceConsumerRecord5.timestamp();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str9, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str13, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
    }

    @Test
    public void test7376() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7376");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        java.lang.String str7 = charSequenceConsumerRecord5.toString();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str7, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers8);
    }

    @Test
    public void test7377() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7377");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        java.lang.String str11 = charSequenceConsumerRecord10.toString();
        long long12 = charSequenceConsumerRecord10.offset();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        java.lang.CharSequence charSequence14 = charSequenceConsumerRecord10.key();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 0L + "'", long12 == 0L);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertEquals("'" + charSequence14 + "' != '" + "" + "'", charSequence14, "");
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
    }

    @Test
    public void test7378() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7378");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer9 = strKafkaSpout0.commitTimer;
        boolean boolean10 = strKafkaSpout0.waitingToEmit();
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.initialized = true;
        strKafkaSpout0.maxRetries = (-1);
        strKafkaSpout0.numUncommittedOffsets = (short) -1;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService19 = strKafkaSpout0.retryService;
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertNull(timer9);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
        org.junit.Assert.assertNull(kafkaSpoutRetryService19);
    }

    @Test
    public void test7379() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7379");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator1 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator2 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator2;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator4 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator5 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator5;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator5.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator8 = offsetComparator4.thenComparing(kafkaSpoutMessageIdComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator9 = offsetComparator2.thenComparing(kafkaSpoutMessageIdComparator8);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = offsetComparator2.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = offsetComparator2.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator12 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator13.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator20 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator20;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = kafkaSpoutMessageIdComparator15.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = offsetComparator12.thenComparing(kafkaSpoutMessageIdComparator23);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator23;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = kafkaSpoutMessageIdComparator11.thenComparing(kafkaSpoutMessageIdComparator23);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator26);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = kafkaSpoutMessageIdComparator27.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = kafkaSpoutMessageIdComparator28.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator28;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator1);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator8);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator9);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
    }

    @Test
    public void test7380() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7380");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType23, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long30 = charSequenceConsumerRecord29.checksum();
        int int31 = charSequenceConsumerRecord29.partition();
        java.lang.String str32 = charSequenceConsumerRecord29.value();
        int int33 = charSequenceConsumerRecord29.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional34 = charSequenceConsumerRecord29.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet36 = strKafkaSpout35.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor37 = null;
        strKafkaSpout35.waitingToEmit = strConsumerRecordItor37;
        boolean boolean39 = strKafkaSpout35.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig40 = null;
        strKafkaSpout35.kafkaSpoutConfig = strKafkaSpoutConfig40;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy42 = strKafkaSpout35.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType15, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord29, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout35);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType53, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int60 = charSequenceConsumerRecord59.serializedValueSize();
        java.lang.CharSequence charSequence61 = charSequenceConsumerRecord59.key();
        org.apache.kafka.common.header.Headers headers62 = charSequenceConsumerRecord59.headers();
        int int63 = charSequenceConsumerRecord59.partition();
        int int64 = charSequenceConsumerRecord59.partition();
        org.apache.kafka.common.header.Headers headers65 = charSequenceConsumerRecord59.headers();
        org.apache.kafka.common.record.TimestampType timestampType70 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord76 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType70, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int77 = charSequenceConsumerRecord76.serializedValueSize();
        long long78 = charSequenceConsumerRecord76.checksum();
        java.util.Optional<java.lang.Integer> intOptional79 = charSequenceConsumerRecord76.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord80 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", (int) (short) 0, (long) (short) 10, (long) 1, timestampType15, (java.lang.Long) 100L, (int) (byte) -1, 52, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", headers65, intOptional79);
        java.util.Optional<java.lang.Integer> intOptional81 = charSequenceConsumerRecord80.leaderEpoch();
        long long82 = charSequenceConsumerRecord80.timestamp();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 10 + "'", int31 == 10);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "hi!" + "'", str32, "hi!");
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + 52 + "'", int33 == 52);
        org.junit.Assert.assertNotNull(intOptional34);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet36);
        org.junit.Assert.assertTrue("'" + boolean39 + "' != '" + false + "'", boolean39 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy42);
        org.junit.Assert.assertTrue("'" + int60 + "' != '" + (-1) + "'", int60 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence61 + "' != '" + "" + "'", charSequence61, "");
        org.junit.Assert.assertNotNull(headers62);
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 10 + "'", int63 == 10);
        org.junit.Assert.assertTrue("'" + int64 + "' != '" + 10 + "'", int64 == 10);
        org.junit.Assert.assertNotNull(headers65);
        org.junit.Assert.assertTrue("'" + int77 + "' != '" + (-1) + "'", int77 == (-1));
        org.junit.Assert.assertTrue("'" + long78 + "' != '" + (-1L) + "'", long78 == (-1L));
        org.junit.Assert.assertNotNull(intOptional79);
        org.junit.Assert.assertNotNull(intOptional81);
        org.junit.Assert.assertTrue("'" + long82 + "' != '" + 1L + "'", long82 == 1L);
    }

    @Test
    public void test7381() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7381");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 100, null = 10, serialized key size = 10, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", 0, 1L, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", "");
        int int6 = charSequenceConsumerRecord5.serializedValueSize();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
    }

    @Test
    public void test7382() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7382");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService1 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService1;
        long long3 = strKafkaSpout0.numUncommittedOffsets;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = strKafkaSpout0.waitingToEmit;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = strKafkaSpout0.emitted;
        int int6 = strKafkaSpout0.maxRetries;
        int int7 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        int int9 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.consumerAutoCommitMode = true;
        boolean boolean12 = strKafkaSpout0.initialized;
        org.junit.Assert.assertTrue("'" + long3 + "' != '" + 0L + "'", long3 == 0L);
        org.junit.Assert.assertNull(strConsumerRecordItor4);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet5);
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + 0 + "'", int6 == 0);
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 0 + "'", int7 == 0);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + 0 + "'", int9 == 0);
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + false + "'", boolean12 == false);
    }

    @Test
    public void test7383() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7383");
        java.lang.CharSequence charSequence3 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", 0, 97L, charSequence3, "");
        java.lang.String str6 = charSequenceConsumerRecord5.toString();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = )" + "'", str6, "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = )");
    }

    @Test
    public void test7384() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7384");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator1 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator1;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator3 = offsetComparator1.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator4 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator3);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator5 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator5;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator5.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator12 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator12;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord14 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = kafkaSpoutMessageIdComparator7.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator0.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator12);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator16;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = kafkaSpoutMessageIdComparator16.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator19 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator20 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator20;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator22 = offsetComparator20.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator27 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator27;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator27);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = kafkaSpoutMessageIdComparator22.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator27);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = offsetComparator19.thenComparing(kafkaSpoutMessageIdComparator30);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = kafkaSpoutMessageIdComparator16.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator19);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator33 = kafkaSpoutMessageIdComparator16.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator33;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator3);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator4);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator22);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator33);
    }

    @Test
    public void test7385() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7385");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig9 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig9;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder11 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder11;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService13 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService13;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder15 = strKafkaSpout0.tuplesBuilder;
        strKafkaSpout0.numUncommittedOffsets = 0L;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig18 = strKafkaSpout0.kafkaSpoutConfig;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder15);
        org.junit.Assert.assertNull(strKafkaSpoutConfig18);
    }

    @Test
    public void test7386() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7386");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor10 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor10;
        org.apache.kafka.common.TopicPartition topicPartition12 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection13 = strKafkaSpout0.toArrayList(topicPartition12);
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy14 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy14;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor16 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor16;
        int int18 = strKafkaSpout0.maxRetries;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.shutdown();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection13);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + (-1) + "'", int18 == (-1));
    }

    @Test
    public void test7387() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7387");
        org.apache.storm.kafka.spout.KafkaSpout<java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdComparatorKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>();
    }

    @Test
    public void test7388() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7388");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        org.apache.kafka.common.TopicPartition topicPartition8 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection9 = strKafkaSpout0.toArrayList(topicPartition8);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer10;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor12 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor12;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig14 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig14;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector16 = strKafkaSpout0.collector;
        boolean boolean17 = strKafkaSpout0.consumerAutoCommitMode;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection9);
        org.junit.Assert.assertNull(spoutOutputCollector16);
        org.junit.Assert.assertTrue("'" + boolean17 + "' != '" + false + "'", boolean17 == false);
    }

    @Test
    public void test7389() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7389");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy10 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy10;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet12 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService13 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService13;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService15 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService15;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig17 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig17;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet12);
    }

    @Test
    public void test7390() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7390");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = strKafkaSpout0.tuplesBuilder;
        java.lang.String str8 = strKafkaSpout0.toString();
        strKafkaSpout0.maxRetries = ' ';
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout12 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = strKafkaSpout12.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor14 = null;
        strKafkaSpout12.waitingToEmit = strConsumerRecordItor14;
        boolean boolean16 = strKafkaSpout12.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig17 = null;
        strKafkaSpout12.kafkaSpoutConfig = strKafkaSpoutConfig17;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector19 = strKafkaSpout12.collector;
        org.apache.kafka.common.record.TimestampType timestampType24 = null;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout28 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams29 = strKafkaSpout28.kafkaSpoutStreams;
        strKafkaSpout28.consumerAutoCommitMode = false;
        java.lang.String str32 = strKafkaSpout28.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout33 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout33.maxRetries = (byte) -1;
        int int36 = strKafkaSpout33.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray37 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet38 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean39 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet38, kafkaSpoutMessageIdArray37);
        strKafkaSpout33.emitted = kafkaSpoutMessageIdSet38;
        strKafkaSpout28.emitted = kafkaSpoutMessageIdSet38;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout42 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout42.maxRetries = (byte) -1;
        int int45 = strKafkaSpout42.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor46 = null;
        strKafkaSpout42.waitingToEmit = strConsumerRecordItor46;
        org.apache.kafka.common.TopicPartition topicPartition48 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection49 = strKafkaSpout42.toArrayList(topicPartition48);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer50 = strKafkaSpout42.commitTimer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector51 = strKafkaSpout42.collector;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout52 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout52.maxRetries = (byte) -1;
        int int55 = strKafkaSpout52.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray56 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet57 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean58 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet57, kafkaSpoutMessageIdArray56);
        strKafkaSpout52.emitted = kafkaSpoutMessageIdSet57;
        strKafkaSpout42.emitted = kafkaSpoutMessageIdSet57;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetConsumerRecord61 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (byte) 0, (long) (short) -1, (long) (byte) 10, timestampType24, (long) (byte) 10, (int) (byte) -1, 0, (java.util.AbstractSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet38, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet57);
        strKafkaSpout12.emitted = kafkaSpoutMessageIdSet57;
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet57;
        strKafkaSpout0.maxRetries = (short) 0;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder7);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet13);
        org.junit.Assert.assertTrue("'" + boolean16 + "' != '" + false + "'", boolean16 == false);
        org.junit.Assert.assertNull(spoutOutputCollector19);
        org.junit.Assert.assertNull(kafkaSpoutStreams29);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str32, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + int36 + "' != '" + (-1) + "'", int36 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray37);
        org.junit.Assert.assertTrue("'" + boolean39 + "' != '" + false + "'", boolean39 == false);
        org.junit.Assert.assertTrue("'" + int45 + "' != '" + (-1) + "'", int45 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection49);
        org.junit.Assert.assertNull(timer50);
        org.junit.Assert.assertNull(spoutOutputCollector51);
        org.junit.Assert.assertTrue("'" + int55 + "' != '" + (-1) + "'", int55 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray56);
        org.junit.Assert.assertTrue("'" + boolean58 + "' != '" + false + "'", boolean58 == false);
    }

    @Test
    public void test7391() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7391");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        java.lang.String str8 = strKafkaSpout0.toString();
        boolean boolean9 = strKafkaSpout0.consumerAutoCommitMode;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.deactivate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + boolean9 + "' != '" + false + "'", boolean9 == false);
    }

    @Test
    public void test7392() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7392");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer6 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer7 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer6);
        org.junit.Assert.assertNull(timer7);
        org.junit.Assert.assertNull(timer8);
    }

    @Test
    public void test7393() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7393");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer6 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService7 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService7;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig9 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig9;
        strKafkaSpout0.numUncommittedOffsets = 35L;
        strKafkaSpout0.initialized = true;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder17 = strKafkaSpout0.tuplesBuilder;
        boolean boolean18 = strKafkaSpout0.consumerAutoCommitMode;
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer6);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder17);
        org.junit.Assert.assertTrue("'" + boolean18 + "' != '" + false + "'", boolean18 == false);
    }

    @Test
    public void test7394() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7394");
        java.lang.CharSequence charSequence3 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (short) 1, (long) 52, charSequence3, "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
    }

    @Test
    public void test7395() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7395");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams6 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.kafka.common.TopicPartition topicPartition7 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection8 = strKafkaSpout0.toArrayList(topicPartition7);
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor9 = strKafkaSpout0.waitingToEmit;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + 0 + "'", int3 == 0);
        org.junit.Assert.assertNull(kafkaSpoutStreams6);
        org.junit.Assert.assertNotNull(topicPartitionCollection8);
        org.junit.Assert.assertNull(strConsumerRecordItor9);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
    }

    @Test
    public void test7396() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7396");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        java.lang.String str13 = charSequenceConsumerRecord10.topic();
        int int14 = charSequenceConsumerRecord10.partition();
        long long15 = charSequenceConsumerRecord10.timestamp();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        int int18 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 52 + "'", int18 == 52);
    }

    @Test
    public void test7397() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7397");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        boolean boolean2 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.kafka.common.TopicPartition topicPartition3 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection4 = strKafkaSpout0.toArrayList(topicPartition3);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService5 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams6 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams6;
        boolean boolean8 = strKafkaSpout0.waitingToEmit();
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertTrue("'" + boolean2 + "' != '" + false + "'", boolean2 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection4);
        org.junit.Assert.assertNull(kafkaSpoutRetryService5);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
    }

    @Test
    public void test7398() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7398");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        int int9 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.maxRetries = (byte) 100;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector12 = strKafkaSpout0.collector;
        strKafkaSpout0.maxRetries = '4';
        long long15 = strKafkaSpout0.numUncommittedOffsets;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertTrue("'" + int9 + "' != '" + (-1) + "'", int9 == (-1));
        org.junit.Assert.assertNull(spoutOutputCollector12);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 0L + "'", long15 == 0L);
    }

    @Test
    public void test7399() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7399");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 0, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = hi!)", (int) (short) 100, (long) (short) 100, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=[]}", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        int int6 = charSequenceConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + (-1) + "'", int6 == (-1));
    }

    @Test
    public void test7400() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7400");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy10 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy10;
        strKafkaSpout0.maxRetries = (short) -1;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector14 = null;
        strKafkaSpout0.collector = spoutOutputCollector14;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService16 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService16;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
    }

    @Test
    public void test7401() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7401");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.offset();
        long long12 = charSequenceConsumerRecord10.timestamp();
        int int13 = charSequenceConsumerRecord10.partition();
        java.lang.String str14 = charSequenceConsumerRecord10.toString();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord10.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 0L + "'", long11 == 0L);
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str14, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNull(timestampType15);
        org.junit.Assert.assertNull(timestampType16);
    }

    @Test
    public void test7402() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7402");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = strKafkaSpout0.waitingToEmit;
        org.apache.kafka.common.TopicPartition topicPartition5 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection6 = strKafkaSpout0.toArrayList(topicPartition5);
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet7 = strKafkaSpout0.emitted;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector8 = null;
        strKafkaSpout0.collector = spoutOutputCollector8;
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertNull(strConsumerRecordItor4);
        org.junit.Assert.assertNotNull(topicPartitionCollection6);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet7);
    }

    @Test
    public void test7403() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7403");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.numUncommittedOffsets = (byte) 1;
        strKafkaSpout0.initialized = false;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet14 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService15 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService15;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder17 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder17;
        strKafkaSpout0.maxRetries = (short) 10;
        int int21 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.maxRetries = 35;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet14);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + 10 + "'", int21 == 10);
    }

    @Test
    public void test7404() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7404");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.initialized = false;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy10 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy10;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService12 = strKafkaSpout0.retryService;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.activate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutRetryService12);
    }

    @Test
    public void test7405() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7405");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType14 = null;
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.common.record.TimestampType timestampType37 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType37, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int44 = charSequenceConsumerRecord43.serializedValueSize();
        java.lang.CharSequence charSequence45 = charSequenceConsumerRecord43.key();
        org.apache.kafka.common.header.Headers headers46 = charSequenceConsumerRecord43.headers();
        java.util.Optional<java.lang.Integer> intOptional47 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType27, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers46, intOptional47);
        org.apache.kafka.common.record.TimestampType timestampType56 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord62 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType56, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int63 = charSequenceConsumerRecord62.serializedValueSize();
        java.lang.CharSequence charSequence64 = charSequenceConsumerRecord62.key();
        org.apache.kafka.common.header.Headers headers65 = charSequenceConsumerRecord62.headers();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray66 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdList67 = new java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean68 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList67, kafkaSpoutMessageIdArray66);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("hi!", 10, (long) (byte) 100, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers65, (java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdList67);
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headersConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.kafka.common.header.Headers, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("", (int) '#', 1L, headers46, kafkaSpoutMessageIdList67);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord71 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) 'a', (long) (byte) 1, (long) (byte) 0, timestampType14, (java.lang.Long) (-1L), (int) (short) 100, 1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}", headers46);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord72 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", (int) (byte) 10, (long) (byte) -1, (long) '#', timestampType4, (java.lang.Long) 100L, (int) (byte) -1, 100, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers46);
        java.lang.String str73 = charSequenceConsumerRecord72.toString();
        int int74 = charSequenceConsumerRecord72.partition();
        java.lang.String str75 = charSequenceConsumerRecord72.value();
        int int76 = charSequenceConsumerRecord72.serializedValueSize();
        long long77 = charSequenceConsumerRecord72.checksum();
        org.apache.kafka.common.record.TimestampType timestampType78 = charSequenceConsumerRecord72.timestampType();
        org.junit.Assert.assertTrue("'" + int44 + "' != '" + (-1) + "'", int44 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence45 + "' != '" + "" + "'", charSequence45, "");
        org.junit.Assert.assertNotNull(headers46);
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + (-1) + "'", int63 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence64 + "' != '" + "" + "'", charSequence64, "");
        org.junit.Assert.assertNotNull(headers65);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray66);
        org.junit.Assert.assertTrue("'" + boolean68 + "' != '" + false + "'", boolean68 == false);
        org.junit.Assert.assertEquals("'" + str73 + "' != '" + "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str73, "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = -1, null = 35, serialized key size = -1, serialized value size = 100, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + int74 + "' != '" + 10 + "'", int74 == 10);
        org.junit.Assert.assertEquals("'" + str75 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str75, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + 100 + "'", int76 == 100);
        org.junit.Assert.assertTrue("'" + long77 + "' != '" + 100L + "'", long77 == 100L);
        org.junit.Assert.assertNull(timestampType78);
    }

    @Test
    public void test7406() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7406");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        strKafkaSpout0.consumerAutoCommitMode = false;
        boolean boolean6 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService7 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = strKafkaSpout0.kafkaSpoutStreams;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.doSeekRetriableTopicPartitions();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNull(kafkaSpoutRetryService7);
        org.junit.Assert.assertNull(kafkaSpoutStreams8);
    }

    @Test
    public void test7407() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7407");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        boolean boolean12 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy13 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy13;
        strKafkaSpout0.numUncommittedOffsets = 35L;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + false + "'", boolean12 == false);
    }

    @Test
    public void test7408() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7408");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        java.lang.String str11 = charSequenceConsumerRecord10.toString();
        long long12 = charSequenceConsumerRecord10.offset();
        int int13 = charSequenceConsumerRecord10.partition();
        java.lang.String str14 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.header.Headers headers15 = charSequenceConsumerRecord10.headers();
        java.util.Optional<java.lang.Integer> intOptional16 = charSequenceConsumerRecord10.leaderEpoch();
        int int17 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str11, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + 0L + "'", long12 == 0L);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 10 + "'", int13 == 10);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertNotNull(headers15);
        org.junit.Assert.assertNotNull(intOptional16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
    }

    @Test
    public void test7409() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7409");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector8 = null;
        strKafkaSpout0.collector = spoutOutputCollector8;
        strKafkaSpout0.consumerAutoCommitMode = true;
        boolean boolean12 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder13;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords15 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords15);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + true + "'", boolean12 == true);
    }

    @Test
    public void test7410() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7410");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray4 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet5 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean6 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet5, kafkaSpoutMessageIdArray4);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet5;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams8 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams8;
        org.apache.kafka.common.TopicPartition topicPartition10 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection11 = strKafkaSpout0.toArrayList(topicPartition10);
        java.lang.String str12 = strKafkaSpout0.toString();
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer13 = strKafkaSpout0.kafkaConsumer;
        long long14 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder15 = strKafkaSpout0.tuplesBuilder;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray4);
        org.junit.Assert.assertTrue("'" + boolean6 + "' != '" + false + "'", boolean6 == false);
        org.junit.Assert.assertNotNull(topicPartitionCollection11);
        org.junit.Assert.assertEquals("'" + str12 + "' != '" + "KafkaSpout{acked=null, emitted=[]}" + "'", str12, "KafkaSpout{acked=null, emitted=[]}");
        org.junit.Assert.assertNull(strKafkaConsumer13);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder15);
    }

    @Test
    public void test7411() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7411");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray12 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet13 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean14 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet13, kafkaSpoutMessageIdArray12);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet13;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer16 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer16;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector18 = null;
        strKafkaSpout0.collector = spoutOutputCollector18;
        strKafkaSpout0.numUncommittedOffsets = 1L;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector22 = null;
        strKafkaSpout0.collector = spoutOutputCollector22;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.doSeekRetriableTopicPartitions();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray12);
        org.junit.Assert.assertTrue("'" + boolean14 + "' != '" + false + "'", boolean14 == false);
    }

    @Test
    public void test7412() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7412");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        int int16 = charSequenceConsumerRecord10.partition();
        int int17 = charSequenceConsumerRecord10.serializedValueSize();
        long long18 = charSequenceConsumerRecord10.timestamp();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + (-1) + "'", int17 == (-1));
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
    }

    @Test
    public void test7413() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7413");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        long long12 = charSequenceConsumerRecord10.checksum();
        int int13 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.String str14 = charSequenceConsumerRecord10.value();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.header.Headers headers16 = charSequenceConsumerRecord10.headers();
        int int17 = charSequenceConsumerRecord10.serializedKeySize();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertTrue("'" + long12 + "' != '" + (-1L) + "'", long12 == (-1L));
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 52 + "'", int13 == 52);
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertNotNull(headers16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 52 + "'", int17 == 52);
    }

    @Test
    public void test7414() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7414");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType23 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord29 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType23, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long30 = charSequenceConsumerRecord29.checksum();
        int int31 = charSequenceConsumerRecord29.partition();
        java.lang.String str32 = charSequenceConsumerRecord29.value();
        int int33 = charSequenceConsumerRecord29.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional34 = charSequenceConsumerRecord29.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout35 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet36 = strKafkaSpout35.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor37 = null;
        strKafkaSpout35.waitingToEmit = strConsumerRecordItor37;
        boolean boolean39 = strKafkaSpout35.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig40 = null;
        strKafkaSpout35.kafkaSpoutConfig = strKafkaSpoutConfig40;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy42 = strKafkaSpout35.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType15, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord29, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout35);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord59 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType53, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long60 = charSequenceConsumerRecord59.checksum();
        int int61 = charSequenceConsumerRecord59.partition();
        java.lang.String str62 = charSequenceConsumerRecord59.value();
        int int63 = charSequenceConsumerRecord59.serializedKeySize();
        org.apache.kafka.common.header.Headers headers64 = charSequenceConsumerRecord59.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord70 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str71 = charSequenceConsumerRecord70.topic();
        java.util.Optional<java.lang.Integer> intOptional72 = charSequenceConsumerRecord70.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord73 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 0, (long) (short) 10, (long) (-1), timestampType15, (java.lang.Long) 35L, 10, (int) (short) 10, (java.lang.CharSequence) "", "KafkaSpout{acked=null, emitted=null}", headers64, intOptional72);
        long long74 = charSequenceConsumerRecord73.timestamp();
        java.lang.String str75 = charSequenceConsumerRecord73.value();
        long long76 = charSequenceConsumerRecord73.checksum();
        int int77 = charSequenceConsumerRecord73.partition();
        org.apache.kafka.common.header.Headers headers78 = charSequenceConsumerRecord73.headers();
        int int79 = charSequenceConsumerRecord73.serializedKeySize();
        long long80 = charSequenceConsumerRecord73.timestamp();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long30 + "' != '" + (-1L) + "'", long30 == (-1L));
        org.junit.Assert.assertTrue("'" + int31 + "' != '" + 10 + "'", int31 == 10);
        org.junit.Assert.assertEquals("'" + str32 + "' != '" + "hi!" + "'", str32, "hi!");
        org.junit.Assert.assertTrue("'" + int33 + "' != '" + 52 + "'", int33 == 52);
        org.junit.Assert.assertNotNull(intOptional34);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet36);
        org.junit.Assert.assertTrue("'" + boolean39 + "' != '" + false + "'", boolean39 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy42);
        org.junit.Assert.assertTrue("'" + long60 + "' != '" + (-1L) + "'", long60 == (-1L));
        org.junit.Assert.assertTrue("'" + int61 + "' != '" + 10 + "'", int61 == 10);
        org.junit.Assert.assertEquals("'" + str62 + "' != '" + "hi!" + "'", str62, "hi!");
        org.junit.Assert.assertTrue("'" + int63 + "' != '" + 52 + "'", int63 == 52);
        org.junit.Assert.assertNotNull(headers64);
        org.junit.Assert.assertEquals("'" + str71 + "' != '" + "" + "'", str71, "");
        org.junit.Assert.assertNotNull(intOptional72);
        org.junit.Assert.assertTrue("'" + long74 + "' != '" + (-1L) + "'", long74 == (-1L));
        org.junit.Assert.assertEquals("'" + str75 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str75, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + long76 + "' != '" + 35L + "'", long76 == 35L);
        org.junit.Assert.assertTrue("'" + int77 + "' != '" + 0 + "'", int77 == 0);
        org.junit.Assert.assertNotNull(headers78);
        org.junit.Assert.assertTrue("'" + int79 + "' != '" + 10 + "'", int79 == 10);
        org.junit.Assert.assertTrue("'" + long80 + "' != '" + (-1L) + "'", long80 == (-1L));
    }

    @Test
    public void test7415() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7415");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout19 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout19.maxRetries = (byte) -1;
        int int22 = strKafkaSpout19.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor23 = null;
        strKafkaSpout19.waitingToEmit = strConsumerRecordItor23;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer25 = strKafkaSpout19.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer26 = strKafkaSpout19.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType32, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long39 = charSequenceConsumerRecord38.offset();
        long long40 = charSequenceConsumerRecord38.checksum();
        int int41 = charSequenceConsumerRecord38.serializedKeySize();
        org.apache.kafka.common.header.Headers headers42 = charSequenceConsumerRecord38.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType15, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout19, (java.lang.CharSequence) "hi!", headers42);
        org.apache.kafka.common.record.TimestampType timestampType53 = null;
        org.apache.kafka.common.record.TimestampType timestampType63 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord69 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType63, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int70 = charSequenceConsumerRecord69.serializedValueSize();
        java.lang.CharSequence charSequence71 = charSequenceConsumerRecord69.key();
        org.apache.kafka.common.header.Headers headers72 = charSequenceConsumerRecord69.headers();
        java.util.Optional<java.lang.Integer> intOptional73 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", 100, (long) (byte) 0, (long) '#', timestampType53, (java.lang.Long) (-1L), (int) (byte) 1, 0, (java.lang.CharSequence) "KafkaSpout{acked=null, emitted=null}", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", headers72, intOptional73);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord75 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (byte) -1, (-1L), (long) (short) 10, timestampType15, (java.lang.Long) 0L, (int) (short) 1, 97, (java.lang.CharSequence) "", "KafkaSpout{acked=null, emitted=null}", headers72);
        int int76 = charSequenceConsumerRecord75.serializedValueSize();
        java.lang.String str77 = charSequenceConsumerRecord75.toString();
        java.lang.String str78 = charSequenceConsumerRecord75.topic();
        int int79 = charSequenceConsumerRecord75.serializedKeySize();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertNull(timer25);
        org.junit.Assert.assertNull(strKafkaConsumer26);
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + 0L + "'", long39 == 0L);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + 52 + "'", int41 == 52);
        org.junit.Assert.assertNotNull(headers42);
        org.junit.Assert.assertTrue("'" + int70 + "' != '" + (-1) + "'", int70 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence71 + "' != '" + "" + "'", charSequence71, "");
        org.junit.Assert.assertNotNull(headers72);
        org.junit.Assert.assertTrue("'" + int76 + "' != '" + 97 + "'", int76 == 97);
        org.junit.Assert.assertEquals("'" + str77 + "' != '" + "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})" + "'", str77, "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
        org.junit.Assert.assertEquals("'" + str78 + "' != '" + "hi!" + "'", str78, "hi!");
        org.junit.Assert.assertTrue("'" + int79 + "' != '" + 1 + "'", int79 == 1);
    }

    @Test
    public void test7416() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7416");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        long long21 = charSequenceConsumerRecord10.offset();
        long long22 = charSequenceConsumerRecord10.timestamp();
        java.lang.CharSequence charSequence23 = charSequenceConsumerRecord10.key();
        int int24 = charSequenceConsumerRecord10.serializedKeySize();
        int int25 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + 0L + "'", long21 == 0L);
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence23 + "' != '" + "" + "'", charSequence23, "");
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + 52 + "'", int24 == 52);
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + (-1) + "'", int25 == (-1));
    }

    @Test
    public void test7417() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7417");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy11 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy11;
        strKafkaSpout0.initialized = true;
        strKafkaSpout0.numUncommittedOffsets = (short) -1;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig17 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder18 = strKafkaSpout0.tuplesBuilder;
        strKafkaSpout0.consumerAutoCommitMode = true;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(strKafkaSpoutConfig17);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder18);
    }

    @Test
    public void test7418() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7418");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer6 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder7;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector9 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder10 = strKafkaSpout0.tuplesBuilder;
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer6);
        org.junit.Assert.assertNull(spoutOutputCollector9);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder10);
    }

    @Test
    public void test7419() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7419");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig5 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy7 = strKafkaSpout0.firstPollOffsetStrategy;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords11 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords11);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer4);
        org.junit.Assert.assertNull(strKafkaSpoutConfig5);
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertNull(firstPollOffsetStrategy7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
    }

    @Test
    public void test7420() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7420");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", 100, 32L, (long) (short) -1, timestampType4, (long) (byte) 0, 97, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 1, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})");
        java.util.Optional<java.lang.Integer> intOptional11 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertNotNull(intOptional11);
    }

    @Test
    public void test7421() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7421");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str21 = charSequenceConsumerRecord10.value();
        java.util.Optional<java.lang.Integer> intOptional22 = charSequenceConsumerRecord10.leaderEpoch();
        int int23 = charSequenceConsumerRecord10.serializedKeySize();
        long long24 = charSequenceConsumerRecord10.timestamp();
        int int25 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "hi!" + "'", str21, "hi!");
        org.junit.Assert.assertNotNull(intOptional22);
        org.junit.Assert.assertTrue("'" + int23 + "' != '" + 52 + "'", int23 == 52);
        org.junit.Assert.assertTrue("'" + long24 + "' != '" + (-1L) + "'", long24 == (-1L));
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + (-1) + "'", int25 == (-1));
    }

    @Test
    public void test7422() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7422");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 100, null = 1, serialized key size = 32, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", (int) ' ', (long) (byte) -1, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
    }

    @Test
    public void test7423() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7423");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        int int18 = charSequenceConsumerRecord10.serializedKeySize();
        int int19 = charSequenceConsumerRecord10.partition();
        int int20 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + int18 + "' != '" + 52 + "'", int18 == 52);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + 10 + "'", int19 == 10);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 10 + "'", int20 == 10);
    }

    @Test
    public void test7424() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7424");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator7 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator7;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = kafkaSpoutMessageIdComparator2.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator7);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = offsetComparator7.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = offsetComparator7.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator13 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator13;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator13.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator20 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator20;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord22 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator23 = kafkaSpoutMessageIdComparator15.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator20);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator24 = kafkaSpoutMessageIdComparator15.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator25 = offsetComparator7.thenComparing(kafkaSpoutMessageIdComparator24);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator26 = offsetComparator7.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator27 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator28 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator28;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = offsetComparator28.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = offsetComparator27.thenComparing(kafkaSpoutMessageIdComparator30);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator32 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator32;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator34 = offsetComparator32.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator39 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator39;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord41 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator39);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator42 = kafkaSpoutMessageIdComparator34.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator39);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator43 = offsetComparator27.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator39);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = offsetComparator39.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator45 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator45;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator47 = offsetComparator45.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator52 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator52;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord54 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator52);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator55 = kafkaSpoutMessageIdComparator47.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator52);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator56 = offsetComparator52.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator57 = kafkaSpoutMessageIdComparator44.thenComparing(kafkaSpoutMessageIdComparator56);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator58 = kafkaSpoutMessageIdComparator26.thenComparing(kafkaSpoutMessageIdComparator56);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator59 = kafkaSpoutMessageIdComparator58.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator58;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator23);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator24);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator25);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator26);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator34);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator42);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator43);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator47);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator55);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator56);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator57);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator58);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator59);
    }

    @Test
    public void test7425() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7425");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer1 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy2 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams3 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams3;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder5 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder5;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = strKafkaSpout0.kafkaConsumer;
        boolean boolean8 = strKafkaSpout0.consumerAutoCommitMode;
        strKafkaSpout0.maxRetries = (short) 1;
        org.junit.Assert.assertNull(timer1);
        org.junit.Assert.assertNull(firstPollOffsetStrategy2);
        org.junit.Assert.assertNull(strKafkaConsumer7);
        org.junit.Assert.assertTrue("'" + boolean8 + "' != '" + false + "'", boolean8 == false);
    }

    @Test
    public void test7426() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7426");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType4, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        java.lang.String str11 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.header.Headers headers12 = charSequenceConsumerRecord10.headers();
        java.lang.CharSequence charSequence13 = charSequenceConsumerRecord10.key();
        java.lang.String str14 = charSequenceConsumerRecord10.topic();
        long long15 = charSequenceConsumerRecord10.offset();
        int int16 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "hi!" + "'", str11, "hi!");
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertEquals("'" + charSequence13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 10 + "'", int16 == 10);
    }

    @Test
    public void test7427() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7427");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder8;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector10 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams11 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder12 = strKafkaSpout0.tuplesBuilder;
        strKafkaSpout0.initialized = false;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(spoutOutputCollector10);
        org.junit.Assert.assertNull(kafkaSpoutStreams11);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder12);
    }

    @Test
    public void test7428() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7428");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord17 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str18 = charSequenceConsumerRecord17.topic();
        org.apache.kafka.common.record.TimestampType timestampType19 = charSequenceConsumerRecord17.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType27 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord33 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType27, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long34 = charSequenceConsumerRecord33.checksum();
        int int35 = charSequenceConsumerRecord33.partition();
        java.lang.String str36 = charSequenceConsumerRecord33.value();
        int int37 = charSequenceConsumerRecord33.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional38 = charSequenceConsumerRecord33.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout39 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet40 = strKafkaSpout39.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor41 = null;
        strKafkaSpout39.waitingToEmit = strConsumerRecordItor41;
        boolean boolean43 = strKafkaSpout39.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig44 = null;
        strKafkaSpout39.kafkaSpoutConfig = strKafkaSpoutConfig44;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy46 = strKafkaSpout39.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord47 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType19, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord33, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout39);
        org.apache.kafka.common.record.TimestampType timestampType57 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord63 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType57, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long64 = charSequenceConsumerRecord63.checksum();
        int int65 = charSequenceConsumerRecord63.partition();
        java.lang.String str66 = charSequenceConsumerRecord63.value();
        int int67 = charSequenceConsumerRecord63.serializedKeySize();
        org.apache.kafka.common.header.Headers headers68 = charSequenceConsumerRecord63.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord74 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str75 = charSequenceConsumerRecord74.topic();
        java.util.Optional<java.lang.Integer> intOptional76 = charSequenceConsumerRecord74.leaderEpoch();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord77 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", 0, (long) (short) 10, (long) (-1), timestampType19, (java.lang.Long) 35L, 10, (int) (short) 10, (java.lang.CharSequence) "", "KafkaSpout{acked=null, emitted=null}", headers68, intOptional76);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord83 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 0, (long) (byte) -1, (long) (short) 10, timestampType19, (-1L), 100, 10, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        long long84 = charSequenceConsumerRecord83.checksum();
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "" + "'", str18, "");
        org.junit.Assert.assertTrue("'" + timestampType19 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType19.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long34 + "' != '" + (-1L) + "'", long34 == (-1L));
        org.junit.Assert.assertTrue("'" + int35 + "' != '" + 10 + "'", int35 == 10);
        org.junit.Assert.assertEquals("'" + str36 + "' != '" + "hi!" + "'", str36, "hi!");
        org.junit.Assert.assertTrue("'" + int37 + "' != '" + 52 + "'", int37 == 52);
        org.junit.Assert.assertNotNull(intOptional38);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet40);
        org.junit.Assert.assertTrue("'" + boolean43 + "' != '" + false + "'", boolean43 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy46);
        org.junit.Assert.assertTrue("'" + long64 + "' != '" + (-1L) + "'", long64 == (-1L));
        org.junit.Assert.assertTrue("'" + int65 + "' != '" + 10 + "'", int65 == 10);
        org.junit.Assert.assertEquals("'" + str66 + "' != '" + "hi!" + "'", str66, "hi!");
        org.junit.Assert.assertTrue("'" + int67 + "' != '" + 52 + "'", int67 == 52);
        org.junit.Assert.assertNotNull(headers68);
        org.junit.Assert.assertEquals("'" + str75 + "' != '" + "" + "'", str75, "");
        org.junit.Assert.assertNotNull(intOptional76);
        org.junit.Assert.assertTrue("'" + long84 + "' != '" + (-1L) + "'", long84 == (-1L));
    }

    @Test
    public void test7429() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7429");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 10, 1L, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=[]}");
        long long14 = charSequenceConsumerRecord13.checksum();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord21 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 32, leaderEpoch = null, offset = 100, null = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = KafkaSpout{acked=null, emitted=null}, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) 1, (long) (byte) 0, (long) (byte) 0, timestampType15, (long) 35, (int) '4', (int) (short) 10, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.apache.kafka.common.record.TimestampType timestampType31 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord37 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType31, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int38 = charSequenceConsumerRecord37.serializedValueSize();
        long long39 = charSequenceConsumerRecord37.checksum();
        int int40 = charSequenceConsumerRecord37.serializedKeySize();
        java.lang.String str41 = charSequenceConsumerRecord37.value();
        long long42 = charSequenceConsumerRecord37.offset();
        org.apache.kafka.common.record.TimestampType timestampType43 = charSequenceConsumerRecord37.timestampType();
        java.util.Optional<java.lang.Integer> intOptional44 = charSequenceConsumerRecord37.leaderEpoch();
        java.lang.CharSequence charSequence45 = charSequenceConsumerRecord37.key();
        org.apache.kafka.common.header.Headers headers46 = charSequenceConsumerRecord37.headers();
        java.util.Optional<java.lang.Integer> intOptional47 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord48 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 35, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)))", 97, (long) '#', (-1L), timestampType15, (java.lang.Long) 100L, 1, (int) '#', (java.lang.CharSequence) "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)", "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = )", headers46, intOptional47);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int38 + "' != '" + (-1) + "'", int38 == (-1));
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + (-1L) + "'", long39 == (-1L));
        org.junit.Assert.assertTrue("'" + int40 + "' != '" + 52 + "'", int40 == 52);
        org.junit.Assert.assertEquals("'" + str41 + "' != '" + "hi!" + "'", str41, "hi!");
        org.junit.Assert.assertTrue("'" + long42 + "' != '" + 0L + "'", long42 == 0L);
        org.junit.Assert.assertNull(timestampType43);
        org.junit.Assert.assertNotNull(intOptional44);
        org.junit.Assert.assertEquals("'" + charSequence45 + "' != '" + "" + "'", charSequence45, "");
        org.junit.Assert.assertNotNull(headers46);
    }

    @Test
    public void test7430() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7430");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence16 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord10.timestampType();
        long long18 = charSequenceConsumerRecord10.checksum();
        long long19 = charSequenceConsumerRecord10.checksum();
        int int20 = charSequenceConsumerRecord10.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional21 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + charSequence16 + "' != '" + "" + "'", charSequence16, "");
        org.junit.Assert.assertNull(timestampType17);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + (-1L) + "'", long18 == (-1L));
        org.junit.Assert.assertTrue("'" + long19 + "' != '" + (-1L) + "'", long19 == (-1L));
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 52 + "'", int20 == 52);
        org.junit.Assert.assertNotNull(intOptional21);
    }

    @Test
    public void test7431() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7431");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer8 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig9 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy10 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy10;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer8);
        org.junit.Assert.assertNull(strKafkaSpoutConfig9);
    }

    @Test
    public void test7432() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7432");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        int int21 = charSequenceConsumerRecord10.serializedValueSize();
        long long22 = charSequenceConsumerRecord10.checksum();
        long long23 = charSequenceConsumerRecord10.timestamp();
        java.util.Optional<java.lang.Integer> intOptional24 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.CharSequence charSequence25 = charSequenceConsumerRecord10.key();
        java.lang.String str26 = charSequenceConsumerRecord10.value();
        int int27 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertTrue("'" + int21 + "' != '" + (-1) + "'", int21 == (-1));
        org.junit.Assert.assertTrue("'" + long22 + "' != '" + (-1L) + "'", long22 == (-1L));
        org.junit.Assert.assertTrue("'" + long23 + "' != '" + (-1L) + "'", long23 == (-1L));
        org.junit.Assert.assertNotNull(intOptional24);
        org.junit.Assert.assertEquals("'" + charSequence25 + "' != '" + "" + "'", charSequence25, "");
        org.junit.Assert.assertEquals("'" + str26 + "' != '" + "hi!" + "'", str26, "hi!");
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + (-1) + "'", int27 == (-1));
    }

    @Test
    public void test7433() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7433");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams2 = strKafkaSpout0.kafkaSpoutStreams;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig3 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig3;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor5 = strKafkaSpout0.waitingToEmit;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer6 = strKafkaSpout0.kafkaConsumer;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(kafkaSpoutStreams2);
        org.junit.Assert.assertNull(strConsumerRecordItor5);
        org.junit.Assert.assertNull(strKafkaConsumer6);
    }

    @Test
    public void test7434() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7434");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy5 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy5;
        java.lang.String str7 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder9;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId[] kafkaSpoutMessageIdArray11 = new org.apache.storm.kafka.spout.KafkaSpoutMessageId[] {};
        java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet12 = new java.util.LinkedHashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>();
        boolean boolean13 = java.util.Collections.addAll((java.util.Collection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) kafkaSpoutMessageIdSet12, kafkaSpoutMessageIdArray11);
        strKafkaSpout0.emitted = kafkaSpoutMessageIdSet12;
        java.lang.String str15 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer16 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout17 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout17.maxRetries = (byte) -1;
        int int20 = strKafkaSpout17.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor21 = null;
        strKafkaSpout17.waitingToEmit = strConsumerRecordItor21;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig23 = null;
        strKafkaSpout17.kafkaSpoutConfig = strKafkaSpoutConfig23;
        int int25 = strKafkaSpout17.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy26 = null;
        strKafkaSpout17.firstPollOffsetStrategy = firstPollOffsetStrategy26;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig28 = strKafkaSpout17.kafkaSpoutConfig;
        int int29 = strKafkaSpout17.maxRetries;
        boolean boolean30 = strKafkaSpout17.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy31 = strKafkaSpout17.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService32 = null;
        strKafkaSpout17.retryService = kafkaSpoutRetryService32;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService34 = null;
        strKafkaSpout17.retryService = kafkaSpoutRetryService34;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.fail((java.lang.Object) strKafkaSpout17);
            org.junit.Assert.fail("Expected exception of type java.lang.ClassCastException; message: org.apache.storm.kafka.spout.KafkaSpout cannot be cast to org.apache.storm.kafka.spout.KafkaSpoutMessageId");
        } catch (java.lang.ClassCastException e) {
        // Expected exception.
        }
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str7, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdArray11);
        org.junit.Assert.assertTrue("'" + boolean13 + "' != '" + false + "'", boolean13 == false);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=[]}" + "'", str15, "KafkaSpout{acked=null, emitted=[]}");
        org.junit.Assert.assertNull(timer16);
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + (-1) + "'", int20 == (-1));
        org.junit.Assert.assertTrue("'" + int25 + "' != '" + (-1) + "'", int25 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig28);
        org.junit.Assert.assertTrue("'" + int29 + "' != '" + (-1) + "'", int29 == (-1));
        org.junit.Assert.assertTrue("'" + boolean30 + "' != '" + false + "'", boolean30 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy31);
    }

    @Test
    public void test7435() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7435");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, org.apache.kafka.common.header.Headers> typeKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.reflect.Type, org.apache.kafka.common.header.Headers>();
    }

    @Test
    public void test7436() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7436");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig11 = strKafkaSpout0.kafkaSpoutConfig;
        int int12 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder13 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder13;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService15 = strKafkaSpout0.retryService;
        boolean boolean16 = strKafkaSpout0.consumerAutoCommitMode;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet17 = strKafkaSpout0.emitted;
        strKafkaSpout0.maxRetries = (byte) -1;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig20 = strKafkaSpout0.kafkaSpoutConfig;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Map<java.lang.String, java.lang.Object> strMap21 = strKafkaSpout0.getComponentConfiguration();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(strKafkaSpoutConfig11);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService15);
        org.junit.Assert.assertTrue("'" + boolean16 + "' != '" + false + "'", boolean16 == false);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet17);
        org.junit.Assert.assertNull(strKafkaSpoutConfig20);
    }

    @Test
    public void test7437() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7437");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        strKafkaSpout0.consumerAutoCommitMode = false;
        java.lang.String str6 = strKafkaSpout0.toString();
        boolean boolean7 = strKafkaSpout0.waitingToEmit();
        strKafkaSpout0.numUncommittedOffsets = 0L;
        // The following exception was thrown during execution in test generation
        try {
            java.lang.String str10 = strKafkaSpout0.getWildCardTopics();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str6, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
    }

    @Test
    public void test7438() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7438");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str10 = charSequenceConsumerRecord9.topic();
        org.apache.kafka.common.record.TimestampType timestampType11 = charSequenceConsumerRecord9.timestampType();
        org.apache.kafka.common.record.TimestampType timestampType19 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord25 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType19, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long26 = charSequenceConsumerRecord25.checksum();
        int int27 = charSequenceConsumerRecord25.partition();
        java.lang.String str28 = charSequenceConsumerRecord25.value();
        int int29 = charSequenceConsumerRecord25.serializedKeySize();
        java.util.Optional<java.lang.Integer> intOptional30 = charSequenceConsumerRecord25.leaderEpoch();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout31 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet32 = strKafkaSpout31.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor33 = null;
        strKafkaSpout31.waitingToEmit = strConsumerRecordItor33;
        boolean boolean35 = strKafkaSpout31.consumerAutoCommitMode;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig36 = null;
        strKafkaSpout31.kafkaSpoutConfig = strKafkaSpoutConfig36;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy38 = strKafkaSpout31.firstPollOffsetStrategy;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent> objConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Object, org.apache.storm.topology.base.BaseComponent>("", (int) (short) 100, (long) (short) 1, (long) (byte) 10, timestampType11, (long) 1, (int) 'a', (-1), (java.lang.Object) charSequenceConsumerRecord25, (org.apache.storm.topology.base.BaseComponent) strKafkaSpout31);
        long long40 = charSequenceConsumerRecord25.offset();
        java.util.Optional<java.lang.Integer> intOptional41 = charSequenceConsumerRecord25.leaderEpoch();
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "" + "'", str10, "");
        org.junit.Assert.assertTrue("'" + timestampType11 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType11.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + long26 + "' != '" + (-1L) + "'", long26 == (-1L));
        org.junit.Assert.assertTrue("'" + int27 + "' != '" + 10 + "'", int27 == 10);
        org.junit.Assert.assertEquals("'" + str28 + "' != '" + "hi!" + "'", str28, "hi!");
        org.junit.Assert.assertTrue("'" + int29 + "' != '" + 52 + "'", int29 == 52);
        org.junit.Assert.assertNotNull(intOptional30);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet32);
        org.junit.Assert.assertTrue("'" + boolean35 + "' != '" + false + "'", boolean35 == false);
        org.junit.Assert.assertNull(firstPollOffsetStrategy38);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + 0L + "'", long40 == 0L);
        org.junit.Assert.assertNotNull(intOptional41);
    }

    @Test
    public void test7439() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7439");
        org.apache.kafka.common.record.TimestampType timestampType7 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType7, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long14 = charSequenceConsumerRecord13.checksum();
        int int15 = charSequenceConsumerRecord13.partition();
        long long16 = charSequenceConsumerRecord13.timestamp();
        long long17 = charSequenceConsumerRecord13.offset();
        java.lang.String str18 = charSequenceConsumerRecord13.value();
        java.lang.String str19 = charSequenceConsumerRecord13.topic();
        int int20 = charSequenceConsumerRecord13.partition();
        org.apache.kafka.common.record.TimestampType timestampType21 = charSequenceConsumerRecord13.timestampType();
        int int22 = charSequenceConsumerRecord13.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional23 = charSequenceConsumerRecord13.leaderEpoch();
        org.apache.kafka.common.header.Headers headers24 = charSequenceConsumerRecord13.headers();
        java.util.AbstractCollection<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdCollection25 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.AbstractCollection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.AbstractCollection<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})", (int) '#', 35L, (java.lang.Iterable<org.apache.kafka.common.header.Header>) headers24, kafkaSpoutMessageIdCollection25);
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + (-1L) + "'", long14 == (-1L));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
        org.junit.Assert.assertEquals("'" + str18 + "' != '" + "hi!" + "'", str18, "hi!");
        org.junit.Assert.assertEquals("'" + str19 + "' != '" + "" + "'", str19, "");
        org.junit.Assert.assertTrue("'" + int20 + "' != '" + 10 + "'", int20 == 10);
        org.junit.Assert.assertNull(timestampType21);
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertNotNull(intOptional23);
        org.junit.Assert.assertNotNull(headers24);
    }

    @Test
    public void test7440() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7440");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 10, 1L, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=[]}");
        java.lang.String str6 = charSequenceConsumerRecord5.value();
        java.util.Optional<java.lang.Integer> intOptional7 = charSequenceConsumerRecord5.leaderEpoch();
        java.lang.CharSequence charSequence8 = charSequenceConsumerRecord5.key();
        java.lang.String str9 = charSequenceConsumerRecord5.topic();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "KafkaSpout{acked=null, emitted=[]}" + "'", str6, "KafkaSpout{acked=null, emitted=[]}");
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertEquals("'" + charSequence8 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence8, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "" + "'", str9, "");
    }

    @Test
    public void test7441() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7441");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        java.lang.String str7 = charSequenceConsumerRecord5.toString();
        java.util.Optional<java.lang.Integer> intOptional8 = charSequenceConsumerRecord5.leaderEpoch();
        long long9 = charSequenceConsumerRecord5.timestamp();
        int int10 = charSequenceConsumerRecord5.serializedValueSize();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str7, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(intOptional8);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + (-1L) + "'", long9 == (-1L));
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
    }

    @Test
    public void test7442() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7442");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        boolean boolean7 = strKafkaSpout0.initialized;
        strKafkaSpout0.maxRetries = (short) 1;
        boolean boolean10 = strKafkaSpout0.initialized;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy11 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy11;
        // The following exception was thrown during execution in test generation
        try {
            java.util.Map<java.lang.String, java.lang.Object> strMap13 = strKafkaSpout0.getComponentConfiguration();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
        org.junit.Assert.assertTrue("'" + boolean10 + "' != '" + false + "'", boolean10 == false);
    }

    @Test
    public void test7443() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7443");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder12 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder12;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder14 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder14;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer16 = strKafkaSpout0.commitTimer;
        org.apache.kafka.common.TopicPartition topicPartition17 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection18 = strKafkaSpout0.toArrayList(topicPartition17);
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.close();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNull(timer16);
        org.junit.Assert.assertNotNull(topicPartitionCollection18);
    }

    @Test
    public void test7444() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7444");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType4, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        java.lang.String str11 = charSequenceConsumerRecord10.topic();
        org.apache.kafka.common.header.Headers headers12 = charSequenceConsumerRecord10.headers();
        java.lang.CharSequence charSequence13 = charSequenceConsumerRecord10.key();
        java.lang.String str14 = charSequenceConsumerRecord10.topic();
        long long15 = charSequenceConsumerRecord10.offset();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "hi!" + "'", str11, "hi!");
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertEquals("'" + charSequence13 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", charSequence13, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "hi!" + "'", str14, "hi!");
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + 52L + "'", long15 == 52L);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "hi!" + "'", str16, "hi!");
    }

    @Test
    public void test7445() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7445");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("KafkaSpout{acked=null, emitted=null}", 100, (long) '#', 100L, timestampType4, (long) 10, (int) '#', (int) (byte) 100, (java.lang.CharSequence) "", "");
        long long11 = charSequenceConsumerRecord10.timestamp();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        int int13 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.header.Headers headers14 = charSequenceConsumerRecord10.headers();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 100L + "'", long11 == 100L);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 100 + "'", int12 == 100);
        org.junit.Assert.assertTrue("'" + int13 + "' != '" + 35 + "'", int13 == 35);
        org.junit.Assert.assertNotNull(headers14);
    }

    @Test
    public void test7446() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7446");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 10, 0L, (java.lang.CharSequence) "", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        int int10 = charSequenceConsumerRecord9.serializedKeySize();
        java.lang.String str11 = charSequenceConsumerRecord9.value();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord9.timestampType();
        java.lang.CharSequence charSequence16 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord18 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = )", 97, (long) (short) 1, (long) 'a', timestampType12, 97L, (int) (short) 0, 0, charSequence16, "ConsumerRecord(topic = ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})");
        org.junit.Assert.assertTrue("'" + int10 + "' != '" + (-1) + "'", int10 == (-1));
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", str11, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        org.junit.Assert.assertTrue("'" + timestampType12 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType12.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
    }

    @Test
    public void test7447() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7447");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig6 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig6;
        int int8 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy9;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet11 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams12 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams12;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector14 = strKafkaSpout0.collector;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector15 = strKafkaSpout0.collector;
        strKafkaSpout0.initialized = false;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + (-1) + "'", int8 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet11);
        org.junit.Assert.assertNull(spoutOutputCollector14);
        org.junit.Assert.assertNull(spoutOutputCollector15);
    }

    @Test
    public void test7448() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7448");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> headerIterableKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.Iterable<org.apache.kafka.common.header.Header>, java.util.List<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>(headerIterableKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test7449() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7449");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 0, NoTimestampType = 35, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)))", 52, 52L, (java.lang.CharSequence) "", "ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = -1, NoTimestampType = 10, serialized key size = 1, serialized value size = 97, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})");
        int int6 = charSequenceConsumerRecord5.partition();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + 52 + "'", int6 == 52);
    }

    @Test
    public void test7450() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7450");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        java.lang.String str4 = strKafkaSpout0.toString();
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer7 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer7;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService11 = strKafkaSpout0.retryService;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertEquals("'" + str4 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str4, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(firstPollOffsetStrategy9);
        org.junit.Assert.assertNull(kafkaSpoutRetryService10);
        org.junit.Assert.assertNull(kafkaSpoutRetryService11);
    }

    @Test
    public void test7451() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7451");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.initialized = false;
        strKafkaSpout0.maxRetries = (short) -1;
        org.apache.kafka.common.TopicPartition topicPartition7 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection8 = strKafkaSpout0.toArrayList(topicPartition7);
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = strKafkaSpout0.firstPollOffsetStrategy;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor10 = strKafkaSpout0.waitingToEmit;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor2);
        org.junit.Assert.assertNotNull(topicPartitionCollection8);
        org.junit.Assert.assertNull(firstPollOffsetStrategy9);
        org.junit.Assert.assertNull(strConsumerRecordItor10);
    }

    @Test
    public void test7452() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7452");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", (int) (short) 1, (long) '4', (long) '#', timestampType4, (long) 10, (int) (byte) -1, 10, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "KafkaSpout{acked=null, emitted=null}");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType12 = charSequenceConsumerRecord10.timestampType();
        long long13 = charSequenceConsumerRecord10.offset();
        int int14 = charSequenceConsumerRecord10.serializedKeySize();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + 35L + "'", long11 == 35L);
        org.junit.Assert.assertNull(timestampType12);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 52L + "'", long13 == 52L);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str15, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(timestampType16);
    }

    @Test
    public void test7453() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7453");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        int int11 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.CharSequence charSequence12 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.header.Headers headers13 = charSequenceConsumerRecord10.headers();
        org.apache.kafka.common.header.Headers headers14 = charSequenceConsumerRecord10.headers();
        long long15 = charSequenceConsumerRecord10.checksum();
        int int16 = charSequenceConsumerRecord10.serializedKeySize();
        long long17 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
        org.junit.Assert.assertEquals("'" + charSequence12 + "' != '" + "" + "'", charSequence12, "");
        org.junit.Assert.assertNotNull(headers13);
        org.junit.Assert.assertNotNull(headers14);
        org.junit.Assert.assertTrue("'" + long15 + "' != '" + (-1L) + "'", long15 == (-1L));
        org.junit.Assert.assertTrue("'" + int16 + "' != '" + 52 + "'", int16 == 52);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
    }

    @Test
    public void test7454() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7454");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        strKafkaSpout0.numUncommittedOffsets = (byte) 1;
        strKafkaSpout0.initialized = false;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet14 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService15 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService15;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder17 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder17;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService19 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService19;
        boolean boolean21 = strKafkaSpout0.initialized;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.deactivate();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet14);
        org.junit.Assert.assertTrue("'" + boolean21 + "' != '" + false + "'", boolean21 == false);
    }

    @Test
    public void test7455() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7455");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService8;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder10 = strKafkaSpout0.tuplesBuilder;
        org.apache.kafka.common.TopicPartition topicPartition11 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection12 = strKafkaSpout0.toArrayList(topicPartition11);
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor13 = strKafkaSpout0.waitingToEmit;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder10);
        org.junit.Assert.assertNotNull(topicPartitionCollection12);
        org.junit.Assert.assertNull(strConsumerRecordItor13);
    }

    @Test
    public void test7456() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7456");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer6 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy8 = null;
        strKafkaSpout0.firstPollOffsetStrategy = firstPollOffsetStrategy8;
        java.lang.String str10 = strKafkaSpout0.toString();
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords11 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords11);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(timer6);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder7);
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str10, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test7457() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7457");
        org.apache.storm.kafka.spout.KafkaSpout<org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>, java.lang.CharSequence> strKafkaSpoutKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>, java.lang.CharSequence>();
    }

    @Test
    public void test7458() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7458");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams7 = null;
        strKafkaSpout0.kafkaSpoutStreams = kafkaSpoutStreams7;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService9 = strKafkaSpout0.retryService;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer10 = strKafkaSpout0.kafkaConsumer;
        strKafkaSpout0.maxRetries = (-1);
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig13 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig14 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig14;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet16 = strKafkaSpout0.emitted;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.doSeekRetriableTopicPartitions();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(kafkaSpoutRetryService9);
        org.junit.Assert.assertNull(strKafkaConsumer10);
        org.junit.Assert.assertNull(strKafkaSpoutConfig13);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet16);
    }

    @Test
    public void test7459() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7459");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        strKafkaSpout0.consumerAutoCommitMode = false;
        java.lang.String str6 = strKafkaSpout0.toString();
        boolean boolean7 = strKafkaSpout0.waitingToEmit();
        strKafkaSpout0.numUncommittedOffsets = 0L;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords10 = strKafkaSpout0.pollKafkaBroker();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str6, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertTrue("'" + boolean7 + "' != '" + false + "'", boolean7 == false);
    }

    @Test
    public void test7460() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7460");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        java.lang.String str15 = charSequenceConsumerRecord10.value();
        java.lang.String str16 = charSequenceConsumerRecord10.topic();
        int int17 = charSequenceConsumerRecord10.partition();
        org.apache.kafka.common.record.TimestampType timestampType18 = charSequenceConsumerRecord10.timestampType();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        java.util.Optional<java.lang.Integer> intOptional20 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str21 = charSequenceConsumerRecord10.topic();
        java.lang.String str22 = charSequenceConsumerRecord10.toString();
        org.apache.kafka.common.header.Headers headers23 = charSequenceConsumerRecord10.headers();
        java.util.Optional<java.lang.Integer> intOptional24 = charSequenceConsumerRecord10.leaderEpoch();
        java.lang.String str25 = charSequenceConsumerRecord10.topic();
        java.lang.CharSequence charSequence26 = charSequenceConsumerRecord10.key();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "hi!" + "'", str15, "hi!");
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "" + "'", str16, "");
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertNull(timestampType18);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(intOptional20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "" + "'", str21, "");
        org.junit.Assert.assertEquals("'" + str22 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str22, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        org.junit.Assert.assertNotNull(headers23);
        org.junit.Assert.assertNotNull(intOptional24);
        org.junit.Assert.assertEquals("'" + str25 + "' != '" + "" + "'", str25, "");
        org.junit.Assert.assertEquals("'" + charSequence26 + "' != '" + "" + "'", charSequence26, "");
    }

    @Test
    public void test7461() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7461");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer8 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy9 = strKafkaSpout0.firstPollOffsetStrategy;
        strKafkaSpout0.maxRetries = (short) 100;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(strKafkaConsumer8);
        org.junit.Assert.assertNull(firstPollOffsetStrategy9);
    }

    @Test
    public void test7462() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7462");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        strKafkaSpout0.maxRetries = 1;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        boolean boolean5 = strKafkaSpout0.waitingToEmit();
        strKafkaSpout0.maxRetries = (short) -1;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
    }

    @Test
    public void test7463() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7463");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        long long7 = charSequenceConsumerRecord5.timestamp();
        org.apache.kafka.common.header.Headers headers8 = charSequenceConsumerRecord5.headers();
        java.lang.String str9 = charSequenceConsumerRecord5.toString();
        org.apache.kafka.common.header.Headers headers10 = charSequenceConsumerRecord5.headers();
        int int11 = charSequenceConsumerRecord5.serializedKeySize();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + (-1L) + "'", long7 == (-1L));
        org.junit.Assert.assertNotNull(headers8);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str9, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers10);
        org.junit.Assert.assertTrue("'" + int11 + "' != '" + (-1) + "'", int11 == (-1));
    }

    @Test
    public void test7464() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7464");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService10 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService10;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor12 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector13 = null;
        strKafkaSpout0.collector = spoutOutputCollector13;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig15 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.kafka.clients.consumer.ConsumerRecords<java.lang.String, java.lang.CharSequence> strConsumerRecords16 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.setWaitingToEmit(strConsumerRecords16);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strConsumerRecordItor12);
        org.junit.Assert.assertNull(strKafkaSpoutConfig15);
    }

    @Test
    public void test7465() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7465");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 0, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = KafkaSpout{acked=null, emitted=null})", (int) '4', (long) 97, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = )", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)");
        long long6 = charSequenceConsumerRecord5.offset();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + 97L + "'", long6 == 97L);
    }

    @Test
    public void test7466() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7466");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.offset();
        int int14 = charSequenceConsumerRecord10.partition();
        java.lang.CharSequence charSequence15 = charSequenceConsumerRecord10.key();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        long long17 = charSequenceConsumerRecord10.offset();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + 0L + "'", long13 == 0L);
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + 10 + "'", int14 == 10);
        org.junit.Assert.assertEquals("'" + charSequence15 + "' != '" + "" + "'", charSequence15, "");
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + long17 + "' != '" + 0L + "'", long17 == 0L);
    }

    @Test
    public void test7467() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7467");
        java.lang.CharSequence charSequence3 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 10, leaderEpoch = null, offset = 10, NoTimestampType = 0, serialized key size = 0, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) '4', (long) 100, charSequence3, "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        int int6 = charSequenceConsumerRecord5.partition();
        org.junit.Assert.assertTrue("'" + int6 + "' != '" + 52 + "'", int6 == 52);
    }

    @Test
    public void test7468() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7468");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor2 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor2;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer5 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer5;
        long long7 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector8 = null;
        strKafkaSpout0.collector = spoutOutputCollector8;
        strKafkaSpout0.initialized = false;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertTrue("'" + long7 + "' != '" + 0L + "'", long7 == 0L);
    }

    @Test
    public void test7469() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7469");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        strKafkaSpout0.numUncommittedOffsets = '#';
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = strKafkaSpout0.retryService;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor7 = strKafkaSpout0.waitingToEmit;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer8 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig9 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig9;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer11 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer11);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(kafkaSpoutRetryService6);
        org.junit.Assert.assertNull(strConsumerRecordItor7);
        org.junit.Assert.assertNull(timer8);
    }

    @Test
    public void test7470() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7470");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams1 = strKafkaSpout0.kafkaSpoutStreams;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.kafka.spout.KafkaSpoutStreams kafkaSpoutStreams4 = strKafkaSpout0.kafkaSpoutStreams;
        boolean boolean5 = strKafkaSpout0.waitingToEmit();
        long long6 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder7 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder7;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig9 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig9;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder11 = strKafkaSpout0.tuplesBuilder;
        org.junit.Assert.assertNull(kafkaSpoutStreams1);
        org.junit.Assert.assertNull(kafkaSpoutStreams4);
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + 0L + "'", long6 == 0L);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder11);
    }

    @Test
    public void test7471() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7471");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 10, 0L, (java.lang.CharSequence) "", "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
        long long6 = charSequenceConsumerRecord5.checksum();
        java.lang.String str7 = charSequenceConsumerRecord5.value();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertEquals("'" + str7 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})" + "'", str7, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 100, serialized value size = 1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null})");
    }

    @Test
    public void test7472() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7472");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        strKafkaSpout0.maxRetries = 1;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        boolean boolean5 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService6;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
    }

    @Test
    public void test7473() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7473");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        java.lang.String str8 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer9 = strKafkaSpout0.commitTimer;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder10 = strKafkaSpout0.tuplesBuilder;
        boolean boolean11 = strKafkaSpout0.consumerAutoCommitMode;
        boolean boolean12 = strKafkaSpout0.waitingToEmit();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor13 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.initialized = false;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean16 = strKafkaSpout0.poll();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str8, "KafkaSpout{acked=null, emitted=null}");
        org.junit.Assert.assertNull(timer9);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder10);
        org.junit.Assert.assertTrue("'" + boolean11 + "' != '" + false + "'", boolean11 == false);
        org.junit.Assert.assertTrue("'" + boolean12 + "' != '" + false + "'", boolean12 == false);
        org.junit.Assert.assertNull(strConsumerRecordItor13);
    }

    @Test
    public void test7474() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7474");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService1 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService1;
        long long3 = strKafkaSpout0.numUncommittedOffsets;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = strKafkaSpout0.waitingToEmit;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.apache.storm.topology.OutputFieldsDeclarer outputFieldsDeclarer7 = null;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.declareOutputFields(outputFieldsDeclarer7);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long3 + "' != '" + 0L + "'", long3 == 0L);
        org.junit.Assert.assertNull(strConsumerRecordItor4);
    }

    @Test
    public void test7475() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7475");
        org.apache.storm.kafka.spout.KafkaSpout<java.util.HashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> kafkaSpoutMessageIdSetKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.util.HashSet<org.apache.storm.kafka.spout.KafkaSpoutMessageId>, java.util.ArrayList<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>();
    }

    @Test
    public void test7476() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7476");
        org.apache.storm.kafka.spout.KafkaSpout kafkaSpout0 = null;
        java.util.concurrent.TimeUnit timeUnit3 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<java.util.RandomAccess, java.lang.reflect.AnnotatedElement>.Timer timer4 = kafkaSpout0.new Timer((long) (byte) 10, 52L, timeUnit3);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: reflection call to org.apache.storm.kafka.spout.KafkaSpout$Timer with null for superclass argument");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test7477() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7477");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator1 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator1;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator3 = offsetComparator1.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator8 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator8;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator8);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator11 = kafkaSpoutMessageIdComparator3.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator8);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator12 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator12;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = offsetComparator12.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator12.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = offsetComparator8.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator17 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator16);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator18 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator20 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator21 = offsetComparator20.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator22 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator22;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator24 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator25 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator25;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = offsetComparator25.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = offsetComparator24.thenComparing(kafkaSpoutMessageIdComparator27);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator29 = offsetComparator22.thenComparing(kafkaSpoutMessageIdComparator28);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator30 = offsetComparator22.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator31 = offsetComparator22.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator32 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator33 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator33;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator35 = offsetComparator33.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator40 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator40;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord42 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator40);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator43 = kafkaSpoutMessageIdComparator35.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator40);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = offsetComparator32.thenComparing(kafkaSpoutMessageIdComparator43);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator43;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator46 = kafkaSpoutMessageIdComparator31.thenComparing(kafkaSpoutMessageIdComparator43);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator47 = offsetComparator20.thenComparing(kafkaSpoutMessageIdComparator46);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator48 = kafkaSpoutMessageIdComparator47.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator49 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator50 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator51 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator51;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator53 = offsetComparator51.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator54 = offsetComparator50.thenComparing(kafkaSpoutMessageIdComparator53);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator55 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator55;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator57 = offsetComparator55.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator58 = offsetComparator55.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator59 = kafkaSpoutMessageIdComparator53.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator55);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator60 = offsetComparator49.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator55);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator61 = kafkaSpoutMessageIdComparator48.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator55);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator61;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator63 = kafkaSpoutMessageIdComparator61.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator61;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator65 = kafkaSpoutMessageIdComparator61.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator66 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator65);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator3);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator11);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator17);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator18);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator21);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator29);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator30);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator31);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator35);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator43);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator46);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator47);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator48);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator53);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator54);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator57);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator58);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator59);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator60);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator61);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator63);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator65);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator66);
    }

    @Test
    public void test7478() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7478");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (short) 0;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor3 = strKafkaSpout0.waitingToEmit;
        boolean boolean4 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector5 = null;
        strKafkaSpout0.collector = spoutOutputCollector5;
        strKafkaSpout0.consumerAutoCommitMode = false;
        org.junit.Assert.assertNull(strConsumerRecordItor3);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
    }

    @Test
    public void test7479() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7479");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor1 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor1;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer3 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer3;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer6 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector7 = strKafkaSpout0.collector;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig8 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder9 = strKafkaSpout0.tuplesBuilder;
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet10 = strKafkaSpout0.emitted;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.subscribeKafkaConsumer();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaConsumer6);
        org.junit.Assert.assertNull(spoutOutputCollector7);
        org.junit.Assert.assertNull(strKafkaSpoutConfig8);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder9);
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet10);
    }

    @Test
    public void test7480() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7480");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer8 = strKafkaSpout0.kafkaConsumer;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig9 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder10 = null;
        strKafkaSpout0.tuplesBuilder = strKafkaSpoutTuplesBuilder10;
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNull(strKafkaConsumer8);
        org.junit.Assert.assertNull(strKafkaSpoutConfig9);
    }

    @Test
    public void test7481() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7481");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord9 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long10 = charSequenceConsumerRecord9.checksum();
        long long11 = charSequenceConsumerRecord9.timestamp();
        org.apache.kafka.common.header.Headers headers12 = charSequenceConsumerRecord9.headers();
        java.lang.String str13 = charSequenceConsumerRecord9.toString();
        org.apache.kafka.common.header.Headers headers14 = charSequenceConsumerRecord9.headers();
        java.lang.String str15 = charSequenceConsumerRecord9.topic();
        long long16 = charSequenceConsumerRecord9.timestamp();
        org.apache.kafka.common.record.TimestampType timestampType17 = charSequenceConsumerRecord9.timestampType();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord23 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (byte) 1, (long) 100, timestampType17, (long) 1, 35, (int) (byte) 10, (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), partition = 1, leaderEpoch = null, offset = 1, null = 10, serialized key size = 100, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = )", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        int int24 = charSequenceConsumerRecord23.serializedKeySize();
        long long25 = charSequenceConsumerRecord23.checksum();
        java.util.Optional<java.lang.Integer> intOptional26 = charSequenceConsumerRecord23.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long10 + "' != '" + (-1L) + "'", long10 == (-1L));
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str13, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertNotNull(headers14);
        org.junit.Assert.assertEquals("'" + str15 + "' != '" + "" + "'", str15, "");
        org.junit.Assert.assertTrue("'" + long16 + "' != '" + (-1L) + "'", long16 == (-1L));
        org.junit.Assert.assertTrue("'" + timestampType17 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType17.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + 35 + "'", int24 == 35);
        org.junit.Assert.assertTrue("'" + long25 + "' != '" + 1L + "'", long25 == 1L);
        org.junit.Assert.assertNotNull(intOptional26);
    }

    @Test
    public void test7482() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7482");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator1 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId2 = null;
        org.apache.storm.kafka.spout.KafkaSpoutMessageId kafkaSpoutMessageId3 = null;
        // The following exception was thrown during execution in test generation
        try {
            int int4 = offsetComparator0.compare(kafkaSpoutMessageId2, kafkaSpoutMessageId3);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator1);
    }

    @Test
    public void test7483() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7483");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService1 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService1;
        long long3 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer4 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer4;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor8 = strKafkaSpout0.waitingToEmit;
        org.junit.Assert.assertTrue("'" + long3 + "' != '" + 0L + "'", long3 == 0L);
        org.junit.Assert.assertNull(strConsumerRecordItor8);
    }

    @Test
    public void test7484() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7484");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator2 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator4 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator4;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator6 = offsetComparator4.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator7 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator6);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator8 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator10 = offsetComparator0.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator0;
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator2);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator6);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator7);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator8);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator10);
    }

    @Test
    public void test7485() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7485");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str6 = charSequenceConsumerRecord5.topic();
        java.util.Optional<java.lang.Integer> intOptional7 = charSequenceConsumerRecord5.leaderEpoch();
        int int8 = charSequenceConsumerRecord5.partition();
        java.lang.String str9 = charSequenceConsumerRecord5.toString();
        java.lang.String str10 = charSequenceConsumerRecord5.toString();
        java.lang.String str11 = charSequenceConsumerRecord5.topic();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "" + "'", str6, "");
        org.junit.Assert.assertNotNull(intOptional7);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 100 + "'", int8 == 100);
        org.junit.Assert.assertEquals("'" + str9 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str9, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertEquals("'" + str10 + "' != '" + "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str10, "ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
    }

    @Test
    public void test7486() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7486");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", (int) (short) 1, 1L, (long) (byte) 10, timestampType4, (long) '#', (int) (byte) 100, (int) (short) -1, (java.lang.CharSequence) "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", "");
        java.lang.String str11 = charSequenceConsumerRecord10.value();
        int int12 = charSequenceConsumerRecord10.serializedValueSize();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        int int14 = charSequenceConsumerRecord10.serializedValueSize();
        int int15 = charSequenceConsumerRecord10.serializedValueSize();
        org.junit.Assert.assertEquals("'" + str11 + "' != '" + "" + "'", str11, "");
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + (-1) + "'", int12 == (-1));
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "" + "'", str13, "");
        org.junit.Assert.assertTrue("'" + int14 + "' != '" + (-1) + "'", int14 == (-1));
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + (-1) + "'", int15 == (-1));
    }

    @Test
    public void test7487() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7487");
        org.apache.storm.kafka.spout.KafkaSpoutConfig<org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator, java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> offsetComparatorKafkaSpoutConfig0 = null;
        // The following exception was thrown during execution in test generation
        try {
            org.apache.storm.kafka.spout.KafkaSpout<org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator, java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>> offsetComparatorKafkaSpout1 = new org.apache.storm.kafka.spout.KafkaSpout<org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator, java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>>(offsetComparatorKafkaSpoutConfig0);
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
    }

    @Test
    public void test7488() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7488");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 52, (long) (byte) 0, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = KafkaSpout{acked=null, emitted=[]}, partition = -1, leaderEpoch = null, offset = 52, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = hi!)");
        java.lang.String str6 = charSequenceConsumerRecord5.topic();
        int int7 = charSequenceConsumerRecord5.partition();
        java.lang.String str8 = charSequenceConsumerRecord5.topic();
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str6, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 52 + "'", int7 == 52);
        org.junit.Assert.assertEquals("'" + str8 + "' != '" + "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))" + "'", str8, "ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))");
    }

    @Test
    public void test7489() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7489");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = 97, leaderEpoch = null, offset = 1, null = 0, serialized key size = 1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", (int) (short) 100, (long) 0, (java.lang.CharSequence) "hi!", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        long long6 = charSequenceConsumerRecord5.checksum();
        int int7 = charSequenceConsumerRecord5.partition();
        int int8 = charSequenceConsumerRecord5.partition();
        long long9 = charSequenceConsumerRecord5.offset();
        org.junit.Assert.assertTrue("'" + long6 + "' != '" + (-1L) + "'", long6 == (-1L));
        org.junit.Assert.assertTrue("'" + int7 + "' != '" + 100 + "'", int7 == 100);
        org.junit.Assert.assertTrue("'" + int8 + "' != '" + 100 + "'", int8 == 100);
        org.junit.Assert.assertTrue("'" + long9 + "' != '" + 0L + "'", long9 == 0L);
    }

    @Test
    public void test7490() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7490");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.partition();
        java.lang.String str16 = charSequenceConsumerRecord10.value();
        java.util.Optional<java.lang.Integer> intOptional17 = charSequenceConsumerRecord10.leaderEpoch();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
        org.junit.Assert.assertEquals("'" + str16 + "' != '" + "hi!" + "'", str16, "hi!");
        org.junit.Assert.assertNotNull(intOptional17);
    }

    @Test
    public void test7491() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7491");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        strKafkaSpout0.maxRetries = (short) 0;
        boolean boolean5 = strKafkaSpout0.consumerAutoCommitMode;
        java.lang.String str6 = strKafkaSpout0.toString();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService7 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService7;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.doSeekRetriableTopicPartitions();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertEquals("'" + str6 + "' != '" + "KafkaSpout{acked=null, emitted=null}" + "'", str6, "KafkaSpout{acked=null, emitted=null}");
    }

    @Test
    public void test7492() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7492");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord13 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 100, (long) (byte) 10, (java.lang.CharSequence) "", "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
        java.lang.String str14 = charSequenceConsumerRecord13.topic();
        org.apache.kafka.common.record.TimestampType timestampType15 = charSequenceConsumerRecord13.timestampType();
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout19 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout19.maxRetries = (byte) -1;
        int int22 = strKafkaSpout19.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor23 = null;
        strKafkaSpout19.waitingToEmit = strConsumerRecordItor23;
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer25 = strKafkaSpout19.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer26 = strKafkaSpout19.kafkaConsumer;
        org.apache.kafka.common.record.TimestampType timestampType32 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord38 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType32, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long39 = charSequenceConsumerRecord38.offset();
        long long40 = charSequenceConsumerRecord38.checksum();
        int int41 = charSequenceConsumerRecord38.serializedKeySize();
        org.apache.kafka.common.header.Headers headers42 = charSequenceConsumerRecord38.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence> iRichSpoutConsumerRecord43 = new org.apache.kafka.clients.consumer.ConsumerRecord<org.apache.storm.topology.IRichSpout, java.lang.CharSequence>("", (int) (short) 100, (long) (byte) 1, 0L, timestampType15, (java.lang.Long) 35L, (int) (short) -1, 0, (org.apache.storm.topology.IRichSpout) strKafkaSpout19, (java.lang.CharSequence) "hi!", headers42);
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord49 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (short) 1, 0L, (long) (byte) 0, timestampType15, (long) ' ', (int) (short) -1, (int) (byte) 10, (java.lang.CharSequence) "", "");
        long long50 = charSequenceConsumerRecord49.checksum();
        long long51 = charSequenceConsumerRecord49.checksum();
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + timestampType15 + "' != '" + org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE + "'", timestampType15.equals(org.apache.kafka.common.record.TimestampType.NO_TIMESTAMP_TYPE));
        org.junit.Assert.assertTrue("'" + int22 + "' != '" + (-1) + "'", int22 == (-1));
        org.junit.Assert.assertNull(timer25);
        org.junit.Assert.assertNull(strKafkaConsumer26);
        org.junit.Assert.assertTrue("'" + long39 + "' != '" + 0L + "'", long39 == 0L);
        org.junit.Assert.assertTrue("'" + long40 + "' != '" + (-1L) + "'", long40 == (-1L));
        org.junit.Assert.assertTrue("'" + int41 + "' != '" + 52 + "'", int41 == 52);
        org.junit.Assert.assertNotNull(headers42);
        org.junit.Assert.assertTrue("'" + long50 + "' != '" + 32L + "'", long50 == 32L);
        org.junit.Assert.assertTrue("'" + long51 + "' != '" + 32L + "'", long51 == 32L);
    }

    @Test
    public void test7493() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7493");
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord5 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("hi!", 52, (long) '4', (java.lang.CharSequence) "ConsumerRecord(topic = ConsumerRecord(topic = KafkaSpout{acked=null, emitted=null}, partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = 10, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = hi!, value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=[]})", "ConsumerRecord(topic = , partition = 52, leaderEpoch = null, offset = 0, NoTimestampType = -1, serialized key size = -1, serialized value size = 0, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test7494() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7494");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        boolean boolean1 = strKafkaSpout0.waitingToEmit();
        strKafkaSpout0.maxRetries = 1;
        boolean boolean4 = strKafkaSpout0.consumerAutoCommitMode;
        boolean boolean5 = strKafkaSpout0.waitingToEmit();
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService6 = null;
        strKafkaSpout0.retryService = kafkaSpoutRetryService6;
        strKafkaSpout0.numUncommittedOffsets = (-1L);
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor10 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor10;
        int int12 = strKafkaSpout0.maxRetries;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig13 = strKafkaSpout0.kafkaSpoutConfig;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector14 = strKafkaSpout0.collector;
        // The following exception was thrown during execution in test generation
        try {
            strKafkaSpout0.nextTuple();
// flaky:             org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + boolean1 + "' != '" + false + "'", boolean1 == false);
        org.junit.Assert.assertTrue("'" + boolean4 + "' != '" + false + "'", boolean4 == false);
        org.junit.Assert.assertTrue("'" + boolean5 + "' != '" + false + "'", boolean5 == false);
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 1 + "'", int12 == 1);
        org.junit.Assert.assertNull(strKafkaSpoutConfig13);
        org.junit.Assert.assertNull(spoutOutputCollector14);
    }

    @Test
    public void test7495() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7495");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        java.util.Set<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdSet1 = strKafkaSpout0.emitted;
        org.apache.storm.kafka.spout.KafkaSpoutConfig<java.lang.String, java.lang.CharSequence> strKafkaSpoutConfig2 = null;
        strKafkaSpout0.kafkaSpoutConfig = strKafkaSpoutConfig2;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector4 = strKafkaSpout0.collector;
        long long5 = strKafkaSpout0.numUncommittedOffsets;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector6 = null;
        strKafkaSpout0.collector = spoutOutputCollector6;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder8 = strKafkaSpout0.tuplesBuilder;
        strKafkaSpout0.consumerAutoCommitMode = true;
        org.apache.storm.kafka.spout.KafkaSpoutConfig.FirstPollOffsetStrategy firstPollOffsetStrategy11 = strKafkaSpout0.firstPollOffsetStrategy;
        org.apache.storm.kafka.spout.KafkaSpoutTuplesBuilder<java.lang.String, java.lang.CharSequence> strKafkaSpoutTuplesBuilder12 = strKafkaSpout0.tuplesBuilder;
        org.apache.storm.spout.SpoutOutputCollector spoutOutputCollector13 = null;
        strKafkaSpout0.collector = spoutOutputCollector13;
        org.junit.Assert.assertNull(kafkaSpoutMessageIdSet1);
        org.junit.Assert.assertNull(spoutOutputCollector4);
        org.junit.Assert.assertTrue("'" + long5 + "' != '" + 0L + "'", long5 == 0L);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder8);
        org.junit.Assert.assertNull(firstPollOffsetStrategy11);
        org.junit.Assert.assertNull(strKafkaSpoutTuplesBuilder12);
    }

    @Test
    public void test7496() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7496");
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator0 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator1 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator2 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator2;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator4 = offsetComparator2.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator9 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator9;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord11 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator9);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator12 = kafkaSpoutMessageIdComparator4.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator9);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator13 = offsetComparator1.thenComparing(kafkaSpoutMessageIdComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator14 = kafkaSpoutMessageIdComparator12.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator15 = offsetComparator0.thenComparing(kafkaSpoutMessageIdComparator12);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator16 = kafkaSpoutMessageIdComparator12.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator17 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator17;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator19 = offsetComparator17.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator24 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator24;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord26 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator24);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator27 = kafkaSpoutMessageIdComparator19.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator24);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator28 = kafkaSpoutMessageIdComparator19.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator29 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator30 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator30;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator32 = offsetComparator30.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator37 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator37;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord39 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator37);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator40 = kafkaSpoutMessageIdComparator32.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator37);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator41 = offsetComparator29.thenComparing(kafkaSpoutMessageIdComparator40);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator42 = kafkaSpoutMessageIdComparator28.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator29);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator42;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator44 = kafkaSpoutMessageIdComparator12.thenComparing(kafkaSpoutMessageIdComparator42);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator45 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator45;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator47 = offsetComparator45.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator45;
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator49 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator49;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator51 = offsetComparator49.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator52 = offsetComparator45.thenComparing(kafkaSpoutMessageIdComparator51);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator53 = offsetComparator45.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator54 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator55 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator55;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator57 = offsetComparator55.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator58 = offsetComparator54.thenComparing(kafkaSpoutMessageIdComparator57);
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator59 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator59;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator61 = offsetComparator59.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator66 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator66;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord68 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator66);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator69 = kafkaSpoutMessageIdComparator61.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator66);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator70 = offsetComparator54.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator66);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator71 = offsetComparator66.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator72 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator72;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator74 = offsetComparator72.reversed();
        org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator offsetComparator79 = new org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator();
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = offsetComparator79;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator> strConsumerRecord81 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, org.apache.storm.kafka.spout.KafkaSpout.OffsetComparator>("KafkaSpout{acked=null, emitted=null}", (int) 'a', (long) 0, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)", offsetComparator79);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator82 = kafkaSpoutMessageIdComparator74.thenComparing((java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId>) offsetComparator79);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator83 = offsetComparator79.reversed();
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator84 = kafkaSpoutMessageIdComparator71.thenComparing(kafkaSpoutMessageIdComparator83);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator85 = kafkaSpoutMessageIdComparator53.thenComparing(kafkaSpoutMessageIdComparator71);
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator86 = kafkaSpoutMessageIdComparator42.thenComparing(kafkaSpoutMessageIdComparator53);
        org.apache.storm.kafka.spout.KafkaSpout.OFFSET_COMPARATOR = kafkaSpoutMessageIdComparator53;
        java.util.Comparator<org.apache.storm.kafka.spout.KafkaSpoutMessageId> kafkaSpoutMessageIdComparator88 = kafkaSpoutMessageIdComparator53.reversed();
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator4);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator12);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator13);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator14);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator15);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator16);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator19);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator27);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator28);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator32);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator40);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator41);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator42);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator44);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator47);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator51);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator52);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator53);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator57);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator58);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator61);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator69);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator70);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator71);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator74);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator82);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator83);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator84);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator85);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator86);
        org.junit.Assert.assertNotNull(kafkaSpoutMessageIdComparator88);
    }

    @Test
    public void test7497() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7497");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.timestamp();
        org.apache.kafka.common.header.Headers headers12 = charSequenceConsumerRecord10.headers();
        java.lang.String str13 = charSequenceConsumerRecord10.value();
        java.lang.String str14 = charSequenceConsumerRecord10.topic();
        int int15 = charSequenceConsumerRecord10.partition();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertNotNull(headers12);
        org.junit.Assert.assertEquals("'" + str13 + "' != '" + "hi!" + "'", str13, "hi!");
        org.junit.Assert.assertEquals("'" + str14 + "' != '" + "" + "'", str14, "");
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 10 + "'", int15 == 10);
    }

    @Test
    public void test7498() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7498");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord10 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType4, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long11 = charSequenceConsumerRecord10.checksum();
        int int12 = charSequenceConsumerRecord10.partition();
        long long13 = charSequenceConsumerRecord10.timestamp();
        long long14 = charSequenceConsumerRecord10.offset();
        int int15 = charSequenceConsumerRecord10.serializedKeySize();
        org.apache.kafka.common.record.TimestampType timestampType16 = charSequenceConsumerRecord10.timestampType();
        int int17 = charSequenceConsumerRecord10.partition();
        long long18 = charSequenceConsumerRecord10.offset();
        int int19 = charSequenceConsumerRecord10.serializedValueSize();
        org.apache.kafka.common.header.Headers headers20 = charSequenceConsumerRecord10.headers();
        java.lang.String str21 = charSequenceConsumerRecord10.toString();
        org.junit.Assert.assertTrue("'" + long11 + "' != '" + (-1L) + "'", long11 == (-1L));
        org.junit.Assert.assertTrue("'" + int12 + "' != '" + 10 + "'", int12 == 10);
        org.junit.Assert.assertTrue("'" + long13 + "' != '" + (-1L) + "'", long13 == (-1L));
        org.junit.Assert.assertTrue("'" + long14 + "' != '" + 0L + "'", long14 == 0L);
        org.junit.Assert.assertTrue("'" + int15 + "' != '" + 52 + "'", int15 == 52);
        org.junit.Assert.assertNull(timestampType16);
        org.junit.Assert.assertTrue("'" + int17 + "' != '" + 10 + "'", int17 == 10);
        org.junit.Assert.assertTrue("'" + long18 + "' != '" + 0L + "'", long18 == 0L);
        org.junit.Assert.assertTrue("'" + int19 + "' != '" + (-1) + "'", int19 == (-1));
        org.junit.Assert.assertNotNull(headers20);
        org.junit.Assert.assertEquals("'" + str21 + "' != '" + "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)" + "'", str21, "ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)");
    }

    @Test
    public void test7499() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7499");
        org.apache.kafka.common.record.TimestampType timestampType4 = null;
        org.apache.kafka.common.record.TimestampType timestampType14 = null;
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord20 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("", (int) (byte) 10, (long) (short) 0, (long) (short) -1, timestampType14, (-1L), (int) '4', (int) (short) -1, (java.lang.CharSequence) "", "hi!");
        long long21 = charSequenceConsumerRecord20.timestamp();
        java.lang.CharSequence charSequence22 = charSequenceConsumerRecord20.key();
        java.lang.String str23 = charSequenceConsumerRecord20.topic();
        int int24 = charSequenceConsumerRecord20.partition();
        java.lang.CharSequence charSequence25 = charSequenceConsumerRecord20.key();
        int int26 = charSequenceConsumerRecord20.partition();
        org.apache.kafka.common.header.Headers headers27 = charSequenceConsumerRecord20.headers();
        org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String> charSequenceConsumerRecord28 = new org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.CharSequence, java.lang.String>("ConsumerRecord(topic = hi!, partition = -1, leaderEpoch = null, offset = 32, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", 0, 35L, (long) (-1), timestampType4, (java.lang.Long) 52L, (int) (byte) 0, (int) (byte) -1, (java.lang.CharSequence) "ConsumerRecord(topic = hi!, partition = 100, leaderEpoch = null, offset = 100, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 100, leaderEpoch = null, offset = 10, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!)), value = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!))", "ConsumerRecord(topic = ConsumerRecord(topic = hi!, partition = 1, leaderEpoch = null, offset = 52, null = 35, serialized key size = -1, serialized value size = 10, headers = RecordHeaders(headers = [], isReadOnly = false), key = ConsumerRecord(topic = , partition = 10, leaderEpoch = null, offset = 0, null = -1, serialized key size = 52, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = , value = hi!), value = KafkaSpout{acked=null, emitted=null}), partition = 0, leaderEpoch = null, offset = 97, NoTimestampType = -1, serialized key size = -1, serialized value size = -1, headers = RecordHeaders(headers = [], isReadOnly = false), key = null, value = )", headers27);
        org.junit.Assert.assertTrue("'" + long21 + "' != '" + (-1L) + "'", long21 == (-1L));
        org.junit.Assert.assertEquals("'" + charSequence22 + "' != '" + "" + "'", charSequence22, "");
        org.junit.Assert.assertEquals("'" + str23 + "' != '" + "" + "'", str23, "");
        org.junit.Assert.assertTrue("'" + int24 + "' != '" + 10 + "'", int24 == 10);
        org.junit.Assert.assertEquals("'" + charSequence25 + "' != '" + "" + "'", charSequence25, "");
        org.junit.Assert.assertTrue("'" + int26 + "' != '" + 10 + "'", int26 == 10);
        org.junit.Assert.assertNotNull(headers27);
    }

    @Test
    public void test7500() throws Throwable {
        if (debug)
            System.out.format("%n%s%n", "RegressionTest14.test7500");
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence> strKafkaSpout0 = new org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>();
        strKafkaSpout0.maxRetries = (byte) -1;
        int int3 = strKafkaSpout0.maxRetries;
        java.util.Iterator<org.apache.kafka.clients.consumer.ConsumerRecord<java.lang.String, java.lang.CharSequence>> strConsumerRecordItor4 = null;
        strKafkaSpout0.waitingToEmit = strConsumerRecordItor4;
        org.apache.kafka.common.TopicPartition topicPartition6 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection7 = strKafkaSpout0.toArrayList(topicPartition6);
        org.apache.storm.kafka.spout.KafkaSpoutRetryService kafkaSpoutRetryService8 = strKafkaSpout0.retryService;
        org.apache.kafka.common.TopicPartition topicPartition9 = null;
        java.util.Collection<org.apache.kafka.common.TopicPartition> topicPartitionCollection10 = strKafkaSpout0.toArrayList(topicPartition9);
        org.apache.storm.kafka.spout.KafkaSpout<java.lang.String, java.lang.CharSequence>.Timer timer11 = strKafkaSpout0.commitTimer;
        org.apache.kafka.clients.consumer.KafkaConsumer<java.lang.String, java.lang.CharSequence> strKafkaConsumer12 = null;
        strKafkaSpout0.kafkaConsumer = strKafkaConsumer12;
        // The following exception was thrown during execution in test generation
        try {
            boolean boolean14 = strKafkaSpout0.poll();
            org.junit.Assert.fail("Expected exception of type java.lang.NullPointerException; message: null");
        } catch (java.lang.NullPointerException e) {
        // Expected exception.
        }
        org.junit.Assert.assertTrue("'" + int3 + "' != '" + (-1) + "'", int3 == (-1));
        org.junit.Assert.assertNotNull(topicPartitionCollection7);
        org.junit.Assert.assertNull(kafkaSpoutRetryService8);
        org.junit.Assert.assertNotNull(topicPartitionCollection10);
        org.junit.Assert.assertNull(timer11);
    }
}
